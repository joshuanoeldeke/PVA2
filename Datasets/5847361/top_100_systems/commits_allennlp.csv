commit_index,author_name,author_email,date,commit_hash,commit_link,commit_message,files_changed,are_we_interested,has_test_file,unittest_in_code,unittest_in_added_diffs,unittest_in_removed_diffs,pytest_in_code,pytest_in_added_diffs,pytest_in_removed_diffs,Mig: assert,Mig: fixture,Mig: import,Mig: skip,Mig: failure,Mig: testcase,Mig: add Param,tags,u_added_count_testcase_subclass,u_added_count_self_assert,u_added_count_setup,u_added_count_setupClass,u_added_count_teardown,u_added_count_teardownClass,u_added_count_unittest_skip,u_added_count_unittest_self_skip,u_added_count_unittest_expected_failure,u_added_count_unittest_mock_pattern,u_added_count_import_unittest,u_removed_count_testcase_subclass,u_removed_count_self_assert,u_removed_count_setup,u_removed_count_setupClass,u_removed_count_teardown,u_removed_count_teardownClass,u_removed_count_unittest_skip,u_removed_count_unittest_self_skip,u_removed_count_unittest_expected_failure,u_removed_count_unittest_mock_pattern,u_removed_count_import_unittest,p_added_count_native_assert,p_added_count_pytest_raises,p_added_count_simple_skip,p_added_count_mark_skip,p_added_count_pytest_expected_failure,p_added_count_fixture,p_added_count_usefixtures,p_added_count_parametrize,p_added_count_generic_mark,p_added_count_generic_pytest,p_added_count_monkeypatch,p_added_count_pytest_mock,p_added_count_import_pytest,p_removed_count_native_assert,p_removed_count_pytest_raises,p_removed_count_simple_skip,p_removed_count_mark_skip,p_removed_count_pytest_expected_failure,p_removed_count_fixture,p_removed_count_usefixtures,p_removed_count_parametrize,p_removed_count_generic_mark,p_removed_count_generic_pytest,p_removed_count_monkeypatch,p_removed_count_pytest_mock,p_removed_count_import_pytest,u_added_matches_testcase_subclass,u_added_matches_self_assert,u_added_matches_setup,u_added_matches_setupClass,u_added_matches_teardown,u_added_matches_teardownClass,u_added_matches_unittest_skip,u_added_matches_unittest_self_skip,u_added_matches_unittest_expected_failure,u_added_matches_unittest_mock_pattern,u_added_matches_import_unittest,u_removed_matches_testcase_subclass,u_removed_matches_self_assert,u_removed_matches_setup,u_removed_matches_setupClass,u_removed_matches_teardown,u_removed_matches_teardownClass,u_removed_matches_unittest_skip,u_removed_matches_unittest_self_skip,u_removed_matches_unittest_expected_failure,u_removed_matches_unittest_mock_pattern,u_removed_matches_import_unittest,p_added_matches_native_assert,p_added_matches_pytest_raises,p_added_matches_simple_skip,p_added_matches_mark_skip,p_added_matches_pytest_expected_failure,p_added_matches_fixture,p_added_matches_usefixtures,p_added_matches_parametrize,p_added_matches_generic_mark,p_added_matches_generic_pytest,p_added_matches_monkeypatch,p_added_matches_pytest_mock,p_added_matches_import_pytest,p_removed_matches_native_assert,p_removed_matches_pytest_raises,p_removed_matches_simple_skip,p_removed_matches_mark_skip,p_removed_matches_pytest_expected_failure,p_removed_matches_fixture,p_removed_matches_usefixtures,p_removed_matches_parametrize,p_removed_matches_generic_mark,p_removed_matches_generic_pytest,p_removed_matches_monkeypatch,p_removed_matches_pytest_mock,p_removed_matches_import_pytest
0,Michael Schmitz,michael@schmitztech.com,2017-05-15 08:52:42-07:00,f7473cd21e218307a958be83662cb7df8c415d2e,https://github.com/allenai/allennlp/commit/f7473cd21e218307a958be83662cb7df8c415d2e,Initial commit,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1,Michael Schmitz,michael@schmitztech.com,2017-05-15 08:54:36-07:00,1ff44dabf12b1893fcbb51d15ba93201a59aca1b,https://github.com/allenai/allennlp/commit/1ff44dabf12b1893fcbb51d15ba93201a59aca1b,Create README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2,Mark Neumann,markn@allenai.org,2017-06-23 16:48:34-07:00,51c26a933996e9415d4c5e059c196b2ca2e46db0,https://github.com/allenai/allennlp/commit/51c26a933996e9415d4c5e059c196b2ca2e46db0,initial commit with data api and minimal docker file + instructions,74,False,True,True,True,False,True,True,False,False,False,False,False,False,False,False,[],1,0,8,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,151,6,0,2,0,0,0,0,2,2,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,['class DeepQaTestCase(TestCase):'],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['util.group_by_count([1, 2, 3, 4, 5, 6, 7], 3, 20) == [[1, 2, 3], [4, 5, 6], [7, 20, 20]]', 'generator.last_num_batches == 4', 'self.as_list(one_epoch_arrays[0][0]) == [1, 0, 4]', 'self.as_list(one_epoch_arrays[1][0]) == [3]', 'self.as_list(one_epoch_arrays[2][0]) == [6, 7, 2]', 'self.as_list(one_epoch_arrays[3][0]) == [8, 9, 5]', 'generator.last_num_batches == 4', 'first_epoch == second_epoch', 'self.as_list(biggest_batches[0][0]) == [3]', 'self.as_list(biggest_batches[1][0]) == [1, 0, 4]', 'generator.last_num_batches == 4', 'self.as_list(one_epoch_arrays[0][0]) == [0, 4]', 'self.as_list(one_epoch_arrays[1][0]) == [3]', 'self.as_list(one_epoch_arrays[2][0]) == [7, 2, 1]', 'self.as_list(one_epoch_arrays[3][0]) == [8, 9, 5, 6]', 'generator.last_num_batches == 4', 'first_epoch != second_epoch', 'generator.last_num_batches == 7', 'self.as_list(one_epoch_arrays[0][0]) == [0]', 'self.as_list(one_epoch_arrays[1][0]) == [2, 1]', 'self.as_list(one_epoch_arrays[2][0]) == [3]', 'self.as_list(one_epoch_arrays[3][0]) == [4]', 'self.as_list(one_epoch_arrays[4][0]) == [5, 6]', 'self.as_list(one_epoch_arrays[5][0]) == [7]', 'self.as_list(one_epoch_arrays[6][0]) == [8, 9]', 'instances[0].fields()[]', 'instances[1].fields()[]', 'instances[2].fields()[]', 'len(dataset.instances) == 3', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'padding_lengths == {: 6}}', 'embedding_layer.output_dim == 3', 'embedding_layer.output_dim == 4', 'not numpy.allclose(word_vector[:2], numpy.asarray([0.1, 0.4]))', 'numpy.allclose(word_vector, numpy.asarray([1.0, 2.3, -1.0]))', 'not numpy.allclose(word_vector, numpy.asarray([0.0, 0.0, 0.0]))', 'lengths == {: 5}', 'counter[] == 1', 'counter[] == 1', 'counter[] == 3', 'set(counter.keys()) == {}', 'tag_field._indexed_tags == [b_index, i_index, o_index, o_index, o_index]', 'tag_field._num_tags == 3', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'list(namespace_token_counts.keys()) == []', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 2', 'namespace_token_counts[] == 3', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 3', 'namespace_token_counts[] == 2', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'list(namespace_token_counts.keys()) == []', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 2', 'namespace_token_counts[] == 3', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 3', 'namespace_token_counts[] == 2', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 1', 'set(namespace_token_counts.keys()) == {}', 'field._indexed_tokens == [[capital_a_index, sentence_index]]', 'field1._indexed_tokens == [[[capital_a_char_index],', 'field2._indexed_tokens == [[capital_a_index, sentence_index],', 'padding_lengths == {: 5}', 'padding_lengths == {: 8}', 'padding_lengths == {: 8}', 'counter[: 2}', 'counter[: 2}', 'padded_tokens == [[1, 2, 3, 4, 5, 0, 0, 0, 0, 0],', 'indices == [3, 4, 5, 6, 4, 5, 6, 1, 1, 1]', 'counter[: 1}', 'counter[: 2}', 'padded_tokens == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'in vocab.tokens_in_namespace()', 'not in vocab.tokens_in_namespace()', 'not in vocab.tokens_in_namespace()', 'in vocab.tokens_in_namespace()', 'in vocab.tokens_in_namespace()', 'in vocab.tokens_in_namespace()', 'in vocab.tokens_in_namespace()', 'vocab.get_token_index() == word_index', 'vocab.get_token_from_index(word_index) == ', 'vocab.get_vocab_size() == initial_vocab_size + 1', 'in vocab.tokens_in_namespace()', 'vocab.get_token_index() == word_index', 'vocab.get_token_from_index(word_index) == ', 'vocab.get_vocab_size() == initial_vocab_size + 1', ')', 'vocab.get_token_index() == word_index', 'vocab.get_token_from_index(word_index, namespace=', 'vocab.get_vocab_size(namespace=) == initial_vocab_size + 1', ')', ')', 'vocab.get_token_index() == word_index', 'vocab.get_token_index() == word2_index', 'vocab.get_token_from_index(word_index, namespace=', 'vocab.get_token_from_index(word2_index, namespace=', 'vocab.get_vocab_size(namespace=) == initial_vocab_size + 2', 'oov_index == 1', 'vocab.get_token_index() == oov_index', 'vocab._oov_token == ', 'vocab.get_token_index() == 3', 'vocab.get_token_index() == 1', 'vocab.get_token_index() == 2', 'vocab.get_token_index() == 3', 'vocab.get_token_index() == 4', 'vocab.get_token_index() == 5', 'vocab.get_token_index() == 6', 'vocab.get_token_from_index(0) == vocab._padding_token', 'vocab.get_token_from_index(1) == ', 'vocab.get_token_from_index(2) == ', 'vocab.get_token_from_index(3) == ', 'vocab.get_token_from_index(4) == ', 'vocab.get_token_from_index(5) == ', 'vocab.get_token_from_index(6) == ']","['(ConfigurationError)', '(Exception)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],"['', '']",[],[],[],[],"['skip', 'skip']","['mark.skip', 'mark.skip']",[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
3,Mark Neumann,markn@allenai.org,2017-06-26 12:40:19-07:00,0fbc764ed8899c9ce2bc22d58013bed264bb0e0e,https://github.com/allenai/allennlp/commit/0fbc764ed8899c9ce2bc22d58013bed264bb0e0e,remove deepqa mentions,17,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,['class AllenNlpTestCase(TestCase):'],[],[],[],[],[],[],[],[],[],[],['class DeepQaTestCase(TestCase):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
4,Mark Neumann,markn@allenai.org,2017-06-26 12:48:48-07:00,0a8f54f7d50e7dfb2b13b367e8cec4b6ddccda69,https://github.com/allenai/allennlp/commit/0a8f54f7d50e7dfb2b13b367e8cec4b6ddccda69,refactor vocab sligtly to return a dict for indices,2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in words', 'not in words', 'not in words', 'in words', 'in words', 'in words', 'in vocab.get_index_to_token_vocabulary().values()', 'in vocab.get_index_to_token_vocabulary().values()', ').values()', ').values()', ').values()']",[],[],[],[],[],[],[],[],[],[],[],[],"['in vocab.tokens_in_namespace()', 'not in vocab.tokens_in_namespace()', 'not in vocab.tokens_in_namespace()', 'in vocab.tokens_in_namespace()', 'in vocab.tokens_in_namespace()', 'in vocab.tokens_in_namespace()', 'in vocab.tokens_in_namespace()', 'in vocab.tokens_in_namespace()', ')', ')', ')']",[],[],[],[],[],[],[],[],[],[],[],[]
5,Matt Gardner,mattg@allenai.org,2017-06-27 08:41:00-07:00,8ae910cbdf18dad8d901d44ea66989bc8b73e4ed,https://github.com/allenai/allennlp/commit/8ae910cbdf18dad8d901d44ea66989bc8b73e4ed,Documentation and namespace fixes for field classes (#5),6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
6,Michael Schmitz,michael@schmitztech.com,2017-06-27 08:47:48-07:00,e4fb1cc0e7658fe31fe97b4aeb28e178fab2622c,https://github.com/allenai/allennlp/commit/e4fb1cc0e7658fe31fe97b4aeb28e178fab2622c,"Improve Vocabulary comments. (#4)

* Change comment on NamespaceDependentDefaultDict.

* Install pytorch with conda.

* Improve comments on Vocabulary.

* Refactor NamespaceDependentDefaultDict and add a test case.

* Fixup: typo

* Respond to PR feedback.

* Respond to PR feedback.",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['default_dict[] == 7', 'default_dict[] == 3', 'default_dict[] == 3', 'default_dict[] == 3']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
7,Mark Neumann,markn@allenai.org,2017-06-27 10:33:53-07:00,b16aa6536adb52c3e90cc0667e0bf88ccdcdef65,https://github.com/allenai/allennlp/commit/b16aa6536adb52c3e90cc0667e0bf88ccdcdef65,"Pytorch embedding v2 (#6)

* pytorch version of embeddings

* fix vocab word list

* address matt's comments",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['embedding_layer.embedding_dim == 3', 'embedding_layer.embedding_dim == 4', 'not numpy.allclose(word_vector.numpy()[:2], numpy.array([0.1, 0.4]))', 'numpy.allclose(word_vector.numpy(), numpy.array([1.0, 2.3, -1.0]))', 'not numpy.allclose(word_vector.numpy(), numpy.array([0.0, 0.0, 0.0]))']",[],[],[],[],[],[],[],[],[],[],[],[],"['embedding_layer.output_dim == 3', 'embedding_layer.output_dim == 4', 'not numpy.allclose(word_vector[:2], numpy.asarray([0.1, 0.4]))', 'numpy.allclose(word_vector, numpy.asarray([1.0, 2.3, -1.0]))', 'not numpy.allclose(word_vector, numpy.asarray([0.0, 0.0, 0.0]))']",[],[],[],[],[],[],[],[],[],[],[],[]
8,Matt Gardner,mattg@allenai.org,2017-06-27 10:35:56-07:00,cfe16abb4ffa4e8842658d80abab43863d5b2d38,https://github.com/allenai/allennlp/commit/cfe16abb4ffa4e8842658d80abab43863d5b2d38,Improved docstring for _NamespaceDependentDefaultDict (#7),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
9,Mark Neumann,markn@allenai.org,2017-06-28 10:43:46-07:00,8d03ef75786539cc5db3facc0e0ad65498307dbf,https://github.com/allenai/allennlp/commit/8d03ef75786539cc5db3facc0e0ad65498307dbf,"add travis stuff (#3)

* add travis stuff

* add travis badge to readme

* add codecov.yaml

* add codecov badge

* use install_requirements bash script in travis build

* fix pylint

* remove conda install from install_requirements

* see if conda install is breaking build

* fix failing test from defaultdict refactoring

* see if making conda quiet fixes build script

* add newline

* upgrade to latest pylint version

* expain pylint commit requirement

* disable else-after-return pylint warning",28,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,2,0,2,0,0,0,0,2,2,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['generator.last_num_batches == 4', 'self.as_list(one_epoch_arrays[0][0]) == [1, 0, 4]', 'self.as_list(one_epoch_arrays[1][0]) == [3]', 'self.as_list(one_epoch_arrays[2][0]) == [6, 7, 2]', 'self.as_list(one_epoch_arrays[3][0]) == [8, 9, 5]', 'generator.last_num_batches == 4', 'first_epoch == second_epoch', 'self.as_list(biggest_batches[0][0]) == [3]', 'self.as_list(biggest_batches[1][0]) == [1, 0, 4]', 'generator.last_num_batches == 4', 'self.as_list(one_epoch_arrays[0][0]) == [0, 4]', 'self.as_list(one_epoch_arrays[1][0]) == [3]', 'self.as_list(one_epoch_arrays[2][0]) == [7, 2, 1]', 'self.as_list(one_epoch_arrays[3][0]) == [8, 9, 5, 6]', 'generator.last_num_batches == 4', 'first_epoch != second_epoch', 'generator.last_num_batches == 7', 'self.as_list(one_epoch_arrays[0][0]) == [0]', 'self.as_list(one_epoch_arrays[1][0]) == [2, 1]', 'self.as_list(one_epoch_arrays[2][0]) == [3]', 'self.as_list(one_epoch_arrays[3][0]) == [4]', 'self.as_list(one_epoch_arrays[4][0]) == [5, 6]', 'self.as_list(one_epoch_arrays[5][0]) == [7]', 'self.as_list(one_epoch_arrays[6][0]) == [8, 9]']","['(ConfigurationError)', '(ConfigurationError)']",[],"['', '']",[],[],[],[],"['skip', 'skip']","['mark.skip', 'mark.skip']",[],[],[]
10,Matt Gardner,mattg@allenai.org,2017-06-28 16:26:25-07:00,79d531b4eaae47f30289737bbd67aa51e64ba6ce,https://github.com/allenai/allennlp/commit/79d531b4eaae47f30289737bbd67aa51e64ba6ce,Remove now-unnecessary testenv352 (#9),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
11,Mark Neumann,markn@allenai.org,2017-07-05 09:57:02-07:00,747b0eebeb3becaa48a7fb7ed582c6d9ff12a8ca,https://github.com/allenai/allennlp/commit/747b0eebeb3becaa48a7fb7ed582c6d9ff12a8ca,"model_api (#10)

* model_api

* fix overriden method

* address some of matt's comments

* unify return signature by returning None

* minor docs corrections

* address api comments

* remove get loss function, clean up docs

* clarify docs",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
12,Joel Grus,joelgrus@gmail.com,2017-07-06 10:39:33-07:00,0901ddda5ec0e939eee6fa77586c77f9447e8795,https://github.com/allenai/allennlp/commit/0901ddda5ec0e939eee6fa77586c77f9447e8795,"remove conda / pytorch from install_requirements.sh (#15)

* remove conda / pytorch from install_requirements.sh

* remove superfluous conda install from scripts",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
13,Matt Gardner,mattg@allenai.org,2017-07-06 12:48:28-07:00,b9871cc1ffbafd323c2c6726d2e5a9a0cf7ee778,https://github.com/allenai/allennlp/commit/b9871cc1ffbafd323c2c6726d2e5a9a0cf7ee778,"Add a `TimeDistributed` layer (#16)

* Added TimeDistributed module

* Moved Embeddings test

* Renamed layers to modules

* Fixed imports and docstring",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
14,Mark Neumann,markn@allenai.org,2017-07-08 13:41:29-07:00,26e4bb7130bf7ad4b3516bb9fd630839bcc6124f,https://github.com/allenai/allennlp/commit/26e4bb7130bf7ad4b3516bb9fd630839bcc6124f,"Split data generator (#11)

* mostly done refactoring

* better docs for iterators

* improve docs

* Clean up iterator API, add initial tests

* Fixes from PR comments

* Removing the old data generator

* remove get_fields from instance api",12,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('_instances_are_correct', '(instances)'), ('_instances_are_correct', '(instances)')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['grouped_instances == [[self.instances[4], self.instances[2], self.instances[0]],', 'grouped_instances == [[self.instances[4], self.instances[2]],', 'grouped_instances == [[self.instances[3]],', 'set(candidate_instances) == set(expected_instances)', 'len(instances) == 5', 'len(instances) == 5 * 6', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[4], self.instances[2]],', 'grouped_instances == [[self.instances[3]],']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
15,Matt Gardner,mattg@allenai.org,2017-07-10 13:46:41-07:00,3dd6e6d4e3b3cb7393626ecb12bd05c0e6d25596,https://github.com/allenai/allennlp/commit/3dd6e6d4e3b3cb7393626ecb12bd05c0e6d25596,"Added NlpApi class (#8)

* Added NlpApi class

* Much improved documentation

* Added tests

* Fixed first paragraph in docstring

* Final rewrite (hopefully)

* Minor wording tweaks",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['api.get_token_embedder() == 1', 'api.get_token_embedder() is None', 'api.get_new_token_embedder() == 2', 'api.get_seq2seq_encoder() == 1', 'api.get_seq2seq_encoder() is None', 'api.get_new_seq2seq_encoder() == 2', 'api.get_seq2vec_encoder() == 1', 'api.get_seq2vec_encoder() is None', 'api.get_new_seq2vec_encoder() == 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
16,Joel Grus,joelgrus@gmail.com,2017-07-10 14:29:30-07:00,88d3803e9d1933b9be0303775b410bf026978361,https://github.com/allenai/allennlp/commit/88d3803e9d1933b9be0303775b410bf026978361,"prototype flask app for serving models + bare-bones webapp (#17)

* simple API proof of concept

* add instructions to readme

* add comment, remove print-debug

* add __init__.py

* add tests",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(data[}', 'prediction.status_code == 400', 'b in prediction.get_data()', 'set(data.keys()) == {}', 'data[', 'data[', 'data[']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
17,Matt Gardner,mattg@allenai.org,2017-07-10 15:58:52-07:00,a6019e4f4f77a7a4df434bb93dc069ba3873009d,https://github.com/allenai/allennlp/commit/a6019e4f4f77a7a4df434bb93dc069ba3873009d,"Removing old test code, copying over and fixing SQuAD reader tests (#19)

* Removing old test code, copying over and fixing SQuAD reader tests

* Moved data methods back to AllenNlpTestCase",5,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,14,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('_list_field_contains_correct_sentences', '(instances[0].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[0].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[0].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields()[],')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['expected_tokens == actual_tokens', 'index_field.sequence_index() == tokens_list.index(sentence_tokens)', 'instances[0].fields()[].tokens() == self.tokenizer.tokenize(self.question0)', 'instances[1].fields()[].tokens() == self.tokenizer.tokenize(self.question1)', 'instances[0].fields()[].sequence_length() == 6', 'instances[1].fields()[].sequence_length() == 6']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
18,Mark Neumann,markn@allenai.org,2017-07-10 16:43:35-07:00,0f96be6a2d2392dc44e70de4f33086901963a547,https://github.com/allenai/allennlp/commit/0f96be6a2d2392dc44e70de4f33086901963a547,"simple tagger (#13)

* simple tagger sketch

* test sketch

* add sequence tagging dataset reader

* tweak some names across the simple tagger

* add tests, clean up tag method

* bump pytorch version to get negative indices in ops

* fix repeated pip command

* better docs

* pylint

* address comments

* fix build",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset.instances) == 4', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'tag in possible_tags']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
19,Nelson Liu,nelson-liu@users.noreply.github.com,2017-07-10 17:06:48-07:00,96d2a1688fbe0c21baf6a23087027bb726c5619b,https://github.com/allenai/allennlp/commit/96d2a1688fbe0c21baf6a23087027bb726c5619b,Make pretrained embed init consistent w/ random (#18),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
20,Joel Grus,joelgrus@gmail.com,2017-07-12 19:55:38-07:00,ed3d215b49e9114c272416e70fbc51fbd1ee7cd1,https://github.com/allenai/allennlp/commit/ed3d215b49e9114c272416e70fbc51fbd1ee7cd1,"get code to pass mypy type checking (#22)

* mypy

* revert model.py

* fix dict types

* fix wrong class

* remove runtime type check

* clean up typing

* address pr comments",36,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
21,Joel Grus,joelgrus@gmail.com,2017-07-13 06:48:34-07:00,5c98282578aa51fa07134d5c0829141a2d9de3b0,https://github.com/allenai/allennlp/commit/5c98282578aa51fa07134d5c0829141a2d9de3b0,change relative imports to absolute imports (#23),37,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
22,Joel Grus,joelgrus@gmail.com,2017-07-13 13:28:46-07:00,7281f3bfc9260e8f639eb19ae8c39637c9105b65,https://github.com/allenai/allennlp/commit/7281f3bfc9260e8f639eb19ae8c39637c9105b65,"make TokenIndexer generic over token type (#24)

* make TokenIndexer generic over token type

* fix type in text_field

* remove unused import

* move no-self-use disable to top of file",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
23,Joel Grus,joelgrus@gmail.com,2017-07-13 14:22:07-07:00,3ab6930c37b6e96724d5656a91e5a08f8a027bc1,https://github.com/allenai/allennlp/commit/3ab6930c37b6e96724d5656a91e5a08f8a027bc1,"add mypy to requirements.txt (#26)

* add mypy to requirements.txt

* update travis scripts to use mypy

* split out test requirements into separate file

* add test_requirements flag

* flip RUN_TESTS flag",8,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
24,Mark Neumann,markn@allenai.org,2017-07-15 10:25:24-07:00,b4f7b9461e7f8f3b2f315f588dbb75f44c208794,https://github.com/allenai/allennlp/commit/b4f7b9461e7f8f3b2f315f588dbb75f44c208794,"use dicts for namespaces within text fields (#25)

* switch text and list fields to use dicts

* unify namespace attribute in token indexers

* switch dataset, iterators and tagger to new dict based textfields

* fix unrecognised arg in char indexer

* improve docs

* make dataset iteration clearer

* change to as_arrays, remove list options from data/

* remove non-defaults from dataset test

* add generic types to fields

* move TextField internals to be dicts

* fix mypy by removing DataArray type annotation

* use new dict for dataset loop

* Revert ""use new dict for dataset loop""

This reverts commit 6447f7a4607ec5725e92e53689e469f73794e0cf.

* address matts comments

* fix typo",25,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['field._indexed_tokens[] == [capital_a_index, sentence_index]', 'field1._indexed_tokens[] == [[capital_a_char_index],', 'field2._indexed_tokens[] == [capital_a_index, sentence_index]', 'field2._indexed_tokens[] == [[capital_a_char_index],']",[],[],[],[],[],[],[],[],[],[],[],[],"['field._indexed_tokens == [[capital_a_index, sentence_index]]', 'field1._indexed_tokens == [[[capital_a_char_index],', 'field2._indexed_tokens == [[capital_a_index, sentence_index],']",[],[],[],[],[],[],[],[],[],[],[],[]
25,Joel Grus,joelgrus@gmail.com,2017-07-17 14:04:48-07:00,d74fbb821065493d7ec54687c97d3a477e814aec,https://github.com/allenai/allennlp/commit/d74fbb821065493d7ec54687c97d3a477e814aec,"change None sentinel to Tuple sentinel (#31)

* change None sentinel to Tuple sentinel

* fix documentation",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
26,Mark Neumann,markn@allenai.org,2017-07-17 14:45:43-07:00,c56ac3c37c06c791469c8e0a3ba208a1114cecbc,https://github.com/allenai/allennlp/commit/c56ac3c37c06c791469c8e0a3ba208a1114cecbc,"Tutorial Jupyter Notebooks (#30)

* started filling out some notebooks

* more notebook stuff

* add way to test notebooks, more on the vocab tutorial

* move to dict for TokenIndexers

* more vocab tutorial

* pylint

* add a readme

* make matt's suggested changes",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['self.execute_notebook()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
27,Joel Grus,joelgrus@gmail.com,2017-07-17 15:01:14-07:00,6fada919dbf086079ed4d9bd9df77886b9848fca,https://github.com/allenai/allennlp/commit/6fada919dbf086079ed4d9bd9df77886b9848fca,"add end-to-end examples with allennlp + pytorch, also add alternative sanic server (#29)

* add sequence tagging example

* add sanic + fake pytorch model

* remove stray newline

* fix TextField constructor

* add more tests

* remove bulk query

* add name to todo

* add more name to todo",13,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['])', 'prediction.status_code == 400', 'b in prediction.get_data()', 'set(data.keys()) == {}', 'data[', 'data[', 'data[', 'set(data.keys()) == {}', 'data[', 'data[', 'data[', 'set(data.keys()) == {}', 'data[', 'data[', 'data[', 'set(data.keys()) == {}', 'data[', 'data[] == 1', 'isinstance(data[], list)', 'isinstance(data[][0], list)', 'set(data.keys()) == {}', '])', 'response.status == 400', 'in response.text', 'set(data.keys()) == {}', 'data[', 'data[', 'data[']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(data[}', 'prediction.status_code == 400', 'b in prediction.get_data()', 'set(data.keys()) == {}', 'data[', 'data[', 'data[']",[],[],[],[],[],[],[],[],[],[],[],[]
28,Matt Gardner,mattg@allenai.org,2017-07-18 09:48:32-07:00,17361796c4e0cb7bfab5a24b60737645e4cd064d,https://github.com/allenai/allennlp/commit/17361796c4e0cb7bfab5a24b60737645e4cd064d,"Adding a registry for things we want to be able to create from parameters. (#28)

* Initial registry design

* Making a Registry class

* Moved DataIterators over to the Registry

* Moved tokenizers and token indexers over to the registry

* Fix pylint errors

* Added docstrings, and switched to using `list_*`",41,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,5,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['Registry.get_dataset_reader(', 'Registry.get_dataset_reader(', 'Registry.get_dataset_reader(', 'Registry.get_dataset_reader(', 'not in Registry.list_dataset_readers()', 'Registry.get_dataset_reader() == Fake', 'Registry.get_data_iterator(', 'Registry.get_data_iterator(', 'Registry.get_data_iterator(', 'not in Registry.list_data_iterators()', 'Registry.get_data_iterator() == Fake', 'Registry.list_data_iterators()[0] == default_iterator', 'Registry.list_data_iterators()[0] == ', 'Registry.get_tokenizer(', 'Registry.get_tokenizer(', 'not in Registry.list_tokenizers()', 'Registry.get_tokenizer() == Fake', 'Registry.list_tokenizers()[0] == default_iterator', 'Registry.list_tokenizers()[0] == ', 'Registry.get_token_indexer(', 'Registry.get_token_indexer(', 'not in Registry.list_token_indexers()', 'Registry.get_token_indexer() == Fake', 'Registry.list_token_indexers()[0] == default_iterator', 'Registry.list_token_indexers()[0] == ']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
29,Mark Neumann,markn@allenai.org,2017-07-20 07:30:36-07:00,f0d296fd65b9aefb26909fbf2a2c5730face19a5,https://github.com/allenai/allennlp/commit/f0d296fd65b9aefb26909fbf2a2c5730face19a5,"Misc additions (#32)

* initial api sketch

* more abstract model api

* complete abstract Model api

* clean up model docs

* adding optimizers and regulariser classes

* add regularizers and initializers

* cleanup, add some trainer parameters

* add types and docs to initializers

* more parameter unpacking, changes to test case

* rewrite ensure_model_trains_and_loads for new api

* change read() interface of dataset_readers

* change dataset_reader tests

* fix merge

* switch sequence tagger reader to new api

* more work towards testing using Trainer

* remove intialisers and regularisers from pr

* add a function to convert data structures to tensors

* working-ish model testing and loading

* skip GPU tests

* pylint + mypy cleanup

* change saving in Trainer and alter load/save test function

* remove trainer from other additions for new PR

* try fixing type, alter missed read arg

* reorder saving and loading

* fix merge conflicts

* fix ndarray annotations

* fix data iterator type, fix spurious type erorrs

* address joel's comments

* matt style fixes",22,False,True,True,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(torch.ByteTensor(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(']",[],[],[''],[],[],[],[],['skip'],['mark.skip'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
30,Mark Neumann,markn@allenai.org,2017-07-20 14:06:14-07:00,f665c927799d86afa3959fd647afbc90b72996f8,https://github.com/allenai/allennlp/commit/f665c927799d86afa3959fd647afbc90b72996f8,"split regularisers and initialisers out from trainer PR (#21)

* split regularisers and initialisers out from trainer PR

* add dicts of possible values

* pylint cleanup

* refactor regularizers and initializers

* tweaks for mypy

* pylint

* address most of matt's comments

* test regularizers from params

* add initializer to registry, add tests

* switch to overriding mypy error rather than pylint

* remove bin files

* pylint

* fix copy paste error",10,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['Registry.get_regularizer(', 'Registry.get_regularizer(', 'not in Registry.list_regularizers()', 'Registry.get_regularizer() == Fake', 'Registry.list_regularizers()[0] == default_regularizer', 'Registry.list_regularizers()[0] == ', 'Registry.get_initializer(key) == value', 'not in Registry.list_initializers()', 'Registry.get_initializer() == fake_initializer', 'Registry.list_initializers()[0] == default_initializer', 'Registry.list_initializers()[0] == ', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 5)', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 10)', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 5)', 'initializers[] == torch.nn.init.orthogonal', 'value.data.numpy() == 115.0', 'value.data.numpy() == 28.75', 'value.data.numpy() == 65.0', 'isinstance(regularizers[], L1Regularizer)', 'isinstance(regularizers[], L2Regularizer)', 'regularizers[].alpha == 10']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
31,Mark Neumann,markn@allenai.org,2017-07-20 15:33:45-07:00,42139016cd7b54ee84b55411db2049bd61c37b25,https://github.com/allenai/allennlp/commit/42139016cd7b54ee84b55411db2049bd61c37b25,"SRL Reader (#33)

* make index field optional, add ontonotes reader for SRL

* better docs

* add test, fix minor bugs

* lint

* fix imports from merge

* add registery, change name to SrlReader

* remove tokenizer

* remove unused imports

* fix missing test in name from refactor

* add index_field test, other minor changes

* add preprocessing information

* add types, switch to new dataset reader interface",8,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['fields[,', 'fields[].sequence_index() == 3', 'fields[,', 'fields[,', 'fields[].sequence_index() == 8', 'fields[,', 'fields[,', 'fields[].sequence_index() == 2', 'fields[,', 'fields[,', 'fields[].sequence_index() == 11', 'fields[]', 'fields[]', 'fields[].sequence_index() is None', 'fields[]', 'index_field.get_padding_lengths() == {: 5}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
32,Matt Gardner,mattg@allenai.org,2017-07-21 07:31:25-07:00,04a7b5513dc5fd3740959fa52de843386a132347,https://github.com/allenai/allennlp/commit/04a7b5513dc5fd3740959fa52de843386a132347,"Add a missing __init__ file, clean up service test files (#36)

* Remove unnecessary __init__ files, clean up service tests

* Add back in __init__.py files, because pylint needs them",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],"['def tearDown(self):', 'def tearDown(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
33,Matt Gardner,mattg@allenai.org,2017-07-21 13:30:23-07:00,50b735a640588d01fe9d271ca43758eb83f97802,https://github.com/allenai/allennlp/commit/50b735a640588d01fe9d271ca43758eb83f97802,"Add TextField and Token Embedder APIs (#34)

* Added TokenEmbedder and TokenVectorizer APIs

* Added test for BasicTokenEmbedder

* Addressed PR feedback

* Remove unnecessary pylint comment

* Fixed failing test

* Some docstring fixes",21,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,3,0,0,0,0,0,0,0,0,0,0,1,22,7,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not in list_fn()', 'get_fn() == fake', 'list_fn()[0] == current_default', 'list_fn()[0] == ', 'Registry.get_token_embedder(', 'Registry.get_text_field_embedder(', 'self.token_embedder.get_output_dim() == 10', 'self.token_embedder.forward(self.inputs).size() == (1, 4, 10)']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],"['not in Registry.list_dataset_readers()', 'Registry.get_dataset_reader() == Fake', 'not in Registry.list_data_iterators()', 'Registry.get_data_iterator() == Fake', 'Registry.list_data_iterators()[0] == default_iterator', 'Registry.list_data_iterators()[0] == ', 'not in Registry.list_tokenizers()', 'Registry.get_tokenizer() == Fake', 'Registry.list_tokenizers()[0] == default_iterator', 'Registry.list_tokenizers()[0] == ', 'not in Registry.list_token_indexers()', 'Registry.get_token_indexer() == Fake', 'Registry.list_token_indexers()[0] == default_iterator', 'Registry.list_token_indexers()[0] == ', 'not in Registry.list_regularizers()', 'Registry.get_regularizer() == Fake', 'Registry.list_regularizers()[0] == default_regularizer', 'Registry.list_regularizers()[0] == ', 'not in Registry.list_initializers()', 'Registry.get_initializer() == fake_initializer', 'Registry.list_initializers()[0] == default_initializer', 'Registry.list_initializers()[0] == ']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[]
34,Matt Gardner,mattg@allenai.org,2017-07-24 11:02:30-07:00,06852fddc436a10868f6e4806bcb8c3dfda2080a,https://github.com/allenai/allennlp/commit/06852fddc436a10868f6e4806bcb8c3dfda2080a,"Added seq2seq and seq2vec encoders to the registry (#35)

* Added seq2seq and seq2vec encoders to the registry

* Made the wrappers less confusing, change SimpleTagger to use this API

* Fixed typo

* Fixes from Mark's feedback

* Fixed tests

* Removed NlpApi class, which is now superseded

* Removed NlpApi tests, added encoder tests

* More encoder tests

* Fix pylint

* Fixed input_dim typos",22,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,2,0,0,0,0,0,0,0,0,0,0,2,9,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['Registry.get_seq2seq_encoder(', 'Registry.get_seq2seq_encoder(', 'Registry.get_seq2seq_encoder(', 'Registry.get_seq2vec_encoder(', 'Registry.get_seq2vec_encoder(', 'Registry.get_seq2vec_encoder(', 'encoder.__class__.__name__ == ', 'encoder._module.__class__.__name__ == ', 'encoder._module.num_layers == 3', 'encoder._module.input_size == 5', 'encoder._module.hidden_size == 7', 'encoder._module.bidirectional is True', 'encoder._module.batch_first is True', 'encoder.get_output_dim() == 14', 'encoder.get_output_dim() == 7', 'encoder.__class__.__name__ == ', 'encoder._module.__class__.__name__ == ', 'encoder._module.num_layers == 3', 'encoder._module.input_size == 5', 'encoder._module.hidden_size == 7', 'encoder._module.bidirectional is True', 'encoder._module.batch_first is True', 'encoder.get_output_dim() == 14', 'encoder.get_output_dim() == 7']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest']","['api.get_token_embedder() == 1', 'api.get_token_embedder() is None', 'api.get_new_token_embedder() == 2', 'api.get_seq2seq_encoder() == 1', 'api.get_seq2seq_encoder() is None', 'api.get_new_seq2seq_encoder() == 2', 'api.get_seq2vec_encoder() == 1', 'api.get_seq2vec_encoder() is None', 'api.get_new_seq2vec_encoder() == 2']",[],[],[],[],[],[],[],[],[],[],[],[]
35,Matt Gardner,mattg@allenai.org,2017-07-24 15:27:55-07:00,1717e5cbb8ff3771f3c3fbbd17c93b4167148378,https://github.com/allenai/allennlp/commit/1717e5cbb8ff3771f3c3fbbd17c93b4167148378,"Adding a CNN encoder (#39)

* Added CNN encoder (still needs tests)

* Added tests, made them pass

* Fixed pylint errors

* Addressing Mark's comments",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['Registry.get_seq2vec_encoder(', 'encoder.get_output_dim() == 8', 'encoder.get_output_dim() == 7', 'encoder.get_output_dim() == 8', 'encoder.get_output_dim() == 7', 'encoder(tensor).size() == (4, 30)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
36,Matt Gardner,mattg@allenai.org,2017-07-24 15:45:36-07:00,48de336898a04b864f7fb4a4b5969d880b375fe1,https://github.com/allenai/allennlp/commit/48de336898a04b864f7fb4a4b5969d880b375fe1,"Token characters encoder (#40)

* Added TokenCharactersEncoder (still needs tests)

* Added tests, but it's not working with the LSTM

* Got tests to pass with CNN

* Better name

* Fix lint errors",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['Registry.get_token_embedder(', 'self.encoder.get_output_dim() == 3']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
37,Mark Neumann,markn@allenai.org,2017-07-24 15:53:45-07:00,048cba07cf94d43376092b61b7e50500bb7f928d,https://github.com/allenai/allennlp/commit/048cba07cf94d43376092b61b7e50500bb7f928d,"Recurrent layers (#37)

* initial recurrent stuff

* augumented lstm, indexing stuff

* add some sorting stuff

* do variational dropout properly

* add working sorting code and test

* linting touch-ups

* merge tensor test

* test augmented lstm is the same as pytorch version :tada:

* add interleaved lstm tests and docs

* docs cleanup, switch to long tensor for seq lengths

* simplify batch states and add comment

* address most of matt's comments",7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['sorted_lengths.equal(torch.LongTensor([7, 5, 4, 3, 1]))', 'sorted_tensor[reverse_indices].equal(tensor)', 'layer.go_forward', 'not layer.go_forward']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
38,Mark Neumann,markn@allenai.org,2017-07-26 13:00:56-07:00,3cc3bdc268590e40af1b3e5b237771f81001e23f,https://github.com/allenai/allennlp/commit/3cc3bdc268590e40af1b3e5b237771f81001e23f,temporary build fix (#44),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
39,Mark Neumann,markn@allenai.org,2017-07-26 13:08:59-07:00,00e8f1d32f235b2e6d952915f389aff9ea741258,https://github.com/allenai/allennlp/commit/00e8f1d32f235b2e6d952915f389aff9ea741258,"Encoder Wrapper Improvements (#41)

* initial fragile fix to see what Matt thinks

* lint fixes

* fix tests and deal with state properly

* move batch_first check into Wrappers

* also catch error in private Wrapper to have sensible defaults

* better comments and concatenated test",12,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,2,0,0,0,0,0,0,0,0,0,0,2,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['encoder.__class__.__name__ == ', 'encoder.get_output_dim() == 14', 'encoder.get_output_dim() == 7', 'encoder.__class__.__name__ == ', 'encoder.get_output_dim() == 14', 'encoder.get_output_dim() == 7']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest']","['encoder.__class__.__name__ == ', 'encoder.get_output_dim() == 14', 'encoder.get_output_dim() == 7', 'encoder.__class__.__name__ == ', 'encoder.get_output_dim() == 14', 'encoder.get_output_dim() == 7']",[],[],[],[],[],[],[],[],[],[],[],[]
40,Joel Grus,joelgrus@gmail.com,2017-07-26 13:20:34-07:00,d657b0ed22ff20720bfcaf6854d59b22d42e5666,https://github.com/allenai/allennlp/commit/d657b0ed22ff20720bfcaf6854d59b22d42e5666,"create `Servable` abstraction and implement v1 of cli (#42)

* first version of cli

* fix for new data api

* clean up

* add servable abstraction

* remove unnecessary TODOs

* merge from master

* remove trailing newlines

* refactor cli and add tests

* add pylint ignores

* change servable static methods to from_params(params)",19,False,True,True,True,False,False,False,False,False,False,False,False,False,False,False,[],2,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,"['class TestMain(TestCase):', 'class TestApp(TestCase):']","[('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(outfile)', 'len(lines) == 2', 'lines[0] == {}', 'lines[1] == {}', 'cm.exception.code == -1', 'available  # not empty', 'in available', 'reverser  # is not None', 'not collection.list_available()', 'available', 'available == []', 'test_servable', 'len(result) == 1', 'result.get(', 'len(available) == 2', 'in available', 'in available', '])', 'data[', 'data[', 'data[', 'data[', '])', 'data[']",[],[],[],[],[],[],[],[],[],[],[],[],"['])', 'data[', 'data[', 'data[', 'data[', '])', 'data[']",[],[],[],[],[],[],[],[],[],[],[],[]
41,Matt Gardner,mattg@allenai.org,2017-07-26 16:04:46-07:00,b2fd408186047dab9e5e5fd8fbacb560f481258a,https://github.com/allenai/allennlp/commit/b2fd408186047dab9e5e5fd8fbacb560f481258a,"Ported similarity functions over from DeepQA (#43)

* Ported similarity functions over from DeepQA

* Added Similarity to names

* Fixed batch matrix multiply, fixing remaining test errors

* Fixed pylint errors, added a few more simple tests

* More pylint

* Improved wording",16,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['Registry.get_similarity_function(', 'Registry.get_similarity_function(', 'Registry.get_similarity_function(', 'Registry.get_similarity_function(', 'list(bilinear._weight_matrix.size()) == [5, 2]', 'list(bilinear._bias.size()) == [1]', 'result.shape == (2,)', 'result.shape == (5, 4, 3, 6)', 'list(bilinear._weight_matrix.size()) == [3, 4]  # pylint: disable=protected-access', 'result.shape == (1, 2)', 'desired_result.shape == (1, 2)', 'result.shape == (5, 4, 3, 6)', 'CosineSimilarity.from_params(Params({})).__class__.__name__ == ', 'result.shape == (2,)', 'numpy.all(result == [2, -1])', 'result.shape == (5, 4, 3, 6)', 'DotProductSimilarity.from_params(Params({})).__class__.__name__ == ', 'list(linear._weight_vector.size()) == [9]', 'list(linear._bias.size()) == [1]', 'result.shape == (1, 2,)', 'result.shape == (5, 4, 3, 6)', 'result.shape == (2,)', 'result.shape == (2,)', 'result.shape == (2,)', 'result.shape == (2,)', 'list(linear._weight_vector.size()) == [16]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
42,Matt Gardner,mattg@allenai.org,2017-07-27 07:20:51-07:00,1cfd51a87149e299392ef9a66976f759747ea455,https://github.com/allenai/allennlp/commit/1cfd51a87149e299392ef9a66976f759747ea455,"Adding a SquadReader (#45)

* Added a SquadReader

* Fix spacy splitter to match docs

* Add test for creating SquadReader from_params

* Fix pylint errors

* Address Mark's comments",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['instances[0].fields()[]', 'instances[2].fields()[]', 'token_span == (1, 5)', 'token_span == (22, 25)', 'token_span == (22, 29)', 'len(instances) == 5', 'instances[0].fields()[]', 'instances[0].fields()[]', 'instances[0].fields()[]', 'instances[0].fields()[].sequence_index() == 102', 'instances[0].fields()[].sequence_index() == 105', 'instances[1].fields()[]', 'instances[1].fields()[]', 'instances[1].fields()[]', 'instances[1].fields()[].sequence_index() == 17', 'instances[1].fields()[].sequence_index() == 24', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[']",[],[],[],[],[],[],[],[],[],[],[],[],"['instances[0].fields()[]', 'instances[2].fields()[]']",[],[],[],[],[],[],[],[],[],[],[],[]
43,Matt Gardner,mattg@allenai.org,2017-07-27 10:43:37-07:00,cac4750b2b600aa1ecedfe3b363e12ceecf05f0f,https://github.com/allenai/allennlp/commit/cac4750b2b600aa1ecedfe3b363e12ceecf05f0f,"Adding Attention and MatrixAttention modules (#46)

* Added Attention and MatrixAttention modules

* Added tests, fixed some lint / mypy issues",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['attention._similarity_function.__class__.__name__ == ', 'attention._normalize is False', 'result.shape == (1, 2, 3)', 'attention._similarity_function.__class__.__name__ == ']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
44,Joel Grus,joelgrus@gmail.com,2017-07-27 12:37:48-07:00,5c45bbd6c49128ff6244922dbe7cd9befd33ccbf,https://github.com/allenai/allennlp/commit/5c45bbd6c49128ff6244922dbe7cd9befd33ccbf,"Dockerfile changes (#47)

* two dockerfiles

* fix typo

* remove dockerfile

* reorder",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
45,Michael Schmitz,michael@schmitztech.com,2017-07-27 14:40:47-07:00,19055b4a8e6e07c7412f7e8b3aa3839c1c373ade,https://github.com/allenai/allennlp/commit/19055b4a8e6e07c7412f7e8b3aa3839c1c373ade,Update README.md (#48),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
46,Joel Grus,joelgrus@gmail.com,2017-07-27 19:15:58-07:00,6f415a2d96dfabb911b566eaa8076c9a7cc71081,https://github.com/allenai/allennlp/commit/6f415a2d96dfabb911b566eaa8076c9a7cc71081,"get rid of registry (#50)

* replace registry

* create registryable class

* switch to registrable

* add comment

* address pr comments, add return types

* add todo",44,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,1,0,0,0,0,0,0,0,0,0,0,1,32,2,0,0,0,0,0,0,0,0,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not in base_class.list_available()', 'base_class.by_name() == Fake', 'base_class.list_available()[0] == default', 'base_class.list_available()[0] == ', 'DatasetReader.by_name(', 'DatasetReader.by_name(', 'DatasetReader.by_name(', 'DatasetReader.by_name(', 'DataIterator.by_name(', 'DataIterator.by_name(', 'DataIterator.by_name(', 'Tokenizer.by_name(', 'Tokenizer.by_name(', 'TokenIndexer.by_name(', 'TokenIndexer.by_name(', 'Regularizer.by_name(', 'Regularizer.by_name(', 'Initializer.by_name(key) == value', 'TokenEmbedder.by_name(', 'TokenEmbedder.by_name(', 'TextFieldEmbedder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['not in list_fn()', 'get_fn() == fake', 'list_fn()[0] == current_default', 'list_fn()[0] == ', 'Registry.get_dataset_reader(', 'Registry.get_dataset_reader(', 'Registry.get_dataset_reader(', 'Registry.get_dataset_reader(', 'Registry.get_data_iterator(', 'Registry.get_data_iterator(', 'Registry.get_data_iterator(', 'Registry.get_tokenizer(', 'Registry.get_tokenizer(', 'Registry.get_token_indexer(', 'Registry.get_token_indexer(', 'Registry.get_regularizer(', 'Registry.get_regularizer(', 'Registry.get_initializer(key) == value', 'Registry.get_token_embedder(', 'Registry.get_token_embedder(', 'Registry.get_text_field_embedder(', 'Registry.get_seq2seq_encoder(', 'Registry.get_seq2seq_encoder(', 'Registry.get_seq2seq_encoder(', 'Registry.get_seq2vec_encoder(', 'Registry.get_seq2vec_encoder(', 'Registry.get_seq2vec_encoder(', 'Registry.get_seq2vec_encoder(', 'Registry.get_similarity_function(', 'Registry.get_similarity_function(', 'Registry.get_similarity_function(', 'Registry.get_similarity_function(']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest']
47,Joel Grus,joelgrus@gmail.com,2017-07-28 10:45:14-07:00,59e1cb2f04355344e608e6de5f73fc83ec215974,https://github.com/allenai/allennlp/commit/59e1cb2f04355344e608e6de5f73fc83ec215974,"add from_params method for DataIterator subclasses (#52)

* add from_params method for DataIterator subclasses

* remove duplicate documentation

* add tests, replace get() with pop()",7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['iterator._adaptive_memory_usage_constant == 10', 'iterator._padding_memory_scaling({}) == 2.4', 'iterator._maximum_batch_size == 10000', 'iterator._batch_size == 32  # default value', 'iterator._batch_size == 10', 'iterator._sorting_keys == []', 'iterator._padding_noise == 0.1', 'not iterator._biggest_batch_first', 'iterator._batch_size == 32', 'iterator._sorting_keys == sorting_keys', 'iterator._padding_noise == 0.5', 'iterator._biggest_batch_first', 'iterator._batch_size == 100']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
48,Matt Gardner,mattg@allenai.org,2017-07-28 14:17:23-07:00,5cbfd3239f673203cc11c5cfc77ce90e9a6ce426,https://github.com/allenai/allennlp/commit/5cbfd3239f673203cc11c5cfc77ce90e9a6ce426,"Adding experiment drivers, putting the whole thing together (#27)

* Initial design of experiment API

* add drivers to registry with tests

* add driver entry point

* pylint cleanup

* fix registry import

* move optimizers to registry

* more workd on train driver

* initial pass at training loop

* some docs, argument tweaking

* add models to registry, fix imports in optimizers

* train driver tests

* cleanup, unpack kwargs properly into Driver

* refactor to use Trainer api over Drivers

* try to fix TeeLogger types

* add docstrings to private Trainer methods

* don't use Registrable as a mixin for SimpleTagger",13,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['epoch == 0'],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
49,Michael Schmitz,michael@schmitztech.com,2017-07-31 09:50:58-07:00,b427dbdec69d583e2cbd68a33b2c9309d37d4276,https://github.com/allenai/allennlp/commit/b427dbdec69d583e2cbd68a33b2c9309d37d4276,Add documentation about Getting Started with Docker (#51),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
50,Mark Neumann,markn@allenai.org,2017-07-31 10:14:12-07:00,c7e2767e24defe552c13dd62055fa8efd93b5a63,https://github.com/allenai/allennlp/commit/c7e2767e24defe552c13dd62055fa8efd93b5a63,"restore peace and order to the allennlp imports (#53)

* restore peace and order to the allennlp imports :dove:

* working towards fixing weird class attribute testing issue

* see if module level teardown fixes build

* add comment, remove logging in Regsitrable

* remove hash in comment",61,False,True,True,True,True,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(scope=)'],[],[],[],['fixture(scope=)'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
51,Matt Gardner,mattg@allenai.org,2017-07-31 11:20:38-07:00,98f6793f7013568e56fa58cf2e34757c3a2926ec,https://github.com/allenai/allennlp/commit/98f6793f7013568e56fa58cf2e34757c3a2926ec,Added highway layer (#54),3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['result.shape == (2, 2)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
52,Matt Gardner,mattg@allenai.org,2017-07-31 11:43:31-07:00,adce8841b398b861a88e468d6cb20658d1a86fae,https://github.com/allenai/allennlp/commit/adce8841b398b861a88e468d6cb20658d1a86fae,"Adding some tensor operations around softmaxes and masks (#55)

* Adding some tensor operations around softmaxes and masks

* Fix pylint error

* Fixes from Mark",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['softmax_tensor.shape == (batch_size, length_1, length_2, num_options)', 'softmax_tensor.shape == (batch_size, length_1, length_2, num_options)', 'aggregated_array.shape == (batch_size, embedding_dim)', 'aggregated_array.shape == (batch_size, length_1, length_2, embedding_dim)', 'aggregated_array.shape == (batch_size, length_1, length_2, embedding_dim)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
53,Joel Grus,joelgrus@gmail.com,2017-07-31 16:24:51-07:00,7571c2aed37d55c7777a5fd7156720690f74b4f5,https://github.com/allenai/allennlp/commit/7571c2aed37d55c7777a5fd7156720690f74b4f5,"unified CLI (#57)

* start of commands

* new cli

* fix pylint issue

* remove cli, add test

* more tests

* add test

* fix stupid mistake

* rename tests

*  address pr comments",8,False,True,True,True,True,False,False,False,False,False,False,False,False,False,False,[],2,3,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,"['class TestBulk(TestCase):', 'class TestMain(TestCase):']","[('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name'), ('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name'), ('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name')]",[],[],[],[],[],[],[],[],[],['class TestMain(TestCase):'],"[('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name')]",[],[],[],[],[],[],[],[],[],"['args.func == bulk', 'args.model == ', 'args.input_file == ', 'args.output_file == ', 'args.print', 'os.path.exists(outfile)', 'len(lines) == 2', 'lines[0] == {}', 'lines[1] == {}', 'cm.exception.code == 2  # argparse code for incorrect usage', 'cm.exception.code == -1', 'cm.exception.code == 2  # argparse code for incorrect usage']",[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(outfile)', 'len(lines) == 2', 'lines[0] == {}', 'lines[1] == {}', 'cm.exception.code == -1']",[],[],[],[],[],[],[],[],[],[],[],[]
54,Michael Schmitz,michael@schmitztech.com,2017-08-01 08:16:39-07:00,efba1309cb02d178c037e0ec7754aaa4453559fc,https://github.com/allenai/allennlp/commit/efba1309cb02d178c037e0ec7754aaa4453559fc,Set locale in Dockerfiles. (#62),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
55,Mark Neumann,markn@allenai.org,2017-08-01 12:26:08-07:00,971100f9204a869a28bf57e4ec7c780376d88e9e,https://github.com/allenai/allennlp/commit/971100f9204a869a28bf57e4ec7c780376d88e9e,"SRL model (#58)

* half way through srl model

* add viterbi alg and tests

* add srl model and tests

* fix text field bug

* remove rouge print statement

* add SRL model with tests

* add viterbi docstring

* make mypy happy

* fix up models and tests

* add hand checked viterbi test, refactor save_and_load

* misc fixes and touch ups

* add get_input_dim to encoder api",18,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model_loss', 'loaded_model_loss', 'indices == argmax_indices.data.squeeze().tolist()', 'indices == [4, 3, 4, 3, 4, 3]', 'indices == [3, 3, 3, 3, 3, 3]', 'indices == [3, 2, 1]', 'value.numpy() == 18', 'tag in possible_tags', 'encoder.get_input_dim() == 2', 'encoder.get_input_dim() == 2', 'encoder.get_input_dim() == 5', 'encoder.get_input_dim() == 5', 'encoder.get_input_dim() == 2', 'encoder.get_input_dim() == 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
56,Matt Gardner,mattg@allenai.org,2017-08-01 13:47:43-07:00,e4c9540147b3bf140df587380b09815ef21b455f,https://github.com/allenai/allennlp/commit/e4c9540147b3bf140df587380b09815ef21b455f,"Bidirectional attention flow (#49)

* Initial skeleton of BiDAF (still plenty of missing functions)

* Got BiDAF passing the initial forward() test

* Added inference code

* Fixed pylint and mypy

* Minor clean up

* Better docs, other minor fixes",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['span_start >= 0', 'span_start < span_end', 'span_end < passage.sequence_length()', 'begin_end_idxs == (1, 2)', 'begin_end_idxs == (0, 1)', 'begin_end_idxs == (1, 2)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
57,Michael Schmitz,michael@schmitztech.com,2017-08-01 13:53:41-07:00,fa7ac778fa8d6a9abebfce4f0cd1c08b76144fc9,https://github.com/allenai/allennlp/commit/fa7ac778fa8d6a9abebfce4f0cd1c08b76144fc9,Add support to the CLI to serve the web service (#59),5,False,True,True,True,False,False,False,False,False,False,False,False,False,False,False,[],1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,['class TestServe(TestCase):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.func == serve', 'args.backend == ', 'args.port == 8000']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
58,Joel Grus,joelgrus@gmail.com,2017-08-01 15:53:40-07:00,284f484ed780dfecc7c4426a0353458442ffe5d5,https://github.com/allenai/allennlp/commit/284f484ed780dfecc7c4426a0353458442ffe5d5,"consolidate CLI entry points (#68)

* consolidate CLI entry points

* add missing file

* cli

* one more test",11,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.func == train_model_from_file', 'args.param_path == ', 'cm.exception.code == 2  # argparse code for incorrect usage']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
59,Mark Neumann,markn@allenai.org,2017-08-01 16:15:41-07:00,455b2f3ad60adb9a173d87f59c363b000c516bc3,https://github.com/allenai/allennlp/commit/455b2f3ad60adb9a173d87f59c363b000c516bc3,"Nll masking (#63)

* replace sequence loss in models with masked loss

* working loss with masking, beginning integrations with models

* lint

* address matt's comments

* add masked log softmax

* add some log softmax tests

* remove unnecessary comment and change nll name",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['loss.data.numpy() == loss2.data.numpy()', 'loss.data.numpy() == vector_loss.data.sum() / 4']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
60,Mark Neumann,markn@allenai.org,2017-08-01 16:24:01-07:00,187da44e3e1ef5ef92f987da9fa974eefca6781f,https://github.com/allenai/allennlp/commit/187da44e3e1ef5ef92f987da9fa974eefca6781f,"add ensure_batch_dimension to arrays_to_variables (#69)

* add ensure_batch_dimension to arrays_to_variables

* remove conditional on dimensions, add to bidaf",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
61,Matt Gardner,mattg@allenai.org,2017-08-01 16:31:12-07:00,799c0c0daa7732a9ee537d2fb9e86f92c6b3176b,https://github.com/allenai/allennlp/commit/799c0c0daa7732a9ee537d2fb9e86f92c6b3176b,"Allow projecting the embedding layer (#65)

* Allow projecting the embedding layer

* Make embeddings handle higher-order inputs",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['embedding_layer.get_output_dim() == 3', 'embedding_layer.get_output_dim() == 4', 'embedding_layer.get_output_dim() == 2', 'embedded.shape == (1, 4, 20)', 'embedded.shape == (1, 1, 4, 20)']",[],[],[],[],[],[],[],[],[],[],[],[],"['embedding_layer.embedding_dim == 3', 'embedding_layer.embedding_dim == 4']",[],[],[],[],[],[],[],[],[],[],[],[]
62,Matt Gardner,mattg@allenai.org,2017-08-01 16:39:14-07:00,3bf6f6d44248c9f3ba8fc943fff648c1fccadd6b,https://github.com/allenai/allennlp/commit/3bf6f6d44248c9f3ba8fc943fff648c1fccadd6b,"Added a FeedForward layer (#66)

* Added an Activation registry

* Fix test / lint errors

* Added a FeedForward layer

* Added some tests, made them pass",18,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['output.shape == (1, 3)']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
63,Michael Schmitz,michael@schmitztech.com,2017-08-01 16:51:11-07:00,277effc346e10d272aa8a5617c2780315e588ea7,https://github.com/allenai/allennlp/commit/277effc346e10d272aa8a5617c2780315e588ea7,"Add a kubernetes file for the web demo. (#70)

* Expose port in Dockerfile.

* First pass on webdemo kube yaml.

* Set the host to 0.0.0.0.

* Improvements to the kubernetes webdemo yaml.",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
64,Joel Grus,joelgrus@gmail.com,2017-08-02 12:48:38-07:00,d4253ecd138763d0577a5ad821342e11e27606e5,https://github.com/allenai/allennlp/commit/d4253ecd138763d0577a5ad821342e11e27606e5,"move default sanic logs to /tmp (#73)

* move default logs to /tmp

* remove now unnecessary cleanup

* fix pylint errors",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['def tearDown(self):', 'def tearDown(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
65,Matt Gardner,mattg@allenai.org,2017-08-02 14:22:45-07:00,b9eea07b22f9b9da6aee36159b71879f8350ef6a,https://github.com/allenai/allennlp/commit/b9eea07b22f9b9da6aee36159b71879f8350ef6a,"Implemented decomposable attention model (#67)

* Implemented decomposable attention model

* Moving SNLI data to fixtures, implemented inference

* Fixing bug in BiDAF._get_best_span

* Added tests for DecomposableAttention, made them pass

* Fix pylint errors

* Making bidaf training test smaller, to see if that speeds up CI

* Fixes from Mark",9,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],"['begin_end_idxs == (0, 1)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
66,Mark Neumann,markn@allenai.org,2017-08-02 16:04:59-07:00,cf20c74c9be08800e9feb1c622c6ecc4f03899a3,https://github.com/allenai/allennlp/commit/cf20c74c9be08800e9feb1c622c6ecc4f03899a3,"Wrapper api improvements (#74)

* re-work wrapper api to allow non-pytorch recurrent modules

* fix state accumulation so it persists for all batch elements

* lint fixes

* remove print statements

* make states have a uniform input dimension, address matt's comments",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.token_embedder(self.inputs).size() == (1, 4, 10)']",[],[],[],[],[],[],[],[],[],[],[],[],"['self.token_embedder.forward(self.inputs).size() == (1, 4, 10)']",[],[],[],[],[],[],[],[],[],[],[],[]
67,Michael Schmitz,michael@schmitztech.com,2017-08-03 10:46:22-07:00,f3033dd2f5cfbf8775aaf2247d07f9d5c85b5974,https://github.com/allenai/allennlp/commit/f3033dd2f5cfbf8775aaf2247d07f9d5c85b5974,Add the root of the project to PYTHONPATH in run.py. (#78),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
68,Joel Grus,joelgrus@gmail.com,2017-08-03 12:26:58-07:00,15e7533972a7d569ce7e49050ce02e678ac82ff8,https://github.com/allenai/allennlp/commit/15e7533972a7d569ce7e49050ce02e678ac82ff8,"Vocabulary serialization and deserialization (#75)

* move default logs to /tmp

* remove now unnecessary cleanup

* fix pylint errors

* vocabulary serialization / deserialization

* fix pylint issues

* gzip test

* change to directory

* add warning + comments

* Use set_from_file in from_files

* Append .txt to vocab files, minor formatting fixes",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,30,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab._oov_token == DEFAULT_OOV_TOKEN', 'vocab.get_token_index(DEFAULT_OOV_TOKEN) == 3', 'vocab.get_token_from_index(3) == DEFAULT_OOV_TOKEN', 'vocab.get_token_index() == 0', 'vocab.get_token_index() == 1', 'vocab.get_token_index() == 2', 'vocab.get_token_index() == 3', 'vocab.get_token_index() == 4', 'vocab.get_token_from_index(0, namespace=', 'vocab.get_token_from_index(1, namespace=', 'vocab.get_token_from_index(2, namespace=', 'vocab.get_token_from_index(3, namespace=', 'vocab.get_token_from_index(4, namespace=', 'vocab2._non_padded_namespaces == []', 'vocab2.get_vocab_size(namespace=) == 3', 'vocab2.get_token_from_index(0, namespace=', 'vocab2.get_token_from_index(1, namespace=', 'vocab2.get_token_from_index(2, namespace=', 'vocab2.get_token_index() == 0', 'vocab2.get_token_index() == 1', 'vocab2.get_token_index() == 2', 'vocab2.get_vocab_size(namespace=) == 4  # (unk + padding + two tokens)', 'vocab2.get_token_from_index(0, namespace=) == vocab._padding_token', 'vocab2.get_token_from_index(1, namespace=) == vocab._oov_token', 'vocab2.get_token_from_index(2, namespace=', 'vocab2.get_token_from_index(3, namespace=', 'vocab2.get_token_index(vocab._padding_token, namespace=) == 0', 'vocab2.get_token_index(vocab._oov_token, namespace=) == 1', 'vocab2.get_token_index() == 2', 'vocab2.get_token_index() == 3']",[],[],[],[],[],[],[],[],[],[],[],[],"['vocab._oov_token == ', 'vocab.get_token_index() == 3', 'vocab.get_token_from_index(3) == ']",[],[],[],[],[],[],[],[],[],[],[],[]
69,Matt Gardner,mattg@allenai.org,2017-08-03 15:12:28-07:00,f712e4f1be47cc31e461eebd1e948dab54140b1c,https://github.com/allenai/allennlp/commit/f712e4f1be47cc31e461eebd1e948dab54140b1c,"Moved common.tensor to nn.util (#80)

* Moved common.tensor to nn.util

* Pin sanic",19,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
70,Matt Gardner,mattg@allenai.org,2017-08-03 15:30:17-07:00,92083a3323755ba796ebcbfd5ae372c73768ea1f,https://github.com/allenai/allennlp/commit/92083a3323755ba796ebcbfd5ae372c73768ea1f,"Cleaning up a bunch of random TODOs (#79)

* Cleaning up a bunch of random TODOs

* Change as_arrays to as_array_dict",19,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
71,Matt Gardner,mattg@allenai.org,2017-08-03 15:58:02-07:00,07a86b2405480b0d18517359b7936000bcf7a11f,https://github.com/allenai/allennlp/commit/07a86b2405480b0d18517359b7936000bcf7a11f,"Moved test case to be under common/, moved `write_*` methods to use fixtures instead (#81)

* Starting to fix up AllenNlpTestCase

* sed command to fix import paths

* Finished cleaning up TestCase",56,False,True,True,True,True,True,True,True,False,False,False,False,False,False,False,[],1,0,1,0,1,0,0,0,0,0,0,1,0,5,0,1,0,0,0,0,0,0,2,0,0,0,0,1,0,0,0,1,0,0,1,2,0,0,0,0,1,0,0,0,1,0,0,1,['class AllenNlpTestCase(TestCase):'],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],['class AllenNlpTestCase(TestCase):'],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],['def tearDown(self):'],[],[],[],[],[],[],"['model_loss', 'loaded_model_loss']",[],[],[],[],['(scope=)'],[],[],[],['fixture(scope=)'],[],[],['import pytest'],"['model_loss', 'loaded_model_loss']",[],[],[],[],['(scope=)'],[],[],[],['fixture(scope=)'],[],[],['import pytest']
72,Mark Neumann,markn@allenai.org,2017-08-03 16:24:38-07:00,c54c430da19670cb030e32558b6810d04767dd99,https://github.com/allenai/allennlp/commit/c54c430da19670cb030e32558b6810d04767dd99,"SRL defaults and initializers (#77)

* add fragile sorting fix for mask

* remove batch size from trainer, add grad clipping

* add SRL defaults and initializers

* add experiment config directory

* make it obvious that the experiment configs are not finished

* add correct masking for all encoders in all models

* small fixes suggested by Matt

* fix for variable indexing

* temp addition of kwargs to cnn encoder to fit api",14,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['sorted_lengths.data.equal(torch.LongTensor([7, 5, 4, 3, 1]))', 'sorted_tensor.index_select(0, reverse_indices).data.equal(tensor.data)']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],"['sorted_lengths.equal(torch.LongTensor([7, 5, 4, 3, 1]))', 'sorted_tensor[reverse_indices].equal(tensor)']",[],[],[],[],[],[],[],[],[],[],[],[]
73,Matt Gardner,mattg@allenai.org,2017-08-03 20:19:05-07:00,abd2aa2b9ec3b4df8602be9ccd3d3390028d059d,https://github.com/allenai/allennlp/commit/abd2aa2b9ec3b4df8602be9ccd3d3390028d059d,"Fix masked max in BiDAF (#82)

* Added replace_masked_values, some other minor clean up

* Mask similarities before max in bidaf (not done yet)

* Use -1e7 instead of float(-inf)

* Remove print statements

* Remove -inf test (I thought that passed when I first wrote it...)",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
74,Mark Neumann,markn@allenai.org,2017-08-06 17:53:03-07:00,bbfbfce5c8c18b39d541d912ffb11182f7d06dfd,https://github.com/allenai/allennlp/commit/bbfbfce5c8c18b39d541d912ffb11182f7d06dfd,"Pytorch 0.2 (#97)

* use explicit non-None checks for new Variable boolean semantics

* remove squeezes after maxes

* use broadcasting in models and utils

* use matmul for similarity functions

* make replace_masked_values broadcastable

* bump version in travis and Dockerfiles

* switch back to equal shape mask replacement, minor fixes

* remove blank line",15,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model_loss is not None', 'loaded_model_loss is not None']",[],[],[],[],[],[],[],[],[],[],[],[],"['model_loss', 'loaded_model_loss']",[],[],[],[],[],[],[],[],[],[],[],[]
75,Michael Schmitz,michael@schmitztech.com,2017-08-07 09:02:23-07:00,cd2c15bcf9733144931ae9d744802768ae2d84bc,https://github.com/allenai/allennlp/commit/cd2c15bcf9733144931ae9d744802768ae2d84bc,Add test case for namespace_match. (#56),1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['util.pad_sequence_to_length([1, 2, 3], 5) == [1, 2, 3, 0, 0]', 'util.pad_sequence_to_length([1, 2, 3], 5, default_value=lambda: 2) == [1, 2, 3, 2, 2]', 'util.pad_sequence_to_length([1, 2, 3], 5, padding_on_right=False) == [0, 0, 1, 2, 3]', 'util.namespace_match()', 'util.namespace_match()', 'util.namespace_match()', 'util.namespace_match()', 'not util.namespace_match()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
76,Matt Gardner,mattg@allenai.org,2017-08-07 12:34:19-07:00,72cc9dd414ee4befbadf9bd3e4804cb2e0908e9c,https://github.com/allenai/allennlp/commit/72cc9dd414ee4befbadf9bd3e4804cb2e0908e9c,"Add exclude to initializer applicator, clean up types (#96)

* Add exclude to initializer applicator, clean up types

* Fix registrable test, and warning in nn.util

* Add back in type ignore statement; I thought it passed...

* Remove brackets",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['Initializer.by_name(key)()._init_function == value', 'initializer_applicator._exclude == to_exclude', 'initializers[]._init_function == torch.nn.init.orthogonal', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 10)', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 7)']",[],[],[],[],[],[],[],[],[],[],[],[],"['Initializer.by_name(key) == value', 'initializers[] == torch.nn.init.orthogonal']",[],[],[],[],[],[],[],[],[],[],[],[]
77,Mark Neumann,markn@allenai.org,2017-08-07 13:20:20-07:00,a19f102c65b943a668616df5f3b46cfb4376e04c,https://github.com/allenai/allennlp/commit/a19f102c65b943a668616df5f3b46cfb4376e04c,"Misc fixes (#88)

* make log_dir if it doesn't exist

* use tqdm for all dataset readers

* save vocab if log_dir exists

* fix logging error

* get around passing batch_first to custom lstms

* fix srl default params

* tentative fix for tensor creation

* use tdqm at correct abstraction in srl reader

* don't do boolean checks on tensors

* use an actual tensor in get_dropout_mask to preserve type

* ensure tensors are on cpu for logging in training loop

* raise if Datasets from readers are empty

* use os.path.join fr logging

* update config

* use incorrect american spelling of labeller

* use more sensible order for bulding things in train

* try different lstm in model

* unpack validation tensors into forward

* fix byteTensor overflow bug in masking

* pylint

* fix merge

* fixes for Matt

* fix pylint",17,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
78,Michael Schmitz,michael@schmitztech.com,2017-08-07 15:20:32-07:00,4ccd0d45c0ea1ff2199815611ca8c02f6bc857c2,https://github.com/allenai/allennlp/commit/4ccd0d45c0ea1ff2199815611ca8c02f6bc857c2,Small fixes to notebooks. (#100),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
79,Michael Schmitz,michael@schmitztech.com,2017-08-07 17:10:14-07:00,241b2755bb7285d1eaa2641ea912e44ef456d889,https://github.com/allenai/allennlp/commit/241b2755bb7285d1eaa2641ea912e44ef456d889,Remove obsolete rm since we upgraded to Pytorch 0.2. (#101),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
80,Michael Schmitz,michael@schmitztech.com,2017-08-08 07:00:51-07:00,7d4023f0f1b5487947169c2ed0d516c655985627,https://github.com/allenai/allennlp/commit/7d4023f0f1b5487947169c2ed0d516c655985627,Add instructions for pulling pre-built images from DockerHub. (#102),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
81,Matt Gardner,mattg@allenai.org,2017-08-08 13:52:36-07:00,280c8a8e0d7a6bbe9e8091cdb3075055eb2ac1de,https://github.com/allenai/allennlp/commit/280c8a8e0d7a6bbe9e8091cdb3075055eb2ac1de,"Masked values should be very negative in masked_log_softmax, not zero (#105)",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
82,Matt Gardner,mattg@allenai.org,2017-08-08 13:52:59-07:00,33773a9708a7b4d40832b24c27bb5e1c3214b5ac,https://github.com/allenai/allennlp/commit/33773a9708a7b4d40832b24c27bb5e1c3214b5ac,"Multiply by zero instead of subtracting masked elements, for better gradient behavior (#106)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
83,Matt Gardner,mattg@allenai.org,2017-08-08 16:29:57-07:00,48a653a2706f52a5809a28d266c54828c4da2a4a,https://github.com/allenai/allennlp/commit/48a653a2706f52a5809a28d266c54828c4da2a4a,"Minor training improvements (#104)

* Put debug batch logging in base class

* Make `train_model_from_file` actually take a file, not args

* Only optimize parameters that require a gradient

* Initialize BiDAF parameters

* Add missing documentation to SRL model

* Use volatile=True for validation data

* Add embedding configuration to SRL config

* Add BiDAF config

* Fix tests and pylint

* Use for_training=False in model inference methods, improve doc",13,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['args.func == _train_model_from_args'],[],[],[],[],[],[],[],[],[],[],[],[],['args.func == train_model_from_file'],[],[],[],[],[],[],[],[],[],[],[],[]
84,Joel Grus,joelgrus@gmail.com,2017-08-08 17:20:27-07:00,d9e2565f8a8ba055cd80ca50fddc73f28cf7dbd1,https://github.com/allenai/allennlp/commit/d9e2565f8a8ba055cd80ca50fddc73f28cf7dbd1,"get real models into demo (#103)

* add real model servables

* models

* write tests

* update index.html

* remove unused imports

* don't instantiate service models until actually run

* remove superfluous comment

* remove superfluous print statements

* pr comments

* fix up pr

* remove logging statements

* refactor tests",17,False,True,True,True,False,False,False,False,False,False,False,False,False,False,False,[],3,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,28,0,0,0,0,0,0,0,0,0,0,0,0,"['class TestBidafServable(TestCase):', 'class TestDecomposableAttentionServable(TestCase):', 'class TestSrlServable(TestCase):']",[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in result', 'in result', 'in result', 'in available', 'bidaf  # is not None', 'result', '])', '])']",[],[],[],[],[],[],[],[],[],[],[],[],"['lines[0] == {}', 'lines[1] == {}', 'in available', 'reverser  # is not None', '])', 'set(data.keys()) == {}', 'data[', 'data[', 'data[', 'set(data.keys()) == {}', 'data[', 'data[', 'data[', 'set(data.keys()) == {}', 'data[', 'data[', 'data[', 'set(data.keys()) == {}', 'data[', 'data[] == 1', 'isinstance(data[], list)', 'isinstance(data[][0], list)', 'set(data.keys()) == {}', '])', 'set(data.keys()) == {}', 'data[', 'data[', 'data[']",[],[],[],[],[],[],[],[],[],[],[],[]
85,Michael Schmitz,michael@schmitztech.com,2017-08-09 11:21:50-07:00,a94631a3c953810d014e7ec902e01f1b9fecb791,https://github.com/allenai/allennlp/commit/a94631a3c953810d014e7ec902e01f1b9fecb791,Create a run_on_kube.sh script (#83),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
86,Michael Schmitz,michael@schmitztech.com,2017-08-09 11:44:49-07:00,65a37c19cc7c633ab51c671508b4b39b88a5dff1,https://github.com/allenai/allennlp/commit/65a37c19cc7c633ab51c671508b4b39b88a5dff1,"Run tests on Dockerfiles. (#107)

* Run tests on Dockerfiles.

* Extend comments.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
87,Joel Grus,joelgrus@gmail.com,2017-08-09 13:33:56-07:00,475083af1d2c36634f8402737e168667fcd1965b,https://github.com/allenai/allennlp/commit/475083af1d2c36634f8402737e168667fcd1965b,"update SRL servable to use spacy POS tagger + update service docs (#109)

* update SRL servable to use spacy POS tagger + update service docs

* smarter loading to use less memory

* address pr feedback",3,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['verbs is not None', 'any(v[ for v in verbs)', 'any(v[ for v in verbs)', 'any(v[ for v in verbs)']",[],[],[],[],[],[],[],[],[],[],[],[],['result'],[],[],[],[],[],[],[],[],[],[],[],[]
88,Mark Neumann,markn@allenai.org,2017-08-09 14:49:33-07:00,9d024ef1fcc6f6f2b7521261757e9b65edd82cce,https://github.com/allenai/allennlp/commit/9d024ef1fcc6f6f2b7521261757e9b65edd82cce,"Vocab fix (#111)

* fix vocab bug

* spelling",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab.get_index_to_token_vocabulary()', 'vocab.get_index_to_token_vocabulary()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
89,Michael Schmitz,michael@schmitztech.com,2017-08-09 16:28:28-07:00,d991cb981a693c724fa3885c6a35977f4062999f,https://github.com/allenai/allennlp/commit/d991cb981a693c724fa3885c6a35977f4062999f,Add content to README. (#108),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
90,Matt Gardner,mattg@allenai.org,2017-08-09 18:33:15-07:00,e39218f5ba6bdc1962034b2d193e8e9028536bbf,https://github.com/allenai/allennlp/commit/e39218f5ba6bdc1962034b2d193e8e9028536bbf,"Add gradient clipping in the backward pass with a hook (#113)

This solves the exploding gradient problem.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
91,Mark Neumann,markn@allenai.org,2017-08-10 09:44:35-07:00,96ff2de76b5151572b1d8889f7f4808495834506,https://github.com/allenai/allennlp/commit/96ff2de76b5151572b1d8889f7f4808495834506,"Metrics (#99)

* wip metrics

* working categorical topk accuracy

* working f1 metric, added masking

* test masking case for both metrics

* better docs

* link metrics into Trainer

* fix docs and add override decorator

* fix pylint

* refactor train, fix minor metrics things

* switch to single f1, add tests for accumulation

* remove srl metrics for now

* remove print statements

* fixes from matt

* make attributes private

* fix whitespace",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,30,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['actual_accuracy == 0.50', 'actual_accuracy == 1.0', 'actual_accuracy == 0.50', 'accuracy.correct_count == 0.0', 'accuracy.total_count == 0.0', 'actual_accuracy == 0.50', 'f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 3.', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 2.0', 'f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 2.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 1.0', 'f1_measure._true_positives == 2.0', 'f1_measure._true_negatives == 6.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 4.0', 'f1_measure._true_positives == 0.0', 'f1_measure._true_negatives == 0.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 0.0', 'f1_measure._true_positives == 2.0', 'f1_measure._true_negatives == 3.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 1.0', 'f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 2.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 1.0']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
92,Joel Grus,joelgrus@gmail.com,2017-08-10 10:07:06-07:00,050504f0f1ee8b96adb4fddce468bd309ac8b746,https://github.com/allenai/allennlp/commit/050504f0f1ee8b96adb4fddce468bd309ac8b746,"refactor `Servable` model wrappers to instantiate `from_params` instead of using default values (#112)

* servables from files

* instantiate servables from params

* fix bidaf servable

* fix up srl

* decomposable attention

* pylint fixes

* use specific reader types to eliminate mypy ignores

* put all servable models in eval() mode

* remove unused import",17,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
93,Mark Neumann,markn@allenai.org,2017-08-10 12:54:48-07:00,4652d7d78aeab7601741d8c858aca04898cadb8b,https://github.com/allenai/allennlp/commit/4652d7d78aeab7601741d8c858aca04898cadb8b,"Tensorboard logging (#114)

* add tensorboard stuff

* add pillow to requirements",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
94,Michael Schmitz,michael@schmitztech.com,2017-08-10 14:26:56-07:00,5e0e771913e101fa3107ad205f01574052c27a47,https://github.com/allenai/allennlp/commit/5e0e771913e101fa3107ad205f01574052c27a47,"Improve Dockerfile. (#110)

* Improve Dockerfile.

* Improve Dockerfile.

* Cleanup dockerignore.

* Fix webdemo yaml.

* Add imagePullPolicy as we're using :latest.

* Small improvements to Dockerfile.

* Use dockerhub image for development environment.

* Correct imagePullPolicy.

* Extend changes to Dockerfile.gpu.

* Update .dockerignore",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
95,Mark Neumann,markn@allenai.org,2017-08-10 15:57:55-07:00,40211fbf8254e6e3ce5c7fed3672de740d1b73a2,https://github.com/allenai/allennlp/commit/40211fbf8254e6e3ce5c7fed3672de740d1b73a2,"make model loading able to happen across devices (#115)

* make model loading happen across devices

* fix loading",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
96,Matt Gardner,mattg@allenai.org,2017-08-10 16:10:15-07:00,b93813d033fca0b970082f714524416d0f986738,https://github.com/allenai/allennlp/commit/b93813d033fca0b970082f714524416d0f986738,"Add metrics to BiDAF (#116)

* Added a BooleanAccuracy metric

* Less verbose logging for tests

* Add metrics to BiDAF

* Fix pylint

* Only disable the worst offenders for the logging statements

* Add masking to BooleanAccuracy

* Fix pylint...",6,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['accuracy.get_metric() == 2. / 4', 'accuracy.get_metric() == 5. / 8', 'accuracy.get_metric() == 8. / 12', 'accuracy.get_metric() == 3. / 4']",[],[],[],[],[],[],[],[],[],[],[],[],"['begin_end_idxs == (1, 2)', 'begin_end_idxs == (0, 1)', 'begin_end_idxs == (0, 1)', 'begin_end_idxs == (1, 2)']",[],[],[],[],[],[],[],[],[],[],[],[]
97,Matt Gardner,mattg@allenai.org,2017-08-11 10:53:18-07:00,7e36a8ae812866f9a05de01f3947415702d43b98,https://github.com/allenai/allennlp/commit/7e36a8ae812866f9a05de01f3947415702d43b98,"Made training output more useful (#118)

* Made training output more useful

* Fix pylint

* Better name",6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
98,Matt Gardner,mattg@allenai.org,2017-08-11 13:28:06-07:00,012285881c3b3a73d6bb66b2065d3ffed28462d5,https://github.com/allenai/allennlp/commit/012285881c3b3a73d6bb66b2065d3ffed28462d5,"Add dropout to BiDAF and the character-level encoder (#120)

* Add dropout to BiDAF and the character-level encoder

* Use eval mode in tests

* Fix pylint",4,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
99,Mark Neumann,markn@allenai.org,2017-08-11 14:06:24-07:00,5d03664334c02a575a980e06812b8a7da9be8ae2,https://github.com/allenai/allennlp/commit/5d03664334c02a575a980e06812b8a7da9be8ae2,"Srl metrics (#121)

* add functions for printing to files in conll format

* fix lint

* use os.path.join in tests

* add missing import",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['conll_tags == []', 'exit_code == 0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
100,Joel Grus,joelgrus@gmail.com,2017-08-11 14:41:58-07:00,53ca2056cb948ce14bbcb92fe6133acd4d6eccda,https://github.com/allenai/allennlp/commit/53ca2056cb948ce14bbcb92fe6133acd4d6eccda,"fix int64 serialization + add tests (#125)

* fix int64 serialization + add tests

* share expensive ServableCollection.default() between tests",4,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['response.status == 200', 'in results', 'response.status == 200', 'in results', 'response.status == 200', 'in results']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
101,Joel Grus,joelgrus@gmail.com,2017-08-14 07:12:01-07:00,cced8abb6a1c7f697eba1521c196fbb58b12ce60,https://github.com/allenai/allennlp/commit/cced8abb6a1c7f697eba1521c196fbb58b12ce60,"add evaluate command and bidaf fixture to test it on (#122)

* add evaluate command and bidaf fixture to test it on

* fix pylint

* address PR comments

* reorganize tests/fixtures

* line too long",25,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['metrics == {: 0.0}'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
102,Michael Schmitz,michael@schmitztech.com,2017-08-14 09:20:19-07:00,6c9bfca6ec7a19f2ccf9d91f25c913816c4f5604,https://github.com/allenai/allennlp/commit/6c9bfca6ec7a19f2ccf9d91f25c913816c4f5604,Add a CONTRIBUTING.md (#117),4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
103,Matt Gardner,mattg@allenai.org,2017-08-14 15:27:08-07:00,b13b3cd39df68a6ccad5cc090ac2d0b907aac66f,https://github.com/allenai/allennlp/commit/b13b3cd39df68a6ccad5cc090ac2d0b907aac66f,"Small collection of misc fixes (#127)

* Small collection of misc fixes

* Also updated servable models, fixed tests",13,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
104,Matt Gardner,mattg@allenai.org,2017-08-16 12:49:17-07:00,cf19a7aedc14f3605321ddad5aaa4ab24c4fbcc0,https://github.com/allenai/allennlp/commit/cf19a7aedc14f3605321ddad5aaa4ab24c4fbcc0,"Training for decomposable attention (#128)

* Training for decomposable attention

* Fixed test

* Fixed lint",5,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
105,Michael Schmitz,michael@schmitztech.com,2017-08-16 16:14:18-07:00,9a837027e0a8b105dd524995c24e8a1bc23bcfd3,https://github.com/allenai/allennlp/commit/9a837027e0a8b105dd524995c24e8a1bc23bcfd3,"Make the demo pretty (#134)

* Add static demo assets.

* Wire up models to the API on submit.

* Wire up the triangle diagram.

* Remove flask and upgrade sanic.

* Remove code that relocates sanic log files, as it's no longer needed.",34,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in available', '])']",[],[],[],[],[],[],[],[],[],[],[],[],"['args.backend == ', 'in available', '])', 'prediction.status_code == 400', 'b in prediction.get_data()', '])']",[],[],[],[],[],[],[],[],[],[],[],[]
106,Matt Gardner,mattg@allenai.org,2017-08-16 16:28:37-07:00,4e9802ed633e4d682fbf95e424c4f0bce0802c7f,https://github.com/allenai/allennlp/commit/4e9802ed633e4d682fbf95e424c4f0bce0802c7f,"Improved Initializer construction from_params, and tests (#137)

* Improved Initializer construction from_params, and tests

* Fix bidaf tests",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.equal(parameter.data, torch.ones(parameter.size()) * 7)', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 10)', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 10)']",[],[],[],[],[],[],[],[],[],[],[],[],"['torch.equal(parameter.data, torch.ones(parameter.size()) * 10)']",[],[],[],[],[],[],[],[],[],[],[],[]
107,Joel Grus,joelgrus@gmail.com,2017-08-16 21:24:41-07:00,de488ac94ed16619b75d7dcb6357c714bc69fddd,https://github.com/allenai/allennlp/commit/de488ac94ed16619b75d7dcb6357c714bc69fddd,"""getting started"" tutorial (#131)

* getting started tutorial

* fix tests / lints / types

* left out files

* get rid of brown corpus dataset reader

* address PR comments

* address PR comments

* missing n

* tiny tutorial fixes",15,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset.instances) == 4', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
108,Michael Schmitz,michael@schmitztech.com,2017-08-17 11:09:59-07:00,b1ee5419b14328f819e6e8d9ccd99f22a0559ca7,https://github.com/allenai/allennlp/commit/b1ee5419b14328f819e6e8d9ccd99f22a0559ca7,"Forms work on start (#140)

* Remove forms to fix submit on page start.

* Stringify JSON to multiple lines.

* Correct indentation.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
109,Joel Grus,joelgrus@gmail.com,2017-08-17 14:28:02-07:00,cb2913d52765ba3d63a0c85b3da92d4e01871d8d,https://github.com/allenai/allennlp/commit/cb2913d52765ba3d63a0c85b3da92d4e01871d8d,"simplify `Servable` abstraction, rename to `Predictor` (#132)

* servable revamp

* servable stuff

* clean up tests / lints

* move default token_indexers behavior into base DatasetReader class

* add tagger servable

* predictors

* rename servable everywhere

* use spacy tokenizer in srl predictor

* fix pylint

* address pr comments

* get rid of PredictorCollection

* fix pylint issues",26,False,True,True,False,True,False,False,False,False,False,False,False,False,False,False,[],3,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,"['class TestBidafPredictor(TestCase):', 'class TestDecomposableAttentionPredictor(TestCase):', 'class TestSrlPredictor(TestCase):']",[],[],[],[],[],[],[],[],[],[],"['class TestBidafServable(TestCase):', 'class TestDecomposableAttentionServable(TestCase):', 'class TestSrlServable(TestCase):', 'class TestApp(TestCase):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['available  # not empty', 'in available', 'bidaf  # is not None', 'not collection.list_available()', 'available', 'available == []', 'test_servable', 'len(result) == 1', 'result.get(', 'len(available) == 2', 'in available', 'in available']",[],[],[],[],[],[],[],[],[],[],[],[]
110,Joel Grus,joelgrus@gmail.com,2017-08-17 16:26:40-07:00,c415b03b9940caf17fd2bcb063effffb789372c0,https://github.com/allenai/allennlp/commit/c415b03b9940caf17fd2bcb063effffb789372c0,"create actual models for the test fixtures (#143)

* move around data

* add trained srl model

* Made decomposable attention config very small

* add decomposable attention weights + update paths",19,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
111,Michael Schmitz,michael@schmitztech.com,2017-08-17 16:41:08-07:00,8de94192590f06bcc0bca155624fe67ac71c98f3,https://github.com/allenai/allennlp/commit/8de94192590f06bcc0bca155624fe67ac71c98f3,"Move notebooks into the tutorials folder. (#142)

* Move notebooks into the tutorials folder.

* Update the notebook test path.",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['self.execute_notebook()'],[],[],[],[],[],[],[],[],[],[],[],[],['self.execute_notebook()'],[],[],[],[],[],[],[],[],[],[],[],[]
112,Mark Neumann,markn@allenai.org,2017-08-17 23:06:07-07:00,6bcb76f38495767a291a1f50d5d9797f8d2a1d2b,https://github.com/allenai/allennlp/commit/6bcb76f38495767a291a1f50d5d9797f8d2a1d2b,"add span based metrics (#126)

* add span based metrics

* add existence check

* also exclude verbs from default metric for SRL model

* fixes suggested by matt

* more cleanup, change metric args to accept vocab

* make metrics less verbose during training

* better docs, add vocab to params",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['spans == {((1, 2), )}', 'spans == {((1, 2), ),', 'spans == {((6, 7), )}', 'metric._true_positives[] == 1', 'metric._true_positives[] == 0', 'not in metric._true_positives.keys()', 'metric._false_negatives[] == 0', 'metric._false_negatives[] == 1', 'not in metric._false_negatives.keys()', 'metric._false_positives[] == 1', 'metric._false_positives[] == 0', 'not in metric._false_positives.keys()', 'metric._true_positives[] == 2', 'metric._true_positives[] == 0', 'not in metric._true_positives.keys()', 'metric._false_negatives[] == 0', 'metric._false_negatives[] == 2', 'not in metric._false_negatives.keys()', 'metric._false_positives[] == 2', 'metric._false_positives[] == 0', 'not in metric._false_positives.keys()', 'metric._ignore_classes == []', 'metric._label_vocabulary == self.vocab.get_index_to_token_vocabulary()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
113,Mark Neumann,markn@allenai.org,2017-08-18 08:42:54-07:00,c9237f2b4002721280d36d71c6ff6de23ccb4ea1,https://github.com/allenai/allennlp/commit/c9237f2b4002721280d36d71c6ff6de23ccb4ea1,"split out metrics (#146)

* split out metrics

* misc cleanup and minor bug fix",14,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,57,2,0,0,0,0,0,0,0,0,0,0,2,57,2,0,0,0,0,0,0,0,0,0,0,1,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],"['accuracy.get_metric() == 2. / 4', 'accuracy.get_metric() == 5. / 8', 'accuracy.get_metric() == 8. / 12', 'accuracy.get_metric() == 3. / 4', 'actual_accuracy == 0.50', 'actual_accuracy == 1.0', 'actual_accuracy == 0.50', 'accuracy.correct_count == 0.0', 'accuracy.total_count == 0.0', 'actual_accuracy == 0.50', 'f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 3.', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 2.0', 'f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 2.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 1.0', 'f1_measure._true_positives == 2.0', 'f1_measure._true_negatives == 6.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 4.0', 'f1_measure._true_positives == 0.0', 'f1_measure._true_negatives == 0.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 0.0', 'f1_measure._true_positives == 2.0', 'f1_measure._true_negatives == 3.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 1.0', 'f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 2.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 1.0', 'spans == {((1, 2), )}', 'spans == {((1, 2), ),', 'spans == {((6, 7), )}', 'metric._true_positives[] == 1', 'metric._true_positives[] == 0', 'not in metric._true_positives.keys()', 'metric._false_negatives[] == 0', 'metric._false_negatives[] == 1', 'not in metric._false_negatives.keys()', 'metric._false_positives[] == 1', 'metric._false_positives[] == 0', 'not in metric._false_positives.keys()', 'metric._true_positives[] == 2', 'metric._true_positives[] == 0', 'not in metric._true_positives.keys()', 'metric._false_negatives[] == 0', 'metric._false_negatives[] == 2', 'not in metric._false_negatives.keys()', 'metric._false_positives[] == 2', 'metric._false_positives[] == 0', 'not in metric._false_positives.keys()', 'metric._ignore_classes == []', 'metric._label_vocabulary == self.vocab.get_index_to_token_vocabulary()']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest']","['actual_accuracy == 0.50', 'actual_accuracy == 1.0', 'actual_accuracy == 0.50', 'accuracy.correct_count == 0.0', 'accuracy.total_count == 0.0', 'actual_accuracy == 0.50', 'accuracy.get_metric() == 2. / 4', 'accuracy.get_metric() == 5. / 8', 'accuracy.get_metric() == 8. / 12', 'accuracy.get_metric() == 3. / 4', 'f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 3.', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 2.0', 'f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 2.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 1.0', 'f1_measure._true_positives == 2.0', 'f1_measure._true_negatives == 6.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 4.0', 'f1_measure._true_positives == 0.0', 'f1_measure._true_negatives == 0.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 0.0', 'f1_measure._true_positives == 2.0', 'f1_measure._true_negatives == 3.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 1.0', 'f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 2.0', 'f1_measure._false_positives == 0.0', 'f1_measure._false_negatives == 1.0', 'spans == {((1, 2), )}', 'spans == {((1, 2), ),', 'spans == {((6, 7), )}', 'metric._true_positives[] == 1', 'metric._true_positives[] == 0', 'not in metric._true_positives.keys()', 'metric._false_negatives[] == 0', 'metric._false_negatives[] == 1', 'not in metric._false_negatives.keys()', 'metric._false_positives[] == 1', 'metric._false_positives[] == 0', 'not in metric._false_positives.keys()', 'metric._true_positives[] == 2', 'metric._true_positives[] == 0', 'not in metric._true_positives.keys()', 'metric._false_negatives[] == 0', 'metric._false_negatives[] == 2', 'not in metric._false_negatives.keys()', 'metric._false_positives[] == 2', 'metric._false_positives[] == 0', 'not in metric._false_positives.keys()', 'metric._ignore_classes == []', 'metric._label_vocabulary == self.vocab.get_index_to_token_vocabulary()']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest']
114,Michael Schmitz,michael@schmitztech.com,2017-08-18 08:49:26-07:00,69488c0cf2052dd027f782087bc53c8c1fb3c491,https://github.com/allenai/allennlp/commit/69488c0cf2052dd027f782087bc53c8c1fb3c491,"Rename mc/te/srl to full names in apis. (#144)

* Rename mc/te/srl to full names in apis.

* Fix spelling of SRL.",8,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['])'],[],[],[],[],[],[],[],[],[],[],[],[],['])'],[],[],[],[],[],[],[],[],[],[],[],[]
115,Michael Schmitz,michael@schmitztech.com,2017-08-18 08:49:54-07:00,f30274310856758edce6e28d405a8e2bad4bcbce,https://github.com/allenai/allennlp/commit/f30274310856758edce6e28d405a8e2bad4bcbce,Add a flag to configure the number of sanic workers. (#148),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
116,Michael Schmitz,michael@schmitztech.com,2017-08-18 08:59:57-07:00,3318f134cb1cfabcc8562d32b05a75b30eaf404c,https://github.com/allenai/allennlp/commit/3318f134cb1cfabcc8562d32b05a75b30eaf404c,Add Sphinx support for generating HTML documentation. (#98),49,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
117,Matt Gardner,mattg@allenai.org,2017-08-18 09:37:44-07:00,851822ad709a4ce44c35ee4e77bf7a71695bb2e3,https://github.com/allenai/allennlp/commit/851822ad709a4ce44c35ee4e77bf7a71695bb2e3,Make service tests only construct the app when they are run (#136),1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
118,Michael Schmitz,michael@schmitztech.com,2017-08-18 13:26:31-07:00,6c0ceb9bfeaf7bd18f7bc9d83120cdc48705db2c,https://github.com/allenai/allennlp/commit/6c0ceb9bfeaf7bd18f7bc9d83120cdc48705db2c,"Fix docker build by disabling notebook tests. (#153)

* Increase memory requirements for kubernetes-webdemo.yaml.

* Disable notebook test.",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
119,Joel Grus,joelgrus@gmail.com,2017-08-18 15:55:01-07:00,bd12252818e4376a52a28b8defa19ac090d927dd,https://github.com/allenai/allennlp/commit/bd12252818e4376a52a28b8defa19ac090d927dd,"add Model.from_files, change bulk -> predict (#149)

* add Model.from_files, change bulk -> predict

* address pr comments

* add test

* add more tests

* remove trailing newline

* rename bulk -> predict in sphinx docs

* force model to cpu or gpu

* add cpu vs gpu test

* rename model.from_files to model.load + write cpu + gpu test

* skip oom test on travis",20,False,True,True,False,False,True,True,False,False,False,False,False,False,False,False,[],1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,10,0,0,1,0,0,0,0,1,1,0,0,1,4,0,0,0,0,0,0,0,0,0,0,0,0,['class TestPredict(TestCase):'],[],[],[],[],[],[],[],[],[],[],['class TestBulk(TestCase):'],"[('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name')]",[],[],[],[],[],[],[],[],[],"['args.func == predict', 'args.config_file == ', 'args.input_file == ', 'in params', 'in params', 'model_params.pop(', 'isinstance(model, BidirectionalAttentionFlow)', 'isinstance(model, DecomposableAttention)', 'isinstance(model, SemanticRoleLabeler)', 'prediction_cpu == prediction_gpu']",[],[],['if(os.environ.get()'],[],[],[],[],['skipif(os.environ.get()'],['mark.skipif(os.environ.get()'],[],[],['import pytest'],"['args.func == bulk', 'args.model == ', 'args.input_file == ', 'cm.exception.code == -1']",[],[],[],[],[],[],[],[],[],[],[],[]
120,Michael Schmitz,michael@schmitztech.com,2017-08-18 16:22:51-07:00,564f6f845a47cc25895368a95f57bbf14771e285,https://github.com/allenai/allennlp/commit/564f6f845a47cc25895368a95f57bbf14771e285,Set port to 80. (#154),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
121,Michael Schmitz,michael@schmitztech.com,2017-08-18 16:41:04-07:00,d0410d298d302c47152d3777e58b81e0f88d3948,https://github.com/allenai/allennlp/commit/d0410d298d302c47152d3777e58b81e0f88d3948,Remove duplicate field from js. (#152),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
122,Matt Gardner,mattg@allenai.org,2017-08-20 14:22:11-07:00,3c6b56deb0a96727d4cccf6d5fde6078a04799ed,https://github.com/allenai/allennlp/commit/3c6b56deb0a96727d4cccf6d5fde6078a04799ed,"Add pytorch to requirements, so readthedocs can build (#151)

* Add pytorch to requirements, so readthedocs can build

* Move to build_tools/readthedocs/requirements.txt",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
123,Matt Gardner,mattg@allenai.org,2017-08-20 15:37:53-07:00,0d05b4a7b7db895f3c2e4ad3cb5a16588ebc629b,https://github.com/allenai/allennlp/commit/0d05b4a7b7db895f3c2e4ad3cb5a16588ebc629b,Moved docs around a bit (#156),28,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
124,Joel Grus,joelgrus@gmail.com,2017-08-21 17:49:15-07:00,4c64ef713ca922b3e328e8ba038dee12de4bbc57,https://github.com/allenai/allennlp/commit/4c64ef713ca922b3e328e8ba038dee12de4bbc57,"add model archiving (#157)

* allow tar.gz archiving of models

* add comments

* remove commented out code

* cleanup

* forgot to include model_test

* address pr comments

* skip archiving if weights file does not exist",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['keys == keys2', 'torch.equal(model.state_dict()[key], model2.state_dict()[key])', 'vocab._token_to_index == vocab2._token_to_index  # pylint: disable=protected-access', 'vocab._index_to_token == vocab2._index_to_token  # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
125,Mark Neumann,markn@allenai.org,2017-08-21 19:12:19-07:00,f312ff31ed2894382275b97084c71f7690e98104,https://github.com/allenai/allennlp/commit/f312ff31ed2894382275b97084c71f7690e98104,"add block orthogonal init for big SRL LSTM (#158)

* add block orthogonal init for big SRL lstm

* fix pylint

* add better tests and docs, address joel's comments

* add tests

* remove comment, use Variables in tests

* fix pylint",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
126,Mark Neumann,markn@allenai.org,2017-08-22 09:48:56-07:00,14f78745a7cef0f1e5b4314069d566394f860bd3,https://github.com/allenai/allennlp/commit/14f78745a7cef0f1e5b4314069d566394f860bd3,correct and augment early stopping and best model logic (#159),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
127,Mark Neumann,markn@allenai.org,2017-08-22 10:54:15-07:00,8366da17931e10ddd841c40a3f31fad7e4cf65ed,https://github.com/allenai/allennlp/commit/8366da17931e10ddd841c40a3f31fad7e4cf65ed,"use +/- to specify increasing/decreasing metrics (#160)

* use +/- to specify increasing/decreasing metrics

* correct default in from_params",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
128,Matt Gardner,mattg@allenai.org,2017-08-22 12:57:04-07:00,d670faa92354057209f50879f4b0051894a3753f,https://github.com/allenai/allennlp/commit/d670faa92354057209f50879f4b0051894a3753f,"Use Params.from_file, add total to evaluate generator (#161)

* Use Params.from_file, add total to evaluate generator

* Fixed pylint and test errors",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
129,Matt Gardner,mattg@allenai.org,2017-08-22 16:32:00-07:00,382047bde4cd1a27ebaf92baa71dd10a68376833,https://github.com/allenai/allennlp/commit/382047bde4cd1a27ebaf92baa71dd10a68376833,"Fix embedding loading, and remove defaults in model `from_params` methods (#155)

* Switch other models / modules

* Done with refactoring

* Fixed pylint

* Fixed docs

* Removed loading_saved_model flag

* Add a common explaining _why_ we remove the embedding file",17,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,4,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tuple(embedding_weights.size()) == (4, 3)  # 4 because of padding and OOV', 'not numpy.allclose(word_vector.numpy(), numpy.array([1.0, 2.3, -1.0]))']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],"['embedding_layer.get_output_dim() == 3', 'embedding_layer.get_output_dim() == 4', 'embedding_layer.get_output_dim() == 2', 'not numpy.allclose(word_vector.numpy()[:2], numpy.array([0.1, 0.4]))']",['(Exception)'],[],[],[],[],[],[],[],[],[],[],[]
130,Joel Grus,joelgrus@gmail.com,2017-08-22 20:17:48-07:00,46614d6ee4894036968d81a361f24387249f34b5,https://github.com/allenai/allennlp/commit/46614d6ee4894036968d81a361f24387249f34b5,"add caching utils (#165)

* local file caching

* add missing file

* add comments

* address pr comments",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not in filename', 'back_to_url == url', 'filename == os.path.join(self.TEST_DIR, url_to_filename(url))', 'len(responses.calls) == 1', 'cached_file.read() == glove_bytes', 'filename2 == filename', 'len(responses.calls) == 1', 'cached_file.read() == glove_bytes', 'cached_path(glove_file) == glove_file', 'len(responses.calls) == 1', 'filename == os.path.join(self.TEST_DIR, url_to_filename(url))', 'cached_file.read() == glove_bytes']","['(FileNotFoundError)', '(ValueError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
131,Joel Grus,joelgrus@gmail.com,2017-08-22 20:52:19-07:00,eed0d42f7ae50bc2238e2494cd576f46eca34f13,https://github.com/allenai/allennlp/commit/eed0d42f7ae50bc2238e2494cd576f46eca34f13,"replace `from_config` everything with `from_archive` (#163)

* replace from_config with from_archive

* remove predictor.from_config altogether, add archives to test fixtures

* really fix merge conflict

* add vocab to Model constructor, remove from Archive namedtuple

* update archive files with embedding_dim key",23,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.archive_file == ', 'len(results) == 2', 'set(result.keys()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],"['args.config_file == ', 'len(lines) == 2']",[],[],[],[],[],[],[],[],[],[],[],[]
132,Matt Gardner,mattg@allenai.org,2017-08-23 11:53:11-07:00,f94c03f554917f6fba48efa7da8138c865231577,https://github.com/allenai/allennlp/commit/f94c03f554917f6fba48efa7da8138c865231577,Fixed bug where embedding was always trainable (#170),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
133,Mark Neumann,markn@allenai.org,2017-08-23 13:12:31-07:00,8d93d1ac21ae02018535b0efd91b98db1cb4ed74,https://github.com/allenai/allennlp/commit/8d93d1ac21ae02018535b0efd91b98db1cb4ed74,"move replace_none into params (#164)

* move replace_none into params

* make replace_none private",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
134,Joel Grus,joelgrus@gmail.com,2017-08-23 13:28:16-07:00,a4b18536d51cce146faf77d1c15dc1c01a258269,https://github.com/allenai/allennlp/commit/a4b18536d51cce146faf77d1c15dc1c01a258269,pin pyhocon to 0.3.35 (until they fix ConfigTree.pop()) (#171),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
135,Joel Grus,joelgrus@gmail.com,2017-08-23 14:08:46-07:00,8275efdf5ed5d87f7e04e8ba6dc061b1516d0e89,https://github.com/allenai/allennlp/commit/8275efdf5ed5d87f7e04e8ba6dc061b1516d0e89,use pytest.approx when comparing unarchived models (#172),1,False,True,True,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['prediction_cpu == pytest.approx(prediction_gpu)'],[],[],[],[],[],[],[],[],[],[],[],[],['prediction_cpu == prediction_gpu'],[],[],[],[],[],[],[],[],[],[],[],[]
136,Matt Gardner,mattg@allenai.org,2017-08-23 14:19:48-07:00,fb14fa7cec62f9f1224a4c6344a246250308c9c5,https://github.com/allenai/allennlp/commit/fb14fa7cec62f9f1224a4c6344a246250308c9c5,Fix calculation of patience and best epoch (#174),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
137,Joel Grus,joelgrus@gmail.com,2017-08-23 14:50:27-07:00,fd71384c9a6fb9fccb0ca4a54089349648ba728e,https://github.com/allenai/allennlp/commit/fd71384c9a6fb9fccb0ca4a54089349648ba728e,"add ""regenerate archived models"" script (#169)

* add  script

* script to autotrain fixtures, also clean up fixtures",19,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
138,Mark Neumann,markn@allenai.org,2017-08-23 15:05:20-07:00,7f00521418f63dc18c6152c67ac59ae841880a95,https://github.com/allenai/allennlp/commit/7f00521418f63dc18c6152c67ac59ae841880a95,"Embedded features (#173)

* add embedding of binary features to SRL model

* add correct experiment config for SRL

* add binary feature dim to config

* regenerate fixtures",12,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
139,Mark Neumann,markn@allenai.org,2017-08-23 16:49:51-07:00,7a8086fe4723ea195053741c1281ad326a3454ab,https://github.com/allenai/allennlp/commit/7a8086fe4723ea195053741c1281ad326a3454ab,remove erroneous print (#176),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
140,Mark Neumann,markn@allenai.org,2017-08-23 19:54:16-07:00,5623e412d0ba8e7d8f3934caf55ca98fce659752,https://github.com/allenai/allennlp/commit/5623e412d0ba8e7d8f3934caf55ca98fce659752,"Integer labels (#168)

* switch to integer labels for tag and label fields

* rename TagField to SequenceLabelField

* add sequence_feature_field, switch over srl model

* clean up docs

* re-visit logic for non-indexing in label field

* switch to labels to match API

* fix pylint and mypy

* fix archived vocabs

* fix docs

* minor fixes

* redo serialized files ...",36,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,23,2,0,0,0,0,0,0,0,0,0,0,2,24,1,0,0,0,0,0,0,0,0,0,0,1,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],"['fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[].labels()[3] == 1', 'fields[,', 'fields[].labels()[8] == 1', 'fields[,', 'fields[].labels()[2] == 1', 'fields[,', 'fields[].labels()[11] == 1', 'fields[]', 'fields[].labels() == [0, 0, 0, 0, 0]', 'fields[]', 'counter[] == 1', 'counter[] == 1', 'counter[] == 3', 'set(counter.keys()) == {}', 'sequence_label_field._indexed_labels == [b_index, i_index, o_index, o_index, o_index]']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest']","['fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[].sequence_index() == 3', 'fields[,', 'fields[].sequence_index() == 8', 'fields[,', 'fields[].sequence_index() == 2', 'fields[,', 'fields[].sequence_index() == 11', 'fields[]', 'fields[].sequence_index() is None', 'fields[]', 'counter[] == 1', 'counter[] == 1', 'counter[] == 3', 'set(counter.keys()) == {}', 'tag_field._indexed_tags == [b_index, i_index, o_index, o_index, o_index]', 'tag_field._num_tags == 3']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest']
141,Joel Grus,joelgrus@gmail.com,2017-08-24 09:50:23-07:00,166809c563f4d30342725fed524cb6fed00fe5bd,https://github.com/allenai/allennlp/commit/166809c563f4d30342725fed524cb6fed00fe5bd,"fix cpu <-> gpu test, hopefully for good (#175)

* fix cpu <-> gpu test, hopefully for good

* remove gpu test + associated fixtures / code

* fix pylint",4,False,True,True,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['prediction_cpu == pytest.approx(prediction_gpu)'],[],[],['if(os.environ.get()'],[],[],[],[],['skipif(os.environ.get()'],['mark.skipif(os.environ.get()'],[],[],['import pytest']
142,Matt Gardner,mattg@allenai.org,2017-08-24 13:04:02-07:00,b1ff55179ef4776b752f8a569aca40a979b2cf49,https://github.com/allenai/allennlp/commit/b1ff55179ef4776b752f8a569aca40a979b2cf49,"Added a script and a Dockerfile to run with beaker (#138)

* Added a script and a Dockerfile to run with beaker

* Switching to one dockerfile, with an argument, moving internal scripts

* Add option to bypass tqdm, which does not work with beaker

* Change back to allennlp-gpu

* Fix pylint and mypy

* Remove old run scripts

* Switch to making the config file a beaker dataset, instead of inside the image

* Use tqdm(disable=self._no_tqdm)

* Make mypy happy

* Remove .beaker from .gitignore",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
143,Joel Grus,joelgrus@gmail.com,2017-08-24 13:37:50-07:00,a8dcb9bc18795f09d05ec4a9101dd945595fc768,https://github.com/allenai/allennlp/commit/a8dcb9bc18795f09d05ec4a9101dd945595fc768,"updates to getting started tutorial (#177)

* local file caching

* add missing file

* add comments

* work on example

* work on tutorial

* add epochs

* add  everywhere

* revamp getting started tutorial using s3 datasets + latest code

* fix mypy complaints",14,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
144,Mark Neumann,markn@allenai.org,2017-08-24 13:58:17-07:00,db97355d56ff11d22943d70decebf543fb732191,https://github.com/allenai/allennlp/commit/db97355d56ff11d22943d70decebf543fb732191,"switch to using public attributes (#179)

* switch to using public attributes

* catch missed overrides",14,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,14,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,58,0,0,0,0,0,0,0,0,0,0,0,0,58,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('_list_field_contains_correct_sentences', '(instances[0].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields[],'), ('_list_field_contains_correct_sentences', '(instances[0].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields[],'), ('_list_field_contains_correct_sentences', '(instances[0].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields[],')]",[],[],[],[],[],[],[],[],[],[],"[('_list_field_contains_correct_sentences', '(instances[0].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[0].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[0].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields()[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields()[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields()[],')]",[],[],[],[],[],[],[],[],[],"['instances[0].fields[]', 'instances[1].fields[]', 'instances[2].fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'instances[0].fields[]', 'instances[0].fields[]', 'instances[0].fields[]', 'instances[0].fields[].sequence_index == 102', 'instances[0].fields[].sequence_index == 105', 'instances[1].fields[]', 'instances[1].fields[]', 'instances[1].fields[]', 'instances[1].fields[].sequence_index == 17', 'instances[1].fields[].sequence_index == 24', 'index_field.sequence_index == tokens_list.index(sentence_tokens)', 'instances[0].fields[].tokens == self.tokenizer.tokenize(self.question0)', 'instances[1].fields[].tokens == self.tokenizer.tokenize(self.question1)', 'instances[0].fields[].sequence_length() == 6', 'instances[1].fields[].sequence_length() == 6', 'fields[,', 'fields[].labels[3] == 1', 'fields[,', 'fields[,', 'fields[].labels[8] == 1', 'fields[,', 'fields[,', 'fields[].labels[2] == 1', 'fields[,', 'fields[,', 'fields[].labels[11] == 1', 'fields[]', 'fields[]', 'fields[].labels == [0, 0, 0, 0, 0]', 'fields[]']",[],[],[],[],[],[],[],[],[],[],[],[],"['instances[0].fields()[]', 'instances[1].fields()[]', 'instances[2].fields()[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'instances[0].fields()[]', 'instances[0].fields()[]', 'instances[0].fields()[]', 'instances[0].fields()[].sequence_index() == 102', 'instances[0].fields()[].sequence_index() == 105', 'instances[1].fields()[]', 'instances[1].fields()[]', 'instances[1].fields()[]', 'instances[1].fields()[].sequence_index() == 17', 'instances[1].fields()[].sequence_index() == 24', 'index_field.sequence_index() == tokens_list.index(sentence_tokens)', 'instances[0].fields()[].tokens() == self.tokenizer.tokenize(self.question0)', 'instances[1].fields()[].tokens() == self.tokenizer.tokenize(self.question1)', 'instances[0].fields()[].sequence_length() == 6', 'instances[1].fields()[].sequence_length() == 6', 'fields[,', 'fields[].labels()[3] == 1', 'fields[,', 'fields[,', 'fields[].labels()[8] == 1', 'fields[,', 'fields[,', 'fields[].labels()[2] == 1', 'fields[,', 'fields[,', 'fields[].labels()[11] == 1', 'fields[]', 'fields[]', 'fields[].labels() == [0, 0, 0, 0, 0]', 'fields[]']",[],[],[],[],[],[],[],[],[],[],[],[]
145,Joel Grus,joelgrus@gmail.com,2017-08-24 14:23:53-07:00,e5a33d9ef0c72a8e6d81c4de06b51ab430008ed3,https://github.com/allenai/allennlp/commit/e5a33d9ef0c72a8e6d81c4de06b51ab430008ed3,"fix metrics to ensure cpu vs gpu (#178)

* fix metrics to ensure cpu vs gpu

* factor out function

* this time it should really be correct

* switch copy_ to fill_",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
146,Matt Gardner,mattg@allenai.org,2017-08-24 14:25:57-07:00,0608921eff0b930a130b1bc7b3f2e1888f0f2735,https://github.com/allenai/allennlp/commit/0608921eff0b930a130b1bc7b3f2e1888f0f2735,"Adding an evaluation script for SQuAD (#167)

* Adding an evaluation script for SQuAD

And other miscellaneous fixes to make this actually work

* Fixes from PR feedback",9,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
147,Matt Gardner,mattg@allenai.org,2017-08-24 16:03:50-07:00,e69089d05fca0ac850b0150ca5e6dc7322cb13c4,https://github.com/allenai/allennlp/commit/e69089d05fca0ac850b0150ca5e6dc7322cb13c4,"Switch word processing stuff to use Registrable, change default word splitter to spacy (#182)

* Switch word processing stuff to use Registrable, change default word splitter to spacy

* Just load the spacy tokenizer, and make it a class variable

* Make mypy happy",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
148,Matt Gardner,mattg@allenai.org,2017-08-24 17:43:55-07:00,3f1efcfabf526f727515cc29ede5e5041bf2aaeb,https://github.com/allenai/allennlp/commit/3f1efcfabf526f727515cc29ede5e5041bf2aaeb,Initialize non-pretrained words to be in the same space as pretrained words (#185),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
149,Joel Grus,joelgrus@gmail.com,2017-08-24 20:26:33-07:00,49b2c49094e3970138bf05ab4d7cc906a8c7f0b8,https://github.com/allenai/allennlp/commit/49b2c49094e3970138bf05ab4d7cc906a8c7f0b8,file caching respects etag (#184),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['back_to_url == url', 'etag is None', 'not in filename', 'etag == ', 'filename == os.path.join(self.TEST_DIR, url_to_filename(url, etag=))', 'len(method_counts) == 2', 'method_counts[] == 1', 'method_counts[] == 1', 'cached_file.read() == self.glove_bytes', 'len(method_counts) == 2', 'method_counts[] == 2', 'method_counts[] == 1', 'cached_file.read() == self.glove_bytes', 'filename3 == os.path.join(self.TEST_DIR, url_to_filename(url, etag=))', 'len(method_counts) == 2', 'method_counts[] == 3', 'method_counts[] == 2', 'cached_file.read() == self.glove_bytes', 'cached_path(self.glove_file) == self.glove_file', 'len(responses.calls) == 2', 'filename == os.path.join(self.TEST_DIR, url_to_filename(url, etag=))', 'cached_file.read() == self.glove_bytes']",[],[],[],[],[],[],[],[],[],[],[],[],"['filename == os.path.join(self.TEST_DIR, url_to_filename(url))', 'len(responses.calls) == 1', 'cached_file.read() == glove_bytes', 'len(responses.calls) == 1', 'cached_file.read() == glove_bytes', 'cached_path(glove_file) == glove_file', 'len(responses.calls) == 1', 'filename == os.path.join(self.TEST_DIR, url_to_filename(url))', 'cached_file.read() == glove_bytes']",[],[],[],[],[],[],[],[],[],[],[],[]
150,Matt Gardner,mattg@allenai.org,2017-08-25 09:59:19-07:00,91890a4234a5099709a5c065ca0a9a3d2db068c7,https://github.com/allenai/allennlp/commit/91890a4234a5099709a5c065ca0a9a3d2db068c7,"Updated decomposable attention code to match paper (#183)

* Updated decomposable attention code to match paper

* Add test for null token

* Update bidaf config while we're at it

* Added a note to predict_entailment",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
151,Joel Grus,joelgrus@gmail.com,2017-08-25 10:19:31-07:00,91555501af2d2cf5c5d5f7fcb7971f32e9dd3fec,https://github.com/allenai/allennlp/commit/91555501af2d2cf5c5d5f7fcb7971f32e9dd3fec,"don't manually add the config file to the params for archiving (#187)

* don't manually add the config file to the params for archiving purposes, it's already there

* add test for params

* rename serialization_prefix to serialization_dir",19,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['params2.as_dict() == params_copy'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
152,Joel Grus,joelgrus@gmail.com,2017-08-25 11:20:47-07:00,e91cbab2a174a76f65a2cf7361644357a1e51cb2,https://github.com/allenai/allennlp/commit/e91cbab2a174a76f65a2cf7361644357a1e51cb2,"move serialization_dir from config file to command line arg to train (#192)

* move serialization_dir from config file to command line arg to train

* update code comments",17,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.serialization_dir == ', 'cm.exception.code == 2  # argparse code for incorrect usage']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
153,Matt Gardner,mattg@allenai.org,2017-08-25 11:56:19-07:00,7221a2c7f78f368aec42ca1af3bc0d8c64d299ea,https://github.com/allenai/allennlp/commit/7221a2c7f78f368aec42ca1af3bc0d8c64d299ea,"Make logging nicer, update beaker script (#193)",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
154,Matt Gardner,mattg@allenai.org,2017-08-25 14:47:58-07:00,40ec35876d38c4797ad3ee9bf911b019faa5a61d,https://github.com/allenai/allennlp/commit/40ec35876d38c4797ad3ee9bf911b019faa5a61d,"Removed default initialization (#194)

* Removed default initialization

* Added logging for unused regexes and uninitialized parameters",22,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.equal(parameter.data, torch.ones(parameter.size()) * 5)', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 10)', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 10)', 'initializer_applicator._exclude == to_exclude', 'initializers[]._init_function == torch.nn.init.orthogonal', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 10)', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 7)']",[],[],[],[],[],[],[],[],[],[],[],[]
155,Joel Grus,joelgrus@gmail.com,2017-08-25 16:06:22-07:00,e20e3fee82c6831872c62518dd91d71f8515ae34,https://github.com/allenai/allennlp/commit/e20e3fee82c6831872c62518dd91d71f8515ae34,deep_qa -> allennlp (#197),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
156,Matt Gardner,mattg@allenai.org,2017-08-25 18:22:54-07:00,a4391fb1783c183b85c27d8cbee29baef502afb7,https://github.com/allenai/allennlp/commit/a4391fb1783c183b85c27d8cbee29baef502afb7,"Simplify the highway layer (#195)

* Simplify the highway layer

* Update fixtures for the modified highway layer

* Sort uninitialized parameter list",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
157,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-08-26 13:12:11-07:00,75aeee8231389d8fb8bc21f1c0302ba46275d3c6,https://github.com/allenai/allennlp/commit/75aeee8231389d8fb8bc21f1c0302ba46275d3c6,"Track parameters in tensorboard (#196)

* Add simple tensorboard tracking of parameters

* Add tracking of gradients

* Fix typos in code

* Rename vars",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
158,Mark Neumann,markn@allenai.org,2017-08-27 09:08:14-07:00,1fac6d0d396f2035b49443067d835c027ebce5c5,https://github.com/allenai/allennlp/commit/1fac6d0d396f2035b49443067d835c027ebce5c5,add embedding dropout to srl model (#202),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
159,Mark Neumann,markn@allenai.org,2017-08-27 09:20:53-07:00,a0066ca3d64783915c5e1604773f314a3186dee4,https://github.com/allenai/allennlp/commit/a0066ca3d64783915c5e1604773f314a3186dee4,"add default initialization to augmented lstm (#200)

* add default initialization to augmented lstm

* simplify experiment config",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
160,Mark Neumann,markn@allenai.org,2017-08-27 09:30:46-07:00,a9d04a6ea811918545e3e3d4069c438df695fb8b,https://github.com/allenai/allennlp/commit/a9d04a6ea811918545e3e3d4069c438df695fb8b,"add LearningRateSchedulers (#201)

* add LearningRateSchedulers

* fix spacing

* rename private class in import",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['LearningRateScheduler.by_name(key) == value'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
161,Matt Gardner,mattg@allenai.org,2017-08-27 10:03:27-07:00,7406b2fbb4894bc30046635725f9d220fab5ec61,https://github.com/allenai/allennlp/commit/7406b2fbb4894bc30046635725f9d220fab5ec61,"Add default initialization to linear and bilinear similarity functions (#198)

* Add default initialization to linear and bilinear similarity functions

And I fixed a small BiDAF parameter bug while I was at it.

* Fix equation",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
162,Matt Gardner,mattg@allenai.org,2017-08-28 10:34:53-07:00,c96426399886503e71a4501d308bd7f7ef2aa9e9,https://github.com/allenai/allennlp/commit/c96426399886503e71a4501d308bd7f7ef2aa9e9,"Added a test for byte encoding, fixed model loading tests (#206)

* Added a test for byte encoding, fixed model loading tests

* Fixd mypy and pylint, increased tolerance threshold

* Fixed decomposable attention test",17,False,True,True,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,1,0,0,0,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['state_keys == loaded_state_keys', 'loaded_model_loss is not None', 'indexed_tokens == indexed_tokens2']",[],[],[],[],[],[],[],[],[],[],[],[],"['model_loss is not None', 'loaded_model_loss is not None', 'isinstance(model, BidirectionalAttentionFlow)', 'isinstance(model, SemanticRoleLabeler)']",[],[],[],[],['(scope=)'],[],[],[],['fixture(scope=)'],[],[],['import pytest']
163,Joel Grus,joelgrus@gmail.com,2017-08-28 12:39:14-07:00,311db7f69ac809ceb4c1a47d1fe8da1203b4947b,https://github.com/allenai/allennlp/commit/311db7f69ac809ceb4c1a47d1fe8da1203b4947b,download urls to tempfile then copy to cache (#207),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
164,Mark Neumann,markn@allenai.org,2017-08-28 13:48:03-07:00,4b4c64fae8fe796cf57789c83bcfe9d15fcbc70d,https://github.com/allenai/allennlp/commit/4b4c64fae8fe796cf57789c83bcfe9d15fcbc70d,indent config so we can read it (#208),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
165,Matt Gardner,mattg@allenai.org,2017-08-28 13:48:28-07:00,0a2973dfa4cea16c18a1379c12f054d5418989de,https://github.com/allenai/allennlp/commit/0a2973dfa4cea16c18a1379c12f054d5418989de,"Add best span string as output to `predict_span` (#209)

* Added best span string as output to `predict_span`

* Fixed test",3,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(result.keys()) == {,', 'isinstance(output_dict[], str)']",[],[],[],[],[],[],[],[],[],[],[],[],['set(result.keys()) == {}'],[],[],[],[],[],[],[],[],[],[],[],[]
166,Matt Gardner,mattg@allenai.org,2017-08-28 14:05:24-07:00,eb3637240e7e0c374c051c1381c4dce4af65f8f6,https://github.com/allenai/allennlp/commit/eb3637240e7e0c374c051c1381c4dce4af65f8f6,"Fix beaker train script, update BiDAF args (#210)",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
167,Michael Schmitz,michael@schmitztech.com,2017-08-29 06:07:15-07:00,6f1f38892132654010fa829ad9ae0142b96167d4,https://github.com/allenai/allennlp/commit/6f1f38892132654010fa829ad9ae0142b96167d4,Add check for PYTHONHASHSEED to run. (#211),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
168,Michael Schmitz,michael@schmitztech.com,2017-08-29 10:48:57-07:00,a87b6034357320f95af0f8f141905b6f2befbb0e,https://github.com/allenai/allennlp/commit/a87b6034357320f95af0f8f141905b6f2befbb0e,"Demo improvements (#213)

* Add real models for SRL and bidaf.

* Better string output for SRL.",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
169,Michael Schmitz,michael@schmitztech.com,2017-08-29 11:44:15-07:00,fc3aa6b871ee4a60ead5648ffa3b9ab495a56ae8,https://github.com/allenai/allennlp/commit/fc3aa6b871ee4a60ead5648ffa3b9ab495a56ae8,Use argparse.FileType in predict. (#214),2,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.input_file == ', 'args.output_file == ']",[],[],[],[],[],[],[],[],[],[],[],[]
170,Michael Schmitz,michael@schmitztech.com,2017-08-29 12:06:04-07:00,8c43aaef6d54f3d1f8244a308f8e4b556b4afa64,https://github.com/allenai/allennlp/commit/8c43aaef6d54f3d1f8244a308f8e4b556b4afa64,Add back Dockerfile.cpu. (#218),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
171,Michael Schmitz,michael@schmitztech.com,2017-08-29 15:16:21-07:00,a8486e4b803d75f0a923c39da369bbbeb949f37f,https://github.com/allenai/allennlp/commit/a8486e4b803d75f0a923c39da369bbbeb949f37f,Use only one Dockerfile for both GPU and CPU (#221),7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
172,Matt Gardner,mattg@allenai.org,2017-08-29 16:44:05-07:00,725b3736d006417678097cceabcf7c974cb16ac3,https://github.com/allenai/allennlp/commit/725b3736d006417678097cceabcf7c974cb16ac3,"Require mask in encoders, update models, fix bug in BiDAF (#219)

* Require mask in encoders, update models, fix bug in BiDAF

* Fix tests",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
173,Michael Schmitz,michael@schmitztech.com,2017-08-29 19:39:27-07:00,28c2a851357776c3e0bfe8718d59e4d959bb55e9,https://github.com/allenai/allennlp/commit/28c2a851357776c3e0bfe8718d59e4d959bb55e9,Increase kubernetes memory and cpu. (#223),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
174,Matt Gardner,mattg@allenai.org,2017-08-30 09:30:53-07:00,fb73633a42053e8a0b2ce71448bad938f33a8442,https://github.com/allenai/allennlp/commit/fb73633a42053e8a0b2ce71448bad938f33a8442,"Pass instance metadata through to `forward`, use it to compute official BiDAF metrics (#216)

* Got it working...

* Fix pylint",31,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model_batch[key] == loaded_batch[key]', 'model_predictions[key] == loaded_model_predictions[key]', 'metrics == {: 0.0}', 'instances[0].fields[].tokens == self.tokenizer.tokenize(self.question0)[0]', 'instances[1].fields[].tokens == self.tokenizer.tokenize(self.question1)[0]', 'sentence[start:end] == token', 'sentence[start:end] == token', 'sentence[start:end] == token', 'sentence[start:end] == token', 'sentence[start:end] == token', 'metrics[] > 0']",[],[],[],[],[],[],[],[],[],[],[],[],"['metrics == {: 0.0}', 'instances[0].fields[].tokens == self.tokenizer.tokenize(self.question0)', 'instances[1].fields[].tokens == self.tokenizer.tokenize(self.question1)']",[],[],[],[],[],[],[],[],[],[],[],[]
175,Mark Neumann,markn@allenai.org,2017-08-30 11:52:36-07:00,850c3ab4e08bbb960dba4d69aab05665176b178d,https://github.com/allenai/allennlp/commit/850c3ab4e08bbb960dba4d69aab05665176b178d,"Predictor fix (#226)

* throw error on non string input to TextField

* fix spacy bug in srl predictor

* add type checks and tests to fields

* better message for text field

* remove unncessary parens

* remove bio tags from SRL display output",10,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
176,Matt Gardner,mattg@allenai.org,2017-08-30 12:37:31-07:00,7aee65a0b9741d92d4dac40116db527c55e2c144,https://github.com/allenai/allennlp/commit/7aee65a0b9741d92d4dac40116db527c55e2c144,"Fix byte encoding, bypassing the vocabulary (#227)

* Fix byte encoding, bypassing the vocabulary

* Fix pylint / mypy, add some comments",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
177,Joel Grus,joelgrus@gmail.com,2017-08-30 13:01:04-07:00,360455ea056561992445613b5ac6f17718623a4f,https://github.com/allenai/allennlp/commit/360455ea056561992445613b5ac6f17718623a4f,"restructure API docs + add docstrings (#224)

* rework docs

* more docs

* add docs for commands

* fix sphinx error",58,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
178,Mark Neumann,markn@allenai.org,2017-08-30 14:32:48-07:00,b5eb7469755c4813279b8367003dc38d1e331818,https://github.com/allenai/allennlp/commit/b5eb7469755c4813279b8367003dc38d1e331818,add initializer to decomp attn model (#229),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
179,Joel Grus,joelgrus@gmail.com,2017-08-30 15:33:43-07:00,61b6813b2d6185455028be7d3930fbe746fc7253,https://github.com/allenai/allennlp/commit/61b6813b2d6185455028be7d3930fbe746fc7253,"second tutorial (configuration.md) (#212)

* fixing cli

* second part of tutorial

* spell my name correctly

* remove duplicate main file

* fix docs

* fix up bugs

* fix docs

* move main function to __init__.py

* polish tutorials

* remove non_padded_namespaces from tutorial

* fix broken docs

* address PR feedback

* add GPU guidance",11,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
180,Joel Grus,joelgrus@gmail.com,2017-08-30 15:54:25-07:00,98539b39e66101f89c0ffe5b9642a093f63ed7b9,https://github.com/allenai/allennlp/commit/98539b39e66101f89c0ffe5b9642a093f63ed7b9,"first iteration on srl viz (#230)

* first iteration on srl viz

* address PR feedback",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
181,Matt Gardner,mattg@allenai.org,2017-08-30 15:55:22-07:00,495b2a03f901748e6baa4443e6578083d1345a69,https://github.com/allenai/allennlp/commit/495b2a03f901748e6baa4443e6578083d1345a69,Set tqdm description in evaluate with running metrics (#231),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
182,Matt Gardner,mattg@allenai.org,2017-08-30 15:58:08-07:00,802744c4b2157f807ba7d70d00d58aaa234ef117,https://github.com/allenai/allennlp/commit/802744c4b2157f807ba7d70d00d58aaa234ef117,Allow TimeDistributed to handle multiple inputs (#232),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
183,Mark Neumann,markn@allenai.org,2017-08-30 19:08:15-07:00,6904e2962abc196fb4095edcf02c92783941d72b,https://github.com/allenai/allennlp/commit/6904e2962abc196fb4095edcf02c92783941d72b,"Logo in readme (#233)

* add logo

* actually add logo

* fix image

* try adding logo to docs

* more styles

* remove fonts",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
184,Michael Schmitz,michael@schmitztech.com,2017-08-31 08:15:18-07:00,9c706a4e3040e40b1c97b65931d3359afc492c6c,https://github.com/allenai/allennlp/commit/9c706a4e3040e40b1c97b65931d3359afc492c6c,Remove pre-release message.,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
185,Michael Schmitz,michael@schmitztech.com,2017-08-31 08:46:59-07:00,868b88bc42aaea0208520987e784ede95e3606a8,https://github.com/allenai/allennlp/commit/868b88bc42aaea0208520987e784ede95e3606a8,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
186,Michael Schmitz,michael@schmitztech.com,2017-08-31 09:12:04-07:00,9688fd0e30135864cafe90f43f0c00e3b5111f67,https://github.com/allenai/allennlp/commit/9688fd0e30135864cafe90f43f0c00e3b5111f67,Use post3 url for PyTorch. (#235),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
187,Michael Schmitz,michael@schmitztech.com,2017-08-31 09:57:31-07:00,17c105ed5a588036606d23d62583ce432b1930bc,https://github.com/allenai/allennlp/commit/17c105ed5a588036606d23d62583ce432b1930bc,Change print to silent in predict. (#215),3,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['args.silent'],[],[],[],[],[],[],[],[],[],[],[],[],['args.print'],[],[],[],[],[],[],[],[],[],[],[],[]
188,Mark Neumann,markn@allenai.org,2017-08-31 11:46:58-07:00,e6e774aa5d323ef2cbb45ef00602bc09d0585447,https://github.com/allenai/allennlp/commit/e6e774aa5d323ef2cbb45ef00602bc09d0585447,"update setup and pip (#186)

* update setup and pip

* bump overrides dependency to allow pip installation

* add experimental travis thing

* de-screw travis and tweak setup",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
189,Matt Gardner,mattg@allenai.org,2017-08-31 12:09:08-07:00,ddbc548b8b5a070e792961def55c0005ee009e19,https://github.com/allenai/allennlp/commit/ddbc548b8b5a070e792961def55c0005ee009e19,Ensure predictions are the same when doing single vs. batched prediction. (#238),9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['single_predicted == batch_predicted, key', 'encoder(tensor, None).size() == (4, 30)']",[],[],[],[],[],[],[],[],[],[],[],[],"['encoder(tensor).size() == (4, 30)']",[],[],[],[],[],[],[],[],[],[],[],[]
190,Matt Gardner,mattg@allenai.org,2017-08-31 13:11:56-07:00,b072513a21d96bb71732c86c9f67f89085ebd03a,https://github.com/allenai/allennlp/commit/b072513a21d96bb71732c86c9f67f89085ebd03a,"Remove ""namespace"" from tutorial, play up a nice feature (#240)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
191,Mark Neumann,markn@allenai.org,2017-08-31 13:39:42-07:00,c9b52613cc3c5ab933bedddef6d63d06380e41b9,https://github.com/allenai/allennlp/commit/c9b52613cc3c5ab933bedddef6d63d06380e41b9,"move optimizer creation inside of Trainer.from_params (#237)

* move optimizer creation inside of Trainer.from_params

* increase tolerance for outputs",12,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
192,Michael Schmitz,michael@schmitztech.com,2017-08-31 14:45:04-07:00,e513bbd5f8c9ed910734a7fceea0d20a8b55983a,https://github.com/allenai/allennlp/commit/e513bbd5f8c9ed910734a7fceea0d20a8b55983a,"Update CONTRIBUTING.md

Added a section about contributing a new state-of-the-art model.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
193,Matt Gardner,mattg@allenai.org,2017-08-31 14:52:56-07:00,c9c4567163b84836ff952a9989f793ea4d559fd3,https://github.com/allenai/allennlp/commit/c9c4567163b84836ff952a9989f793ea4d559fd3,Don't write newlines to vocab file (#242),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
194,Matt Gardner,mattg@allenai.org,2017-08-31 16:00:03-07:00,614c507d88e9797fb86216e41ef6fa83e33b30f7,https://github.com/allenai/allennlp/commit/614c507d88e9797fb86216e41ef6fa83e33b30f7,"Add start/end tokens to tokenizers, instead of in readers (#228)

* Add start/end tokens to tokenizers, instead of in readers

* Add one to bytes

* Removed padding_index override, added some tests

* Fix pylint

* Move paths back, remove stop token

* Switch to inclusive span end

* Added debug output to the character span -> token span conversion

* Fix docstring, type annotation

* Fix PR comments, add a small test

* Mark flaky tests

* Fix test...",23,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics.keys() == {}', 'set(result.keys()) == {}', 'len(instances) == 5', 'instances[0].fields[]', 'instances[0].fields[]', 'instances[1].fields[]', 'instances[1].fields[]', 'instances[2].fields[]', 'instances[2].fields[]', 'instances[3].fields[]', 'instances[3].fields[]', 'instances[4].fields[]', 'instances[4].fields[]', 'token_span == (1, 4)', 'token_span == (22, 24)', 'token_span == (22, 28)', 'token_span == (184, 185)', 'instances[0].fields[]', 'instances[0].fields[].sequence_index == 104', 'instances[1].fields[]', 'instances[1].fields[].sequence_index == 23', 'instances[3].fields[]', 'instances[3].fields[]', 'instances[3].fields[]', 'answer_tokens == expected_answer_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'span_start <= span_end']",[],[],[],[],[],[],[],[],[],[],[],[],"['metrics == {: 0.0}', 'set(result.keys()) == {,', 'instances[0].fields[]', 'instances[1].fields[]', 'instances[2].fields[]', 'token_span == (1, 5)', 'token_span == (22, 25)', 'token_span == (22, 29)', 'instances[0].fields[]', 'instances[0].fields[].sequence_index == 105', 'instances[1].fields[]', 'instances[1].fields[].sequence_index == 24', 'span_start < span_end', 'isinstance(output_dict[], str)']",[],[],[],[],[],[],[],[],[],[],[],[]
195,Joel Grus,joelgrus@gmail.com,2017-08-31 17:57:19-07:00,aec6ecdf4d56d9056233f924ebf27b659635b32b,https://github.com/allenai/allennlp/commit/aec6ecdf4d56d9056233f924ebf27b659635b32b,"remove evalution_json_file key from config during load_archive (#246)

* remove evalution_json_file key from config during load_archive

* address PR feedback

* add comment referencing issue

* clean up tests

* pylint",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"[']', 'config.as_dict() == original', 'config.as_dict() != original', ']', 'config.as_dict() == original']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
196,Joel Grus,joelgrus@gmail.com,2017-09-01 07:16:22-07:00,c034eeefc69a928cc9b58c45624fc85553476887,https://github.com/allenai/allennlp/commit/c034eeefc69a928cc9b58c45624fc85553476887,"just a ton more documentation (#248)

* docs all the things

* more docs

* pylint

* evaluate -> train

* fix some rst vs md issues

* more formatting nits",55,False,True,True,True,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
197,Michael Schmitz,michael@schmitztech.com,2017-09-01 08:04:22-07:00,22c97f0da03fd7e3d4649c267c0d2d9e8ac303ae,https://github.com/allenai/allennlp/commit/22c97f0da03fd7e3d4649c267c0d2d9e8ac303ae,"Highlight answer in paragraph for MC. (#234)

* Add token information to prediction results.

* Show answer in paragraph context.",5,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['set(result.keys()) == {}'],[],[],[],[],[],[],[],[],[],[],[],[],['set(result.keys()) == {}'],[],[],[],[],[],[],[],[],[],[],[],[]
198,Michael Schmitz,michael@schmitztech.com,2017-09-01 08:31:04-07:00,87b667eb0fc2d0d84b5339255027ac7b1c698463,https://github.com/allenai/allennlp/commit/87b667eb0fc2d0d84b5339255027ac7b1c698463,"Add best_span_string back into the MC prediction API (#249)

* Add best_span_str back to API.

* Fix tests.

* Update default webdemo mc model.

* Fix pylint warning.

* Fix warning.",3,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(result.keys()) == {,']",[],[],[],[],[],[],[],[],[],[],[],[],['set(result.keys()) == {}'],[],[],[],[],[],[],[],[],[],[],[],[]
199,Mark Neumann,markn@allenai.org,2017-09-01 08:52:04-07:00,27d0a19e4a2e77cab847b0153ba77cad730ec191,https://github.com/allenai/allennlp/commit/27d0a19e4a2e77cab847b0153ba77cad730ec191,"Data tutorial (#217)

* add data pipeline

* more tutorial

* correct label field, more on the tutorial

* add test

* fix notebook tests to run with Docker, sort out regressions in vocab notebook

* fix cpu dockerfile from merge

* tutorial improvements",5,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['self.execute_notebook()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],['import pytest']
200,Matt Gardner,mattg@allenai.org,2017-09-01 10:03:41-07:00,43a06256a8792271c0687c4ed3fdf9c9b7db0e1f,https://github.com/allenai/allennlp/commit/43a06256a8792271c0687c4ed3fdf9c9b7db0e1f,"Add option to not use masking for LSTMs in BiDAF (#250)

* Add option to not use masking for LSTMs in BiDAF

* Fix docstring",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
201,Michael Schmitz,michael@schmitztech.com,2017-09-01 11:17:28-07:00,68bfb3d7db96032fa6b9c697806169a64f599d44,https://github.com/allenai/allennlp/commit/68bfb3d7db96032fa6b9c697806169a64f599d44,"Update kubernetes-webdemo configuration. (#251)

* 4 replicas.
* Explicit image version.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
202,Joel Grus,joelgrus@gmail.com,2017-09-01 12:22:07-07:00,751ba9d67fb2db860c51e58bd03ce98fcb50eed0,https://github.com/allenai/allennlp/commit/751ba9d67fb2db860c51e58bd03ce98fcb50eed0,"add cache to web server (#252)

* add caching to sanic app

* use environment variable to control cache

* fix comment

* fix mypy

* mypy

* mypy yet again",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not predictor.calls', 'response.status == 200', 'json.loads(response.text) == data', 'predictor.calls.get(key) == 1', 'len(predictor.calls) == 1', 'response.status == 200', 'json.loads(response.text) == noyes', 'predictor.calls[key] == 1', 'predictor.calls[json.dumps(noyes)] == 1', 'len(predictor.calls) == 2', 'response.status == 200', 'json.loads(response.text) == data', 'predictor.calls[key] == 1', 'predictor.calls[json.dumps(noyes)] == 1', 'len(predictor.calls) == 2', 'not predictor.calls', 'response.status == 200', 'json.loads(response.text) == data', 'predictor.calls[key] == i + 1', 'len(predictor.calls) == 1']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
203,Matt Gardner,mattg@allenai.org,2017-09-01 15:35:05-07:00,7072e4a14217010f0532389c4e9617edc7bac1a2,https://github.com/allenai/allennlp/commit/7072e4a14217010f0532389c4e9617edc7bac1a2,"Move spacy load to first call to the tokenizer (#253)

* Move spacy load to first call to the tokenizer

* Trying to fix the import bug...",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
204,Michael Schmitz,michael@schmitztech.com,2017-09-01 16:53:28-07:00,37bda52fa14e92533fea97b3d2dec3d1f2bab01a,https://github.com/allenai/allennlp/commit/37bda52fa14e92533fea97b3d2dec3d1f2bab01a,Update README.md (#255),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
205,Aaron Sarnat,aaronsarnat@users.noreply.github.com,2017-09-05 07:55:41-07:00,6d74f296fa72c8ae2a6237f6639dcb0516f877d1,https://github.com/allenai/allennlp/commit/6d74f296fa72c8ae2a6237f6639dcb0516f877d1,"styling SRL, fixing scroll bug, styling passage context, unminifying CSS (#262)",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
206,Aaron Sarnat,aaronsarnat@users.noreply.github.com,2017-09-05 07:58:52-07:00,78b9d91d8c645e669a5c17126a87aa8ceff443b8,https://github.com/allenai/allennlp/commit/78b9d91d8c645e669a5c17126a87aa8ceff443b8,fixing button working state (#263),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
207,Mark Neumann,markn@allenai.org,2017-09-05 08:48:00-07:00,96fcbe3bf616d9e65ee99880aa45d8d4744e83dc,https://github.com/allenai/allennlp/commit/96fcbe3bf616d9e65ee99880aa45d8d4744e83dc,"unify how Vocabs are created (#260)

* unify how Vocabs are created

* add tests, alter logic slightly to favour loading from file

* add semi-colon to docs

* explicitly pop off from_dataset params

* change key in Params dict",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab.get_index_to_token_vocabulary()', 'vocab.get_index_to_token_vocabulary()', 'vocab2.get_index_to_token_vocabulary(,']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
208,Michael Schmitz,michael@schmitztech.com,2017-09-05 09:21:01-07:00,235d62ccf97a6c185d44e370a021e4e0dd22efee,https://github.com/allenai/allennlp/commit/235d62ccf97a6c185d44e370a021e4e0dd22efee,Remove debugging output from TE. (#264),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
209,Michael Schmitz,michael@schmitztech.com,2017-09-05 11:17:49-07:00,3e041aa67264ab0285fd671aebad88385307c975,https://github.com/allenai/allennlp/commit/3e041aa67264ab0285fd671aebad88385307c975,Deploy allennlp/webdemo:2017.09.05 (#267),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
210,Mark Neumann,markn@allenai.org,2017-09-05 11:29:28-07:00,62f43b9851356fd800c795189506ac0a82efc2b2,https://github.com/allenai/allennlp/commit/62f43b9851356fd800c795189506ac0a82efc2b2,add decomposable attention model to demo (#261),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
211,Joel Grus,joelgrus@gmail.com,2017-09-05 12:31:23-07:00,a337ba28be078813627d4b3e60adc38f34735fef,https://github.com/allenai/allennlp/commit/a337ba28be078813627d4b3e60adc38f34735fef,get rid of relative paths in server / serve (#271),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
212,Mark Neumann,markn@allenai.org,2017-09-05 12:48:52-07:00,62f8ea655bfa0f2e91aa85b9b0b5f1f504e19f17,https://github.com/allenai/allennlp/commit/62f8ea655bfa0f2e91aa85b9b0b5f1f504e19f17,"better examples, update SRL model (#269)",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
213,Michael Schmitz,michael@schmitztech.com,2017-09-05 13:08:54-07:00,153f3c5f80ad59bb9ba49df5af314c02b64d4b83,https://github.com/allenai/allennlp/commit/153f3c5f80ad59bb9ba49df5af314c02b64d4b83,Add some documentation around releasing. (#270),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
214,Matt Gardner,mattg@allenai.org,2017-09-05 13:53:21-07:00,027b63adb2498d8482704b317255de92ce447de8,https://github.com/allenai/allennlp/commit/027b63adb2498d8482704b317255de92ce447de8,"Centralize creation of TokenIndexer dictionary (#258)

I'm not thrilled with the method name I used here, but that's easy to
change.",6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
215,Matt Gardner,mattg@allenai.org,2017-09-05 13:59:57-07:00,992774e7c566655a1395ed2869aa1b734255dcf1,https://github.com/allenai/allennlp/commit/992774e7c566655a1395ed2869aa1b734255dcf1,"Upgrade to python 3.6 (#259)

This lets us put type annotations on variables directly, instead of in
comments, so we can get rid of all of the places we had to disable
pylint's `unused-imports` check.",19,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
216,Joel Grus,joelgrus@gmail.com,2017-09-05 16:22:34-07:00,cac1594e49a71a3716af82024539a75483e47e03,https://github.com/allenai/allennlp/commit/cac1594e49a71a3716af82024539a75483e47e03,"api docs for the modules class (#268)

* modules

* remove noindex

* module docstrings

* docs

* more module docs

* fix line break",19,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
217,Matt Gardner,mattg@allenai.org,2017-09-05 16:39:42-07:00,58a813dc5ad727afd7ea0ec69912a31a7751271f,https://github.com/allenai/allennlp/commit/58a813dc5ad727afd7ea0ec69912a31a7751271f,"Adding a `text_to_instance` method on DatasetReader (#256)

* Adding a `text_to_instance` method on DatasetReader

This is so that the `Predictors`, or anything else that wants to make
predictions given a trained model, has an easier time of processing the
data in the same way the trained model did - all you need is the
instantiated `DatasetReader`, and not any private members pulled out
from that class.

Changing this on the `DatasetReaders`, though, meant changing the
`Predictors` themselves.  And that meant unifying the API around making
model predictions from single instance inputs.  I was able to remove
all of the `tag` and `predict_` methods on individual models, replacing
them with a single `Model.forward_on_instance` method.  I _think_ the
result is a lot cleaner, but I could have missed something important
when making this change - it was a whole bunch of pulling things apart
and putting them back together.

* Use text_to_instance in _process_sentence

* Moved decoding logic back into models

* Fix mypy and pylint",23,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(result.keys()) == {,', 'span_start >= 0', 'span_start <= span_end', 'span_end < self.dataset.instances[0].fields[].sequence_length()', 'isinstance(output_dict[][0], str)']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(result.keys()) == {,', 'span_start >= 0', 'span_start <= span_end', 'span_end < passage.sequence_length()', 'tag in possible_tags', 'tag in possible_tags']",[],[],[],[],[],[],[],[],[],[],[],[]
218,Joel Grus,joelgrus@gmail.com,2017-09-05 16:47:23-07:00,64ff69b72872e8f84f54e1973f25cc0827376c96,https://github.com/allenai/allennlp/commit/64ff69b72872e8f84f54e1973f25cc0827376c96,"polish tutorials (#273)

* split getting started tutorial into 3 parts

* fail on missing static dir

* remove log files

* fix merge conflict

* clean up",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(SystemExit) as cm:')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['cm.code == -1  # pylint: disable=no-member'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
219,Mark Neumann,markn@allenai.org,2017-09-05 18:01:17-07:00,dab44dd59370a07181e0d9fdc7c5b8bb1b8e518c,https://github.com/allenai/allennlp/commit/dab44dd59370a07181e0d9fdc7c5b8bb1b8e518c,use broadcasting in viterbi (#265),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
220,Matt Gardner,mattg@allenai.org,2017-09-05 19:07:48-07:00,686ba64038a8f552708f9c7bc6ec62453bb20ed6,https://github.com/allenai/allennlp/commit/686ba64038a8f552708f9c7bc6ec62453bb20ed6,"Replace hacky ""metadata"" checks with a MetadataField (#257)

There was one place where I had to leave in a check, though.  I'm not
very happy about it, but I'm not sure how to fix it.  Suggestions
welcome.",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('_fields_equal', '(model_batch[key][subfield],'), ('_fields_equal', '(model_batch[key], loaded_batch[key], 1e-6, key)'), ('_fields_equal', '(model_predictions[key],')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['field1 == field2'],[],[],[],[],[],[],[],[],[],[],[],[],"['model_batch[key] == loaded_batch[key]', 'model_predictions[key] == loaded_model_predictions[key]']",[],[],[],[],[],[],[],[],[],[],[],[]
221,Mark Neumann,markn@allenai.org,2017-09-06 01:15:46-07:00,6255788308db781f792dc73f4ab5472699f41dc1,https://github.com/allenai/allennlp/commit/6255788308db781f792dc73f4ab5472699f41dc1,"dimension matching checks for bidaf and simple_tagger (#266)

* dimension matching checks for bidaf and simple_tagger

* fix imports

* fix issue with test coverage

* more tests for bidaf and DA

* add another bidaf test, fix pylint

* use base class from_params

* make america great again",8,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
222,Michael Schmitz,michael@schmitztech.com,2017-09-06 09:11:24-07:00,2528677d5b5244116f417a8918a7469c38f04188,https://github.com/allenai/allennlp/commit/2528677d5b5244116f417a8918a7469c38f04188,Fix release README.,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
223,Michael Schmitz,michael@schmitztech.com,2017-09-06 09:53:59-07:00,5041e69be2366601a40391df8e04095ce58be65a,https://github.com/allenai/allennlp/commit/5041e69be2366601a40391df8e04095ce58be65a,"Add GA tag to web demo. (#274)

* Add GA tag to web demo.

* Only send GA stats from demo.allenai.org.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
224,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-09-06 11:36:46-07:00,9905e1b680f77d65b0fe2a7a1f8cec641b391002,https://github.com/allenai/allennlp/commit/9905e1b680f77d65b0fe2a7a1f8cec641b391002,Fix ordering of text field embedders (#276),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
225,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-09-06 11:53:09-07:00,81f46a03ce6901c1418e5e6b56e93114111f5f4e,https://github.com/allenai/allennlp/commit/81f46a03ce6901c1418e5e6b56e93114111f5f4e,"Get rid of evaluation_json_file in model  (#275)

* Remove evaluation_json in lieu of new metadata

* Add deprecation warning, minor tweaks per PR",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
226,Michael Schmitz,michael@schmitztech.com,2017-09-06 15:29:17-07:00,1cfb830762fdc45f3ed13e8f58eca975aea052d9,https://github.com/allenai/allennlp/commit/1cfb830762fdc45f3ed13e8f58eca975aea052d9,"Correct url from allenai to allennlp. (#278)

* Deploy allennlp/webdemo:2017-09-06-1

* Correct url from allenai to allennlp.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
227,Mark Neumann,markn@allenai.org,2017-09-07 08:18:40-07:00,cfe8c3110fff28030463c2bada67e852bddc1cf7,https://github.com/allenai/allennlp/commit/cfe8c3110fff28030463c2bada67e852bddc1cf7,correct python version in readme (#280),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
228,Michael Schmitz,michael@schmitztech.com,2017-09-07 08:26:38-07:00,7e178de584f819da776219b7d6e16e41e2a81167,https://github.com/allenai/allennlp/commit/7e178de584f819da776219b7d6e16e41e2a81167,"Remove bad example from MC. (#279)

* Remove bad example from MC.

* Refactor how examples are represented.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
229,Michael Schmitz,michael@schmitztech.com,2017-09-08 11:19:50-07:00,5a803781ea48fc2d17b85e744079f500d813a192,https://github.com/allenai/allennlp/commit/5a803781ea48fc2d17b85e744079f500d813a192,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
230,Mark Neumann,markn@allenai.org,2017-09-09 06:20:33+02:00,9c11c4a3a5d3b6ad8a624aba476d3020b2ebedf2,https://github.com/allenai/allennlp/commit/9c11c4a3a5d3b6ad8a624aba476d3020b2ebedf2,"minor changes to setup and readme for pip package (#283)

* minor changes to setup and readme for pip package

* clarify readme",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
231,Michael Schmitz,michael@schmitztech.com,2017-09-11 11:35:51-07:00,34135662bc882d5e65cd1b4a24e17fa3c6611fab,https://github.com/allenai/allennlp/commit/34135662bc882d5e65cd1b4a24e17fa3c6611fab,"Demo fixes (#289)

* Add favicon.ico.

* Add event argument to fix demo in FireFox.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
232,Mark Neumann,markn@allenai.org,2017-09-11 22:07:59+02:00,b4214251a9507bfe49b0f41e15ac536672d07a8a,https://github.com/allenai/allennlp/commit/b4214251a9507bfe49b0f41e15ac536672d07a8a,"fix python version compatibility (#290)

* fix python version compatibility

* update release marker",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
233,Michael Schmitz,michael@schmitztech.com,2017-09-12 14:38:36-07:00,2f2a675a70f05c32c920399d0499e9c5d25c2822,https://github.com/allenai/allennlp/commit/2f2a675a70f05c32c920399d0499e9c5d25c2822,Add DockerHub badge. (#291),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
234,Michael Schmitz,michael@schmitztech.com,2017-09-12 15:10:28-07:00,aa4dfd0cc4f1565d501651cecfe29d6e57385a9d,https://github.com/allenai/allennlp/commit/aa4dfd0cc4f1565d501651cecfe29d6e57385a9d,Update RELEASE.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
235,Joel Grus,joelgrus@gmail.com,2017-09-12 15:25:50-07:00,f7de8ebaa891072eadbee5f2a3669d54f31980cf,https://github.com/allenai/allennlp/commit/f7de8ebaa891072eadbee5f2a3669d54f31980cf,log requests (#297),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
236,Joel Grus,joelgrus@gmail.com,2017-09-12 16:17:29-07:00,f1b7a549a885db2cb96d7604dc7c99f0e0898dcb,https://github.com/allenai/allennlp/commit/f1b7a549a885db2cb96d7604dc7c99f0e0898dcb,update webdemo (#301),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
237,Joel Grus,joelgrus@gmail.com,2017-09-12 17:03:56-07:00,55580a72ac848ee0df059441b15e85d30e5e1572,https://github.com/allenai/allennlp/commit/55580a72ac848ee0df059441b15e85d30e5e1572,"better prediction logging (#302)

* better prediction logging

* add srl logging",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
238,Joel Grus,joelgrus@gmail.com,2017-09-12 17:41:32-07:00,9f6ccd53762af5321ff82a7c939db85ed5844678,https://github.com/allenai/allennlp/commit/9f6ccd53762af5321ff82a7c939db85ed5844678,bump webdemo (#307),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
239,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-09-12 23:09:04-07:00,f547e712e741c7f6e0a07ac7d794a08e3e228830,https://github.com/allenai/allennlp/commit/f547e712e741c7f6e0a07ac7d794a08e3e228830,"Change doc for span end exclusive to inclusive (#299)

* Change doc for span end exclusive to inclusive

* Update bidaf.py",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
240,Michael Schmitz,michael@schmitztech.com,2017-09-13 09:41:11-07:00,3f6854552d67ce705bb1c033a956101774acc44e,https://github.com/allenai/allennlp/commit/3f6854552d67ce705bb1c033a956101774acc44e,Use the runtime cuda images rather than devel. (#294),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
241,Joel Grus,joelgrus@gmail.com,2017-09-13 11:35:01-07:00,795266dc974290a539051f60331396ab8bbb7c7d,https://github.com/allenai/allennlp/commit/795266dc974290a539051f60331396ab8bbb7c7d,"refactor demo (#293)

* refactor demo

* fix manifest

* update Dockerfile + tutorial

* fix tests

* more test simplification

* fix test",43,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
242,Joel Grus,joelgrus@gmail.com,2017-09-13 12:57:49-07:00,8945bc8577f7fd9fd3141c818710ae152cf586e2,https://github.com/allenai/allennlp/commit/8945bc8577f7fd9fd3141c818710ae152cf586e2,"add descriptions to demo (#310)

* refactor demo

* fix manifest

* update Dockerfile + tutorial

* fix tests

* more test simplification

* fix test

* add descriptions",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
243,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-09-13 13:07:16-07:00,ba7be33b488ca6bb4fe16fb1f5a94ac62d930aa6,https://github.com/allenai/allennlp/commit/ba7be33b488ca6bb4fe16fb1f5a94ac62d930aa6,Replace deprecated --name argument to beaker (#281),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
244,Matt Gardner,mattg@allenai.org,2017-09-13 18:43:00-07:00,2c4a6e537126f4123de7c97f30587310d3712c06,https://github.com/allenai/allennlp/commit/2c4a6e537126f4123de7c97f30587310d3712c06,"Make Tokenizers return List[Token] (#311)

* Make Tokenizers return List[Token]

* Fixes from PR feedback",40,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,43,0,0,0,0,0,0,0,0,0,0,0,0,47,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[2].fields[]', '[t.text for t in instances[2].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[4].fields[]', '[t.text for t in instances[4].fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in answer_tokens] == expected_answer_tokens', 'tokens == [t.text for t in self.tokenizer.tokenize(self.question0)]', 'tokens == [t.text for t in self.tokenizer.tokenize(self.question1)]', 'tokens == [,', 'tokens == [,', 'tokens == [,', 'tokens == [,', 'tokens == []', 'token_text == expected_tokens', 'sentence[start:end] == token.text']",[],[],[],[],[],[],[],[],[],[],[],[],"['instances[0].fields[]', 'instances[0].fields[]', 'instances[1].fields[]', 'instances[1].fields[]', 'instances[2].fields[]', 'instances[2].fields[]', 'instances[3].fields[]', 'instances[3].fields[]', 'instances[4].fields[]', 'instances[4].fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'fields[]', 'instances[0].fields[]', 'instances[0].fields[]', 'instances[0].fields[]', 'instances[1].fields[]', 'instances[1].fields[]', 'instances[1].fields[]', 'instances[3].fields[]', 'instances[3].fields[]', 'instances[3].fields[]', 'answer_tokens == expected_answer_tokens', 'instances[0].fields[].tokens == self.tokenizer.tokenize(self.question0)[0]', 'instances[1].fields[].tokens == self.tokenizer.tokenize(self.question1)[0]', 'fields[,', 'fields[,', 'fields[,', 'fields[,', 'fields[]', 'tokens == expected_tokens', 'sentence[start:end] == token', 'sentence[start:end] == token', 'sentence[start:end] == token', 'sentence[start:end] == token', 'sentence[start:end] == token']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[]
245,Michael Schmitz,michael@schmitztech.com,2017-09-14 10:17:00-07:00,fb1507f03521fcbe5ffba7e7736398591f5333f8,https://github.com/allenai/allennlp/commit/fb1507f03521fcbe5ffba7e7736398591f5333f8,"Ignore empty lines in predict jsonl. (#305)

* Ignore empty lines in predict jsonl.

* Idiomatic change.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
246,Matt Gardner,mattg@allenai.org,2017-09-14 11:20:09-06:00,3ad4e7d5188858a6ce6e02ab75dbb49d66abda55,https://github.com/allenai/allennlp/commit/3ad4e7d5188858a6ce6e02ab75dbb49d66abda55,"Fixes #304 by setting random seeds (#314)

* Fixes #304 by setting random seeds

* Fix pylint and mypy",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
247,Mark Neumann,markn@allenai.org,2017-09-14 11:59:25-07:00,1aeaf611e017c787c72daf65a8a7c1fa9cb4cb5f,https://github.com/allenai/allennlp/commit/1aeaf611e017c787c72daf65a8a7c1fa9cb4cb5f,"fix epoch bug (#318)

* fix epoch bug

* correct epoch resume for restoring

* fix test",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['epoch == 1'],[],[],[],[],[],[],[],[],[],[],[],[],['epoch == 0'],[],[],[],[],[],[],[],[],[],[],[],[]
248,Mark Neumann,markn@allenai.org,2017-09-14 13:43:38-07:00,636aaebf5561965947c09bd7786115ed412069a3,https://github.com/allenai/allennlp/commit/636aaebf5561965947c09bd7786115ed412069a3,update da-config (#272),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
249,Matt Gardner,mattg@allenai.org,2017-09-14 20:08:14-06:00,d564d16b5bf4530def19312dbad7a36da6687042,https://github.com/allenai/allennlp/commit/d564d16b5bf4530def19312dbad7a36da6687042,"Build demo before copying python code, for better caching behavior (#316)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
250,Matt Gardner,mattg@allenai.org,2017-09-14 20:08:37-06:00,360df7f0920b6f7585c978ea75f71d81a0283250,https://github.com/allenai/allennlp/commit/360df7f0920b6f7585c978ea75f71d81a0283250,"Moving SQuAD metrics to a common place (#315)

* Moving SQuAD metrics to a common place

* Fix pylint",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
251,Mark Neumann,markn@allenai.org,2017-09-14 19:14:17-07:00,fc80a07f505dbef9ba4f259f7d4c512e505cfc43,https://github.com/allenai/allennlp/commit/fc80a07f505dbef9ba4f259f7d4c512e505cfc43,fix srl config (#320),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
252,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-09-14 20:07:16-07:00,c3e338f9b04898f640c7b6596d111ac267fd4661,https://github.com/allenai/allennlp/commit/c3e338f9b04898f640c7b6596d111ac267fd4661,"Letters+digits word splitter (#317)

* Add simple letters_digits word splitter

* Add tests for letters+digits word splitter",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == expected_tokens', '[t.text for t in tokens] == [t.text for t in expected_tokens]', '[t.idx for t in tokens] == [t.idx for t in expected_tokens]', 'tokens == expected_tokens']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
253,Michael Schmitz,michael@schmitztech.com,2017-09-14 20:09:57-07:00,c7da9d91c90cd04317064b5b86139e749f992a65,https://github.com/allenai/allennlp/commit/c7da9d91c90cd04317064b5b86139e749f992a65,Add MAINTAINER label to Dockerfile. (#319),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
254,Matt Gardner,mattg@allenai.org,2017-09-14 22:13:50-06:00,0f4632a3cd3090e76a124759870950a3de294cdd,https://github.com/allenai/allennlp/commit/0f4632a3cd3090e76a124759870950a3de294cdd,"Add TokenIndexers for POS tags and dependency labels (#312)

* Add TokenIndexers for POS tags and dependency labels

* Use SpacyWordSplitter in SrlPredictor

* Fix pylint

* Fix None issue",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['counter[: 2}', 'indexer.token_to_indices(tokens[1], vocab) == root_index', 'indexer.token_to_indices(tokens[-1], vocab) == none_index', 'indexer.get_padding_token() == 0', 'indexer.get_padding_lengths(0) == {}', 'padded_tokens == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'counter[: 2}', 'counter[: 2}', 'indexer.token_to_indices(tokens[1], vocab) == verb_index', 'indexer.token_to_indices(tokens[-1], vocab) == none_index', 'indexer.token_to_indices(tokens[1], vocab) == cop_index', 'indexer.get_padding_token() == 0', 'indexer.get_padding_lengths(0) == {}', 'padded_tokens == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'counter[: 1}', 'counter[: 2}']",[],[],[],[],[],[],[],[],[],[],[],[],"['counter[: 1}', 'counter[: 2}']",[],[],[],[],[],[],[],[],[],[],[],[]
255,Ibrahim Sharaf ElDen,ibrahimsharafelden@gmail.com,2017-09-15 17:20:33+02:00,e125a490b71b21e914af01e70e9b00b165d64dcd,https://github.com/allenai/allennlp/commit/e125a490b71b21e914af01e70e9b00b165d64dcd,"Iterators warning when shuffle is False (#324)

* add warnings to iterators

* more descriptive warning messages",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
256,Joel Grus,joelgrus@gmail.com,2017-09-15 13:30:49-07:00,7ef6adf2462b1f3617ca5e97fde642880179050d,https://github.com/allenai/allennlp/commit/7ef6adf2462b1f3617ca5e97fde642880179050d,"make default models and default predictors configurable (#329)

* make default models and default predictors configurable

* add test for predict override

* fix pylint issues

* fix broken serve

* fix pylint

*  add comment",12,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.func.__name__ == ', 'os.path.exists(outfile)', 'len(results) == 2', 'set(result.keys()) == {,', 'args.func.__name__ == ']",[],[],[],[],[],[],[],[],[],[],[],[],"['args.func == predict', 'args.func == serve']",[],[],[],[],[],[],[],[],[],[],[],[]
257,Mark Neumann,markn@allenai.org,2017-09-15 16:09:36-07:00,dd3ee144a661314713d4e323554084b3205ce7d4,https://github.com/allenai/allennlp/commit/dd3ee144a661314713d4e323554084b3205ce7d4,"make file format more precise (#330)

* make file format more precise

* rename fixture",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
258,Mark Neumann,markn@allenai.org,2017-09-15 18:43:22-07:00,e44b2f3ff241d034aedad5f97ee617df3ae48096,https://github.com/allenai/allennlp/commit/e44b2f3ff241d034aedad5f97ee617df3ae48096,"Token Embedder tutorial (#328)

* embedding tutorial work

* clean up notebook

* better comments in notebook

* clean up notebook

* add to tests

* address joel's comments",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['self.execute_notebook()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
259,Michael Schmitz,michael@schmitztech.com,2017-09-18 08:48:43-07:00,533662d6f817874a9ab194019b9c36deebd01179,https://github.com/allenai/allennlp/commit/533662d6f817874a9ab194019b9c36deebd01179,"Update BIDAF to use Oyvind's best model. (#331)

em: 0.6833491012298959
f1: 0.7780870748211246",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
260,Matt Gardner,mattg@allenai.org,2017-09-18 23:58:30-06:00,7f54f57bc048c08d43f7776525250ffafba6f5b8,https://github.com/allenai/allennlp/commit/7f54f57bc048c08d43f7776525250ffafba6f5b8,"Add MultiHeadedSimilarity (#333)

* Add MultiHeadedSimilarity

This is a wrapper around any similarity function that projects and
splits each tensor into multiple heads before computing the similarity.

I also moved `similarity_function.py` to be inside the
`similarity_functions` module.

* Use view instead of split/stack, add dims to test

* Fix docs",13,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(similarity._tensor_1_projection.size()) == [9, 6]', 'list(similarity._tensor_2_projection.size()) == [6, 12]', 'result.shape == (1, 1, 2, 3)']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
261,Matt Gardner,mattg@allenai.org,2017-09-19 12:56:47-07:00,5aea7b2f67bc8c928161e9fb190105782f7969d8,https://github.com/allenai/allennlp/commit/5aea7b2f67bc8c928161e9fb190105782f7969d8,"Move combine_tensor methods into a common location (#335)

* Moved combine_tensor methods into a common location

* Simplify logic, add error checking",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
262,Mark Neumann,markn@allenai.org,2017-09-19 16:33:34-07:00,4062e54c655cc78aaa4555e4756d8695d287d615,https://github.com/allenai/allennlp/commit/4062e54c655cc78aaa4555e4756d8695d287d615,"Custom extensions (#334)

* add nick's cuda lstm

* format c with clang

* add dummy initial_state to lstm

* fold in gpu build opts from pr in other repo

* add raw sru code

* fix cherrypick

* refactor SRU so we can read it

* clean up sru

* use block orth initialization

* add back in string kernel

* remove sru, highway lstm cleanup

* add test and comments

* Streams in kernel

* use fixed makefile

* test fixes

* check eval forward pass

* python changes for simpler dropout kernel interface

* new kernels

* test fixes

* fix test

* switch tests to use allennlp module, clean up custom_extensions

* use more sane way of initialising weights

* fix block orth sizes

* fix test

* more test fixes

* more test fixes

* see if additional bias is reason for discrepancy

* fix wrong self refs

* add attribute for testing

* better comments

* fix lengths as variable

* pylint clean-up

* switch to Function rather than NestedIOFunction

* fix the rest of the tests

* remove biases from augmented lstm tests

* fix tests so they don't spray warnings everywhere

* exclude custom_extensions from pylint

* rename some stuff, address pylint errors

* add alternating lstm docs

* add todo about returning state

* add compiled kernel and auto-generated C wrappers

* ignore type of C wrapper call

* better docs

* fix issue with gradient of state

* pylint

* unify arguments to module",18,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['if(not torch.cuda.is_available(), reason=)']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)']","['mark.skipif(not torch.cuda.is_available(), reason=)']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
263,Matt Gardner,mattg@allenai.org,2017-09-19 19:44:45-07:00,99fe6b1028f10f575c84f62a0af39bdb15b6cb25,https://github.com/allenai/allennlp/commit/99fe6b1028f10f575c84f62a0af39bdb15b6cb25,"Adding an intra-sentence attention encoder (with optional multi-head attention). (#336)

* Added intra-sentence attention

* Update comment, add test for from_params

* Fix tests",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,3,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['encoder.get_input_dim() == 5', 'encoder.get_output_dim() == 9', 'encoder.get_input_dim() == 5', 'encoder.get_output_dim() == 5', 'encoder.get_input_dim() == 8', 'encoder.get_output_dim() == 24', 'in exception_info.value.message', 'in exception_info.value.message', 'in exception_info.value.message', 'list(encoder_output.size()) == [4, 3, 4]  # default combination is 1,2', 'list(encoder_output.size()) == [4, 6, 24]']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
264,Mark Neumann,markn@allenai.org,2017-09-20 08:48:03-07:00,0e4277038d04a97670a091ac10380e80ca12bc81,https://github.com/allenai/allennlp/commit/0e4277038d04a97670a091ac10380e80ca12bc81,ignore custom extensions in codecov (#337),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
265,Mark Neumann,markn@allenai.org,2017-09-20 09:07:19-07:00,c6bc7fde370e54312d9fabdeec66818240b6e783,https://github.com/allenai/allennlp/commit/c6bc7fde370e54312d9fabdeec66818240b6e783,"SRL eval script (#220)

* script for SRL evaluation

* rename script

* script tweaks

* fix for sentences with no verbal predicates

* change name and remove perl script bit

* script for SRL evaluation

* rename script

* script tweaks

* fix for sentences with no verbal predicates

* change name and remove perl script bit

* make evaluation faster by doing batch prediction

* spacing

* fix viterbi decoding in SRL model, edit script to use model.decode

* make forward_on_instance call decode

* pylint

* fix out of date docstring",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['len(prediction) == length'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
266,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-09-20 17:44:50-07:00,b12517c78db605eda815a0468fd92c014e37821b,https://github.com/allenai/allennlp/commit/b12517c78db605eda815a0468fd92c014e37821b,"Fix misreading of newline-like vocab tokens (#344)

* Fix misreading of newline-like vocab tokens

* Remove whitespace tokens in spacy word splitter",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == expected_tokens', 'vocab.get_token_index() == 5', 'vocab.get_token_index() == 6', 'vocab.get_token_index() == 7', 'vocab.get_token_from_index(5) == ', 'vocab.get_token_from_index(6) == ', 'vocab.get_token_from_index(7) == ']",[],[],[],[],[],[],[],[],[],[],[],[],"['vocab.get_token_index() == 5', 'vocab.get_token_index() == 6', 'vocab.get_token_from_index(5) == ', 'vocab.get_token_from_index(6) == ']",[],[],[],[],[],[],[],[],[],[],[],[]
267,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-09-22 08:55:36-07:00,f9ee3d8b00ef4e64c9897cfc4e61e33ed7c74e8c,https://github.com/allenai/allennlp/commit/f9ee3d8b00ef4e64c9897cfc4e61e33ed7c74e8c,Fix some typos and total epoch logging (#340),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
268,Matt Gardner,mattg@allenai.org,2017-09-22 11:55:07-07:00,0b5a2ed6a226a70865d5e1ce045c91b46cf5b1b5,https://github.com/allenai/allennlp/commit/0b5a2ed6a226a70865d5e1ce045c91b46cf5b1b5,"Make reading comprehension directories (#351)

* Moved SquadReader into a reading_comprehension/ module, removed old sentence selection code

* Moved BiDAF into a reading_comprehension/ module

* Update docs",25,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,0,0,0,0,0,0,0,22,0,0,0,0,0,0,0,0,0,0,0,0,28,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('_list_field_contains_correct_sentences', '(instances[0].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields[],'), ('_list_field_contains_correct_sentences', '(instances[0].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields[],'), ('_list_field_contains_correct_sentences', '(instances[0].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields[],'), ('_list_field_contains_correct_sentences', '(instances[1].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[0].fields[],'), ('_index_field_points_to_correct_sentence', '(instances[1].fields[],')]",['def setUp(self):'],[],[],[],[],[],[],[],[],"['DatasetReader.by_name(', 'len(instances) == 5', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', 'instances[0].fields[].sequence_index == 102', 'instances[0].fields[].sequence_index == 104', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', 'instances[1].fields[].sequence_index == 17', 'instances[1].fields[].sequence_index == 23', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in answer_tokens] == expected_answer_tokens', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[', 'token_span == (1, 4)', 'token_span == (22, 24)', 'token_span == (22, 28)', 'token_span == (184, 185)']",[],[],[],[],[],[],[],[],[],[],[],[],"['DatasetReader.by_name(', 'token_span == (1, 4)', 'token_span == (22, 24)', 'token_span == (22, 28)', 'token_span == (184, 185)', 'len(instances) == 5', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', 'instances[0].fields[].sequence_index == 102', 'instances[0].fields[].sequence_index == 104', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', 'instances[1].fields[].sequence_index == 17', 'instances[1].fields[].sequence_index == 23', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in answer_tokens] == expected_answer_tokens', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[', 'expected_tokens == actual_tokens', 'index_field.sequence_index == tokens_list.index(sentence_tokens)', 'tokens == [t.text for t in self.tokenizer.tokenize(self.question0)]', 'tokens == [t.text for t in self.tokenizer.tokenize(self.question1)]', 'instances[0].fields[].sequence_length() == 6', 'instances[1].fields[].sequence_length() == 6']",[],[],[],[],[],[],[],[],[],[],[],[]
269,Mark Neumann,markn@allenai.org,2017-09-22 15:01:34-07:00,2a207ae989702dbd31d6944829890925cc939b6c,https://github.com/allenai/allennlp/commit/2a207ae989702dbd31d6944829890925cc939b6c,add flag to preserve srl model backward compatability (#341),3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
270,Joel Grus,joelgrus@gmail.com,2017-09-26 10:13:26-07:00,a58eb2cc4ab506f1611c06a308cb6a2ae710707b,https://github.com/allenai/allennlp/commit/a58eb2cc4ab506f1611c06a308cb6a2ae710707b,"big refactoring of Trainer (#353)

* refactor Trainer

* further cleanup

* clip gradients -> rescale gradients

* address PR feedback

* fix typo

* add missing line

* make global_step not optional",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
271,Mark Neumann,markn@allenai.org,2017-09-26 12:36:26-07:00,c7395e3c5b71f97983129c7c4fddced5ce341147,https://github.com/allenai/allennlp/commit/c7395e3c5b71f97983129c7c4fddced5ce341147,"Entropy (#352)

* add unwrap_variables method to base class

* add entropy metric

* pylint

* ignore type for __call__

* pr comments",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metric.get_metric() == 0.0', 'metric._entropy == 0.0', 'metric._count == 0.0', 'metric.get_metric() == 0.0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
272,Joel Grus,joelgrus@gmail.com,2017-09-26 14:13:31-07:00,5ea2eab7090c2f1c0449d1ab93c0fba318f61628,https://github.com/allenai/allennlp/commit/5ea2eab7090c2f1c0449d1ab93c0fba318f61628,"implement regularization (#347)

* make regularization happen

* have model.from_params call initialize

* better defaults

* fix docs

* add test for regularization

* remove initializer from model subclass constructors

* fix comment

* add missing test fixture

* address PR feedback

* add regularization tests

* use InitializerApplicator() instead of None

* update docstrings

* update doscstrings more

* change variable return type to float

* fix docstring that was breaking sphinx

* remove regularizer from simple_tagger",22,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['penalty == 0', '(training_loss == validation_loss).all()', '(penalty > 0).all()', '(penalty == penalty2.data).all()', '(training_loss != validation_loss).all()', '(training_loss == penalized).all()', 'isinstance(conv, L1Regularizer)', 'isinstance(linear, L2Regularizer)', 'linear.alpha == 10']",[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(regularizers[], L1Regularizer)', 'isinstance(regularizers[], L2Regularizer)', 'regularizers[].alpha == 10']",[],[],[],[],[],[],[],[],[],[],[],[]
273,Joel Grus,joelgrus@gmail.com,2017-09-26 15:17:51-07:00,67d181d574c08b857ebbc79356a37a1fe390b613,https://github.com/allenai/allennlp/commit/67d181d574c08b857ebbc79356a37a1fe390b613,"don't log metrics to console in the middle of an epoch (#355)

* don't log metrics to console in the middle of an epoch

* make pylint happy

* address PR comments",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
274,Mark Neumann,markn@allenai.org,2017-09-27 10:05:02-07:00,93dbfd68888172436949ab72e68fea75837b6f82,https://github.com/allenai/allennlp/commit/93dbfd68888172436949ab72e68fea75837b6f82,"fix train metrics being logged twice (#357)

* fix train metrics being logged twice

* use separate global step

* fix pylint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
275,Mark Neumann,markn@allenai.org,2017-09-27 15:08:25-07:00,965188fbb175ca6a0c8b26a448edc65c6a8c26aa,https://github.com/allenai/allennlp/commit/965188fbb175ca6a0c8b26a448edc65c6a8c26aa,fix lstm size bug (#356),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
276,Matt Gardner,mattg@allenai.org,2017-09-27 16:34:37-07:00,9cfae4e5b6ef33aadd84437020909cd623966089,https://github.com/allenai/allennlp/commit/9cfae4e5b6ef33aadd84437020909cd623966089,"Initial TriviaQA dataset reader (#354)

* Initial TriviaQA dataset reader

* Refactor text_to_instance - it should never return None

* Normalize human answers, add note about duplicate spans",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', 'instances[0].fields[].sequence_index == 12', 'instances[0].fields[].sequence_index == 13', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', 'instances[1].fields[].sequence_index == 38', 'instances[1].fields[].sequence_index == 39', '[t.text for t in instances[2].fields[]', '[t.text for t in instances[2].fields[]', '[t.text for t in instances[2].fields[]', 'instances[2].fields[].sequence_index == 16', 'instances[2].fields[].sequence_index == 16']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
277,Joel Grus,joelgrus@gmail.com,2017-09-28 07:10:02-07:00,c74ef958cfbfe72e04350e6fa591d72355f44a29,https://github.com/allenai/allennlp/commit/c74ef958cfbfe72e04350e6fa591d72355f44a29,persist validation metric per epoch (#359),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(val_metrics_per_epoch) == 1', 'isinstance(val_metrics_per_epoch[0], float)', 'val_metrics_per_epoch[0] != 0.']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
278,Joel Grus,joelgrus@gmail.com,2017-09-30 16:20:05-07:00,a70849dc8e0ade58f6580110f9032e2adea42b4d,https://github.com/allenai/allennlp/commit/a70849dc8e0ade58f6580110f9032e2adea42b4d,fix broken predictor + add comprehensive predictor tests (#362),4,False,True,True,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['best_span is not None', 'isinstance(best_span, list)', 'len(best_span) == 2', 'all(isinstance(x, int) for x in best_span)', 'best_span[0] <= best_span[1]', 'isinstance(best_span_str, str)', 'best_span_str != ', 'probs is not None', 'all(isinstance(x, float) for x in probs)', 'sum(probs) == approx(1.0)', 'label_probs is not None', 'isinstance(label_probs, list)', 'len(label_probs) == 3', 'all(isinstance(x, float) for x in label_probs)', 'all(x >= 0 for x in label_probs)', 'sum(label_probs) == approx(1.0)', 'label_logits is not None', 'isinstance(label_logits, list)', 'len(label_logits) == 3', 'all(isinstance(x, float) for x in label_logits)', 'e / sumexps == approx(p)', 'words == [,', 'isinstance(verbs, list)', 'tags is not None', 'isinstance(tags, list)', 'all(isinstance(tag, str) for tag in tags)', 'len(tags) == num_words']",[],[],[],[],[],[],[],[],[],[],[],[],"['in result', 'in result', 'in result']",[],[],[],[],[],[],[],[],[],[],[],[]
279,Mark Neumann,markn@allenai.org,2017-10-02 12:56:57-07:00,3b809fee6b37c6b99dd1fb5867b13e775e1f4b4d,https://github.com/allenai/allennlp/commit/3b809fee6b37c6b99dd1fb5867b13e775e1f4b4d,"make viterbi test more specific (#365)

* make viterbi test more specific

* fix comment",1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
280,nafitzgerald,nicholas.fitzgerald@gmail.com,2017-10-02 15:40:34-07:00,68f2bd43f6a66d35ac6a2c59175f4ef3d629c740,https://github.com/allenai/allennlp/commit/68f2bd43f6a66d35ac6a2c59175f4ef3d629c740,"Free GPU memory after backwards call (#367)

* Free GPU memory after backwards call

* Free host array correctly",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
281,nafitzgerald,nicholas.fitzgerald@gmail.com,2017-10-03 13:02:17-07:00,f755f5cc6fc2f98cd85ab5b5f58fe236d47d3f0a,https://github.com/allenai/allennlp/commit/f755f5cc6fc2f98cd85ab5b5f58fe236d47d3f0a,Compile highway lstm properly (was previously compiled with Python 2.7) (#371),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
282,Joel Grus,joelgrus@gmail.com,2017-10-05 14:20:11-07:00,4436287b5a92a5f031379f9373ca381f7aef5a06,https://github.com/allenai/allennlp/commit/4436287b5a92a5f031379f9373ca381f7aef5a06,"allow empty sequences as inputs to wrapped seq2vec encoders (#370)

* allow empty sequences in seq2vec encoders

* update comment

* address PR feedback

* add comment",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not (results[i] == 0.).data.all()', '(results[i] == 0.).data.all()', 'not (results[i] == 0.).data.all()', '(results[i] == 0.).data.all()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
283,nafitzgerald,nicholas.fitzgerald@gmail.com,2017-10-09 11:36:31-07:00,89aa2d0054ef47c658ebd792f2d6628a6144990c,https://github.com/allenai/allennlp/commit/89aa2d0054ef47c658ebd792f2d6628a6144990c,"Add an optional prediction map to SpanBasedF1Measure (#376)

* Added an optional prediction_map to the SpanBasedF1Measure. This allows for use when each instance can have a different set of roles.

* Added comments and a test for the prediction_map in span_based_f1_measure_test

* cleaned up for pylint checks

* Added an additional comment describing the use-case for prediction_map",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metric._true_positives[] == 1', 'metric._true_positives[] == 0', 'metric._true_positives[] == 2', 'not in metric._true_positives.keys()', 'metric._false_negatives[] == 0', 'metric._false_negatives[] == 1', 'metric._false_negatives[] == 0', 'not in metric._false_negatives.keys()', 'metric._false_positives[] == 1', 'metric._false_positives[] == 1', 'metric._false_positives[] == 0', 'not in metric._false_positives.keys()', 'metric._true_positives[] == 2', 'metric._true_positives[] == 0', 'metric._true_positives[] == 4', 'not in metric._true_positives.keys()', 'metric._false_negatives[] == 0', 'metric._false_negatives[] == 2', 'metric._false_negatives[] == 0', 'not in metric._false_negatives.keys()', 'metric._false_positives[] == 2', 'metric._false_positives[] == 2', 'metric._false_positives[] == 0', 'not in metric._false_positives.keys()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
284,Michael Schmitz,michael@schmitztech.com,2017-10-09 12:52:14-07:00,2bbb7919c10f011944b06402c5d632aa647dc953,https://github.com/allenai/allennlp/commit/2bbb7919c10f011944b06402c5d632aa647dc953,Use charpad BiDAF model. (#339),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
285,Mark Neumann,markn@allenai.org,2017-10-09 14:30:12-07:00,d92efd97dd0abd00915f9cc69457d5be1c20c5c1,https://github.com/allenai/allennlp/commit/d92efd97dd0abd00915f9cc69457d5be1c20c5c1,don't pull cuda runtime twice (#380),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
286,nafitzgerald,nicholas.fitzgerald@gmail.com,2017-10-09 15:53:22-07:00,18e008a8589044f7a263c56a55d7f71287f65b5c,https://github.com/allenai/allennlp/commit/18e008a8589044f7a263c56a55d7f71287f65b5c,"Fixes empty_field method of LabelField and adds a test (#383)

* fixed empty_field method of label_field and added a test

* Changed empty_field test for LabelField to test value of padding",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['empty_label.label == -1'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
287,Mark Neumann,markn@allenai.org,2017-10-09 17:36:50-07:00,aaa1b479a985fcee582866a6e189d015b9eeb384,https://github.com/allenai/allennlp/commit/aaa1b479a985fcee582866a6e189d015b9eeb384,use device mapping for optimiser state (#386),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
288,Mark Neumann,markn@allenai.org,2017-10-10 08:43:58-07:00,7bc7d2b006e45ab028bb507bbb9d5e1ae07fcfd0,https://github.com/allenai/allennlp/commit/7bc7d2b006e45ab028bb507bbb9d5e1ae07fcfd0,"add optional test data to train (#375)

* add optional test data to train

* fix string interpolation

* add extra test set flag",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
289,Joel Grus,joelgrus@gmail.com,2017-10-10 11:45:16-07:00,3941e4e60d51d1c7682b759db549323f2bece2f0,https://github.com/allenai/allennlp/commit/3941e4e60d51d1c7682b759db549323f2bece2f0,don't assign from index_instances (#391),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
290,Pradeep Dasigi,pradeep.dasigi@gmail.com,2017-10-10 16:34:16-04:00,7a5b58fede93821b8eb4f8d01cb6209ad659373a,https://github.com/allenai/allennlp/commit/7a5b58fede93821b8eb4f8d01cb6209ad659373a,"Basic Encoder decoder model (#366)

* basic encoder decoder model

* silenced a couple of mypy errors

* Added a simple test for encoder decoder

* Ignore temporary vim files

* Undid local gitignore changes

* Changed names of sequences to source and target, added target tokenizer, fixed loss computation

* Added default staat and end tokens to from_params

* Fixed new variable devices and added scheduled sampling

* More sensible hyperparameters

* Minor bug fixes in predict

* Moved namespace selection to config file and adrressed other Matt's comments

* More tests

* Removed old test file

* Added a test for the decode method

* Minor changes in comments

* Addressed Matt's comments for documentation",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset.instances) == 3', '[t.text for t in fields[]', '[t.text for t in fields[,', '[t.text for t in fields[]', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', 'numpy.equal(expected_loss.data.numpy(), actual_loss.data.numpy())', 'in decode_output_dict']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
291,Mark Neumann,markn@allenai.org,2017-10-10 16:38:52-07:00,5335c88b34ad1c08c3797fa6c3a561796a311295,https://github.com/allenai/allennlp/commit/5335c88b34ad1c08c3797fa6c3a561796a311295,"don't mutate training data with test data (#394)

* don't mutate training data with test data

* append datasets not instances

* pylint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
292,Mark Neumann,markn@allenai.org,2017-10-11 09:49:07-07:00,f1eaa0cca4c910610ac179701d68d07b7cd2b2f8,https://github.com/allenai/allennlp/commit/f1eaa0cca4c910610ac179701d68d07b7cd2b2f8,use /tmp to hold temp test directories (#381),1,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
293,Michael Schmitz,michael@schmitztech.com,2017-10-11 12:33:27-07:00,dc6510d98c6e235f531c47c6244c2c02884496f4,https://github.com/allenai/allennlp/commit/dc6510d98c6e235f531c47c6244c2c02884496f4,Add a `cuda_device` option to `predict`. (#384),6,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
294,Matt Gardner,mattg@allenai.org,2017-10-11 13:02:17-07:00,b164061b42380ea98641d3efce2789b3cc18e9d3,https://github.com/allenai/allennlp/commit/b164061b42380ea98641d3efce2789b3cc18e9d3,"Rename EncoderDecoder to SimpleSeq2Seq (#395)

* Rename EncoderDecoder to SimpleSeq2Seq

This is so that anyone wanting to build a sequence-to-sequence model
in AllenNLP has an obvious simple starting place.  I also copied the
`EncoderDecoder` model into a new `WikiTablesSemanticParser` model,
which we'll be modifying as we add in various components that the
original parser had.  So this effectively takes what was
`EncoderDecoder` and makes two classes, one that is simpler (I made
some very small changes to simplify the code slightly, and added some
comments in the main docstring), and one that will soon get a whole lot
more complicated.

* Remove work in progress from PR to master branch",13,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
295,Michael Schmitz,michael@schmitztech.com,2017-10-11 13:33:37-07:00,978d6d1ea37985d07092180ddd558c4ebea09e2c,https://github.com/allenai/allennlp/commit/978d6d1ea37985d07092180ddd558c4ebea09e2c,"Use a Python base image. (#389)

* Use python base image.

* Stop appending empty path to LD_LIBRARY_PATH.

* Add cffi to requirements.txt.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
296,Matt Gardner,mattg@allenai.org,2017-10-11 16:55:06-07:00,3592970d4b680404d91f8a1605550631caeecadb,https://github.com/allenai/allennlp/commit/3592970d4b680404d91f8a1605550631caeecadb,Use bmm to do an efficient weighted sum in cases where it applies (#398),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['aggregated_array.shape == (batch_size, length_1, embedding_dim)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
297,graham,graham.annett@gmail.com,2017-10-12 09:34:07-07:00,90ae49e9009fc4e17618fad45f2e756cc075fc78,https://github.com/allenai/allennlp/commit/90ae49e9009fc4e17618fad45f2e756cc075fc78,Add optional model caching to docker build (#392),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
298,Matt Gardner,mattg@allenai.org,2017-10-12 14:04:21-07:00,83d0253cd1bcba18b9fe31961146a8e81c0eae8c,https://github.com/allenai/allennlp/commit/83d0253cd1bcba18b9fe31961146a8e81c0eae8c,"Using F.softmax directly to do the softmax, with more efficient fixes (#399)",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
299,Michael Schmitz,michael@schmitztech.com,2017-10-13 08:48:13-07:00,d2d4e18fc6b300fc6d45da85caef3bc0f455208e,https://github.com/allenai/allennlp/commit/d2d4e18fc6b300fc6d45da85caef3bc0f455208e,"Remove param method from logger, and just use info. (#401)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
300,Michael Schmitz,michael@schmitztech.com,2017-10-13 10:54:20-07:00,9c712f50d0a73a9283c06ff8f03f9c76f3a2d6c6,https://github.com/allenai/allennlp/commit/9c712f50d0a73a9283c06ff8f03f9c76f3a2d6c6,"Remove evaluation_json_file and _sanitize_json. (#404)

`evaluation_json_file` is fully deprecated and no longer exists in any of our production models.",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"[']', 'config.as_dict() == original', 'config.as_dict() != original', ']', 'config.as_dict() == original']",[],[],[],[],[],[],[],[],[],[],[],[]
301,Michael Schmitz,michael@schmitztech.com,2017-10-13 12:40:53-07:00,f6da828bdf884891a69377f233ca93fadec1bc75,https://github.com/allenai/allennlp/commit/f6da828bdf884891a69377f233ca93fadec1bc75,Mark test_model_can_train_save_and_load as flaky. (#405),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
302,Michael Schmitz,michael@schmitztech.com,2017-10-16 08:55:14-07:00,18c55f0b580faf02aa7c164dbb7cd8d8e56773ec,https://github.com/allenai/allennlp/commit/18c55f0b580faf02aa7c164dbb7cd8d8e56773ec,Move cache_models.sh to a Python script. (#400),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
303,nafitzgerald,nicholas.fitzgerald@gmail.com,2017-10-16 14:28:47-07:00,d03e87b7b7297821d384a0b129268e6ca4d8e679,https://github.com/allenai/allennlp/commit/d03e87b7b7297821d384a0b129268e6ca4d8e679,"Bag of embeddings (#393)

* Implemented BagOfWordsEmbedding, a Seq2VecEncoder which sums (and optionally averages) the word embeddings across the time dimension.",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['encoder.get_input_dim() == 5', 'encoder.get_output_dim() == 5', 'encoder.get_input_dim() == 12', 'encoder.get_output_dim() == 12', 'encoder.get_input_dim() == 5', 'encoder.get_output_dim() == 5', 'encoder.get_input_dim() == 12', 'encoder.get_output_dim() == 12']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
304,Tushar Khot,tushark@allenai.org,2017-10-17 14:48:55-07:00,766911d6397c137248d4dab1f2d77a4c2f74a7be,https://github.com/allenai/allennlp/commit/766911d6397c137248d4dab1f2d77a4c2f74a7be,"Make sure IndexField padding passes valid arguments (#411)

* Make sure IndexField padding passes valid arguments

* Updated docstring and type info",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['empty_index.sequence_index == -1'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
305,Michael Schmitz,michael@schmitztech.com,2017-10-18 13:52:30-07:00,59371fd195363de0dc94368c09f18618115e562e,https://github.com/allenai/allennlp/commit/59371fd195363de0dc94368c09f18618115e562e,Support overrides for params during evaluation and prediction. (#402),6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in params', 'in params', 'params[', 'model_params.pop(', 'model_params[']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
306,Mark Neumann,markn@allenai.org,2017-10-18 16:13:48-07:00,ae45a83e910078a1bd1b5d1aa98436c0721a23a1,https://github.com/allenai/allennlp/commit/ae45a83e910078a1bd1b5d1aa98436c0721a23a1,add critical parameters for DA model (#416),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
307,Michael Schmitz,michael@schmitztech.com,2017-10-19 13:57:24-07:00,79c349a541e3df0334167111719b7730ce5b5d37,https://github.com/allenai/allennlp/commit/79c349a541e3df0334167111719b7730ce5b5d37,Update model configurations for easy training. (#417),6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
308,Matt Gardner,mattg@allenai.org,2017-10-19 15:41:38-07:00,3436ca76956f3fb53140fc515a6315361a9e6f49,https://github.com/allenai/allennlp/commit/3436ca76956f3fb53140fc515a6315361a9e6f49,"Adding logsumexp to nn.util (#419)

* Adding logsumexp to nn.util

* pylint",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
309,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-10-19 17:30:33-07:00,4d7404ec0cc31671ce4fefb5df663cb65180e5f2,https://github.com/allenai/allennlp/commit/4d7404ec0cc31671ce4fefb5df663cb65180e5f2,"Allow empty token lists to be padded (#422)

* Allow empty token lists to be padded

* Make mypy happy...",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
310,Michael Schmitz,michael@schmitztech.com,2017-10-20 07:50:26-07:00,7148d387f6d9cfb8cbcb00cf7c74fcedb60d6445,https://github.com/allenai/allennlp/commit/7148d387f6d9cfb8cbcb00cf7c74fcedb60d6445,Add timing per-epoch and time remaining estimate. (#421),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
311,Michael Schmitz,michael@schmitztech.com,2017-10-20 14:48:04-07:00,3a83b35dcab113a1800a59ac26b002c2b68687a1,https://github.com/allenai/allennlp/commit/3a83b35dcab113a1800a59ac26b002c2b68687a1,Close tqdm progress in file_utils. (#427),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
312,nafitzgerald,nicholas.fitzgerald@gmail.com,2017-10-21 09:56:22-07:00,ed37843d528b0902d73e4d5dde931812fd65835d,https://github.com/allenai/allennlp/commit/ed37843d528b0902d73e4d5dde931812fd65835d,"Fix patience (#426)

* Fixes patience in the trainer. Patience should be defines as ""Stop if you haven't improved the metric in N epochs"", but the previous implementation was ""Stop if the current score is worse than the worst in N epochs"".",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['new_trainer._should_stop_early([.5, .3, .2, .1, .4, .4]) #pylint: disable=protected-access', 'not new_trainer._should_stop_early([.3, .3, .3, .2, .5, .1]) #pylint: disable=protected-access', 'new_trainer._should_stop_early([.02, .3, .2, .1, .4, .4]) #pylint: disable=protected-access', 'not new_trainer._should_stop_early([.3, .3, .2, .1, .4, .5]) #pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
313,Matt Gardner,mattg@allenai.org,2017-10-21 12:53:55-07:00,c40e279eb0c3a16d1566962c1640f5883951e241,https://github.com/allenai/allennlp/commit/c40e279eb0c3a16d1566962c1640f5883951e241,Minor fix to beaker script (#429),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
314,Matt Gardner,mattg@allenai.org,2017-10-21 14:17:45-07:00,16d6acaba229bbea244b5f132134f541ecdf6bcc,https://github.com/allenai/allennlp/commit/16d6acaba229bbea244b5f132134f541ecdf6bcc,"Add NER tag token indexer (#430)

* Add NER tag token indexer

* pos -> ner in test names",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['counter[: 6}', 'indexer.token_to_indices(tokens[1], vocab) == person_index', 'indexer.token_to_indices(tokens[-1], vocab) == none_index', 'indexer.get_padding_token() == 0', 'indexer.get_padding_lengths(0) == {}', 'padded_tokens == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
315,Matt Gardner,mattg@allenai.org,2017-10-21 14:54:11-07:00,a2878a883280dc0525b57ae800d7b3c719f6046c,https://github.com/allenai/allennlp/commit/a2878a883280dc0525b57ae800d7b3c719f6046c,"Remove `with torch.cuda.device_of`, which doesn't do what we thought (#433)

* Remove with torch.cuda.device_of, which doesn't do what we thought

* Use float variable for copying instead of long variable

* Actually get the types right this time...",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
316,Joel Grus,joelgrus@gmail.com,2017-10-23 07:16:40-07:00,e8aba3fe479293388b722ff1da46baea7bb49466,https://github.com/allenai/allennlp/commit/e8aba3fe479293388b722ff1da46baea7bb49466,"CRF tagging model (#343)

* ner wip

* clean up dims

* progress

* wip

* more progress on hierarchical tagger

* get crf working correctly with masks

* vectorize

* fix for gpu

* fix padding

* fix bugs

* remove print statement

* fix off by one error

* cleanup

* better cross section of f1 scores

* update span-based-f1 for U- tags + switch crf_tagger to use it

* add viterbi decoding before metrics calculation

* fix pylint

* vectorize the forward calculation (2x speedup)

* clean up log_sum_exp

* work on simple tagger model

* wip

* add regularization

* don't log metrics to console in the middle of an epoch

* make pylint happy

* address PR comments

* wip

* crf model

* more ner

* progress

* progress

* fix bugs

* pylint

* add test for crf module

* add tests

* remove internal-only dataset reader

* clean up crf_tagger

* update tutorial/config to use correct dataset reader

* address pr comments, part 1

* add test that really tests the CRF model

* use manually set transitions

* address PR feedback

* pylint

* switch to logsumexp

* transpose transitions matrix to match viterbi decode

* add in transposes

* add missing param

* fix masking issue + add better tests

* update tutorial to reflect changes

* address last batch of pr comments",29,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}', 'manual_log_likelihood == approx(log_likelihood)', 'manual_log_likelihood == approx(log_likelihood)', 'viterbi_tags == [', 'viterbi_tags == most_likely_tags', 'spans == {((1, 2), )}']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
317,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-10-23 10:49:15-07:00,ec47c438b773721f74409a378b0b068cf2fa5c00,https://github.com/allenai/allennlp/commit/ec47c438b773721f74409a378b0b068cf2fa5c00,"Fix masked softmax (#437)

* Improve numerical instability in masked_softmax

* Add masked_softmax test",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
318,Mark Neumann,markn@allenai.org,2017-10-23 13:11:30-07:00,7fd48657301f5910ad96756665c29e75ad3cae86,https://github.com/allenai/allennlp/commit/7fd48657301f5910ad96756665c29e75ad3cae86,"add debug logging statement for pip-install issue with custom extension (#439)

* add debug logging statement for pip-install issue with custom extension

* add TODO",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
319,Mark Neumann,markn@allenai.org,2017-10-23 15:23:04-07:00,a8870bfc332b0d0f4524ba814d949a2fb7a352c8,https://github.com/allenai/allennlp/commit/a8870bfc332b0d0f4524ba814d949a2fb7a352c8,"add ability to provide evidence to viterbi_decode (#436)

* add ability to provide evidence to viterbi_decode

* update comment

* pylint

* PR comments",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indices == [2, 3, 3, 0, 4, 3]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
320,Joel Grus,joelgrus@gmail.com,2017-10-23 19:10:08-07:00,c9e5c2db236073409d4ee2038ef206cf1b57c10c,https://github.com/allenai/allennlp/commit/c9e5c2db236073409d4ee2038ef206cf1b57c10c,"sphinx coverage (#440)

* add to test script

* add sphinx coverage plugin

* add whitelists to check_docs

* add missing docs

* final doc fix

* fix sphinx complaints

* address PR feedback

* fix one more comment

* combine BUILD_DOCS and CHECK_DOCS",31,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
321,Matt Gardner,mattg@allenai.org,2017-10-24 08:32:11-07:00,e2a649354e67584eff90bf9fc5b405b0c6e0d6ce,https://github.com/allenai/allennlp/commit/e2a649354e67584eff90bf9fc5b405b0c6e0d6ce,"Increase number of attempts for BiDAF training test, which is very flaky (#441)",1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
322,Michael Schmitz,michael@schmitztech.com,2017-10-25 08:13:42-07:00,0e21ff5695c94168d900f6e51bab04490af1f3aa,https://github.com/allenai/allennlp/commit/0e21ff5695c94168d900f6e51bab04490af1f3aa,"Remove PYTHONHASHSEED. (#424)

* Remote PYTHONHASHSEED.

* Remove unused import.

* Remove unused import.",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
323,Michael Schmitz,michael@schmitztech.com,2017-10-25 16:08:45-07:00,362103a6224aa98aa1ddb530b2005c6d12acb2a7,https://github.com/allenai/allennlp/commit/362103a6224aa98aa1ddb530b2005c6d12acb2a7,Add simpler docs for building and running the demo. (#438),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
324,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-10-25 17:30:30-07:00,dc8cc55d4bd82585536ad62b2d5e67f7c17678bc,https://github.com/allenai/allennlp/commit/dc8cc55d4bd82585536ad62b2d5e67f7c17678bc,Sync with requirements.txt (#445),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
325,Joel Grus,joelgrus@gmail.com,2017-10-26 10:09:24-07:00,a77e1e8fed7b57cad2652dae4129eb7f6390c6da,https://github.com/allenai/allennlp/commit/a77e1e8fed7b57cad2652dae4129eb7f6390c6da,"add Subcommand abstraction + overrides (#446)

* add Subcommand abstraction + overrides

* add missing docs",13,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['fake_evaluate.add_subparser_called', 'args.func == train_model_from_args']",[],[],[],[],[],[],[],[],[],[],[],[],['args.func == _train_model_from_args'],[],[],[],[],[],[],[],[],[],[],[],[]
326,Ronald Huggler,rHuggler@users.noreply.github.com,2017-10-26 16:56:12-02:00,69134a251a68e8975e1216fce84f18fe32db2b31,https://github.com/allenai/allennlp/commit/69134a251a68e8975e1216fce84f18fe32db2b31,"Add inspect_cache.py script (#406) (#423)

* Add inspect_cache.py script (#406)

* Import constant from file_utils",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
327,Mark Neumann,markn@allenai.org,2017-10-26 17:34:20-07:00,5fd28f0f63d8ca96fc0931bebac8224fa071c35f,https://github.com/allenai/allennlp/commit/5fd28f0f63d8ca96fc0931bebac8224fa071c35f,"add class variable for logging (#448)

* add class variable for logging

* private class variables

* spacing

* make warning a function

* return type annotation",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not in LabelField._already_warned_namespaces', 'in LabelField._already_warned_namespaces', 'not in LabelField._already_warned_namespaces', 'not in SequenceLabelField._already_warned_namespaces', 'in SequenceLabelField._already_warned_namespaces', 'not in SequenceLabelField._already_warned_namespaces']","['(AssertionError)', '(AssertionError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
328,Mark Neumann,markn@allenai.org,2017-11-01 11:37:56-07:00,a22a8ff3aa588dc334575c7000400df1f293c4f9,https://github.com/allenai/allennlp/commit/a22a8ff3aa588dc334575c7000400df1f293c4f9,"add batch prediction to model and predictor (#453)

* add batch prediction to model and predictor

* fix mypy and spacing

* add batch arg to predict cli

* add note about speed",7,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(outfile)', 'len(results) == 2', 'set(result.keys()) == {,', 'len(results) == 2', 'best_span is not None', 'isinstance(best_span, list)', 'len(best_span) == 2', 'all(isinstance(x, int) for x in best_span)', 'best_span[0] <= best_span[1]', 'isinstance(best_span_str, str)', 'best_span_str != ', 'probs is not None', 'all(isinstance(x, float) for x in probs)', 'sum(probs) == approx(1.0)', 'len(results) == 2', 'label_probs is not None', 'isinstance(label_probs, list)', 'len(label_probs) == 3', 'all(isinstance(x, float) for x in label_probs)', 'all(x >= 0 for x in label_probs)', 'sum(label_probs) == approx(1.0)', 'label_logits is not None', 'isinstance(label_logits, list)', 'len(label_logits) == 3', 'all(isinstance(x, float) for x in label_logits)', 'e / sumexps == approx(p)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
329,Michael Schmitz,michael@schmitztech.com,2017-11-02 13:21:08-07:00,de5736b402889965f8bc560928fa7353ea8fa3c4,https://github.com/allenai/allennlp/commit/de5736b402889965f8bc560928fa7353ea8fa3c4,Enable CORS so dev is possible using npm. (#444),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
330,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-11-03 13:08:54-07:00,e6f5ce7db2534fa01804364d0cbeb1b5564688d2,https://github.com/allenai/allennlp/commit/e6f5ce7db2534fa01804364d0cbeb1b5564688d2,"More sanitize cases (#460)

* Sanitize LongTensor and Variable

* Fix pylint warnings

* Use _TensorBase for sanitize, add tests",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['util.sanitize(torch.Tensor([1, 2])) == [1, 2]', 'util.sanitize(torch.LongTensor([1, 2])) == [1, 2]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
331,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2017-11-03 13:30:53-07:00,5570027be4c8779cdd88d2011e7a5e7661f08bde,https://github.com/allenai/allennlp/commit/5570027be4c8779cdd88d2011e7a5e7661f08bde,Add sanic-cors to match requirements.txt (#462),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
332,Mark Neumann,markn@allenai.org,2017-11-03 18:38:15-07:00,c4d80d0b68d575e831cef2e249b844db15b5e228,https://github.com/allenai/allennlp/commit/c4d80d0b68d575e831cef2e249b844db15b5e228,"List field padding fix (#461)

* add failing listfield tests

* wip list field padding

* add tests for empty and nested list fields

* clean up

* trailing new line

* better comment in textfield

* matt syntax",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['lengths == {: 5}', 'padding_lengths == {: 6}']",[],[],[],[],[],[],[],[],[],[],[],[],['lengths == {: 5}'],[],[],[],[],[],[],[],[],[],[],[],[]
333,Mark Neumann,markn@allenai.org,2017-11-06 15:36:11-08:00,98ea3aa597aa63945d040fd199943d35922b77bd,https://github.com/allenai/allennlp/commit/98ea3aa597aa63945d040fd199943d35922b77bd,fix simple tagger (#466),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
334,Joel Grus,joelgrus@gmail.com,2017-11-07 12:52:17-08:00,2d4ff9cb7e1055259e9c3a33c6d3666d3709f106,https://github.com/allenai/allennlp/commit/2d4ff9cb7e1055259e9c3a33c6d3666d3709f106,"permalinks (#451)

* start with components

* progress

* add permarendering

* fix header

* working permalink service

* fix bug

* new permalink scheme

* clean up javascript

* pylint

* fixes

* add tests

* fix css

* only create predictors once

* import spacy before numpy

* move import inside class

* move another spacy import inside

* import spacy first

* add spacy to doc/conf.py?

* move spacy around :(

* remove import spacy, just to see if that fixes the docs

* mess with docs

* remove more docs

* delete files

* pin sanic-cors

* add back docs

* address js comments

* add docstring",22,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['response.status == 200', 'not in result', 'response.status == 400', 'response.status == 200', 'slug is not None', 'response.status == 400', 'response.status == 200', 'set(result2.keys()) == {}', 'result2[', 'result2[] == data', 'result2[] == result']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
335,Mark Neumann,markn@allenai.org,2017-11-07 13:12:11-08:00,3b0ed358c084c2b619f5147f189d1f969f4fec75,https://github.com/allenai/allennlp/commit/3b0ed358c084c2b619f5147f189d1f969f4fec75,"Seq length padding fix (#472)

* add failing sequence length test

* preserve sequence length in seq2seq encoder",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['encoder_output.size(1) == 8'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
336,Mark Neumann,markn@allenai.org,2017-11-07 14:38:48-08:00,b4fa4bb68b1fc22101bbbfa35faead8b3544599c,https://github.com/allenai/allennlp/commit/b4fa4bb68b1fc22101bbbfa35faead8b3544599c,add variable wrapper around zeros tensor (#473),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
337,Michael Schmitz,michael@schmitztech.com,2017-11-07 17:36:02-08:00,e8a4a9c997a646618465ba42388fff7731ead34b,https://github.com/allenai/allennlp/commit/e8a4a9c997a646618465ba42388fff7731ead34b,Use longer names for models. (#476),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
338,Joel Grus,joelgrus@gmail.com,2017-11-08 10:25:44-08:00,386b7444d8b43b5c001b8dfc16999123fbd0b0fa,https://github.com/allenai/allennlp/commit/386b7444d8b43b5c001b8dfc16999123fbd0b0fa,"add sniff test (#277)

* add sniff test

* update sniff test

* fix pylint whitespace + have travis cache datasets",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(DEFAULT_MODELS.keys()) == {', 'correct == result[]', 'result[] == [', 'result[] == [', 'result[] == [', 'result[][0] > 0.7  # entailment', 'result[][1] > 0.8  # contradiction', 'result[][2] > 0.7  # neutral']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
339,Mark Neumann,markn@allenai.org,2017-11-08 11:49:00-08:00,1f221a554f509f777c0b95c96f7fac2a624373d9,https://github.com/allenai/allennlp/commit/1f221a554f509f777c0b95c96f7fac2a624373d9,add database package to setup.py (#479),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
340,Mark Neumann,markn@allenai.org,2017-11-08 13:15:08-08:00,c47b073acf97155e4dfbbfa2e032ecf06f6fd659,https://github.com/allenai/allennlp/commit/c47b073acf97155e4dfbbfa2e032ecf06f6fd659,"fix things spacy 2.0 broke (#477)

* fix things spacy 2.0 broke

* pin spacy

* be mediumly flexible about spacy versions",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['counter[: 1,']",[],[],[],[],[],[],[],[],[],[],[],[],['counter[: 2}'],[],[],[],[],[],[],[],[],[],[],[],[]
341,nafitzgerald,nicholas.fitzgerald@gmail.com,2017-11-08 14:10:14-08:00,fb9331da270da6184896798dfe3a40cdd173195b,https://github.com/allenai/allennlp/commit/fb9331da270da6184896798dfe3a40cdd173195b,"Specify a pretrained embedding file when creating a Vocabulary (#478)

* Added ability to specify pretrained file to Vocabulary and either inclusively or exclusively add words from it
* added keyword args to Vocabulary.from_params",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in words', 'not in words', 'not in words', 'in words', 'in words', 'not in words', 'in words', 'in words', 'not in words', 'in words', 'in words', 'in words']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
342,Matthew Peters,matt-peters@users.noreply.github.com,2017-11-09 16:22:18-08:00,c3c3549887a6b1fb0bc8abf77bc820a3ab97f788,https://github.com/allenai/allennlp/commit/c3c3549887a6b1fb0bc8abf77bc820a3ab97f788,"Compute context insensitive ELMo representations (#471)

* Add build artifacts to .gitignore

* Add ELMo character indexer

* Add a function to add BOS/EOS tokens to id tensors

* Add .envrc to gitignore

* Add ELMo token embedder

* pylint

* pylint

* more pylint

* Add .mypy_cache to .gitignore

* mypy

* Rename test

* Add h5py to requirements

* pylint

* code review

* code review comments

* More code review

* code review comments

* Code review

* Try to fix the docs

* pylint

* More docs

* Don't inherit from object

* Use verbose variable names

* pylint

* code review

* pylint

* pylint

* Code review

* Code review

* pylint

* pylint

* fix the docs",16,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indices == expected_indices', 'indices == expected_indices', 'indices == expected_indices', 'padded_tokens == expected_padded_tokens', 'numpy.allclose(actual_embeddings[:len(tokens)], expected_embeddings, atol=1e-6)', '(new_tensor.data.numpy() == expected_new_tensor).all()', '(new_mask.data.numpy() == (expected_new_tensor > 0)).all()', '(new_tensor.data.numpy() == expected_new_tensor).all()', '(new_mask.data.numpy() == ((expected_new_tensor > 0).sum(axis=-1) > 0)).all()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
343,Pradeep Dasigi,pradeep.dasigi@gmail.com,2017-11-10 15:00:33-08:00,87db4d2d76795e66f2ed473018614e0ec367917b,https://github.com/allenai/allennlp/commit/87db4d2d76795e66f2ed473018614e0ec367917b,"Deleted an unnecessary print statement (#484)

Merging this without review because it's just deletion of a single print statement.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
344,Joel Grus,joelgrus@gmail.com,2017-11-13 12:35:30-08:00,85d2ceea8440ace70d3bbcacd56f15e18be6f2b5,https://github.com/allenai/allennlp/commit/85d2ceea8440ace70d3bbcacd56f15e18be6f2b5,make API_ROOT depend on window.location.origin (#487),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
345,Michael Schmitz,michael@schmitztech.com,2017-11-13 13:42:59-08:00,4c377eac8ce2f63f31cc8fd3a74ba870a506eb6f,https://github.com/allenai/allennlp/commit/4c377eac8ce2f63f31cc8fd3a74ba870a506eb6f,Demo deploy updates. (#488),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
346,Matt Gardner,mattg@allenai.org,2017-11-13 15:44:39-08:00,50a3e1603287310b38c5fce4fd9947738cbd10aa,https://github.com/allenai/allennlp/commit/50a3e1603287310b38c5fce4fd9947738cbd10aa,"Fix how spacy components are disabled for spacy 2.0 (#489)

* Fix how spacy components are disabled for spacy 2.0

* Fix pylint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
347,Mark Neumann,markn@allenai.org,2017-11-13 18:30:23-08:00,3c761ba9d857677efb60ae5c2dbbe321f0b3b702,https://github.com/allenai/allennlp/commit/3c761ba9d857677efb60ae5c2dbbe321f0b3b702,"Coref Model (#465)

* Initial simplified e2e-coref implementation. (#364)

* Initial simplified e2e-coref implementation.

* WIP: refactoring coref code to address some comments.

* Fix all shape annotations.

* Mostly naming refactoring.

* More comments for the coref mdoel.

* More util comments.

* Added more doc strings and expanded some variable naming.

* make bash script take ontonotes path as arg, add note about python 2.7

* types and docstrings, unify label computation inside conditional block

* add basic test for coref model

* remove uncessecary side effects from handle_line

* add documentation for DocumentState

* minor updates to model

* add test shell

* more docs

* add dataset reader test, shorten fixture

* Initial simplified e2e-coref implementation.

* WIP: refactoring coref code to address some comments.

* Fix all shape annotations.

* Mostly naming refactoring.

* More comments for the coref mdoel.

* More util comments.

* Added more doc strings and expanded some variable naming.

* make bash script take ontonotes path as arg, add note about python 2.7

* types and docstrings, unify label computation inside conditional block

* add basic test for coref model

* remove uncessecary side effects from handle_line

* add documentation for DocumentState

* minor updates to model

* add test shell

* more docs

* add dataset reader test, shorten fixture

* pylint and mypy sweep

* Coref util tests (#408)

* add tests and docs for index select stuff

* add note about singlton mentions so I remember

* pylint

* address PR comments

* rename some stuff, fix a shape comment

* improve test, add example to docs

* Add Coref shell to service (#412)

* wip predictor and decode method

* wip predictor and decode method

* define output spec of predictor

* better formatting for comments

* add decode method and tests

* actually fix merge conflict

* better names

* add coref test fixture

* integrate test coref model into service

* remove unncessary enumeration

* remove defaultdict, use consistent name for predictor

* make mypy happy by not unpacking tensor into tuple

* add todo about skipped test

* fix docs for util function

* fix fat fingers

* address PR comments

* go back to previous way of doing code blocks

* refactor spacy cache

* try adding a space to code block

* [WIP] Coref demo (#435)

Coref demo

* rebase fixes

* add docs for new modules

* fix infuriating rst requirements

* add models and dataset readers to sphinx hierarchy

* fix label

* Checkpoint.

* Mouseover works.

* Fix some Javascript errors.

* better defaults for coref component

* rewrite coref viz for new frontend

* add sniff test, fix a few spacy things, upload model to s3

* pylint

* misc cleanup sweep

* address most of Joel's comments

* big refactor for matt's PR comments

* remove nfs references

* linting

* fix merge, refactor add_bos_eos to make it easier to read

* don't use backslash in string literal for docs

* ignore type for MentionRecall

* try adding spaces to appease the Sphinx god

* put ~ in the right place

* massively simplify span attention

* cleaned up scorers, added descriptions

* balance backticks for docs

* add explaination of span index masking

* address most of matt's follow-up comments

* add API_ROOT to demo

* use simpler method for marginal likelihood, add last dim log softmax

* specify log softmax

* variable names, better comments",41,False,True,True,True,False,True,True,False,False,False,False,False,False,False,False,[],1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,['class TestCorefPredictor(TestCase):'],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset.instances) == 2', 'text == [,', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', 'not ([], 1) in gold_mentions_with_ids', 'text == [,', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', 'all([self.span_width >= len(x) > 0 for x in candidate_mentions])  # pylint: disable=len-as-condition', 'len(clusters) == 2', 'gold1 in clusters', 'gold2 in clusters', 'result[] == [[[0, 0], [10, 10]],', 'result[,', 'list(selected.size()) == [2, 2, 2, 3]', 'list(selected.size()) == [2, 2, 2, 3]', 'document == [,', 'isinstance(clusters, list)', 'isinstance(cluster, list)', 'isinstance(mention[0], int)', 'isinstance(mention[1], int)', '0 < mention[0] <= len(document)', '0 < mention[1] <= len(document)']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
348,Michael Schmitz,michael@schmitztech.com,2017-11-14 15:24:10-08:00,9d8fe241db98f5ce4773fd8d11d8981d702b1326,https://github.com/allenai/allennlp/commit/9d8fe241db98f5ce4773fd8d11d8981d702b1326,Add a script that deploys the demo to staging. (#495),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
349,Michael Schmitz,michael@schmitztech.com,2017-11-14 17:44:46-08:00,c27713fecf727a8520de963ebfe610340baf3b04,https://github.com/allenai/allennlp/commit/c27713fecf727a8520de963ebfe610340baf3b04,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
350,Michael Schmitz,michael@schmitztech.com,2017-11-14 17:49:04-08:00,efea2b47a0abb9becc30734f7401a6d1575e3cbf,https://github.com/allenai/allennlp/commit/efea2b47a0abb9becc30734f7401a6d1575e3cbf,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
351,Joel Grus,joelgrus@gmail.com,2017-11-16 09:44:31-08:00,8f57b8c33677f57131d18cdedd9b85100dff5da8,https://github.com/allenai/allennlp/commit/8f57b8c33677f57131d18cdedd9b85100dff5da8,"introduce `DemoModel` abstraction (#503)

* introduce DemoModel abstraction

* remove unnecessary import

* move DEFAULT_MODELS + DEFAULT_PREDICTORS into commands/serve and commands/predict",10,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
352,Mark Neumann,markn@allenai.org,2017-11-16 10:06:16-08:00,4be70098f7bc6ac4ebd39a2817b6bdec99ed7dc2,https://github.com/allenai/allennlp/commit/4be70098f7bc6ac4ebd39a2817b6bdec99ed7dc2,"make span f1 robust to zero length sequences (#505)

* make span f1 robust to zero length sequences

* add test",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
353,Joel Grus,joelgrus@gmail.com,2017-11-16 12:23:13-08:00,ea8a2af2801963a3d255a426330367264a83a517,https://github.com/allenai/allennlp/commit/ea8a2af2801963a3d255a426330367264a83a517,"NER demo (#501)

* add NER demo

* fixes

* add comments

* add sniff test

* add sentence-tagger

* remove simple_tagger predictor

* change ner endpoint to /predict/named-entity-recognition

* sphinx",14,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['result[]', 'result[]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
354,Michael Schmitz,michael@schmitztech.com,2017-11-16 13:42:39-08:00,32e29ae2cb60d278f3ec05f33f9af5a0d4584863,https://github.com/allenai/allennlp/commit/32e29ae2cb60d278f3ec05f33f9af5a0d4584863,Remove tests from Dockerfile. (#507),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
355,Mark Neumann,markn@allenai.org,2017-11-17 09:44:00-08:00,46251029999d61a144a9f8340f4a6058502121a9,https://github.com/allenai/allennlp/commit/46251029999d61a144a9f8340f4a6058502121a9,"Elmo lstm (#480)

* lstm sketch

* first pass lstm cell

* better names, docstring

* more work on the stacked version

* add cell clipping, add test

* superficial changes

* lint, fix zip in lstm stacks

* switch away from PackedSequences, get returned state working

* tests for stacked elmo lstm

* add docs

* address matt's PR comments

* use cat instead of stack, fix docs

* add initial states to tests

* correct docstring and remove print statements",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(lstm_state[0].size()) == [1, 4, 5]', 'list((lstm_state[1].size())) == [1, 4, 7]', 'list(lstm_state[0].size()) == [2, 4, 10]', 'list((lstm_state[1].size())) == [2, 4, 14]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
356,Joel Grus,joelgrus@gmail.com,2017-11-17 16:49:00-08:00,f700584ed1b72ab45215e405ed0d22564938d1cb,https://github.com/allenai/allennlp/commit/f700584ed1b72ab45215e405ed0d22564938d1cb,"update CLI casing (#512)

* update CLI casing

* update docs

* add tests",10,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Logs', '(level=logging.WARNING) as context:')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics.keys() == {}', 'set(context.output) == {', 'args.func.__name__ == ', 'args.archive_file == ', 'args.output_file.name == ', 'args.batch_size == 10', 'args.cuda_device == 0', 'args.silent', 'args.func == train_model_from_args', 'args.param_path == ', 'args.serialization_dir == ']",[],[],[],[],[],[],[],[],[],[],[],[],"['metrics.keys() == {}', 'args.func.__name__ == ', 'args.archive_file == ', 'args.silent', 'args.func == train_model_from_args', 'args.param_path == ', 'args.serialization_dir == ']",[],[],[],[],[],[],[],[],[],[],[],[]
357,Michael Schmitz,michael@schmitztech.com,2017-11-20 12:53:42-08:00,33b9e5525a92a3d287d0f245d45a730e3ab3c321,https://github.com/allenai/allennlp/commit/33b9e5525a92a3d287d0f245d45a730e3ab3c321,"Add a script to handle production deploys. (#496)

* Create a script for production deploys.

* Add more checks to bash scripts.

* Fixup",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
358,Michael Schmitz,michael@schmitztech.com,2017-11-20 13:32:58-08:00,ce967c0ab89ec8b8655d6be9185f27260a1c9eef,https://github.com/allenai/allennlp/commit/ce967c0ab89ec8b8655d6be9185f27260a1c9eef,"Fix bug in production deployment script (#517)

* Fix image name in production deploy.

* Increase memory usage for staging and production.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
359,Michael Schmitz,michael@schmitztech.com,2017-11-21 16:13:34-08:00,a2e24fe1f2f815e8b3e96031663a1548a5266bfa,https://github.com/allenai/allennlp/commit/a2e24fe1f2f815e8b3e96031663a1548a5266bfa,Add SOURCE_COMMIT to Dockerfile. (#523),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
360,Michael Schmitz,michael@schmitztech.com,2017-11-21 16:14:28-08:00,ecc236059454f151d7161406bbe582766f084f08,https://github.com/allenai/allennlp/commit/ecc236059454f151d7161406bbe582766f084f08,Add readiness probe for production deployments. (#519),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
361,Joel Grus,joelgrus@gmail.com,2017-11-22 10:46:32-08:00,913073540c3af66f36b843662f1c57ce4360c942,https://github.com/allenai/allennlp/commit/913073540c3af66f36b843662f1c57ce4360c942,"Harmonize tutorials (#525)

* harmonize tutorials

* add headers to notebooks

* add makefile

* rename

* add hyphenate command to makefile",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
362,Joel Grus,joelgrus@gmail.com,2017-11-22 12:18:24-08:00,93b2ed7e33327c123d4bfe580e842cf251555496,https://github.com/allenai/allennlp/commit/93b2ed7e33327c123d4bfe580e842cf251555496,"fix Makefile to work in docker (#529)

yes, I am a moral reprobate",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
363,Michael Schmitz,michael@schmitztech.com,2017-11-22 13:50:41-08:00,3d311c75317dd43a6b209b25e76a3f01d05fa2f6,https://github.com/allenai/allennlp/commit/3d311c75317dd43a6b209b25e76a3f01d05fa2f6,Add info route. (#528),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
364,Sam Skjonsberg,skoneberg@gmail.com,2017-11-22 14:06:08-08:00,75c627fc10f527bbde9618236b0e62345cecf878,https://github.com/allenai/allennlp/commit/75c627fc10f527bbde9618236b0e62345cecf878,"Add `hierplane` to the SRL output as a vizualization method. (#526)

* Add `hierplane` to the SRL output as a vizualization method.

* Adds a `hierplane` visualization to the SRL output, where each
  verb is rendered as it's own tree.

* Add UI controls that allow the user to toggle between the ""table"" and
  ""tree"" view.
* Ignore `node_modules`, as it's a generated folder.

* Fix the container, so it takes up all available height.

* Fix the active tab indicator so that it's in the right spot.

* Don't select the label, it makes it harder to use.

* Polish.

* Make the passage resize to fit the text.
* Set a max-width for nodes so they don't get too big.

* Make the tree the default viz.

* Parsing adjustments; Display labels.

* Adjust parsing to handle references, continuations and `ARGA`
  nodes as appropriate.

* Convert attributes to a friendly display value.",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
365,Michael Schmitz,michael@schmitztech.com,2017-11-22 15:45:10-08:00,52e0698f7569c5c0a6143aa57535d7f4054a94e3,https://github.com/allenai/allennlp/commit/52e0698f7569c5c0a6143aa57535d7f4054a94e3,Disable Service Workers (#531),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
366,Sam Skjonsberg,skoneberg@gmail.com,2017-11-22 15:56:59-08:00,08e48c9dbf220fb1c0ffe2029f47acdc37d0ea5d,https://github.com/allenai/allennlp/commit/08e48c9dbf220fb1c0ffe2029f47acdc37d0ea5d,"Polish for the new Hierplane based SRL Demo. (#533)

* Polish.

Resolve wrapping issues; Add comments to some of the other polish
hacks.

* Make wrapping dyanmic / based on viewport width.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
367,Joel Grus,joelgrus@gmail.com,2017-11-24 08:33:53-08:00,5d2cfcdcb3c5943406e47bcf9cc3ce6b3f3529de,https://github.com/allenai/allennlp/commit/5d2cfcdcb3c5943406e47bcf9cc3ce6b3f3529de,raise RuntimeError if python < 3.6 (#539),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
368,Michael Schmitz,michael@schmitztech.com,2017-11-27 07:43:44-08:00,b452e82caca4f7e5e3db2c1e634d0512def75531,https://github.com/allenai/allennlp/commit/b452e82caca4f7e5e3db2c1e634d0512def75531,Output start time in UTC along with uptime. (#536),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
369,Michael Schmitz,michael@schmitztech.com,2017-11-27 14:42:33-08:00,fa0c5c657c9ad1c0af79ae9c93e2e9fa67876554,https://github.com/allenai/allennlp/commit/fa0c5c657c9ad1c0af79ae9c93e2e9fa67876554,"Add a port option for database. (#542)

* Add a port option for database.
* Disable database if there's an initial connection error.
* Don't display a permalink if there's a connection error.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
370,Matthew Peters,matt-peters@users.noreply.github.com,2017-11-27 16:02:28-08:00,e82f225d1ff157cd896092a9cf8ec414e9277282,https://github.com/allenai/allennlp/commit/e82f225d1ff157cd896092a9cf8ec414e9277282,"Add `ScalarMix` module (#543)

* Add ScalarMix module

* pylint

* mypy and pylint

* fix the docs

* Add a docstring to ScalarMix.forward",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
371,Michael Schmitz,michael@schmitztech.com,2017-11-28 08:05:04-08:00,8957c86012e774714f8e73c215f1a2f54a10a3d8,https://github.com/allenai/allennlp/commit/8957c86012e774714f8e73c215f1a2f54a10a3d8,"Support databases on GCP. (#545)

* Update staging to work with a Google Cloud database.

* Add a liveness probe to staging.

* Update production to work with a Google Cloud database.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
372,nafitzgerald,nicholas.fitzgerald@gmail.com,2017-11-28 13:21:27-08:00,eb24cad9baed4dee31c5b2524544fa71eaeef0be,https://github.com/allenai/allennlp/commit/eb24cad9baed4dee31c5b2524544fa71eaeef0be,fixed srl prediction script swapping gold and pred (#547),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
373,Michael Schmitz,michael@schmitztech.com,2017-11-28 16:17:26-08:00,50c79aaf0c71f2a3b44df0310105123794e61e16,https://github.com/allenai/allennlp/commit/50c79aaf0c71f2a3b44df0310105123794e61e16,Change production container name. (#548),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
374,Joel Grus,joelgrus@gmail.com,2017-11-28 17:27:29-08:00,b4064f0066342eeb9d9915baaac7dbd31dccb7bd,https://github.com/allenai/allennlp/commit/b4064f0066342eeb9d9915baaac7dbd31dccb7bd,Autocommit database modifications (#549),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
375,Mark Neumann,markn@allenai.org,2017-11-29 12:45:56-08:00,5acb5a785b9ed60743e6f687a96bd92dd4e88578,https://github.com/allenai/allennlp/commit/5acb5a785b9ed60743e6f687a96bd92dd4e88578,"Encoder abstractions (#518)

* Allow stacked RNNs in PytorchSeq2SeqWrapper

* Modify the zero sequence length logic in PytorchSeq2SeqWrapper to work with stateful RNNs

* WIP: stateful RNNs

* Stateful RNNs

* pylint

* more pylint

* fix the docs

* Address Joel's comments

*  stateful=True that works with GRU

* Deal with sorting in stateful RNNs

* pylint

* mypy

* pylint

* Remove max_batch_size

* Add tests for correctness

* pylint

* initial pass at adding Seq2StackEncoder and adding an EncoderBase

* remove print statements

* docs work

* make sort function return the indices it sorted by

* more work on getting statefulness working correctly

* tweaks to comments, make it clear that wrapping the state in a list is only for statefulness

* finish state update logic and improve docs

* add TODO for review

* fix current tests

* remove abstract Seq2Stack encoder

* use Callable type for base

* add tests for update states

* lint, fix mypy using elipsis in tuple

* fix up ELMo with docs and test

* don't require docs for encoder_base

* add comment for ignored docs

* remove out of date docstring

* remove num_valid from encoder_base, superficial fixes

* use random state in tests, use correct num_valid size

* rename a few things, don't zero out actual tensor in test

* don't split elmo output, fix docs

* actually fix docs",18,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.encoder_base._get_initial_states(self.batch_size, self.num_valid, self.sorting_indices) is None', 'self.encoder_base._states is None', 'list(lstm._states[0].size()) == [2, 4, 10]', 'list((lstm._states[1].size())) == [2, 4, 14]']",[],[],[],[],[],[],[],[],[],[],[],[],"['list(lstm_state[0].size()) == [2, 4, 10]', 'list((lstm_state[1].size())) == [2, 4, 14]']",[],[],[],[],[],[],[],[],[],[],[],[]
376,Michael Schmitz,michael@schmitztech.com,2017-11-29 13:24:39-08:00,29b90ef6387b251d926119f8cb0adebac9c45f41,https://github.com/allenai/allennlp/commit/29b90ef6387b251d926119f8cb0adebac9c45f41,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
377,Mark Neumann,markn@allenai.org,2017-11-29 15:00:25-08:00,1fd1356a579b86c62d6c4f942b896fbcf994e5ac,https://github.com/allenai/allennlp/commit/1fd1356a579b86c62d6c4f942b896fbcf994e5ac,bump versions (#551),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
378,Michael Schmitz,michael@schmitztech.com,2017-11-29 15:03:52-08:00,8186daa681db569f27dcfd39ec2c005b2a4ccd15,https://github.com/allenai/allennlp/commit/8186daa681db569f27dcfd39ec2c005b2a4ccd15,Delete RELEASE.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
379,Mark Neumann,markn@allenai.org,2017-11-29 16:02:41-08:00,da92b8489751c29e929c8bababd6a2da58e9abdd,https://github.com/allenai/allennlp/commit/da92b8489751c29e929c8bababd6a2da58e9abdd,"Dataset for vocab selection (#530)

* add parameter specifying how the vocabulary should be created

* see what joel thinks of cute itertools thing

* forgot .items()

* clarify comment

* don't itertools everything",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
380,Matt Gardner,mattg@allenai.org,2017-11-29 17:05:24-08:00,79e81f776c3c2715e10a01045be647279afc909c,https://github.com/allenai/allennlp/commit/79e81f776c3c2715e10a01045be647279afc909c,"Adding a proposed style guide (#522)

* Adding a proposed style guide

* Add a section on docstrings

* Fix wording",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
381,Mark Neumann,markn@allenai.org,2017-11-30 17:30:47-08:00,0085162b236c7f95495b1340c4eb3bd7dbb6a708,https://github.com/allenai/allennlp/commit/0085162b236c7f95495b1340c4eb3bd7dbb6a708,"add array field (#556)

* add array field

* lint, docs",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['lengths[.format(i)] == shape[i]'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
382,Matthew Peters,matt-peters@users.noreply.github.com,2017-11-30 22:17:00-08:00,10469ac6dc47a5474b9e6830fb5f6b05000241db,https://github.com/allenai/allennlp/commit/10469ac6dc47a5474b9e6830fb5f6b05000241db,"More ELMo functionality (#559)

* Add remove_sentence_boundaries utility

* Replace the test fixture ELMo model with one that has skip connections

* Fix a bug in elmo_token_embedder

* A working ElmoBiLm class

* Add Elmo class

* Add from_params to ELMo

* Refactor a little

* Add ElmoTokenEmbedder and test

* Move things around

* pylint

* pylint

* pylint

* pylint

* pylint

* mypy

* fix the docs

* Add test fixture

* Code review 1

* Code review 2

* s/num_elmo_layers/num_output_representations

* pylint",22,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Equal', '(lengths.tolist(), expected_lengths)'), ('True', '(')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(elmo_representations) == 2', 'list(elmo_representations[0].size()) == [2, 7, 32]', 'list(elmo_representations[1].size()) == [2, 7, 32]', 'list(mask.size()) == [2, 7]', 'numpy.allclose(actual_embeddings[:len(tokens)], expected_embeddings, atol=1e-6)', 'numpy.allclose(embeddings[0, correct_index, :].data.numpy(), embeddings[0, 1, :].data.numpy())', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}', '(new_mask.data.numpy() == expected_new_mask.data.numpy()).all()']",[],[],[],[],[],[],[],[],[],[],[],[],"['numpy.allclose(actual_embeddings[:len(tokens)], expected_embeddings, atol=1e-6)']",[],[],[],[],[],[],[],[],[],[],[],[]
383,Michael Schmitz,michael@schmitztech.com,2017-12-01 16:43:54-08:00,377ba840fc0a26403f73b6f759574b4f3616b04d,https://github.com/allenai/allennlp/commit/377ba840fc0a26403f73b6f759574b4f3616b04d,Replace SRL table output with simple text output. (#534),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
384,Michael Schmitz,michael@schmitztech.com,2017-12-01 17:02:08-08:00,cd2d6a3e73ca906588bf71d8bc91d17520c6cee6,https://github.com/allenai/allennlp/commit/cd2d6a3e73ca906588bf71d8bc91d17520c6cee6,Add numbers to installation steps. (#553),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
385,Michael Schmitz,michael@schmitztech.com,2017-12-01 17:06:58-08:00,3f431799776dbf2a42091ba114fc3b6f38b268c8,https://github.com/allenai/allennlp/commit/3f431799776dbf2a42091ba114fc3b6f38b268c8,"Documentation improvements (#557)

* Add comments to pad_sequence_to_length.

* Specify more specific return type on get_spacy_model.

* Reword pad_sequence_to_length comment after Slack conversation.

* Improve padding comment.

* Add explanation for why we can return a spacy Token as an AllenNLP token.

* Improve comments in TextField.

* Improve comments in TokenCharactersIndexer.

* Tweak padding comment.",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
386,Mark Neumann,markn@allenai.org,2017-12-04 09:44:49-08:00,31a5eb8b7f85e895071abe6c7665e5079d65f781,https://github.com/allenai/allennlp/commit/31a5eb8b7f85e895071abe6c7665e5079d65f781,use better tensorboard distribution (#561),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
387,Joel Grus,joelgrus@gmail.com,2017-12-04 11:23:46-08:00,83f0c5ecaa1020371d7788f6683764ff806dbe36,https://github.com/allenai/allennlp/commit/83f0c5ecaa1020371d7788f6683764ff806dbe36,add missing install_requires (#564),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
388,Matthew Peters,matt-peters@users.noreply.github.com,2017-12-04 14:04:38-08:00,3995f70c1cb6190352eb5e063e3ba37b3121112f,https://github.com/allenai/allennlp/commit/3995f70c1cb6190352eb5e063e3ba37b3121112f,"Add ability to read hdf5 formatted Embedding (#563)

* Add ability to read hdf5 in Embedding

* pylint

* doc

* code review

* pylint",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['numpy.allclose(embedding_layer.weight.data.numpy(), embeddings)']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
389,Michael Schmitz,michael@schmitztech.com,2017-12-05 13:14:43-08:00,1dd18e82419135a88178f0c2a260aa5fba3e6652,https://github.com/allenai/allennlp/commit/1dd18e82419135a88178f0c2a260aa5fba3e6652,"Increase tolerance of BiDAF tests. (#568)

* Increase tolerance of BiDAF tests.

They have been failing due to a mismatch of 0.141%.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
390,Matthew Peters,matt-peters@users.noreply.github.com,2017-12-05 17:04:17-08:00,a7dd38038995369982022b745a89f06fbcbf1f26,https://github.com/allenai/allennlp/commit/a7dd38038995369982022b745a89f06fbcbf1f26,"Add support for purely character input in `get_text_field_mask` (#577)

* Add support for purely character input in

* Make get_text_field_mask work for ListField

* pylint

* Minor docstring tweaks

* pylint",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
391,Mark Neumann,markn@allenai.org,2017-12-05 18:57:25-08:00,d057d50f5a0d140f3a5d0e044ad167545b670ec2,https://github.com/allenai/allennlp/commit/d057d50f5a0d140f3a5d0e044ad167545b670ec2,"Sorting state fixes (#576)

* add failing tests

* add Variable to zeros, fix sorting for non-stateful encoders

* clarify tests",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(state.size()) == [6, 3, 7]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
392,Mark Neumann,markn@allenai.org,2017-12-06 09:55:49-08:00,c2203c414b0b88b378ec2b07100b985df2f66512,https://github.com/allenai/allennlp/commit/c2203c414b0b88b378ec2b07100b985df2f66512,"Canonical ontonotes (#571)

* more work on reader

* more work on reading all conll annotations

* reader with all annotations and tests

* cleaned up, added docstrings

* linting

* fix spacing

* add docs

* fix docs

* include utils in top level toctree

* backticks for days

* PR comments

* lint",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['annotation.document_id == ', 'annotation.sentence_id == 0', 'annotation.words == [,', 'annotation.pos_tags == [,', 'annotation.word_senses == [None, None, 1, 1, None, 2, None, None, 1, None, None]', 'annotation.predicate_framenet_ids == [None, None, None, , None,', 'annotation.srl_frames == {,', 'annotation.named_entities == [,', 'annotation.predicate_lemmas == [None, None, , None,', 'annotation.speakers == [None, None, None, None, None, None,', 'annotation.parse_tree == Tree.fromstring(', 'annotation.coref_spans == {(1, (4, 6)), (3, (4, 7))}', 'annotation.document_id == ', 'annotation.sentence_id == 0', 'annotation.words == [,', 'annotation.pos_tags == [,', 'annotation.word_senses == [None, 2, 5, None, 2, None, None,', 'annotation.predicate_framenet_ids == [None, None, , None, None, None,', 'annotation.srl_frames == {,', 'annotation.named_entities == [,', 'annotation.predicate_lemmas == [None, ,', 'annotation.speakers == [None, None, None, None, None, None,', 'annotation.parse_tree == Tree.fromstring(', 'annotation.coref_spans == {(2, (0, 1)), (2, (3, 3))}', 'annotation.document_id == ', 'annotation.sentence_id == 0', 'annotation.words == []', 'annotation.pos_tags == []', 'annotation.word_senses == [None, None, None, None, None]', 'annotation.predicate_framenet_ids == [None, None, None, None, None]', 'annotation.srl_frames == {}', 'annotation.named_entities == [,', 'annotation.predicate_lemmas == [None, None, None, None, None]', 'annotation.speakers == [None, None, None, None, None]', 'annotation.parse_tree == Tree.fromstring(', 'annotation.coref_spans == {(2, (0, 1))}', 'files == []']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
393,Mark Neumann,markn@allenai.org,2017-12-06 10:35:43-08:00,169e7279413e9d1ef4afb2e1e01c19b2ed042956,https://github.com/allenai/allennlp/commit/169e7279413e9d1ef4afb2e1e01c19b2ed042956,temporary fix for coref visualisation wrapping (#552),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
394,Mark Neumann,markn@allenai.org,2017-12-06 10:47:52-08:00,01abb0f9248a19a71955ece96ee89818d6d22403,https://github.com/allenai/allennlp/commit/01abb0f9248a19a71955ece96ee89818d6d22403,bump versions (#582),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
395,Matt Gardner,mattg@allenai.org,2017-12-06 11:06:04-08:00,806731155aa059ce4f6297d75f9dbfb2f0dad7ad,https://github.com/allenai/allennlp/commit/806731155aa059ce4f6297d75f9dbfb2f0dad7ad,"Removed arrays_to_variables (#580)

* Removed arrays_to_variables

* Fix merged tests",35,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,1,0,0,0,0,1,1,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(torch.ByteTensor(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(', 'torch_array_dict[].data.equal(']",[],[],[''],[],[],[],[],['skip'],['mark.skip'],[],[],[]
396,Mark Neumann,markn@allenai.org,2017-12-06 11:21:52-08:00,7f5d9f7587e1a799e161c37e3383686323e34956,https://github.com/allenai/allennlp/commit/7f5d9f7587e1a799e161c37e3383686323e34956,remove max width constraint (#555),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
397,Matthew Peters,matt-peters@users.noreply.github.com,2017-12-06 14:48:16-08:00,5e88a2b1c5249b3bfd66f89c15a1fced7965d1e2,https://github.com/allenai/allennlp/commit/5e88a2b1c5249b3bfd66f89c15a1fced7965d1e2,"Ensure ELMo can run on GPU (#570)

* WIP: ELMo on GPU

* Add todo",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
398,Maksym Del,max.del.edu@gmail.com,2017-12-07 02:55:04+02:00,54e0bb4dd9c025a551b2071151a49f88946624d4,https://github.com/allenai/allennlp/commit/54e0bb4dd9c025a551b2071151a49f88946624d4,Fixed casting to FloatTensor in simple_seq2seq.py (#585),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
399,Maksym Del,max.del.edu@gmail.com,2017-12-07 03:03:35+02:00,3d389d6cd141f1c06b3ce995dd0a403066b049b6,https://github.com/allenai/allennlp/commit/3d389d6cd141f1c06b3ce995dd0a403066b049b6,Fix typo in simple_seq2seq.py docstring (#587),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
400,Matt Gardner,mattg@allenai.org,2017-12-06 17:07:27-08:00,d978101616bfe29a2f50327a953e101cab8ba152,https://github.com/allenai/allennlp/commit/d978101616bfe29a2f50327a953e101cab8ba152,"Added another model tutorial (#566)

* Added another model tutorial

* Fixes from PR feedback

* Wording and tone fixes

* Renamed the tutorial, fixed intro

* Rename to ""project""",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
401,Mark Neumann,markn@allenai.org,2017-12-06 17:31:57-08:00,ccc4af33736ce4801a751fb2e9717e8f815aa9d0,https://github.com/allenai/allennlp/commit/ccc4af33736ce4801a751fb2e9717e8f815aa9d0,fix decode in encoder decoder (#586),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
402,Michael Schmitz,michael@schmitztech.com,2017-12-07 09:37:22-08:00,ee7d42af306f25d216431bbb1e4c39d1d40c6c96,https://github.com/allenai/allennlp/commit/ee7d42af306f25d216431bbb1e4c39d1d40c6c96,"Move to PyTorch 0.3 (#578)

* Change URLs to PyTorch 0.3

* Add dim args to softmaxes to stop warnings",12,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
403,Matthew Peters,matt-peters@users.noreply.github.com,2017-12-07 11:17:30-08:00,64c5a5b1f415bda92a4205e91799ecf1438712e4,https://github.com/allenai/allennlp/commit/64c5a5b1f415bda92a4205e91799ecf1438712e4,"Allow ELMo to accept higher dimensional input (#588)

* Allow ELMo to accept higher dimensional input

* Make remove_sentence_boundaries robust to empty sequences

* Add comment

* Make test more robust

* pylint",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
404,Mark Neumann,markn@allenai.org,2017-12-07 14:26:00-08:00,27cdcb561fb3f3746575d209a856e51ef1357029,https://github.com/allenai/allennlp/commit/27cdcb561fb3f3746575d209a856e51ef1357029,"Elmo vocab embeddings (#579)

* checkpoint whilst other PR is merged

* more elmo scripting with added batch size

* working version of script

* use complete paths to files

* tweaks

* switch to using gzip format

* docstring + formatting

* PR comments",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
405,Mark Neumann,markn@allenai.org,2017-12-07 20:09:22-08:00,364a5c2bd8574076824fa3aa48e1c5ea8c24afd9,https://github.com/allenai/allennlp/commit/364a5c2bd8574076824fa3aa48e1c5ea8c24afd9,use cached path (#596),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
406,Mark Neumann,markn@allenai.org,2017-12-08 10:03:22-08:00,d5bc2d3984a4fae2e74b5d355f6f13c824ecb080,https://github.com/allenai/allennlp/commit/d5bc2d3984a4fae2e74b5d355f6f13c824ecb080,add dropout to elmo (#597),3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
407,Sam Skjonsberg,skoneberg@gmail.com,2017-12-08 10:40:03-08:00,10af402a3b059d26bb4c02d359906e05a3231e2c,https://github.com/allenai/allennlp/commit/10af402a3b059d26bb4c02d359906e05a3231e2c,"Filter out trees with no children, but retain those with a single child. (#598)

* Fixes #562;
* Fixes #567;",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
408,Mark Neumann,markn@allenai.org,2017-12-08 15:42:10-08:00,01291ee822687667ec0557c5c358dde02b7c89d8,https://github.com/allenai/allennlp/commit/01291ee822687667ec0557c5c358dde02b7c89d8,"Grad checks (#600)

* add grad checks to model test case

* remove references to .forward

* fix .data bug in sentence boundary function

* fix pylint

* reorder things, remove print",19,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(parameter.grad.data.cpu() != zeros).any()', 'parameter.grad is None']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
409,Maksym Del,max.del.edu@gmail.com,2017-12-10 07:34:31+02:00,b73754734d0e40cea86d5f26ff2b1cca70e5e5b1,https://github.com/allenai/allennlp/commit/b73754734d0e40cea86d5f26ff2b1cca70e5e5b1,"Fix a link to the open research corpus (#603)

Missing ""http://"" caused it to think it is a relative path.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
410,Maksym Del,max.del.edu@gmail.com,2017-12-10 07:35:26+02:00,473522e4fa59bca4f139e0e09c330dd62fe67071,https://github.com/allenai/allennlp/commit/473522e4fa59bca4f139e0e09c330dd62fe67071,Fix link in README.md (#604),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
411,Michael Schmitz,michael@schmitztech.com,2017-12-13 12:42:26-08:00,508c3b25c9d3be89b53233de45be307c45c97ccf,https://github.com/allenai/allennlp/commit/508c3b25c9d3be89b53233de45be307c45c97ccf,"Remove NVIDIA paths from Dockerfile.

These paths do not exist in the Docker image.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
412,Michael Schmitz,michael@schmitztech.com,2017-12-13 12:43:14-08:00,5666e7c287bcaeb45209ec78f76931706769a46c,https://github.com/allenai/allennlp/commit/5666e7c287bcaeb45209ec78f76931706769a46c,"Revert ""Remove NVIDIA paths from Dockerfile.""

This reverts commit 508c3b25c9d3be89b53233de45be307c45c97ccf.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
413,Michael Schmitz,michael@schmitztech.com,2017-12-14 12:45:40-08:00,101693c54284c776a6723cbf03f7f8497d7ba8c9,https://github.com/allenai/allennlp/commit/101693c54284c776a6723cbf03f7f8497d7ba8c9,Bump version numbers to 0.3.0. (#615),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
414,Michael Schmitz,michael@schmitztech.com,2017-12-14 13:07:24-08:00,ec953c2eccb062dcecd6c7eea39fb22795217acf,https://github.com/allenai/allennlp/commit/ec953c2eccb062dcecd6c7eea39fb22795217acf,Bump version numbers to v0.3.1-unreleased. (#616),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
415,Michael Schmitz,michael@schmitztech.com,2017-12-14 13:14:58-08:00,975bbccead6a423b3b0c84d75956993620edfbac,https://github.com/allenai/allennlp/commit/975bbccead6a423b3b0c84d75956993620edfbac,"Revert ""Bump version numbers to v0.3.1-unreleased. (#616)""

This reverts commit ec953c2eccb062dcecd6c7eea39fb22795217acf.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
416,Michael Schmitz,michael@schmitztech.com,2017-12-14 13:15:04-08:00,688f5cafc697562e2527626548b1c1545df8657a,https://github.com/allenai/allennlp/commit/688f5cafc697562e2527626548b1c1545df8657a,"Revert ""Bump version numbers to 0.3.0. (#615)""

This reverts commit 101693c54284c776a6723cbf03f7f8497d7ba8c9.",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
417,Michael Schmitz,michael@schmitztech.com,2017-12-14 13:46:10-08:00,734efe9eb6477c6ea4db7414ff5e9e7cc47cf3c1,https://github.com/allenai/allennlp/commit/734efe9eb6477c6ea4db7414ff5e9e7cc47cf3c1,Update README.md (#617),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
418,Michael Schmitz,michael@schmitztech.com,2017-12-14 13:54:57-08:00,2bc09520c7a6df85da101f58694e1512ee5728b3,https://github.com/allenai/allennlp/commit/2bc09520c7a6df85da101f58694e1512ee5728b3,Add pytz to requirements.txt and setup.py. (#619),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
419,Michael Schmitz,michael@schmitztech.com,2017-12-14 12:45:40-08:00,6d4da4306051822e739b278e863da6ee2d54b56b,https://github.com/allenai/allennlp/commit/6d4da4306051822e739b278e863da6ee2d54b56b,Bump version numbers to 0.3.0. (#615),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
420,Michael Schmitz,michael@schmitztech.com,2017-12-14 13:07:24-08:00,3de911827346154f71399532f864c20b22346b86,https://github.com/allenai/allennlp/commit/3de911827346154f71399532f864c20b22346b86,Bump version numbers to v0.3.1-unreleased. (#616),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
421,Michael Schmitz,michael@schmitztech.com,2017-12-14 15:16:09-08:00,b15fa7e228b5ef84800cc51c88a3c6b7bb8e6506,https://github.com/allenai/allennlp/commit/b15fa7e228b5ef84800cc51c88a3c6b7bb8e6506,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
422,Michael Schmitz,michael@schmitztech.com,2017-12-14 15:18:05-08:00,f997649a7307c2d250c470585b18f038d3f355c3,https://github.com/allenai/allennlp/commit/f997649a7307c2d250c470585b18f038d3f355c3,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
423,Michael Schmitz,michael@schmitztech.com,2017-12-15 13:18:11-08:00,94737bd75855dfb698a1671e871f15e7f86d4afd,https://github.com/allenai/allennlp/commit/94737bd75855dfb698a1671e871f15e7f86d4afd,"Resolve ReactJS warnings. (#613)

* Replace divs with spans to avoid warning.

* Remove selected to fix warnings.

* Add a key for iterations in ReactJS to fix warnings.",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
424,Joel Grus,joelgrus@gmail.com,2017-12-15 13:59:31-08:00,1793768b3c3be52c144b43266a83e87be52f7c2f,https://github.com/allenai/allennlp/commit/1793768b3c3be52c144b43266a83e87be52f7c2f,"modify Params to support adding arbitrary files to the archive (#590)

* wip archivable

* clean up

* updates

* revamp

* modify elmo

* revert some changes

* update docstring

* update tests

* workaround pyhocon bug

* add one more assert

* pylint

* add back line

* change to dict

* rename Archivable to FileArchiver

* rename some things

* move files_to_archive over to Params

* update docs etc

* add end to end test

* return cls directly

* address pr feedback",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['params.files_to_archive == {', 'params.get()', 'params.get(', 'os.path.exists(fta_file)', 'files_to_archive == {', 'filecmp.cmp(original_filename, new_filename)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
425,Nelson Liu,nelson-liu@users.noreply.github.com,2017-12-15 14:35:22-08:00,f814c0f65b8568388a09883a2d78d379cfe03227,https://github.com/allenai/allennlp/commit/f814c0f65b8568388a09883a2d78d379cfe03227,Add __str__ and __repr__ to Token class (#626),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
426,Mark Neumann,markn@allenai.org,2017-12-15 23:01:26+00:00,26041a7781e4358ef668cebe6997a52158853414,https://github.com/allenai/allennlp/commit/26041a7781e4358ef668cebe6997a52158853414,"Stacked self attention (#605)

* add layer norm

* add positional encoding and stacked self attention

* modify intra-sentence attention to take an output projection

* fix dimension issue with hidden_size param

* lint

* add docs

* use device agnostic range

* stars not dashes for bullet points

* add tensor2tensor comparison

* try to appease sphinx

* line up the lines

* address PR comments

* fix mypy

* fix lint

* add efficient version of self attention

* add docs for attention

* remove redundant type

* correct spelling

* PR comments

* change docs",13,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(attention(inputs).size()) == [2, 12, 5]', 'encoder.get_input_dim() == 9', 'encoder.get_output_dim() == 12', 'list(encoder_output.size()) == [3, 5, 12]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
427,Nelson Liu,nelson-liu@users.noreply.github.com,2017-12-16 10:35:57-08:00,928bbb9414fd4cadcc3f00bc131f8e23b2f15ec0,https://github.com/allenai/allennlp/commit/928bbb9414fd4cadcc3f00bc131f8e23b2f15ec0,"Update install tutorial for PyTorch 0.3, mention python setup.py install (#627)

* Add setup.py install step to install from source tutorial

* Update installation tutorial to mention Pytorch 0.3 dependency

* Update installation.md",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
428,Maksym Del,max.del.edu@gmail.com,2017-12-17 20:20:52+02:00,eec65d61d0e4e026d35e3acc41c254ba56cece88,https://github.com/allenai/allennlp/commit/eec65d61d0e4e026d35e3acc41c254ba56cece88,"Add end and optional start tokens to source sentence in seq2seq DatasetReader (fixes #611) (#631)

* Add end and optional start tokens to source sentence in seq2seq DatasetReader

* Polish doc strings

* Make mypy happy

* Make pylint happy",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', 'len(dataset.instances) == 3', '[t.text for t in fields[]', '[t.text for t in fields[,']",[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[]', '[t.text for t in fields[]', '[t.text for t in fields[,']",[],[],[],[],[],[],[],[],[],[],[],[]
429,Michael Schmitz,michael@schmitztech.com,2017-12-18 11:02:29-08:00,842e2b4dcab220b50b970eb05990084090586df4,https://github.com/allenai/allennlp/commit/842e2b4dcab220b50b970eb05990084090586df4,Add pylintrc to Dockerfie (#625),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
430,Michael Schmitz,michael@schmitztech.com,2017-12-18 11:30:24-08:00,d47ac92f1f7fcd905618f4c928f5b95556a2997c,https://github.com/allenai/allennlp/commit/d47ac92f1f7fcd905618f4c928f5b95556a2997c,Advertise pip as the way to install AllenNLP (#628),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
431,Michael Schmitz,michael@schmitztech.com,2017-12-18 15:37:14-08:00,55869bc2d0bce111b021d6d50d565f53fe0efd52,https://github.com/allenai/allennlp/commit/55869bc2d0bce111b021d6d50d565f53fe0efd52,Upgrade pylint. (#638),6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
432,Matt Gardner,mattg@allenai.org,2017-12-18 15:39:52-08:00,5a65f7246bf0eb2db69a6fb780bc696ab2823dc3,https://github.com/allenai/allennlp/commit/5a65f7246bf0eb2db69a6fb780bc696ab2823dc3,"Remove references to individual commits in tutorial, add data (#637)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
433,Joel Grus,joelgrus@gmail.com,2017-12-18 16:12:33-08:00,8308c941605db4ab44597bbec2ccee262b223294,https://github.com/allenai/allennlp/commit/8308c941605db4ab44597bbec2ccee262b223294,remove quotes from etag (#618),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not in filename', 'back_to_url == url', 'etag == ']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
434,Michael Schmitz,michael@schmitztech.com,2017-12-19 09:55:54-08:00,09269052ce1bc99c1d7c81b7268889df6d4ad846,https://github.com/allenai/allennlp/commit/09269052ce1bc99c1d7c81b7268889df6d4ad846,Allow the header to resize on small resolutions. (#629),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
435,Joel Grus,joelgrus@gmail.com,2017-12-19 13:29:24-08:00,fc013779b4f39d8e1c3f0712f7fe400533e4fd44,https://github.com/allenai/allennlp/commit/fc013779b4f39d8e1c3f0712f7fe400533e4fd44,"switch out sanic to flask (#636)

* wip flask

* get tests to pass

* replace sanic with flask in setup.py

* remove sanic

* remove num_workers flag / argument

* clean up tests

* fix docs

* fix api docs

* fix errors",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['response.status_code == 400', 'b in data', 'response.status_code == 200', 'response.status_code == 200', 'response.status_code == 200', 'response.status_code == 200', 'json.loads(response.get_data()) == data', 'response.status_code == 200', 'json.loads(response.get_data()) == noyes', 'response.status_code == 200', 'json.loads(response.get_data()) == data', 'response.status_code == 200', 'json.loads(response.get_data()) == data', 'response.status_code == 200', 'response.status_code == 400', 'response.status_code == 200', 'response.status_code == 400', 'response.status_code == 200']",[],[],[],[],[],[],[],[],[],[],[],[],"['response.status == 400', 'in response.text', 'response.status == 200', 'response.status == 200', 'response.status == 200', 'response.status == 200', 'json.loads(response.text) == data', 'response.status == 200', 'json.loads(response.text) == noyes', 'response.status == 200', 'json.loads(response.text) == data', 'response.status == 200', 'json.loads(response.text) == data', 'response.status == 200', 'response.status == 400', 'response.status == 200', 'response.status == 400', 'response.status == 200']",[],[],[],[],[],[],[],[],[],[],[],[]
436,Michael Schmitz,michael@schmitztech.com,2017-12-19 13:57:36-08:00,ac6e62bc46417de2b4babe46e75d39b5c30aed2f,https://github.com/allenai/allennlp/commit/ac6e62bc46417de2b4babe46e75d39b5c30aed2f,Create README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
437,Michael Schmitz,michael@schmitztech.com,2017-12-19 15:53:15-08:00,45d1103e16839d541c7692b5f22efc6d6d3d14f3,https://github.com/allenai/allennlp/commit/45d1103e16839d541c7692b5f22efc6d6d3d14f3,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
438,Mark Neumann,markn@allenai.org,2017-12-20 21:42:35+00:00,4a491cd74c3dcb4f41270a0d4770c3ca5abadb7d,https://github.com/allenai/allennlp/commit/4a491cd74c3dcb4f41270a0d4770c3ca5abadb7d,"Self attention improvements (#640)

* add layernorm everywhere, fix attention temp

* better names

* remove snake case

* undo scaling thing, heads aren't stacked

* add uniform unit scaling

* remove superflous parentheses

* do the pre and post processing in a better order

* use the right dims for LayerNorm

* PR fixes",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tensor.data.max() < math.sqrt(3/10)', 'tensor.data.min() > -math.sqrt(3/10)', 'tensor.data.max() < math.sqrt(3/10) * 1.43', 'tensor.data.min() > -math.sqrt(3/10) * 1.43']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
439,Michael Schmitz,michael@schmitztech.com,2017-12-21 15:51:44-08:00,ce2e7628f3ccc740890e7dd9d17153f86d6d697c,https://github.com/allenai/allennlp/commit/ce2e7628f3ccc740890e7dd9d17153f86d6d697c,"Move jupyter dependency to requirements_test. (#645)

* Move jupyter dependency to requirements_test.

* Remove Jupyter from setup.py.

* Add installing Jupyter to the notebook instructions.",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
440,Michael Schmitz,michael@schmitztech.com,2017-12-21 15:52:06-08:00,fd8eebb066ca4c902a45b37ca6e437948818a4e8,https://github.com/allenai/allennlp/commit/fd8eebb066ca4c902a45b37ca6e437948818a4e8,Add titles to the tutorials. (#647),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
441,Mark Neumann,markn@allenai.org,2017-12-22 14:47:41+00:00,b3522af919a53e0efe516f6f5aa63bcfcd948423,https://github.com/allenai/allennlp/commit/b3522af919a53e0efe516f6f5aa63bcfcd948423,even more layer norm (#644),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
442,Michael Schmitz,michael@schmitztech.com,2017-12-22 07:48:08-08:00,4cda858012261c5fa5f668236abaeb4333d587ec,https://github.com/allenai/allennlp/commit/4cda858012261c5fa5f668236abaeb4333d587ec,Configure version in one place. (#630),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
443,Joel Grus,joelgrus@gmail.com,2018-01-02 10:11:47-08:00,c5e1cf8c4c4aa6592e2175fc9ad2d961a8aa75c2,https://github.com/allenai/allennlp/commit/c5e1cf8c4c4aa6592e2175fc9ad2d961a8aa75c2,"simple server (#642)

* simple server

* make it pretty

* add some js comments

* silence pylint too-many-lines

* remove lots of css",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['b in data', 'b in data', 'in data', 'in data', 'in data', 'not in data', 'data == html', 'data == jpg']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
444,Joel Grus,joelgrus@gmail.com,2018-01-02 13:08:17-08:00,45bd1bc265450106d121df13b4b0ed8f986fd0fb,https://github.com/allenai/allennlp/commit/45bd1bc265450106d121df13b4b0ed8f986fd0fb,"add static `load_line` and `dump_line` methods to predictor to allow non-JSONL formats (#655)

* allow predictors to read/write CSVs

* remove extra print statement

* address PR comments

* remove static annotations",8,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(outfile)', 'len(results) == 2', 'len(row) == 5', '0 <= float(prob) <= 1', '0 <= int(span_start) <= int(span_end) <= 8', 'span != ']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
445,Matt Gardner,mattg@allenai.org,2018-01-02 14:00:18-08:00,b1b832a4e17ab084ac91c70268d1072d25db6cb7,https://github.com/allenai/allennlp/commit/b1b832a4e17ab084ac91c70268d1072d25db6cb7,"Add a check_dimensions_match function (#657)

* Add a check_dimensions_match function

* Pylint",6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
446,Matt Gardner,mattg@allenai.org,2018-01-02 14:00:46-08:00,f20f34c7e8100fc4580c6919713e5c16aa96476b,https://github.com/allenai/allennlp/commit/f20f34c7e8100fc4580c6919713e5c16aa96476b,"Make assert_fields_equal more robust to different Field structures. (#656)

* Minor improvements to ModelTestCase

* Address PR comments",1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,3,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('_fields_equal', '(model_batch[key], loaded_batch[key], key, 1e-6)'), ('_fields_equal', '(field1[key],'), ('_fields_equal', '(subfield1,')]",[],[],[],[],[],[],[],[],[],[],"[('_fields_equal', '(model_batch[key][subfield],'), ('_fields_equal', '(model_batch[key], loaded_batch[key], 1e-6, key)')]",[],[],[],[],[],[],[],[],[],"['model_batch.keys() == loaded_batch.keys()', 'field1.keys() == field2.keys()', 'len(field1) == len(field2)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
447,Matt Gardner,mattg@allenai.org,2018-01-02 14:33:32-08:00,4bf4294c947913569b5856e1cfa95805b39efb70,https://github.com/allenai/allennlp/commit/4bf4294c947913569b5856e1cfa95805b39efb70,"Make ListField batching robust (#658)

* Make ListField batching robust

* Use `all` instead of `set() == set()`",6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
448,Mark Neumann,markn@allenai.org,2018-01-03 20:57:58+00:00,85b2c2d2b9fa8bbaa3335d889c610e46d253e6cc,https://github.com/allenai/allennlp/commit/85b2c2d2b9fa8bbaa3335d889c610e46d253e6cc,"Ontonotes for readers (#584)

* refactor SRL reader to use Ontonotes reader

* use Ontonotes for coref reader

* add pos tags to parse tree, gracefully handle bad annotations

* remove duplicate conll data in tests

* remove uncessary coref script

* lint

* add back non-redundant spaces in parse tree strings

* lint

* don't use uncessary union in type

* actually fix pylint

* PR feedback",9,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset.instances) == 1', 'text == [,', 'gold_mentions_with_ids == [([], 0),', 'gold_mentions_with_ids == [([], 2),', 'annotation.parse_tree == Tree.fromstring(', 'annotation.parse_tree == Tree.fromstring(', 'annotation.parse_tree == Tree.fromstring(']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset.instances) == 2', 'text == [,', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', 'not ([], 1) in gold_mentions_with_ids', 'text == [,', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', 'annotation.parse_tree == Tree.fromstring(', 'annotation.parse_tree == Tree.fromstring(', 'annotation.parse_tree == Tree.fromstring(']",[],[],[],[],[],[],[],[],[],[],[],['import pytest']
449,Mark Neumann,markn@allenai.org,2018-01-04 15:40:42+00:00,b9525c85e1ef1c4bf8d24b5dce0265e721f46a84,https://github.com/allenai/allennlp/commit/b9525c85e1ef1c4bf8d24b5dce0265e721f46a84,"Predictor api (#646)

* fix merge conflict

* move to Tuples for predictors

* move coref and sentence tagger to use new api

* big refactor of SRL predictor to use support batch processing

* add better docs to SRL predictor

* clarify comment

* add tests

* spacing for docs

* no O(n^2) list flattening

* fix hideous merge

* fix pylint",7,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['result[0] == result[1]'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
450,Michael Schmitz,michael@schmitztech.com,2018-01-04 14:49:21-08:00,d8226ddcbb1746b9f6ff0606e2c8d6d9857d2e75,https://github.com/allenai/allennlp/commit/d8226ddcbb1746b9f6ff0606e2c8d6d9857d2e75,Add --overrides for train. (#649),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
451,Michael Schmitz,michael@schmitztech.com,2018-01-05 08:21:49-08:00,31483d50c2101375eabe8356953343b5a0632b6e,https://github.com/allenai/allennlp/commit/31483d50c2101375eabe8356953343b5a0632b6e,Update README.md (#662),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
452,Michael Schmitz,michael@schmitztech.com,2018-01-05 13:28:31-08:00,377311fc03a84e497ed86c1150d89c92153dc9f4,https://github.com/allenai/allennlp/commit/377311fc03a84e497ed86c1150d89c92153dc9f4,"Add pop_int, pop_float, and pop_bool (#648)",33,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
453,Michael Schmitz,michael@schmitztech.com,2018-01-05 16:11:26-08:00,24803d5674f9dba5f4950034f05996c54e9477d2,https://github.com/allenai/allennlp/commit/24803d5674f9dba5f4950034f05996c54e9477d2,Configure logging level with env variable. (#665),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
454,Mark Neumann,markn@allenai.org,2018-01-08 17:17:34+00:00,e82bbcabd5223275f8ba80d1077fa260a0a56542,https://github.com/allenai/allennlp/commit/e82bbcabd5223275f8ba80d1077fa260a0a56542,"fix tutorials, make namespace vs keys unambiguous (#633)

* fix tutorials, make namespace vs keys unambiguous

* fix namespace typo",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
455,Joel Grus,joelgrus@gmail.com,2018-01-08 10:32:54-08:00,df53ae8778ff8366767f0e4f905328fe9af5b20f,https://github.com/allenai/allennlp/commit/df53ae8778ff8366767f0e4f905328fe9af5b20f,"run flask with gevent (#666)

* run flask with gevent

* add gevent to server_simple",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
456,Mark Neumann,markn@allenai.org,2018-01-08 21:28:53+00:00,2de3ad35ed5ca236b28b5e8c22ce63053e8ddeb0,https://github.com/allenai/allennlp/commit/2de3ad35ed5ca236b28b5e8c22ce63053e8ddeb0,"Move bio_tags_to_spans out of SpanBasedF1Metric (#668)

* pylint

* PR comments",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(spans) == {(, (7, 7))}', 'set(spans) == {(, (7, 7))}', 'set(spans) == {(, (7, 7)),', 'set(spans) == {(, (9, 9))}']",[],[],[],[],[],[],[],[],[],[],[],[],"['spans == {((1, 2), )}', 'spans == {((1, 2), )}', 'spans == {((1, 2), ),', 'spans == {((6, 7), )}']",[],[],[],[],[],[],[],[],[],[],[],[]
457,Mark Neumann,markn@allenai.org,2018-01-09 15:32:53-08:00,14d0cba076bd2f2682d3473338b55f71ecb23c0c,https://github.com/allenai/allennlp/commit/14d0cba076bd2f2682d3473338b55f71ecb23c0c,"handle continued spans correctly in SpanBasedF1Measure (#670)

* handle continued spans correctly in SpanBasedF1Measure

* remove stupid comment

* parse perl script output in test",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metric._true_positives[] == 1', 'not in metric._true_positives.keys()', 'metric._true_positives[] == 1', 'metric._true_positives[] == 1', 'num_correct_arg1_instances_from_perl_evaluation == metric._true_positives[]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
458,Mark Neumann,markn@allenai.org,2018-01-09 17:44:08-08:00,1ba8b771a5f819a676d31bf65227b7e837491623,https://github.com/allenai/allennlp/commit/1ba8b771a5f819a676d31bf65227b7e837491623,update SRL script to work without arrays_to_variables (#672),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
459,Mark Neumann,markn@allenai.org,2018-01-11 13:55:53-08:00,6c66c7e487c44a5d0cd0e5847cf78c3814b42acf,https://github.com/allenai/allennlp/commit/6c66c7e487c44a5d0cd0e5847cf78c3814b42acf,little tweaks to elmo embeddings script (#677),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
460,Matt Gardner,mattg@allenai.org,2018-01-15 08:50:37-08:00,ea33ffa3517d26308317dc972fc81bc22b235e90,https://github.com/allenai/allennlp/commit/ea33ffa3517d26308317dc972fc81bc22b235e90,"Removed the `evaluate_squad_model.py` script, which is no longer necessary (#679)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
461,Nicholas A. Lourie,nicholasl@allenai.org,2018-01-15 16:13:37-05:00,76bc9bc95ef435b5b837787a556657f3f1f8d0ed,https://github.com/allenai/allennlp/commit/76bc9bc95ef435b5b837787a556657f3f1f8d0ed,"Fix Links in Tutorials (#669)

* Fix link in installation.md

* Fix link in tutorials/getting_started/configuration.md

* Fix link in tutorials/getting_started/using_in_your_repo.md

* Replace 404'd link to a tutorial with link to documentation

The data-pipeline tutorial doesn't seem to be present in the
tutorials directoy, so replace it with a link to the relevant
documentation.

* Revert ""Replace 404'd link to a tutorial with link to documentation""

This reverts commit 968cad69e3311234da175ae34be63c3f57a3520c.

* Update data-pipeline link to point to the notebook tutorial",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
462,Mark Neumann,markn@allenai.org,2018-01-15 13:46:24-08:00,786dfc489e81b4ca7f9add8577a9f45d6177aec0,https://github.com/allenai/allennlp/commit/786dfc489e81b4ca7f9add8577a9f45d6177aec0,"Ontonotes srl fix (#678)

* don't use verbs as keys due to duplication within sentences

* add test fixture which includes sentence with 2 identical verbs",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['annotation.srl_frames == [(,', 'annotation.srl_frames == [(,', 'annotation.srl_frames == []', 'annotation.document_id == ', 'annotation.sentence_id == 0', 'annotation.words == [,', 'annotation.pos_tags == [,', 'annotation.word_senses == [None, None, None, 4.0, None, None, None, None,', 'annotation.predicate_framenet_ids == [None, None, None, , None, None,', 'annotation.srl_frames == [(,', 'annotation.named_entities == [,', 'annotation.predicate_lemmas == [None, None, None, , None, None, None,', 'annotation.speakers == [,', 'annotation.parse_tree == Tree.fromstring(', 'annotation.coref_spans == {(14, (6, 6))}']",[],[],[],[],[],[],[],[],[],[],[],[],"['annotation.srl_frames == {,', 'annotation.srl_frames == {,', 'annotation.srl_frames == {}']",[],[],[],[],[],[],[],[],[],[],[],[]
463,Joel Grus,joelgrus@gmail.com,2018-01-16 07:59:47-08:00,2d77a2d6039bc444f2a5801f0c4624cd140c3a23,https://github.com/allenai/allennlp/commit/2d77a2d6039bc444f2a5801f0c4624cd140c3a23,"lazy datasets (#675)

* lazy datasets

* add end-to-end lazy dataset test + fix bugs

* fix notebook tests

* remove accidentally committed ipynb checkpoints

* remove duplicate code in tests

* Iterator -> Iterable

* address PR comments

* fix api docs",29,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('_instances_are_correct', '(instances)'), ('_instances_are_correct', '(instances)')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(candidate_instances) == set(expected_instances)', 'len(instances) == 5', 'len(instances) == 5 * 6', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[0], self.instances[1]]]', 'grouped_instances == [[self.instances[2], self.instances[3]]]', 'grouped_instances == [[self.instances[4], self.instances[0]]]', 'grouped_instances == [[self.instances[1], self.instances[2]]]', 'grouped_instances == [[self.instances[3], self.instances[4]]]', 'grouped_instances == [[self.instances[0], self.instances[1]]]', 'grouped_instances == [[self.instances[0]], [self.instances[1]]]', 'grouped_instances == [[self.instances[0]], [self.instances[1]]]', 'grouped_instances == [[self.instances[2]], [self.instances[3]]]', 'grouped_instances == [[self.instances[2]], [self.instances[3]]]', 'iterator._batch_size == 32  # default value', 'iterator._batch_size == 10']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
464,Michael Schmitz,michael@schmitztech.com,2018-01-16 12:53:40-08:00,edbb1451cc463bc02845027204d9b57a61040796,https://github.com/allenai/allennlp/commit/edbb1451cc463bc02845027204d9b57a61040796,Disable running coverage in Travis. (#687),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
465,Matt Gardner,mattg@allenai.org,2018-01-17 11:49:51-08:00,95eae1a02694bd45422679a036bef1a38d01274e,https://github.com/allenai/allennlp/commit/95eae1a02694bd45422679a036bef1a38d01274e,Pin mypy to 0.521 (#689),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
466,Michael Schmitz,michael@schmitztech.com,2018-01-17 13:57:49-08:00,6cb107cc2bdc12acd7e46cdc5eb5896e13bae6f6,https://github.com/allenai/allennlp/commit/6cb107cc2bdc12acd7e46cdc5eb5896e13bae6f6,Remove Travis configuration. (#674),6,False,False,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
467,Joel Grus,joelgrus@gmail.com,2018-01-17 15:51:15-08:00,745e2a5b30516cf130dd428a48b27b2f6aabbae6,https://github.com/allenai/allennlp/commit/745e2a5b30516cf130dd428a48b27b2f6aabbae6,"quick and dirty logging of memory usage (sort of) (#696)

* cheap logging of memory usage

* fix comments

* add comment

* add peak memory to flask /info

* add type: ignore",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
468,Mark Neumann,markn@allenai.org,2018-01-17 16:29:50-08:00,3aa33139216ff3f597fe2630d44aa69afe4d97a7,https://github.com/allenai/allennlp/commit/3aa33139216ff3f597fe2630d44aa69afe4d97a7,"Coref data fix (#691)

* add iterator for multiple docs per file, change coref reader accordingly

* add back script for compiling coref data

* add tests and fixtures

* add tqdm

* add newlines",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset.instances) == 2', 'text == [,', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', 'not ([], 1) in gold_mentions_with_ids', 'text == [,', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', 'len(documents) == 2']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset.instances) == 1', 'text == [,', 'gold_mentions_with_ids == [([], 0),', 'gold_mentions_with_ids == [([], 2),']",[],[],[],[],[],[],[],[],[],[],[],[]
469,Matt Gardner,mattg@allenai.org,2018-01-18 14:44:55-08:00,9aedbac142a5d95948e2e580a7ac692a1c9ec755,https://github.com/allenai/allennlp/commit/9aedbac142a5d95948e2e580a7ac692a1c9ec755,"Remove readthedocs build tools (#700)

We don't use readthedocs anymore, so we don't need this requirements file.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
470,Mark Neumann,markn@allenai.org,2018-01-18 15:42:34-08:00,9d15b996ba3c8d8f5afff13782d3a351b789c840,https://github.com/allenai/allennlp/commit/9d15b996ba3c8d8f5afff13782d3a351b789c840,remove registerable from elmo (#698),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
471,Mark Neumann,markn@allenai.org,2018-01-18 16:01:40-08:00,9c29d3e4375bbbf703e678173638324345db5854,https://github.com/allenai/allennlp/commit/9c29d3e4375bbbf703e678173638324345db5854,add driver label to Dockerfile (#701),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
472,Mark Neumann,markn@allenai.org,2018-01-19 09:27:58-08:00,c7ae7c804cdb6ce09c467b9b38c8eb0fe6d3fc57,https://github.com/allenai/allennlp/commit/c7ae7c804cdb6ce09c467b9b38c8eb0fe6d3fc57,make driver config robust to nvidia-docker version (#702),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
473,Matthew Peters,matt-peters@users.noreply.github.com,2018-01-19 13:17:26-08:00,260476d3017529eb9859983b2d15066eacd039d1,https://github.com/allenai/allennlp/commit/260476d3017529eb9859983b2d15066eacd039d1,"ELMo tutorial (#699)

* WIP: ELMo documentation

* Use relative paths in tutorials/README.md

* Update doc

* Doc

* Add script to dump elmo

* doc

* doc

* doc

* doc

* doc

* PR comments",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
474,Matt Gardner,mattg@allenai.org,2018-01-22 14:06:38-08:00,6de331b6e4eff01ef9e86f991d7c1c820f2fe902,https://github.com/allenai/allennlp/commit/6de331b6e4eff01ef9e86f991d7c1c820f2fe902,"Allow tokenizers to do batch tokenization (#680)

* Added a batch_tokenize method to the tokenizers

* Let spacy figure out how many threads to use

* Fix bug

* Fix mypy",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(batch_tokenized) == len(separately_tokenized)', 'len(batch_sentence) == len(separate_sentence)', 'batch_word.text == separate_word.text', 'len(batch_split) == len(separately_split)', 'len(batch_sentence) == len(separate_sentence)', 'batch_word.text == separate_word.text', 'len(batch_tokenized) == len(separately_tokenized)', 'len(batch_sentence) == len(separate_sentence)', 'batch_word.text == separate_word.text']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
475,Mark Neumann,markn@allenai.org,2018-01-22 14:37:25-08:00,4e97ea190ad48674052e4cf5343617d17c219f73,https://github.com/allenai/allennlp/commit/4e97ea190ad48674052e4cf5343617d17c219f73,"let there be validation metrics which aren't computed during training (#705)

* let there be validation metrics which aren't computed during training

* fix logging message

* use default values for .get

* fix optional validation metrics

* more None removal

* trailing whitespace",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
476,Mark Neumann,markn@allenai.org,2018-01-23 12:31:49-08:00,a17f8a3bd97da25f6d189cdad36f751a4929b3b5,https://github.com/allenai/allennlp/commit/a17f8a3bd97da25f6d189cdad36f751a4929b3b5,"Span field (#707)

* span field

* docs

* PR feedback

* remove unused imports",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['empty_span.span_start == -1', 'empty_span.span_end == -1']","['(TypeError)', '(ValueError)', '(ValueError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],['index_field.get_padding_lengths() == {: 5}'],[],[],[],[],[],[],[],[],[],[],[],[]
477,Mark Neumann,markn@allenai.org,2018-01-23 16:54:45-08:00,3ba691d253babff5ba1f16452a837788026f5a21,https://github.com/allenai/allennlp/commit/3ba691d253babff5ba1f16452a837788026f5a21,"Span utils (#708)

* add span utils

* use enumerate spans in coref reader

* correct indentation

* make enumerate_spans generic

* catch Token reference in docstring

* PR comments

* address PR comments

* make generics specific to str and Token",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(spans) == {(, (7, 7))}', 'set(spans) == {(, (7, 7))}', 'set(spans) == {(, (7, 7)),', 'set(spans) == {(, (9, 9))}', 'spans == [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 1), (1, 2),', 'spans == [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3), (2, 4), (3, 4)]', 'spans == [(20, 21), (20, 22), (21, 22), (21, 23), (22, 23), (22, 24), (23, 24)]', 'spans == [(0, 1), (0, 2), (1, 2), (1, 3), (2, 3)]']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(spans) == {(, (7, 7))}', 'set(spans) == {(, (7, 7))}', 'set(spans) == {(, (7, 7)),', 'set(spans) == {(, (9, 9))}']",[],[],[],[],[],[],[],[],[],[],[],[]
478,Joel Grus,joelgrus@gmail.com,2018-01-23 17:36:58-08:00,442059af2aaa757a4d6204cc80b0082e6e45f02a,https://github.com/allenai/allennlp/commit/442059af2aaa757a4d6204cc80b0082e6e45f02a,"add make-vocab command (#710)

* add make-vocab command

* add missing period

* add docs",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(vocab_files) == {}', 'tokens == []', 'labels == []']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
479,Michael Schmitz,michael@schmitztech.com,2018-01-25 11:51:39-08:00,d502b3b730df1d8fdfa81e6503930d882282ad8c,https://github.com/allenai/allennlp/commit/d502b3b730df1d8fdfa81e6503930d882282ad8c,Change backspace to carriage return in TeeLogger. (#719),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
480,Michael Schmitz,michael@schmitztech.com,2018-01-25 13:22:16-08:00,97f41078e091374004c39c55d28b9f5e533208fa,https://github.com/allenai/allennlp/commit/97f41078e091374004c39c55d28b9f5e533208fa,Update tee_logger.py,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
481,Joel Grus,joelgrus@gmail.com,2018-01-25 17:19:42-08:00,3c428f9cbe3fa149e30bc85ebfcb6e567cabb0a7,https://github.com/allenai/allennlp/commit/3c428f9cbe3fa149e30bc85ebfcb6e567cabb0a7,"programmatic imports of third-party models (#695)

* import programmatically

* add tests

* missing files

* fix pylint + mypy

* fixed to server_simple

* add tests for dynamic module imports

* update tutorials",11,False,True,False,False,True,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,11,3,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],['class TestPredict(TestCase):'],[],[],[],[],[],[],[],[],[],[],"['metrics.keys() == {}', 'os.path.exists(outfile)', 'len(results) == 2', 'set(result.keys()) == {,', 'os.path.exists(outfile)', 'len(results) == 2', 'set(result.keys()) == {,', 'not in sys.modules', 'not in sys.modules', 'in sys.modules', 'in sys.modules']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
482,Joel Grus,joelgrus@gmail.com,2018-01-25 19:07:17-08:00,7edcdf5a90a8ca067badb8903ad30bf50c18e0ec,https://github.com/allenai/allennlp/commit/7edcdf5a90a8ca067badb8903ad30bf50c18e0ec,"Revert ""programmatic imports of third-party models (#695)"" (#726)

This reverts commit 3c428f9cbe3fa149e30bc85ebfcb6e567cabb0a7.",11,False,True,True,True,False,False,False,True,False,False,False,False,False,False,False,[],1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,3,0,0,0,0,0,0,0,0,0,0,3,['class TestPredict(TestCase):'],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics.keys() == {}', 'os.path.exists(outfile)', 'len(results) == 2', 'set(result.keys()) == {,', 'os.path.exists(outfile)', 'len(results) == 2', 'set(result.keys()) == {,', 'not in sys.modules', 'not in sys.modules', 'in sys.modules', 'in sys.modules']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest', 'import pytest']"
483,Mark Neumann,markn@allenai.org,2018-01-26 13:19:54-08:00,e665767f3f25c638fc30be6bd435c15f014a4433,https://github.com/allenai/allennlp/commit/e665767f3f25c638fc30be6bd435c15f014a4433,fix setup.py to not import version (#721),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
484,Michael Schmitz,michael@schmitztech.com,2018-01-29 07:51:52-08:00,a1b59eeffd4401a3c0de68354416602a8d75b6c9,https://github.com/allenai/allennlp/commit/a1b59eeffd4401a3c0de68354416602a8d75b6c9,Update elmo.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
485,Michael Schmitz,michael@schmitztech.com,2018-01-29 10:49:17-08:00,2a90ed83ac62a3ab77bb8eb9d4c1543b73df729c,https://github.com/allenai/allennlp/commit/2a90ed83ac62a3ab77bb8eb9d4c1543b73df729c,Add a --file-friendly-logging argument for Beaker (#722),23,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
486,Mark Neumann,markn@allenai.org,2018-01-29 13:33:33-08:00,2a86dc32eef9c69ed1d6a096d12308d2fa1495ca,https://github.com/allenai/allennlp/commit/2a86dc32eef9c69ed1d6a096d12308d2fa1495ca,"SpanPruner and new coref model (#720)

* initial Pruner work

* working span pruner

* add tests

* weave SpanPruner into new coref model

* working SpanPruner integration

* pylint stuff

* tidy up

* add docs

* address PR comments

* better test

* pylint, fix docs

* don't require docs for temp coref model

* add test for fully masked case

* change type

* remove unused import",11,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(clusters) == 2', 'gold1 in clusters', 'gold2 in clusters']",['(ValueError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
487,Mark Neumann,markn@allenai.org,2018-01-29 14:29:58-08:00,66ec8af51ab044a80071d31598ba633bd8a6fd9f,https://github.com/allenai/allennlp/commit/66ec8af51ab044a80071d31598ba633bd8a6fd9f,update bulk to predict in readme (#733),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
488,Joel Grus,joelgrus@gmail.com,2018-01-30 11:38:49-08:00,924e56f301ee01533fb6bb07fb4d1b5ae24589a9,https://github.com/allenai/allennlp/commit/924e56f301ee01533fb6bb07fb4d1b5ae24589a9,"programmatic imports of third-party modules (#727)

* import programmatically

* add tests

* missing files

* fix pylint + mypy

* fixed to server_simple

* add tests for dynamic module imports

* update tutorials

* add call to invalidate_caches

* fix mypy",11,False,True,False,False,True,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,11,3,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],['class TestPredict(TestCase):'],[],[],[],[],[],[],[],[],[],[],"['metrics.keys() == {}', 'os.path.exists(outfile)', 'len(results) == 2', 'set(result.keys()) == {,', 'os.path.exists(outfile)', 'len(results) == 2', 'set(result.keys()) == {,', 'not in sys.modules', 'not in sys.modules', 'in sys.modules', 'in sys.modules']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
489,Joel Grus,joelgrus@gmail.com,2018-01-30 15:09:01-08:00,675733b63e41cccbabf1d95ff2e90585bf33efba,https://github.com/allenai/allennlp/commit/675733b63e41cccbabf1d95ff2e90585bf33efba,"eliminate Dataset abstraction (#725)

* instance_generator

* fix tests

* clean up

* index instances before calling get_padding_lengths

* include laziness in the dataset reader

* add lazy dataset reader test

* fix pylint

* remove instancegenerator

* restore test

* renaming

* update comments

* fix comments

* address pr feedback

* address pr feedback

* rename DatasetReader.instances() -> DatasetReader.read()

* convert current dataset readers to generators

* address pr comments

* update comment

* always _check_batch()

* fix pylint",51,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'reader.num_reads == 0', 'ensure_list(_instances) == self.instances', 'reader.num_reads == 10', 'reader.num_reads == 0', 'ensure_list(_instances) == self.instances', 'reader.num_reads == 1', 'len(instances) == 3', 'len(instances) == 3', 'len(instances) == 4', 'len(instances) == 4', 'len(instances) == 3', 'span_end < self.instances[0].fields[].sequence_length()']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset.instances) == 2', 'len(dataset.instances) == 3', 'len(dataset.instances) == 3', 'len(dataset.instances) == 4', 'len(dataset.instances) == 4', 'len(dataset.instances) == 3', 'span_end < self.dataset.instances[0].fields[].sequence_length()']",[],[],[],[],[],[],[],[],[],[],[],[]
490,Michael Schmitz,michael@schmitztech.com,2018-01-31 09:27:42-08:00,d1c5962988ff8ffdad0c639b31a048a920346bdc,https://github.com/allenai/allennlp/commit/d1c5962988ff8ffdad0c639b31a048a920346bdc,Add a verify.py script that runs all tests (#731),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
491,Mark Neumann,markn@allenai.org,2018-01-31 11:04:32-08:00,0b3ca77cf33aa688f298fae06f3c221af7c7161d,https://github.com/allenai/allennlp/commit/0b3ca77cf33aa688f298fae06f3c221af7c7161d,"Span extractor (#730)

* initial span extractor work

* add endpoint extractor

* add locally normalised span extractor

* make max_span_width more dynamic by calculating it at runtime

* add span_extractors to the docs

* fix mypy by adding empty Vocab to embedding from_params

* fix build

* add span_extractors to top level module docs

* address PR comments

* pylint

* correct docs for new name",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(extractor, EndpointSpanExtractor)', 'list(span_representations.size()) == [2, 2, 14]', 'extractor.get_output_dim() == 14', 'extractor.get_input_dim() == 7', 'isinstance(extractor, SelfAttentiveSpanExtractor)', 'extractor.get_output_dim() == input_dim', 'extractor.get_input_dim() == input_dim', 'list(span_representations.size()) == [2, 2, input_dim]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
492,Mark Neumann,markn@allenai.org,2018-01-31 13:09:10-08:00,50946749d3e774573545ae684f694df6338c567b,https://github.com/allenai/allennlp/commit/50946749d3e774573545ae684f694df6338c567b,"integrate span_extractors into coref model (#744)

* integrate span_extractors into coref model

* correct indentation

* better names",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['extractor.get_output_dim() == 10'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
493,Joel Grus,joelgrus@gmail.com,2018-01-31 13:28:05-08:00,c0cb3275d7e2b25e4965763f7f83e7a89ef7c0e4,https://github.com/allenai/allennlp/commit/c0cb3275d7e2b25e4965763f7f83e7a89ef7c0e4,"unify iterators / get rid of lazy iterator (#743)

* get rid of lazy iterator

* clean up test

* text max_instances with both lazy and non-lazy instances

* remove redundant test

* address PR feedback",11,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,4,1,0,0,0,0,0,0,0,0,24,1,0,0,0,0,0,0,0,0,0,0,1,19,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('_instances_are_correct', '(instances)'), ('_instances_are_correct', '(instances)')]",[],[],[],[],[],[],[],[],[],[],"[('_instances_are_correct', '(instances)'), ('_instances_are_correct', '(instances)'), ('_instances_are_correct', '(instances)'), ('_instances_are_correct', '(instances)')]",['def setUp(self):'],[],[],[],[],[],[],[],[],"['next(groups) == [1, 2, 3]', 'next(groups) == [4, 5, 6]', 'next(groups) == [7]', 'BasicIterator(batch_size=2).get_num_batches(self.lazy_instances) == 1', 'BasicIterator(batch_size=2, instances_per_epoch=21).get_num_batches(self.lazy_instances) == 11', 'BasicIterator(batch_size=2, instances_per_epoch=21).get_num_batches(self.instances) == 11', 'BasicIterator(batch_size=2).get_num_batches(self.instances) == 3', 'len(instances) == 5', 'len(instances) == 5 * 6', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[3], self.instances[4]],', 'grouped_instances == [[self.instances[1], self.instances[2]],', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[2], self.instances[3]],', 'len(in_order_batches) == len(shuffled_batches)', 'in_order_batches != shuffled_batches', 'in_order_counts == shuffled_counts', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[0]], [self.instances[1]]]', 'grouped_instances == [[self.instances[0]], [self.instances[1]]]', 'grouped_instances == [[self.instances[2]], [self.instances[3]]]', 'grouped_instances == [[self.instances[2]], [self.instances[3]]]', 'grouped_instances == [[self.instances[2], self.instances[0]],']",['(StopIteration)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['len(instances) == 5', 'len(instances) == 5 * 6', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'set(candidate_instances) == set(expected_instances)', 'len(instances) == 5', 'len(instances) == 5 * 6', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[0], self.instances[1]]]', 'grouped_instances == [[self.instances[2], self.instances[3]]]', 'grouped_instances == [[self.instances[4], self.instances[0]]]', 'grouped_instances == [[self.instances[1], self.instances[2]]]', 'grouped_instances == [[self.instances[3], self.instances[4]]]', 'grouped_instances == [[self.instances[0], self.instances[1]]]', 'grouped_instances == [[self.instances[0]], [self.instances[1]]]', 'grouped_instances == [[self.instances[0]], [self.instances[1]]]', 'grouped_instances == [[self.instances[2]], [self.instances[3]]]', 'grouped_instances == [[self.instances[2]], [self.instances[3]]]', 'iterator._batch_size == 32  # default value', 'iterator._batch_size == 10']",[],[],[],[],[],[],[],[],[],[],[],[]
494,Michael Schmitz,michael@schmitztech.com,2018-01-31 15:19:45-08:00,ceb94afe7499a9d2a47851167f025151e71760dc,https://github.com/allenai/allennlp/commit/ceb94afe7499a9d2a47851167f025151e71760dc,Set refresh to False when training to prevent extra TQDM output. (#746),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
495,Michael Schmitz,michael@schmitztech.com,2018-01-31 15:20:08-08:00,089237a60633b2b6f38362ff15584be84c11b826,https://github.com/allenai/allennlp/commit/089237a60633b2b6f38362ff15584be84c11b826,Fix Beaker scripts. (#747),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
496,Joel Grus,joelgrus@gmail.com,2018-01-31 15:42:10-08:00,b3e47f9715ceeb9bc2e96ec3aec8595e48f30727,https://github.com/allenai/allennlp/commit/b3e47f9715ceeb9bc2e96ec3aec8595e48f30727,require sorting_keys for bucket_iterator (#745),7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['iterator._sorting_keys == sorting_keys'],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],['iterator._sorting_keys == []'],[],[],[],[],[],[],[],[],[],[],[],[]
497,Mark Neumann,markn@allenai.org,2018-01-31 16:37:51-08:00,7d2b63cda3968bd818c2773e8b3fbfc937f06815,https://github.com/allenai/allennlp/commit/7d2b63cda3968bd818c2773e8b3fbfc937f06815,"PTB dataset reader (#741)

* add working reader

* finish tests for PTB reader

* please mypy by shuffling some code around

* pylint

* update dataset reader to work without Dataset

* fix mypy

* remove mistakenly added test fixture

* add ptb reader to docs

* address PR feedback",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'tokens == [,', 'pos_tags == [,', 'spans == enumerate_spans(tokens)', 'correct_spans_and_labels[span] == label', 'tokens == [,', 'pos_tags == [,', 'spans == enumerate_spans(tokens)', 'correct_spans_and_labels[span] == label', 'spans == [((0, 0), ),']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
498,Mark Neumann,markn@allenai.org,2018-02-02 11:47:55-08:00,2dfcf3cca3cf7d059b12079030e77e87b1118429,https://github.com/allenai/allennlp/commit/2dfcf3cca3cf7d059b12079030e77e87b1118429,remove would've from test fixture (#759),1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
499,Matt Gardner,mattg@allenai.org,2018-02-02 12:46:03-08:00,b1b7e9e480795b93f6feb84e676e6bc993ae4c83,https://github.com/allenai/allennlp/commit/b1b7e9e480795b93f6feb84e676e6bc993ae4c83,"Set minimum tqdm version (#750)

* Set minimum tqdm version

* Set minimum version in setup.py also",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
500,Joel Grus,joelgrus@gmail.com,2018-02-02 13:19:55-08:00,630e2c431259e9bfe91112dbbaab8aede36b21ce,https://github.com/allenai/allennlp/commit/630e2c431259e9bfe91112dbbaab8aede36b21ce,"predictor tutorial (#681)

* predictor tutorial

* update tutorial to reflect latest code

* add custom html tutorial

* update tutorial

* remove unnecessary png

* update tutorial

* address pr feedback",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
501,Mark Neumann,markn@allenai.org,2018-02-02 14:35:45-08:00,aec361aeccbbbc8278659460d972eb918e58d044,https://github.com/allenai/allennlp/commit/aec361aeccbbbc8278659460d972eb918e58d044,add gevent to setup.py (#760),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
502,Matthew Peters,matt-peters@users.noreply.github.com,2018-02-02 17:31:02-08:00,ab4aeb28f1b81747c985a188b6c4c569c02aaa75,https://github.com/allenai/allennlp/commit/ab4aeb28f1b81747c985a188b6c4c569c02aaa75,"Trainer feature improvements (#749)

* Add option to only retain last N checkpoints in trainer

* Add ability to save checkpoints more frequently then every epoch

* pylint and mypy

* Log norm of gradient

* Log the magnitude of gradient updates

* Log histograms of parameters

* Add option to log activations of some modules

* pylint

* Make sure we can restore from timestamped checkpoints in Trainer

* Allow models to specify which parameters to log

* Fix bug

* Support sparse gradient norm clipping

* Support sparse updates in trainer

* Log ratio of norm of gradient update

* use  for logging

* Support learning rate schedulers that can update on every batch

* Update lr before calling optimizer.step()

* Add batch_num_total to trainer checkpoints

* Support clipping sparse gradients

* WIP: multiGPU support

* WIP: multi gpu training

* Multi GPU

* Average loss across GPUs instead of summing

* Clean up logging

* Clean up logging

* More clones

* Add option to keep checkpoints every N seconds

* Fix tests after rebase

* Fix tests

* mypy

* pylint

* Fix pytorch's docstring so it passes our doc build...

* Add a test for histogram logging

* bug

* fix

* fix

* Add disclaimer

* PR comments

* pylint

* Add a comment about

* Readable timestamps in checkpoints

* mypy

* Fix the previous docstring fix

* docstring

* Move  to a method",13,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,3,0,0,0,0,3,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('AlmostEqual', '(grad._values().norm(2.0), 1.5, places=5) # pylint: disable=protected-access')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['sorted(epochs) == [2, 3, 4]', 'sorted(epochs) == [1, 3, 4, 5]', 'len(epochs) == 4', 'epochs[3] == ', 'in epochs[0]', 'epoch == 2', 'restore_trainer._batch_num_total == 4 # pylint: disable=protected-access', 'is_sparse(embedding.weight.grad)']",[],[],"['if(not torch.cuda.is_available(), reason=)', 'if(torch.cuda.device_count()', 'if(os.uname().sysname == )']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)', 'skipif(torch.cuda.device_count() < 2,', 'skipif(os.uname().sysname == )']","['mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.skipif(torch.cuda.device_count() < 2,', 'mark.skipif(os.uname().sysname == )']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
503,Michael Schmitz,michael@schmitztech.com,2018-02-05 09:03:11-08:00,c9bcbc40ad7fd5f5b3411a7035b4684f9c188adc,https://github.com/allenai/allennlp/commit/c9bcbc40ad7fd5f5b3411a7035b4684f9c188adc,Add logging configuration to elmo.md. (#729),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
504,Michael Schmitz,michael@schmitztech.com,2018-02-05 09:10:34-08:00,78dbe4584aa6cc64dcd9dbb0f3aca593bc9873d2,https://github.com/allenai/allennlp/commit/78dbe4584aa6cc64dcd9dbb0f3aca593bc9873d2,Use /stage/allennlp as the working directory. (#752),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
505,Michael Schmitz,michael@schmitztech.com,2018-02-05 09:42:12-08:00,c536c8f2941f2e6184692a0cc330af1642f82fa0,https://github.com/allenai/allennlp/commit/c536c8f2941f2e6184692a0cc330af1642f82fa0,Add friendly message about the demo being started. (#769),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
506,Michael Schmitz,michael@schmitztech.com,2018-02-05 09:59:32-08:00,6ca3d4845ebe3a5e4969fc189f820a7148e5d568,https://github.com/allenai/allennlp/commit/6ca3d4845ebe3a5e4969fc189f820a7148e5d568,Support using a directory as an archive file. (#734),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
507,Joel Grus,joelgrus@gmail.com,2018-02-05 11:30:26-08:00,96e440539ef6d4f9b607d375c90a502621d59409,https://github.com/allenai/allennlp/commit/96e440539ef6d4f9b607d375c90a502621d59409,"make all dataset readers (optionally) lazy (#773)

* add laziness to existing dataset readers

* fix pylint + etc

* parametrize tests",18,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,8,8,8,0,0,8,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],['([t.text for t in instances[3].fields[].tokens[:3]] =='],[],[],[],[],[],[],"['(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))']","['parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))']","['mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))']",[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest']",['[t.text for t in instances[3].fields[]'],[],[],[],[],[],[],[],[],[],[],[],[]
508,Michael Schmitz,michael@schmitztech.com,2018-02-05 11:57:30-08:00,c8c7d676e230988553f52ef864083c70e7b6cffc,https://github.com/allenai/allennlp/commit/c8c7d676e230988553f52ef864083c70e7b6cffc,Add flags to avoid recording calls in the database and caching. (#711),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
509,Mark Neumann,markn@allenai.org,2018-02-05 13:23:22-08:00,29af8672b5b5811597322ff6692d878acf3c2578,https://github.com/allenai/allennlp/commit/29af8672b5b5811597322ff6692d878acf3c2578,"Domain filter (#775)

* add domain filtering to SRL reader

* add filestructure to fixtures to allow domain test

* fix other tests which needed conll_2012 fixtures

* pylint, add domain to logging per PR comments",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['files == [,', 'len(instances) == 2']",[],[],[],[],[],[],[],[],[],[],[],[],['files == []'],[],[],[],[],[],[],[],[],[],[],[],[]
510,Mark Neumann,markn@allenai.org,2018-02-05 13:36:01-08:00,7915c28132fc61d1eb7e16aedcd653c9622d46be,https://github.com/allenai/allennlp/commit/7915c28132fc61d1eb7e16aedcd653c9622d46be,"Span field in coref model (#754)

* use SpanFields in coref model, switch new model in

* re-generate fixtures, add coref model to regeneration script

* fix test for span field

* add model to demo, tweak sniff test and demo sentence for new model

* fix trailing whitespace",26,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(clusters) == 2', 'gold1 in clusters', 'gold2 in clusters']",[],[],[],[],[],[],[],[],[],[],[],[]
511,Michael Schmitz,michael@schmitztech.com,2018-02-05 14:22:04-08:00,1bd953269960f42f2f51c374b38b40f21d065bf4,https://github.com/allenai/allennlp/commit/1bd953269960f42f2f51c374b38b40f21d065bf4,Add metrics.json output and migrate to run_with_beaker.py (#757),6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['params == {}'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
512,Michael Schmitz,michael@schmitztech.com,2018-02-05 15:26:33-08:00,7db82c12bfa97597cf6b69ec995359b0cfaabdbe,https://github.com/allenai/allennlp/commit/7db82c12bfa97597cf6b69ec995359b0cfaabdbe,A couple of small fixups for verify.sh. (#776),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
513,Matthew Peters,matt-peters@users.noreply.github.com,2018-02-05 16:18:26-08:00,e3c54d2cc75da8c027629eca44b393e0ce895314,https://github.com/allenai/allennlp/commit/e3c54d2cc75da8c027629eca44b393e0ce895314,"ELMo tuning (#767)

* requires_grad for ElmoLstm

* Allow configurable requires_grad for ELMo

* Allow to specify parameter groups when constructing optimizers

* pylint

* pylint

* mypy

* Cleanup

* docstring

* Add comments

* Add some logging

* Make mypy happy

* flaky test",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['all([grad is not None for grad in elmo_grads])', 'all([grad is None for grad in elmo_grads])', 'len(param_groups) == 1', 'param_groups[0][] == 1', 'len(param_groups) == 3', 'param_groups[0][] == 2', 'param_groups[1][] == 3', 'param_groups[2][] == 1', 'param_groups[k][] == 5', 'len(param_groups[0][]) == 6', 'len(param_groups[1][]) == 2', 'len(param_groups[2][]) == 3', 'restore_trainer._batch_num_total == 2 # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[],['restore_trainer._batch_num_total == 4 # pylint: disable=protected-access'],[],[],[],[],[],[],[],[],[],[],[],[]
514,Michael Schmitz,michael@schmitztech.com,2018-02-06 07:53:37-08:00,8764f661eae82e32dd1ae56b1a53f2d8088f4212,https://github.com/allenai/allennlp/commit/8764f661eae82e32dd1ae56b1a53f2d8088f4212,Increase tolerance to the default. (#783),1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
515,Joel Grus,joelgrus@gmail.com,2018-02-06 14:53:10-08:00,792027449bf77a0b6797e9a414aa81a78d21919e,https://github.com/allenai/allennlp/commit/792027449bf77a0b6797e9a414aa81a78d21919e,"laziness tutorial (#778)

* laziness tutorial

* split out how-to into its own tutorial

* address PR feedback

* address PR feedback",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
516,Mark Neumann,markn@allenai.org,2018-02-06 16:16:18-08:00,1f67d9ca0e8cc9c31f02669a92f1d0ac05083c32,https://github.com/allenai/allennlp/commit/1f67d9ca0e8cc9c31f02669a92f1d0ac05083c32,pin tensorboard version (#787),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
517,Michael Schmitz,michael@schmitztech.com,2018-02-07 12:49:56-08:00,04b8f39668b633c129cd46855b5acb8575c6e8cd,https://github.com/allenai/allennlp/commit/04b8f39668b633c129cd46855b5acb8575c6e8cd,"Remove allennlp/run (#791)

* Remove all references to allennlp/run.

* Remove allennlp/run command.",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
518,Mark Neumann,markn@allenai.org,2018-02-07 13:22:28-08:00,6c813decda6202842c0ff86c07b8419912f63567,https://github.com/allenai/allennlp/commit/6c813decda6202842c0ff86c07b8419912f63567,"update and unify commands (#788)

* update and unify commands

* use the same syntax for make-vocab

* update tutorial",6,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
519,Matt Gardner,mattg@allenai.org,2018-02-07 16:01:41-08:00,5f6c9b8ca29b56ab2d2e1acfc38ea61001b92c4b,https://github.com/allenai/allennlp/commit/5f6c9b8ca29b56ab2d2e1acfc38ea61001b92c4b,"Add an attention visualization to the BiDAF demo and a rough how-to (#692)

* Added a rough attention visualization to the BiDAF demo

* Made demo look a bit nicer

* Fix tests

* Fix component to be suitable for BiDAF demo, not Mandar's model

* Fixed npm warning

* Added a how-to for visualizing model internals (almost done)

* Add some parser images to the how-to

* How-to fixes

* Added comments for react components",20,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
520,Michael Schmitz,michael@schmitztech.com,2018-02-08 08:51:30-08:00,f7b2e3ffb4f53049a05fd4e5c42bfad787bf3563,https://github.com/allenai/allennlp/commit/f7b2e3ffb4f53049a05fd4e5c42bfad787bf3563,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
521,Michael Schmitz,michael@schmitztech.com,2018-02-08 09:22:09-08:00,b8d6d0bd5fdd108abb54e29e2433d954c202fb2a,https://github.com/allenai/allennlp/commit/b8d6d0bd5fdd108abb54e29e2433d954c202fb2a,Update README.md (#796),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
522,Michael Schmitz,michael@schmitztech.com,2018-02-08 13:33:59-08:00,2cc8377c62ad26101a2c07bceeaaa8bf094907e8,https://github.com/allenai/allennlp/commit/2cc8377c62ad26101a2c07bceeaaa8bf094907e8,Remove the --all flag and make --checks optional. (#797),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
523,Michael Schmitz,michael@schmitztech.com,2018-02-08 13:34:26-08:00,3dd9de8435035278e3f51afa887df41b228df2f2,https://github.com/allenai/allennlp/commit/3dd9de8435035278e3f51afa887df41b228df2f2,Add an Elmo command (#781),8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(output_path)', 'list(h5py_file.keys()) == []', 'h5py_file.get().shape == (3, len(sentence.split()), 32)', 'os.path.exists(output_path)', 'list(h5py_file.keys()) == []', 'h5py_file.get(str(i)).shape == (3, len(sentence.split()), 32)', 'os.path.exists(output_path)', 'list(h5py_file.keys()) == []', 'h5py_file.get().shape == (3, len(sentences[0].split()) - 1, 32)', 'h5py_file.get().shape == (3, len(sentences[1].split()) - 1, 32)', 'len(loaded_sentences) == len(loaded_embeddings)', 'len(expected_embeddings) == len(sentences)', 'len(embeddings) == len(sentences)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
524,Michael Schmitz,michael@schmitztech.com,2018-02-08 14:23:25-08:00,d035e81654530a324330ec601a11f673becb007f,https://github.com/allenai/allennlp/commit/d035e81654530a324330ec601a11f673becb007f,Address some missed comments from Matt Peters. (#798),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
525,Michael Schmitz,michael@schmitztech.com,2018-02-08 14:28:48-08:00,c447a3f07d2daccf132c8c8f7e993ec4ac700a8d,https://github.com/allenai/allennlp/commit/c447a3f07d2daccf132c8c8f7e993ec4ac700a8d,Use the sentence as the key in elmo command. (#799),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(h5py_file.keys()) == [sentence]', 'h5py_file.get(sentence).shape == (3, len(sentence.split()), 32)', 'set(h5py_file.keys()) == set(sentences)', 'h5py_file.get(sentence).shape == (3, len(sentence.split()), 32)']",[],[],[],[],[],[],[],[],[],[],[],[],"['list(h5py_file.keys()) == []', 'h5py_file.get().shape == (3, len(sentence.split()), 32)', 'list(h5py_file.keys()) == []', 'h5py_file.get(str(i)).shape == (3, len(sentence.split()), 32)', 'os.path.exists(output_path)', 'list(h5py_file.keys()) == []', 'h5py_file.get().shape == (3, len(sentences[0].split()) - 1, 32)', 'h5py_file.get().shape == (3, len(sentences[1].split()) - 1, 32)']",[],[],[],[],[],[],[],[],[],[],[],[]
526,Michael Schmitz,michael@schmitztech.com,2018-02-08 16:03:43-08:00,8876c5d432b903134fa1f282b2f44280d94d136c,https://github.com/allenai/allennlp/commit/8876c5d432b903134fa1f282b2f44280d94d136c,Warn on duplicate sentences (#800),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(output_path)', 'len(h5py_file.keys()) == 1', 'set(h5py_file.keys()) == set(sentences)', 'h5py_file.get(sentence).shape == (3, len(sentence.split()), 32)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
527,Tushar Khot,tushark@allenai.org,2018-02-08 18:25:31-08:00,1b08ada853ed701a4c4367e46207284ff464b91c,https://github.com/allenai/allennlp/commit/1b08ada853ed701a4c4367e46207284ff464b91c,"Handle padding in ListField[ArrayField] (#802)

* Handle padding in ListField[ArrayField]

* Capitalize comment

* Remove extra space",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
528,Michael Schmitz,michael@schmitztech.com,2018-02-09 10:17:50-08:00,c841e54f96f42d385bde115e5bc9ba0623685505,https://github.com/allenai/allennlp/commit/c841e54f96f42d385bde115e5bc9ba0623685505,"Add options --all, --top, and --average to elmo command (#806)

* Add --all, --top, and --average options to elmo command.

* Add tests for --all, --top, and --average.

* Switch all_close to array_almost_equal.  While it passed locally, it failed on TC.

* Try allclose with rtol=1e-4",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(h5py_file.keys()) == [sentence]', 'embedding.shape == (3, len(sentence.split()), 32)', 'os.path.exists(output_path)', 'list(h5py_file.keys()) == [sentence]', 'embedding.shape == (len(sentence.split()), 32)', 'os.path.exists(output_path)', 'embedding.shape == (len(sentence.split()), 32)']",[],[],[],[],[],[],[],[],[],[],[],[],"['h5py_file.get(sentence).shape == (3, len(sentence.split()), 32)']",[],[],[],[],[],[],[],[],[],[],[],[]
529,Michael Schmitz,michael@schmitztech.com,2018-02-09 10:18:28-08:00,f3f7d2480fc2b4b7e41ecf0c854380ece0741f39,https://github.com/allenai/allennlp/commit/f3f7d2480fc2b4b7e41ecf0c854380ece0741f39,"Append a random SHA to Docker image if dirty. (#805)

* Append a random SHA if dirty.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
530,Michael Schmitz,michael@schmitztech.com,2018-02-09 10:23:04-08:00,7eec2984811d28f1afc2d090a89ea4564bfda95a,https://github.com/allenai/allennlp/commit/7eec2984811d28f1afc2d090a89ea4564bfda95a,Pass through Beaker commands in run_with_beaker.py. (#801),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
531,Maksym Del,max.del.edu@gmail.com,2018-02-09 21:31:56+02:00,a65cab7f8903c07b53c472258bfdbed84f7aa992,https://github.com/allenai/allennlp/commit/a65cab7f8903c07b53c472258bfdbed84f7aa992,"Update README.md (#807)

Update docs for `verify` command",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
532,Michael Schmitz,michael@schmitztech.com,2018-02-09 11:47:28-08:00,e11f68dd8b0585cfc67496e70a2e016b91f5078d,https://github.com/allenai/allennlp/commit/e11f68dd8b0585cfc67496e70a2e016b91f5078d,Remove --all flag from verify. (#808),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
533,Matt Gardner,mattg@allenai.org,2018-02-09 15:24:15-08:00,40dcf53c57464a51488a86e58fa583aff3058d44,https://github.com/allenai/allennlp/commit/40dcf53c57464a51488a86e58fa583aff3058d44,Some minor flag fixes for the beaker script (#813),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
534,Matt Gardner,mattg@allenai.org,2018-02-12 11:05:42-08:00,300c8959b0d32026759dfa1f5a4d6244a8427b88,https://github.com/allenai/allennlp/commit/300c8959b0d32026759dfa1f5a4d6244a8427b88,"Fix tqdm behavior around lazy datasets (#815)

* Add in tqdm when reading non-lazy data from a generator

* Remove tqdm from existing dataset readers

* Remove unused import",11,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
535,Joel Grus,joelgrus@gmail.com,2018-02-12 13:31:01-08:00,76e7d2a34a28066a2e25addd09fe04162d130867,https://github.com/allenai/allennlp/commit/76e7d2a34a28066a2e25addd09fe04162d130867,"add constrained decoding for CRFs (#818)

* add constraints

* add tests

* vectorize

* clean up crf

* don't use constraint mask in None case

* update comment

* clean up

* update comment

* address PR feedback",3,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['viterbi_tags == [', 'set(allowed) == {', 'set(allowed) == {']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
536,Matt Gardner,mattg@allenai.org,2018-02-12 14:03:33-08:00,d0b018b2b61fd21c89ea3721939d184dd95ae987,https://github.com/allenai/allennlp/commit/d0b018b2b61fd21c89ea3721939d184dd95ae987,"Allow min_count to be namespace-specific (#821)

* Allow min_count to be namespace-specific

* Fixed tests I missed the first time",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
537,Matt Gardner,mattg@allenai.org,2018-02-12 15:10:11-08:00,b64162c6d4e53ede2ef3fdafa6b7f276ee498072,https://github.com/allenai/allennlp/commit/b64162c6d4e53ede2ef3fdafa6b7f276ee498072,"Make BasicTextFieldEmbedder handle higher-order inputs (#825)

* Make BasicTextFieldEmbedder handle higher-order inputs

* Update base class, too",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['token_embedder(inputs, num_wrapping_dims=2).size() == (3, 4, 5, 6, 12)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
538,Mark Neumann,markn@allenai.org,2018-02-12 16:26:08-08:00,cd32df88d94738e914c10bb3c6f708e74722d57e,https://github.com/allenai/allennlp/commit/cd32df88d94738e914c10bb3c6f708e74722d57e,specify CPU memory usage (#828),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
539,Matthew Peters,matt-peters@users.noreply.github.com,2018-02-12 16:51:54-08:00,e141e378acd1894a2de2229a63e444d01ac5fe6b,https://github.com/allenai/allennlp/commit/e141e378acd1894a2de2229a63e444d01ac5fe6b,"Clarity the parameter group options (#824)

* Clarity the parameter group options

* clarify comment

* Use logger.info instead of print

* pylint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
540,Joel Grus,joelgrus@gmail.com,2018-02-13 10:51:09-08:00,1f4865cb8df63428e802002e22382c8adabe1de7,https://github.com/allenai/allennlp/commit/1f4865cb8df63428e802002e22382c8adabe1de7,"log GPU memory (#829)

* add gpu memory check

* fix bugs

* fix import order

* fix pylint

* address PR feedback

* fix bug

* update comment",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
541,rajasagashe,rajasagashe@users.noreply.github.com,2018-02-13 13:19:32-08:00,7aa71af4489faf81fa3e0d35dba0c857a83736d7,https://github.com/allenai/allennlp/commit/7aa71af4489faf81fa3e0d35dba0c857a83736d7,"Removed unsupported arguments from comment. (#833)

* Removed unsupported arguments from comment.

* Remove redundant ""[command]""",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
542,Matthew Peters,matt-peters@users.noreply.github.com,2018-02-13 13:33:59-08:00,23a1303caf440973afa65b74760738a0bbcee2f0,https://github.com/allenai/allennlp/commit/23a1303caf440973afa65b74760738a0bbcee2f0,Modify ELMo tutorial (#841),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
543,Matt Gardner,mattg@allenai.org,2018-02-14 09:01:26-08:00,b7cbda7188067c7d22cb3b3d4a6343a6cd21bfa5,https://github.com/allenai/allennlp/commit/b7cbda7188067c7d22cb3b3d4a6343a6cd21bfa5,"Add best validation metric and epoch to output metrics (#823)

* Add best validation metric and epoch to output metrics

* Added some test coverage",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'new_trainer._should_stop_early([.5, .3, .2, .1, .4, .4])  # pylint: disable=protected-access', 'not new_trainer._should_stop_early([.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'new_trainer._should_stop_early([.02, .3, .2, .1, .4, .4])  # pylint: disable=protected-access', 'not new_trainer._should_stop_early([.3, .3, .2, .1, .4, .5])  # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[],"['new_trainer._should_stop_early([.5, .3, .2, .1, .4, .4]) #pylint: disable=protected-access', 'not new_trainer._should_stop_early([.3, .3, .3, .2, .5, .1]) #pylint: disable=protected-access', 'new_trainer._should_stop_early([.02, .3, .2, .1, .4, .4]) #pylint: disable=protected-access', 'not new_trainer._should_stop_early([.3, .3, .2, .1, .4, .5]) #pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[]
544,Michael Schmitz,michael@schmitztech.com,2018-02-14 11:13:03-08:00,4c56e9f62c458d921db7ea77af8c1007ac6b7cbe,https://github.com/allenai/allennlp/commit/4c56e9f62c458d921db7ea77af8c1007ac6b7cbe,Handle batches with only a single empty sentence (#842),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(output_path)', 'len(h5py_file.keys()) == 2', 'set(h5py_file.keys()) == set([])', 'embeddings.shape == (3, 0, 1024)', 'len(embeddings) == 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
545,Michael Schmitz,michael@schmitztech.com,2018-02-14 13:04:45-08:00,82dfc53fd57a9a626cd294cb2b2d9c0cc712e43e,https://github.com/allenai/allennlp/commit/82dfc53fd57a9a626cd294cb2b2d9c0cc712e43e,"Format json (#847)

* Format tutorial json

* Format bidaf.json",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
546,Mark Neumann,markn@allenai.org,2018-02-14 13:17:54-08:00,0415bcb8515e29df216d07158d69cd5b373b22ae,https://github.com/allenai/allennlp/commit/0415bcb8515e29df216d07158d69cd5b373b22ae,remove out of date readmes (#846),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
547,Mark Neumann,markn@allenai.org,2018-02-14 13:49:04-08:00,dc48bfe1fd366a6646035ecf2a22bd032c3e86ee,https://github.com/allenai/allennlp/commit/dc48bfe1fd366a6646035ecf2a22bd032c3e86ee,"Pass through encoder (#849)

* add a pass through encoder, fix up docs a bit

* make multi-head attention buildable from params

* whitespace

* don't use default value in from_params",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(encoder, MultiHeadSelfAttention)', 'encoder.get_input_dim() == 2', 'encoder.get_output_dim() == 2', 'encoder.get_input_dim() == 9', 'encoder.get_output_dim() == 9']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
548,Mark Neumann,markn@allenai.org,2018-02-14 15:53:56-08:00,b63307714967839c129baf528057479df03882c5,https://github.com/allenai/allennlp/commit/b63307714967839c129baf528057479df03882c5,add params.assert_empty to relevant constructors (#850),10,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
549,Michael Schmitz,michael@schmitztech.com,2018-02-14 15:54:57-08:00,88eefbdb971967584a0a588043a1a7079eba8ca9,https://github.com/allenai/allennlp/commit/88eefbdb971967584a0a588043a1a7079eba8ca9,Convert URLs to cached files in add_file_to_archive (#851),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
550,Michael Schmitz,michael@schmitztech.com,2018-02-14 16:26:58-08:00,f6baad4339d2242e2985c16ef8e1beec7268cac9,https://github.com/allenai/allennlp/commit/f6baad4339d2242e2985c16ef8e1beec7268cac9,"Update elmo.md (#853)

Some small changes that I would find helpful if adding ELMo to a model other than SRL.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
551,Michael Schmitz,michael@schmitztech.com,2018-02-15 10:53:36-08:00,33d3f342bc538a253eb6116aee16e20522b4b564,https://github.com/allenai/allennlp/commit/33d3f342bc538a253eb6116aee16e20522b4b564,"Add a weights-file flag to evaluate and predict (#854)

* Add a weights-file flag to evaluate and predict.

* Rename model_params.json to config.json.",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
552,Mark Neumann,markn@allenai.org,2018-02-15 13:58:36-08:00,2d9bf0507696fe553eafeeafd164dbb9359ad135,https://github.com/allenai/allennlp/commit/2d9bf0507696fe553eafeeafd164dbb9359ad135,"Bi-directional span extractor (#826)

* initial work on bidirectional extractor

* add working bidirectional span extractor, add masks to api

* add tests for masking and new extractor

* pylint

* add better comments for what is happening with the spans

* add new span extractor to docs

* fix superficial PR comments

* flip semantics of start and end for backward

* flip start/end in tests

* pylint

* add indices runtime check

* use span_indices, add runtime checks",9,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(extractor, BidirectionalEndpointSpanExtractor)', 'extractor.get_output_dim() == 2 + 2 + 3', 'list(span_representations.size()) == [2, 2, 16]', 'extractor.get_output_dim() == 16', 'extractor.get_input_dim() == 8']","['(ConfigurationError)', '(ValueError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
553,Mark Neumann,markn@allenai.org,2018-02-15 15:00:14-08:00,aa56493cf1439358a9a7599c3867bc5a67106623,https://github.com/allenai/allennlp/commit/aa56493cf1439358a9a7599c3867bc5a67106623,"make using pos tags configurable in the PTB reader (#836)

* make using pos tags configurable

* PR comments",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
554,Michael Schmitz,michael@schmitztech.com,2018-02-15 15:11:55-08:00,36a67d9c4b6ad0f3c667eee77305ae6ce5c12544,https://github.com/allenai/allennlp/commit/36a67d9c4b6ad0f3c667eee77305ae6ce5c12544,Update README.md (#859),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
555,Matthew Peters,matt-peters@users.noreply.github.com,2018-02-15 15:48:00-08:00,ca6e72e3b7cd0b119b0eb36c37d4a45da06b81d1,https://github.com/allenai/allennlp/commit/ca6e72e3b7cd0b119b0eb36c37d4a45da06b81d1,"Fix clamping in LSTMCellWithProjection (#862)

* More logging options in trainer

* Don't clamp in place

* cleanup",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
556,Matthew Peters,matt-peters@users.noreply.github.com,2018-02-16 07:49:57-08:00,07823131a9e6dc4484190cadac41e65e5d3f394c,https://github.com/allenai/allennlp/commit/07823131a9e6dc4484190cadac41e65e5d3f394c,Update links to ELMo paper (#865),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
557,Matthew Peters,matt-peters@users.noreply.github.com,2018-02-16 09:43:52-08:00,8ad145bee016e2b71f9a4c7c78be9e963a3036e8,https://github.com/allenai/allennlp/commit/8ad145bee016e2b71f9a4c7c78be9e963a3036e8,Avoid GPU OOM when loading large models (#864),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
558,Mark Neumann,markn@allenai.org,2018-02-16 11:37:00-08:00,c591d2c38f6ebc1e540ce3b1313277a4cba2a9f7,https://github.com/allenai/allennlp/commit/c591d2c38f6ebc1e540ce3b1313277a4cba2a9f7,"add ability to have seperate dataset readers for train and val (#869)

* add ability to have seperate dataset readers for train and val

* drop test dataset reader

* whitespace",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
559,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-02-16 12:55:39-08:00,259e677af4a5cd69585c02e3b092c0085246ab2c,https://github.com/allenai/allennlp/commit/259e677af4a5cd69585c02e3b092c0085246ab2c,"Made number of requested gpus configurable (#870)

* Made number of gpus configurable

* Moved default out of argparse",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
560,Michael Schmitz,michael@schmitztech.com,2018-02-16 13:15:53-08:00,53974b49396835e1e366ea4fef7360180755155f,https://github.com/allenai/allennlp/commit/53974b49396835e1e366ea4fef7360180755155f,Remove deprecated snake_case args. (#863),8,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('Logs', '(level=logging.WARNING) as context:')]",[],[],[],[],[],[],[],[],[],"['metrics.keys() == {}', 'args.func.__name__ == ', 'args.archive_file == ', 'args.output_file.name == ', 'args.batch_size == 10', 'args.cuda_device == 0', 'args.silent']",[],[],[],[],[],[],[],[],[],[],[],[],"['metrics.keys() == {}', 'set(context.output) == {', 'args.func.__name__ == ', 'args.archive_file == ', 'args.output_file.name == ', 'args.batch_size == 10', 'args.cuda_device == 0', 'args.silent']",[],[],[],[],[],[],[],[],[],[],[],[]
561,Nelson Liu,nelson-liu@users.noreply.github.com,2018-02-17 07:49:46-08:00,937dfc16fb052429acd2b62bca1a192052c99f40,https://github.com/allenai/allennlp/commit/937dfc16fb052429acd2b62bca1a192052c99f40,Fix OntoNotes dataset path iterator test by using set equality (#875),1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(files) == len(expected_paths)', 'set(files) == set(expected_paths)']",[],[],[],[],[],[],[],[],[],[],[],[],"['files == [,']",[],[],[],[],[],[],[],[],[],[],[],[]
562,Matt Gardner,mattg@allenai.org,2018-02-17 10:16:14-08:00,2a0804e77e34f04a64fc4d0e005185f2e50e0e3f,https://github.com/allenai/allennlp/commit/2a0804e77e34f04a64fc4d0e005185f2e50e0e3f,"Update visualization howto (#872)

* Update demo tutorials

* Make simple server work work CORS, make port configurable

* Capitalization, change default demo port to 8000",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
563,Mark Neumann,markn@allenai.org,2018-02-18 19:52:57-08:00,94fd75be13648e83b14e9dfa8c1f590bdaff9201,https://github.com/allenai/allennlp/commit/94fd75be13648e83b14e9dfa8c1f590bdaff9201,"Span constituency parser (#839)

* first pass at a span based parser

* add constituency parser with tests

* add decoding to parser

* pylint, use correct namespace for labels

* add a chunk of documentation

* add model docs

* more pylint

* add tests for decoding methods

* add f1 scores for all labels

* tidy up, remove pos tags

* fix inplace modification of spans :clap: :clap:

* please the sphinx

* add a feedforward layer to the model

* address some PR comments

* fix config, make it more obvious that spans are mutated

* use namedtuples

* pylint

* bump pylint version to 1.8.2 to catch typing.NamedTuple lint error

* make it more obvious why we are using exclusive indices for decoding

* wiggle around pylint for namedtuple constructor

* add average metrics

* fix lint for tests too",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(decode_output_dict.keys()) == {,', 'resolved_spans == [SpanInformation(start=2, end=7, no_label_prob=0.5,', 'tree == correct_tree']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
564,Nelson Liu,nelson-liu@users.noreply.github.com,2018-02-19 09:12:19-08:00,2bfc01d0cbc0072314cf50b35057f1c7d9e8257e,https://github.com/allenai/allennlp/commit/2bfc01d0cbc0072314cf50b35057f1c7d9e8257e,"Use tensorboardX instead of tensorboard package for writing tensorboard files (#876)

* Replace tensorboard with tensorboardX in requirements.txt

* Replace tensorboard with tensorboardX in setup.py

* Switch TensorboardWriter to use tensorboardX

* Remove skiptest for Tensorboard logging on OS X",4,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['if(os.uname().sysname == )'],[],[],[],[],['skipif(os.uname().sysname == )'],['mark.skipif(os.uname().sysname == )'],[],[],[]
565,Nelson Liu,nelson-liu@users.noreply.github.com,2018-02-19 09:45:42-08:00,00c3c657365c7f3b19986259e905ddf3506298d2,https://github.com/allenai/allennlp/commit/00c3c657365c7f3b19986259e905ddf3506298d2,Fix multiGPU Trainer test by indexing iterator (#874),1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
566,Joel Grus,joelgrus@gmail.com,2018-02-19 10:14:32-08:00,161059183f24fe6b6c08de0612997fb4bdfc7bab,https://github.com/allenai/allennlp/commit/161059183f24fe6b6c08de0612997fb4bdfc7bab,"update NER model in demo to latest + add some words about it to the tutorial (#886)

* update NER tutorial

* tweaks",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
567,Mark Neumann,markn@allenai.org,2018-02-19 10:53:52-08:00,fa9f02044699a3b8a94726698b05c415a9a7ecf5,https://github.com/allenai/allennlp/commit/fa9f02044699a3b8a94726698b05c415a9a7ecf5,"use nltk.Tree instead of my made up JSON (#882)

* use nltk.Tree instead of my made up JSON

* fix comment

* fix comment

* decode mis-specified trees correctly, add test

* less nesting",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['tree == correct_tree'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
568,Mark Neumann,markn@allenai.org,2018-02-19 11:13:56-08:00,43de13dbd59f8e13c35433ce2304eb8465ec4a73,https://github.com/allenai/allennlp/commit/43de13dbd59f8e13c35433ce2304eb8465ec4a73,switch demo model to use elmo (#887),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['result[][2] > 0.6  # neutral'],[],[],[],[],[],[],[],[],[],[],[],[],['result[][2] > 0.7  # neutral'],[],[],[],[],[],[],[],[],[],[],[],[]
569,Michael Schmitz,michael@schmitztech.com,2018-02-19 11:40:55-08:00,1bccdb27b339ce9def1cf46daee6b42a8695c2c0,https://github.com/allenai/allennlp/commit/1bccdb27b339ce9def1cf46daee6b42a8695c2c0,"Add a --continue flag and improve warning messages (#861)

* Add --continue flag to train.

* Add warnings if the serialization directory contains a different configuration.

* Log a clear error when training cannot resume from a checkpoint.

* Fail if configurations mismatch.

* Add test for configuration mismatch.

* Use ConfigurationError instead of Exception.

* Response to CR.

* Add periods.

* Print exception and raise a new exception.

* Rename --continue to --recover

* Crash when user passes wrong directory

* Update train.py",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
570,Matt Gardner,mattg@allenai.org,2018-02-19 13:30:11-08:00,dc2f80cd721e1e6890669165e741f5cd193ffb03,https://github.com/allenai/allennlp/commit/dc2f80cd721e1e6890669165e741f5cd193ffb03,"Add a fine-tune command for continuing training on a new dataset (#880)

* Add a fine-tune command for continuing training on a new dataset

* Fix bug from removing serialization parameter group

* Switched to using a config file instead of command line flags

* Remove old piece of docstring, add a TODO to clean up old arguments",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(SystemExit) as context:'), ('Raises', '(SystemExit) as context:'), ('Raises', '(SystemExit) as context:')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.func == fine_tune_model_from_args', 'args.model_archive == self.model_archive', 'args.config_file == self.config_file', 'args.serialization_dir == self.serialization_dir', 'context.exception.code == 2  # argparse code for incorrect usage', 'context.exception.code == 2  # argparse code for incorrect usage', 'context.exception.code == 2  # argparse code for incorrect usage']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
571,Matt Gardner,mattg@allenai.org,2018-02-19 14:50:46-08:00,660cff43b7695bbc98f78ef5d49da23e376e8346,https://github.com/allenai/allennlp/commit/660cff43b7695bbc98f78ef5d49da23e376e8346,"Fix masked_log_softmax when the entire vector is masked (#893)

* Fix masked_log_softmax when the entire vector is masked

* Remove unnecessary cast

* Simplify the logic

* Add a note to the docstring about side effects of how we do masking

* Add a note about float precision",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['not numpy.isnan(vector_1d_softmaxed).any()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
572,Matthew Peters,matt-peters@users.noreply.github.com,2018-02-19 15:35:24-08:00,b210f030df01e941665ceda4ff86b3b49dc4564c,https://github.com/allenai/allennlp/commit/b210f030df01e941665ceda4ff86b3b49dc4564c,Fix bug in elmo command with cuda_device (#896),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
573,Mark Neumann,markn@allenai.org,2018-02-19 15:48:30-08:00,7466fdedad5f4afdfb8a231b1ce56204f6169fdf,https://github.com/allenai/allennlp/commit/7466fdedad5f4afdfb8a231b1ce56204f6169fdf,"add EVALB as a metric (#891)

* add EVALB as a metric

* use subprocess instead of os, add docs

* fix docs and pylint

* remove extra brackets

* actually fix docs

* see if EVALB needs archiecture dependent compilation

* remove unused import

* check EVALB is compiled in constructor

* PR feedback

* whitespace",22,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics[] == 1.0', 'metrics[] == 1.0', 'metrics[] == 1.0', 'metrics[] == 0.75', 'metrics[] == 0.75', 'metrics[] == 0.75']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
574,Matt Gardner,mattg@allenai.org,2018-02-19 18:10:19-08:00,563dd017e0a5bd6b17862b66f16e30539eec026c,https://github.com/allenai/allennlp/commit/563dd017e0a5bd6b17862b66f16e30539eec026c,"Upgrade to pytorch 0.3.1 in dockerfile, update documentation (#897)

* Upgrade to pytorch 0.3.1 in dockerfile, update documentation

* Use a list comprehension",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
575,Joel Grus,joelgrus@gmail.com,2018-02-20 06:34:01-08:00,b398aa9520280dda182dea55c7da300dfd89ae23,https://github.com/allenai/allennlp/commit/b398aa9520280dda182dea55c7da300dfd89ae23,always use constraint mask (#892),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
576,Mark Neumann,markn@allenai.org,2018-02-20 10:25:36-08:00,70974d2d10f1d70555b9385ce3a9223f179c7bdd,https://github.com/allenai/allennlp/commit/70974d2d10f1d70555b9385ce3a9223f179c7bdd,"add nltk trees as metadata to the constituency parser (#895)

* add nltk trees as metadata to the constituency parser

* override nltk prettyprinting, catch nan f1 from evalb

* add evalb as a validation only metric to parser

* add missing tearDown super calls

* split decode in two, other PR comments",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['fields[].metadata == gold_tree', 'fields[].metadata == gold_tree', 'in metric_keys', 'in metric_keys', 'in metric_keys', 'metrics[] == 1.0', 'metrics[] == 1.0', 'metrics[] == 1.0', 'metrics[] == 0.75', 'metrics[] == 0.75', 'metrics[] == 0.75', 'metrics[] == 0.0', 'metrics[] == 0.0', 'metrics[] == 0.0']",[],[],[],[],[],[],[],[],[],[],[],[],"['metrics[] == 1.0', 'metrics[] == 1.0', 'metrics[] == 1.0', 'metrics[] == 0.75', 'metrics[] == 0.75', 'metrics[] == 0.75']",[],[],[],[],[],[],[],[],[],[],[],[]
577,Mark Neumann,markn@allenai.org,2018-02-20 10:50:47-08:00,741ea01e50cfbda2d890110adea41e9141ed46f7,https://github.com/allenai/allennlp/commit/741ea01e50cfbda2d890110adea41e9141ed46f7,initial config (#900),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
578,Michael Schmitz,michael@schmitztech.com,2018-02-20 11:40:24-08:00,50a10e73add95106f081b2bccbe10126e098f0a7,https://github.com/allenai/allennlp/commit/50a10e73add95106f081b2bccbe10126e098f0a7,Bump version numbers to v0.4.0,3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
579,Michael Schmitz,michael@schmitztech.com,2018-02-20 13:30:12-08:00,630700280256d00548958ad18aad86cbad82a28a,https://github.com/allenai/allennlp/commit/630700280256d00548958ad18aad86cbad82a28a,Bump version numbers to v0.4.1-unreleased.,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
580,Mark Neumann,markn@allenai.org,2018-02-20 13:33:59-08:00,5756ff6c24aaee510256a752a59626546806d5fa,https://github.com/allenai/allennlp/commit/5756ff6c24aaee510256a752a59626546806d5fa,"Span tutorial (#903)

* initial span tutorial work

* more content

* add more content, some more code

* address PR feedback",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
581,Michael Schmitz,michael@schmitztech.com,2018-02-20 15:03:35-08:00,6f4de8532b12802ac38561adfa02cfb5530cbfba,https://github.com/allenai/allennlp/commit/6f4de8532b12802ac38561adfa02cfb5530cbfba,Update TextualEntailment text to highlight ELMo. (#906),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
582,Mark Neumann,markn@allenai.org,2018-02-21 09:54:01-08:00,bca992ef8d73da88b0a81707f79bf2759a8158dc,https://github.com/allenai/allennlp/commit/bca992ef8d73da88b0a81707f79bf2759a8158dc,"Fix span masking (#905)

* fix a few things with the parser

* pylint

* fix sphinx

* update variable name, try new thing for sphinx",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
583,Joel Grus,joelgrus@gmail.com,2018-02-21 12:35:40-08:00,6ad7d5bc4621aec5bbb0b9bd4655f5fcb2a44b3c,https://github.com/allenai/allennlp/commit/6ad7d5bc4621aec5bbb0b9bd4655f5fcb2a44b3c,"Migrating to 0.4.0 (#909)

* migration guide

* tweaks

* address PR feedback",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
584,Mark Neumann,markn@allenai.org,2018-02-22 11:29:00-08:00,6a108577d9425a8a8e8c36641213a42a08c18458,https://github.com/allenai/allennlp/commit/6a108577d9425a8a8e8c36641213a42a08c18458,"Constituency training pr (#913)

* improvements and fixes from actually trying to train the parser

* clean up tests for functional tags

* recurse to include root

* Don't add nfs paths to git

* fix batch size 1, single word sentence case, add test

* trying to find pylint errors doesn't work if you're on the wrong branch",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['tree == Tree.fromstring()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
585,Mark Neumann,markn@allenai.org,2018-02-22 14:37:48-08:00,740f4fbb961425c101c0b4461d84fa9a32905f39,https://github.com/allenai/allennlp/commit/740f4fbb961425c101c0b4461d84fa9a32905f39,"Constituency Parser Predictor and tests (#914)

* add constituency predictor, clean up some span padding in decode

* regenerate test fixtures, address some regressions

* batch test

* fix up test, docs",24,False,True,True,True,False,False,False,False,False,False,False,False,False,False,False,[],1,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,['class TestConstituencyParserPredictor(TestCase):'],"[('AlmostEqual', '(sum(class_distribution), 1.0, places=4)'), ('AlmostEqual', '(sum(class_distribution), 1.0, places=4)'), ('AlmostEqual', '(sum(class_distribution), 1.0, places=4)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(result[]) == 21 # number of possible substrings of the sentence.', 'len(result[]) == 21', 'result[]', 'isinstance(result[], str)', 'len(result[]) == 21 # number of possible substrings of the sentence.', 'len(result[]) == 21', 'result[]', 'isinstance(result[], str)', 'len(result[]) == 36 # number of possible substrings of the sentence.', 'len(result[]) == 36', 'result[]', 'isinstance(result[], str)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
586,Mark Neumann,markn@allenai.org,2018-02-23 16:27:12-08:00,8b706e4261f35f275bf0f5b9f04f08b7cd96e52c,https://github.com/allenai/allennlp/commit/8b706e4261f35f275bf0f5b9f04f08b7cd96e52c,"Constituency js (#916)

* 'working' constituency parsing demo

* wire the actual sentence through model, predictor and dataset reader

* 90% working hierplane vis

* tidy up, remove sentence lengths from return dict

* clean up some js, remove spans from the demo

* better description of the model

* add explicit hierplane tree in test",10,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['fields[] == gold_tree', 'fields[] == tokens', 'fields[] == gold_tree', 'fields[] == tokens', 'result[]', 'result[]', 'result[]', 'correct_tree == hierplane_tree']",[],[],[],[],[],[],[],[],[],[],[],[],"['fields[].metadata == gold_tree', 'fields[].metadata == gold_tree', 'result[]', 'result[]', 'result[]']",[],[],[],[],[],[],[],[],[],[],[],[]
587,Mark Neumann,markn@allenai.org,2018-02-26 09:47:08-08:00,085a7509a2301cd991f372e2f79eff560ff3aa4a,https://github.com/allenai/allennlp/commit/085a7509a2301cd991f372e2f79eff560ff3aa4a,"use gold pos tags for tree evaluation (#921)

* use gold pos tags for tree evaluation

* spacing",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
588,Mark Neumann,markn@allenai.org,2018-02-26 11:46:12-08:00,b7a9784ec1ac1392c5b129712af8376738139be5,https://github.com/allenai/allennlp/commit/b7a9784ec1ac1392c5b129712af8376738139be5,"Nested constituents (#920)

* correctly handle nested constituents with the same span

* pylint

* spelling

* add todo about test time labels

* lint

* unmangle commit, lint",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['spans == [((0, 0), ),', 'tree == correct_tree']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
589,Matt Gardner,mattg@allenai.org,2018-02-26 13:46:51-08:00,de5df62923235de6269660ca01af63d148ac19da,https://github.com/allenai/allennlp/commit/de5df62923235de6269660ca01af63d148ac19da,Fix random hash that's appened to git SHA (#924),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
590,Matt Gardner,mattg@allenai.org,2018-02-26 13:55:11-08:00,97bc7a2d25c3e9a0b3ffedff22ab399f7baeddcc,https://github.com/allenai/allennlp/commit/97bc7a2d25c3e9a0b3ffedff22ab399f7baeddcc,"Combined recovery logic, made it not crash on beaker (#925)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
591,Mark Neumann,markn@allenai.org,2018-02-26 14:44:30-08:00,394c26d8cdba1f4c46b65adbf603d6f83a306653,https://github.com/allenai/allennlp/commit/394c26d8cdba1f4c46b65adbf603d6f83a306653,add try except block with helpful message (#923),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
592,Mark Neumann,markn@allenai.org,2018-02-27 10:02:24-08:00,0cb2f60609b9d15e156a523ab3fe71acc1eb5f3a,https://github.com/allenai/allennlp/commit/0cb2f60609b9d15e156a523ab3fe71acc1eb5f3a,"speed up metrics (#927)

* speed up metrics

* change parser to use accuracy rather than f1

* strip VROOT from all trees

* tweak to work with topk",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
593,Sebastian Gehrmann,s.gehrmann@outlook.com,2018-02-28 11:42:36-05:00,acf21a53e7001bb6c7c3f7113c0d2805ffccceb2,https://github.com/allenai/allennlp/commit/acf21a53e7001bb6c7c3f7113c0d2805ffccceb2,"Fix #928 - Minor naming inconsistency in tutorial json files (#929)

* change stacked_encoder to encoder

* remove log file

* new default model",20,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
594,Mark Neumann,markn@allenai.org,2018-02-28 13:47:26-08:00,dcd6487ea8612c56f44613fa6060f75eb20ab7d3,https://github.com/allenai/allennlp/commit/dcd6487ea8612c56f44613fa6060f75eb20ab7d3,"More parser improvements (#934)

* catch singleton words for labels, refactor span extractor internals

* add ability to use embedded pos tags

* use a text field embedder for pos tags

* use pos tags in fixtures to test more complex case

* update to use original Embedding

* remove postag indexers",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
595,Mark Neumann,markn@allenai.org,2018-02-28 15:12:26-08:00,c66fac020ec071042243c7d97e61ef1126f41208,https://github.com/allenai/allennlp/commit/c66fac020ec071042243c7d97e61ef1126f41208,"pos -> tag (#935)

* pos -> tag

* don't use *.tags so pos tags have unk tokens

* update fixtures",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
596,Mark Neumann,markn@allenai.org,2018-02-28 17:05:00-08:00,cdfe9aed70ca567b3c16b412dcbaee4f06134df2,https://github.com/allenai/allennlp/commit/cdfe9aed70ca567b3c16b412dcbaee4f06134df2,add ImportError to lstm import (#938),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
597,Michael Schmitz,michael@schmitztech.com,2018-03-01 11:12:41-08:00,c12d43567af2be5f51ae8131143ea5e06091aea1,https://github.com/allenai/allennlp/commit/c12d43567af2be5f51ae8131143ea5e06091aea1,"Automatically install spacy models, if missing (#933)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
598,Mark Neumann,markn@allenai.org,2018-03-01 17:08:20-08:00,f81e27a5cbe72ec3bf22f12d5a9ea60008bb8f1c,https://github.com/allenai/allennlp/commit/f81e27a5cbe72ec3bf22f12d5a9ea60008bb8f1c,"get the dimensions correct for the transformer (#941)

* get the dimensions correct for the transformer

* remove last layer norm, lint

* update param descriptions

* PR feedback

* whitespace",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
599,Mark Neumann,markn@allenai.org,2018-03-01 17:22:06-08:00,e657353281324eee7b37ccb27948c553cc9f4df5,https://github.com/allenai/allennlp/commit/e657353281324eee7b37ccb27948c553cc9f4df5,"add label smoothing to loss (#942)

* add label smoothing to loss

* correct comment

* use uniformly distributed smoothing

* add docstring examples",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
600,Matthew Peters,matt-peters@users.noreply.github.com,2018-03-02 11:06:02-08:00,6044cceddd359a23f5bf7eb7ba895bec8e77fbb8,https://github.com/allenai/allennlp/commit/6044cceddd359a23f5bf7eb7ba895bec8e77fbb8,"Allow to provide a custom `Module` in `Elmo` class (#945)

* Allow to provide a custom module for Elmo

* pylint

* grammar",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(elmo_representations) == 2', 'list(elmo_representations[k].size()) == [2, 7, 32]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
601,Michael Schmitz,michael@schmitztech.com,2018-03-05 10:35:52-08:00,71c80e393c9488d266b9b9b63f94a88c2d568d6e,https://github.com/allenai/allennlp/commit/71c80e393c9488d266b9b9b63f94a88c2d568d6e,Install nltk the normal way. (#932),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
602,Mark Neumann,markn@allenai.org,2018-03-05 17:24:19-08:00,c84c714c64f85c01c2b748fd035a19e6e9154648,https://github.com/allenai/allennlp/commit/c84c714c64f85c01c2b748fd035a19e6e9154648,"use biased estimator for layernorm, fix some views in multi head attention (#953)

* use biased estimator for layernorm, fix some views in multi head attention

* remove commented out line",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
603,Mark Neumann,markn@allenai.org,2018-03-06 14:39:55-08:00,0ef211dac4b15d10d22f3e7cefe28c27b1a2826c,https://github.com/allenai/allennlp/commit/0ef211dac4b15d10d22f3e7cefe28c27b1a2826c,fix online metric calculation for EVALB (#956),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics[] == 0.875', 'metrics[] == 0.875', 'metrics[] == 0.875']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
604,Maksym Del,max.del.edu@gmail.com,2018-03-07 17:09:35+02:00,cc2756db870414f93158cf64d038dd8a0357cb4e,https://github.com/allenai/allennlp/commit/cc2756db870414f93158cf64d038dd8a0357cb4e,"Add a link to the span representations tutorial (#959)

Add the link to the ""how-to"" tutorials README",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
605,Matt Gardner,mattg@allenai.org,2018-03-07 11:39:23-08:00,9121eed62a717baa0c5dcbcd10c60a52d3b6d285,https://github.com/allenai/allennlp/commit/9121eed62a717baa0c5dcbcd10c60a52d3b6d285,"Move --include-packages flag up to top level (#962)

* Moved --include-packages flag up to top level

* Moved tests around, removed a test that is now a duplicate

* Pylint

* More pylint",8,False,True,False,False,True,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,1,1,3,0,0,0,0,0,0,0,0,0,0,2,[],[],[],[],[],[],[],[],[],[],[],['class TestMain(TestCase):'],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],['metrics.keys() == {}'],"['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest']"
606,Mark Neumann,markn@allenai.org,2018-03-07 16:21:02-08:00,18eb4218c81fb70bffb99c737f4ad5e148d40bd7,https://github.com/allenai/allennlp/commit/18eb4218c81fb70bffb99c737f4ad5e148d40bd7,fix sentence encoder from params (#963),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
607,Maksym Del,max.del.edu@gmail.com,2018-03-08 19:51:01+02:00,3d100d31cc8d87efcf95c0b8d162bfce55c64926,https://github.com/allenai/allennlp/commit/3d100d31cc8d87efcf95c0b8d162bfce55c64926,"Fix max_vocab_size bug (#964) (#966)

* Adds the test that breaks max_vocab_size 

While #965 fixes that

* Fix max_vocab_size

* Minor renaming",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(words) == max_vocab_size + 2', 'len(words) == 5']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
608,Mark Neumann,markn@allenai.org,2018-03-12 15:28:00-07:00,5c663c45bdbf456387cce9a6d04a713ba2e2e6e7,https://github.com/allenai/allennlp/commit/5c663c45bdbf456387cce9a6d04a713ba2e2e6e7,"fix span construction (#975)

* fix span construction

* remove print statements

* spacing",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['spans == [((0, 1), )]', 'span_dict == {(1, 1): ,']",[],[],[],[],[],[],[],[],[],[],[],[],"['spans == [((0, 0), ),', 'spans == [((0, 0), ),']",[],[],[],[],[],[],[],[],[],[],[],[]
609,Mark Neumann,markn@allenai.org,2018-03-13 11:38:00-07:00,c7a4e6d4a218d849971169225c968a71ddac4c13,https://github.com/allenai/allennlp/commit/c7a4e6d4a218d849971169225c968a71ddac4c13,don't require that EVALB is compiled on instantiation (#980),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
610,Mark Neumann,markn@allenai.org,2018-03-14 17:09:39-07:00,40d337ea80c56ed9f9771fa605afd4aa0add2c6c,https://github.com/allenai/allennlp/commit/40d337ea80c56ed9f9771fa605afd4aa0add2c6c,"Keyboard interrupt + training admin (#983)

* pull global logging config into a function

* lint

* fix most issues

* remove python logging, stream to stdout instead

* re-add this epoch batch count",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
611,Howard Yu-Chun Lo,howard.lo@nlplab.cc,2018-03-16 00:54:04+08:00,7b2e09dbaa35e314e4446ad9d3d81378f3b7e54c,https://github.com/allenai/allennlp/commit/7b2e09dbaa35e314e4446ad9d3d81378f3b7e54c,"Fix issue #973 and add predictor for SimpleSeq2Seq (#976)

* Fix issue #973

* Add predictor for SimpleSeq2Seq

* Added test for predictor, simplified train_fixtures.py script

* Fix final newline, add missing doc

* Remove unnecessary slash

* Fix pylint",15,False,True,True,True,False,False,False,False,False,False,False,False,False,False,False,[],1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,['class TestSimpleSeq2SeqPredictor(TestCase):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['predicted_tokens is not None', 'isinstance(predicted_tokens, list)', 'all(isinstance(x, str) for x in predicted_tokens)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
612,Matt Gardner,mattg@allenai.org,2018-03-15 11:48:59-07:00,eb7942882ea92f177039aebd48e2d859acc9b0e5,https://github.com/allenai/allennlp/commit/eb7942882ea92f177039aebd48e2d859acc9b0e5,"Change input name from ""source_string"" to ""source"" in Seq2SeqPredictor (#984)",2,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
613,Mark Neumann,markn@allenai.org,2018-03-15 14:37:51-07:00,565b95cf5b4f70f514795064f3b4a395942c7746,https://github.com/allenai/allennlp/commit/565b95cf5b4f70f514795064f3b4a395942c7746,"Constituency parser demo (#985)

* remove weird resizing css

* add node styling to hierplane

* add more comments, change default sentences

* add PaneTop and PaneBottom components

* add styling for Top and Bottom components

* tweak logging for parser

* mention elmo

* add 'consider-iterating-dictionary' to pylintrc

* add sniff test and s3 model link

* typo

* add training config with s3 paths

* fix test

* better name for orientation of Pane

* python dict iterator syntax

* fix duplicated css

* use test acc and clarify error reduction

* use relative height to stop overlapping elements",9,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['result[]', 'result[']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
614,Mark Neumann,markn@allenai.org,2018-03-16 10:04:40-07:00,dc7a9d6842b0785ccf0828f15c733d9688def2ef,https://github.com/allenai/allennlp/commit/dc7a9d6842b0785ccf0828f15c733d9688def2ef,make hierplane div overflow so it's scrollable (#989),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
615,Mark Neumann,markn@allenai.org,2018-03-16 13:42:17-07:00,0c532d50ac52bca48bf9906864daf6735d5d02de,https://github.com/allenai/allennlp/commit/0c532d50ac52bca48bf9906864daf6735d5d02de,use correct PTB results on demo page (#990),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
616,Mark Neumann,markn@allenai.org,2018-03-19 12:52:10-07:00,1d68f88923475fb388d3318b5087bd8f779c41c4,https://github.com/allenai/allennlp/commit/1d68f88923475fb388d3318b5087bd8f779c41c4,"add allennlp command (#987)

* add allennlp command

* change code references",19,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
617,Joel Grus,joelgrus@gmail.com,2018-03-19 14:50:20-07:00,e28415ca6a93d76006a8544b7fc71f2179b2ea42,https://github.com/allenai/allennlp/commit/e28415ca6a93d76006a8544b7fc71f2179b2ea42,remove PREDICTOR_OVERRIDES and MODEL_OVERRIDES (#999),5,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.func.__name__ == ', 'args.func.__name__ == ']",[],[],[],[],[],[],[],[],[],[],[],[],"['args.func.__name__ == ', 'os.path.exists(outfile)', 'len(results) == 2', 'set(result.keys()) == {,', 'args.func.__name__ == ']",[],[],[],[],[],[],[],[],[],[],[],[]
618,Sergey Feldman,sergeyfeldman@gmail.com,2018-03-20 10:27:12-07:00,d351ac7e74dabd14fa520cfa9191edf80caf16c1,https://github.com/allenai/allennlp/commit/d351ac7e74dabd14fa520cfa9191edf80caf16c1,"Fix simple tagger link in creating a model tutorial (#1003)

* Fix simple tagger link in creating a model tutorial

Previous link went to a 404.

* Fix as per Joel's comment",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
619,Mark Neumann,markn@allenai.org,2018-03-20 12:43:09-07:00,3c8e299a0064f42f79a42b8c07b03f55d82f5d2c,https://github.com/allenai/allennlp/commit/3c8e299a0064f42f79a42b8c07b03f55d82f5d2c,"fix predictor issue for constituency parser (#1004)

* fix predictor issue for constituency parser

* matt",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
620,Mark Neumann,markn@allenai.org,2018-03-20 13:28:18-07:00,760853c5f9a3b3d470bbdcc65526f2fac012514a,https://github.com/allenai/allennlp/commit/760853c5f9a3b3d470bbdcc65526f2fac012514a,"Winobias reader (#968)

* initial winobias work

* add winobias reader

* add reader to docs

* refer to document, not sentence

* review comments",7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'text == [,', 'gold_mentions_with_ids == [([], 0)]', 'text == [,', 'gold_mentions_with_ids == [([], 0),', 'all([self.span_width >= len(x) > 0 for x in candidate_mentions])  # pylint: disable=len-as-condition']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
621,Dimid Duchovny,dimidd@users.noreply.github.com,2018-03-21 17:34:21+02:00,f06d62f5896361c605aeace39fddd16573c299e2,https://github.com/allenai/allennlp/commit/f06d62f5896361c605aeace39fddd16573c299e2,"readme: add port publishing for docker (#1009)

Match the main README to the installation one
https://github.com/allenai/allennlp/blob/master/tutorials/getting_started/installation.md",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
622,Mark Neumann,markn@allenai.org,2018-03-21 13:57:06-07:00,31f4f60426f566a8da3ad2742614a6878b71ee83,https://github.com/allenai/allennlp/commit/31f4f60426f566a8da3ad2742614a6878b71ee83,"better error for gradient check (#1010)

* better error for gradient check

* simplify

* stdout not stack trace",1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(parameter.grad.data.cpu() != zeros).any()'],[],[],[],[],[],[],[],[],[],[],[],[]
623,Nelson Liu,nelson-liu@users.noreply.github.com,2018-03-21 15:23:03-07:00,5f722fcdf2f3d24ef7b2d812bc34bb9354c271cb,https://github.com/allenai/allennlp/commit/5f722fcdf2f3d24ef7b2d812bc34bb9354c271cb,"Add .pytest_cache folder to gitignore (#1006)

* Add .pytest_cache folder to gitignore

* Fix newline at end of file",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
624,Mark Neumann,markn@allenai.org,2018-03-21 16:16:05-07:00,a327d03ca5a5cec35fa40fc9e48a2f407258f96e,https://github.com/allenai/allennlp/commit/a327d03ca5a5cec35fa40fc9e48a2f407258f96e,"make srl predictor more robust (#1011)

* make srl predictor more robust

* remove tokens from SRL API",3,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['result == {: []}', 'results[0] == {: []}', 'results[1] == {],']",[],[],[],[],[],[],[],[],[],[],[],[],['result[] == ['],[],[],[],[],[],[],[],[],[],[],[],[]
625,Mark Neumann,markn@allenai.org,2018-03-21 16:40:54-07:00,f37bc6cc2cec5e6705b04f495ebae03526e1bde0,https://github.com/allenai/allennlp/commit/f37bc6cc2cec5e6705b04f495ebae03526e1bde0,add some new optimisers and a cosine LR schedule (#1012),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
626,Mark Neumann,markn@allenai.org,2018-03-22 10:58:09-07:00,ab3bd0f510245e35beb026115dac24d7cdb58cd6,https://github.com/allenai/allennlp/commit/ab3bd0f510245e35beb026115dac24d7cdb58cd6,"add optional exclusive start indices flag to Enpoint Extractor (#1005)

* add optional exclusive start indices flag to Enpoint Extractor

* fix lint

* fix dimension matching in parser, refresh fixtures

* fix from params test

* PR feedback",18,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['extractor.get_output_dim() == 17  # 2 * input_dim + span_width_embedding_dim'],[],[],[],[],[],[],[],[],[],[],[],[],['extractor.get_output_dim() == 10'],[],[],[],[],[],[],[],[],[],[],[],[]
627,Mark Neumann,markn@allenai.org,2018-03-22 13:59:14-07:00,3ea3e64d90aa10d54b645393411aad58b2d22831,https://github.com/allenai/allennlp/commit/3ea3e64d90aa10d54b645393411aad58b2d22831,fix logging error (#1017),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
628,Iz Beltagy,iz@beltagy.net,2018-03-23 11:02:47-07:00,a0ced895ad32b09a6185c2b85ff00e5be40d9a45,https://github.com/allenai/allennlp/commit/a0ced895ad32b09a6185c2b85ff00e5be40d9a45,reset meteric when done evaluation (#1020),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
629,Michael Schmitz,michael@schmitztech.com,2018-03-23 12:25:46-07:00,008ceb2659b60ff285f117b0fa76969c289f5af8,https://github.com/allenai/allennlp/commit/008ceb2659b60ff285f117b0fa76969c289f5af8,Break up AWS login command in two to catch failures. (#1022),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
630,Mark Neumann,markn@allenai.org,2018-03-23 13:14:39-07:00,496867ca167dad30499aec6b80078f3777645d0b,https://github.com/allenai/allennlp/commit/496867ca167dad30499aec6b80078f3777645d0b,"add an initial string representation to fields and instances (#1021)

* add an initial string representation to fields and instances

* indent labels

* ignore type for metadata field

* add printing tests

* uniform syntax",16,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
631,Mark Neumann,markng@allenai.org,2018-03-23 14:54:14-07:00,1e8bca8a897d467ef0a57083cafcded4f0da32be,https://github.com/allenai/allennlp/commit/1e8bca8a897d467ef0a57083cafcded4f0da32be,update version,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
632,Mark Neumann,markng@allenai.org,2018-03-23 15:11:44-07:00,f403207f3ba207256f83d7e8da75da44819d52a4,https://github.com/allenai/allennlp/commit/f403207f3ba207256f83d7e8da75da44819d52a4,fix subcommand addition,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
633,Michael Schmitz,michael@schmitztech.com,2018-03-23 17:00:15-07:00,6a5c6df1e550d0c957b8daed3bd0fd92c52cf640,https://github.com/allenai/allennlp/commit/6a5c6df1e550d0c957b8daed3bd0fd92c52cf640,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
634,Nelson Liu,nelson-liu@users.noreply.github.com,2018-03-25 14:06:14-07:00,395646a2a473ce33d80f1c8b2a52ffa71149cfed,https://github.com/allenai/allennlp/commit/395646a2a473ce33d80f1c8b2a52ffa71149cfed,"Add Stanford Sentiment Treebank dataset reader (#1032)

* Add StanfordSentimentTreebankTokensDatasetReader

* Add test for SST data reader

* Add docs

* Fix typo

* Address joelg's comments, add more commentary about label conversion

* Remove tqdm

* Some lint and style fixes

* Docstring fixes

* Remove Tokens from class name

* Fix lint and tests

* Add test for StanfordSentimentTreebankDatasetReader.from_params

* Fix lint by disabling protected access in test",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 21', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 3', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 2', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'reader._use_subtrees is True', 'reader._granularity == ']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
635,Mark Neumann,markn@allenai.org,2018-03-26 12:43:06-07:00,2b55bfb4f96fb3b72a8af8e5aa987e6428c569ca,https://github.com/allenai/allennlp/commit/2b55bfb4f96fb3b72a8af8e5aa987e6428c569ca,"re-jig readme (#1034)

* re-jig readme

* PR feedback

* link to pytorch, formatting",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
636,Nelson Liu,nelson-liu@users.noreply.github.com,2018-03-26 21:12:52-07:00,1700db4aa9323adb156cd87fd7bd9bba5b92532c,https://github.com/allenai/allennlp/commit/1700db4aa9323adb156cd87fd7bd9bba5b92532c,"Minor enhancements to seq2seq data reader (#1037)

* Add data caching to seq2seq reader

* Explicitly construct with kwargs in seq2seq_reader.from_params",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
637,Mark Neumann,markn@allenai.org,2018-03-27 13:46:40-07:00,d57717eae303799644dd1632901bb6119e54e1f8,https://github.com/allenai/allennlp/commit/d57717eae303799644dd1632901bb6119e54e1f8,srl model tweaks (#1040),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
638,Matthew Peters,matt-peters@users.noreply.github.com,2018-03-27 16:18:40-07:00,d0bb3d2a64b0c02fb5c2e2f2e1ea4224ec018ebe,https://github.com/allenai/allennlp/commit/d0bb3d2a64b0c02fb5c2e2f2e1ea4224ec018ebe,"CoNLL dataset reader that allows BIOLU tags (#1041)

* Add a function to convert BIOLU tags to spans

* Add a function to recode iob1 as biolu

* Allow biolu labels in conll2003 dataset reader

* pylint

* mypy

* Skip docstart lines when reading CoNLL data

* s/iob1/bio/ s/biolu/bioul/

* Backticks around types

* pylint

* s/bio/iob/",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,2,2,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(span_utils.InvalidTagSequence):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == []', 'fields[].labels == expected_labels', 'tokens == []', 'fields[].labels == expected_labels', 'spans == [(, (4, 4))]', 'bioul_sequence == []', 'bioul_sequence == []']",[],[],[],[],[],[],"['(, (True, False))', '())']","['parametrize(, (True, False))', 'parametrize())']","['mark.parametrize(, (True, False))', 'mark.parametrize())']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
639,Mark Neumann,markn@allenai.org,2018-03-28 10:10:51-07:00,78aa07190fde588a369a5c3759ec76c4da12d9c8,https://github.com/allenai/allennlp/commit/78aa07190fde588a369a5c3759ec76c4da12d9c8,proper configuration of all dropout in self attention (#1042),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
640,Nelson Liu,nelson-liu@users.noreply.github.com,2018-03-28 14:39:13-07:00,a5a827e7ef828edfe63db48ad14f9046c0438144,https://github.com/allenai/allennlp/commit/a5a827e7ef828edfe63db48ad14f9046c0438144,"Add Biattentive Classification Network (#1038)

* Add initial BiattentiveClassificationNetwork

* Add test for BCN

* Add BCN docs

* Initial training config for BCN

* Improve docstring

* self attentive pooling projection should have bias

* Edit LR to match paper

* Original paper only has 3 final layers

* Add maxout network

* Add test for maxout

* Add maxout docs

* Fix typo in maxout tests

* Fix typo in maxout self._input_dim

* Enable using maxout or FFNN as BCN output layer

* Test BCN with both Maxout and FFNN output layer

* Fix typo in maxout docstring

* Update BCN training config to use maxout network

* Add embedding and integrator dropout

* Edit BCN training config to use Bryan's hyperparameters

* Address mattg's PR comments

* Remove contiguous call in self-attentive pooling",14,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,4,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['output.shape == (1, 3)']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
641,Michael Schmitz,michael@schmitztech.com,2018-03-28 15:04:45-07:00,e4442166561990a056de599cb1a2cde324504242,https://github.com/allenai/allennlp/commit/e4442166561990a056de599cb1a2cde324504242,Add an ensemble model for BiDAF (#1000),14,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics[] > 0', 'torch.equal(ensemble_output_dict[])', 'ensemble_output_dict[]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
642,Mark Neumann,markn@allenai.org,2018-03-28 15:26:54-07:00,77da4251e42f56316942aa33008157ada5112184,https://github.com/allenai/allennlp/commit/77da4251e42f56316942aa33008157ada5112184,"don't allow U tags in BIO to spans, use BIOUL in SpanF1Measure (#1045)

* don't allow U tags in BIO to spans, use BIOUL in SpanF1Measure

* pylint",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(span_utils.InvalidTagSequence):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(spans) == {(, (7, 7))}']",[],[],[],[],[],[],[],[],[],[],[],[]
643,Matt Gardner,mattg@allenai.org,2018-03-29 12:22:18-07:00,db44a25bb453011a3f8144ef9901007cf652ad7d,https://github.com/allenai/allennlp/commit/db44a25bb453011a3f8144ef9901007cf652ad7d,"Add a get_final_encoder_states function that handles bidirectional encoders (#1048)

* Add a get_final_encoder_states function that handles bidirectional encoders

* Fix overrides",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
644,Iz Beltagy,iz@beltagy.net,2018-03-30 15:27:12-07:00,929913116c1cd2f2f0c0060b244b7a6e5c2cfe48,https://github.com/allenai/allennlp/commit/929913116c1cd2f2f0c0060b244b7a6e5c2cfe48,"Add a multilabel field (#1054)

* Add a multilabel field

* documentation

* code reviews

* type checking

* replace the static variable

* mypy

* code review",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,6,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not in MultiLabelField._already_warned_namespaces', 'in MultiLabelField._already_warned_namespaces', 'not in MultiLabelField._already_warned_namespaces']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(AssertionError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
645,Yixin Nie,easonnie@users.noreply.github.com,2018-04-02 16:10:50-04:00,ebf25ead6f3ad5fdd19a7c86eec2d725afaf4196,https://github.com/allenai/allennlp/commit/ebf25ead6f3ad5fdd19a7c86eec2d725afaf4196,"One line update in file_utiles.py (#1059)

Update file_utiles.py such that it could accept customized ALLENNLP_CACHE_ROOT.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
646,Mark Neumann,markn@allenai.org,2018-04-02 16:23:36-07:00,bcbc12e4e4f56ef14ca91cdbf02a6e82d372be61,https://github.com/allenai/allennlp/commit/bcbc12e4e4f56ef14ca91cdbf02a6e82d372be61,"don't use mutable sys.stdout for both logs (#1060)

* don't use mutable sys.stdout for both logs

* whitespace",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
647,Mark Neumann,markn@allenai.org,2018-04-03 14:08:02-07:00,e8e2499e8c68a8a4eb43ff4ba5811c13073b7a0d,https://github.com/allenai/allennlp/commit/e8e2499e8c68a8a4eb43ff4ba5811c13073b7a0d,"install pytorch via pip (#1062)

* install pytorch via pip

* add note about CUDA, add to requirements.txt

* torch not pytorch",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
648,Joel Grus,joelgrus@gmail.com,2018-04-03 16:07:17-07:00,da1e6f4579b673a57ceb541ee8eae251d15eb4cb,https://github.com/allenai/allennlp/commit/da1e6f4579b673a57ceb541ee8eae251d15eb4cb,"Update setup.py

cowboy coding here",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
649,Mark Neumann,markn@allenai.org,2018-04-05 15:01:17-07:00,8ddc8cb095acc312d3a07ff1d7f7cdd681e67e3c,https://github.com/allenai/allennlp/commit/8ddc8cb095acc312d3a07ff1d7f7cdd681e67e3c,"initial dry run command (#1063)

* first bash at dry run

* add random selction of instances

* add max and min, use get_padding_lengths for computing stats

* iterate over instance fields properly

* add docstring and docs

* appease the sphinx

* PR comments

* fix pylint",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(predefined_vocab_files) == {}', 'set(new_vocab_files) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
650,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-04-11 11:24:13-07:00,0a918aa7bb3ca41647ea9070420be60dda6b41bc,https://github.com/allenai/allennlp/commit/0a918aa7bb3ca41647ea9070420be60dda6b41bc,read vocab params in model test when available (#1071),1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
651,Mandar Joshi,mandarjoshi90@users.noreply.github.com,2018-04-12 08:41:29-07:00,4c02d92f4b1e372739ae50c22ecc4ded6b54899e,https://github.com/allenai/allennlp/commit/4c02d92f4b1e372739ae50c22ecc4ded6b54899e,"Reading glove embeddings: strip() --> rstrip() (#1056)

* changed to rstrip() for correct reading of glove files

* add test case for rstrip

* Add unicode space to vocab",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['numpy.allclose(word_vector.numpy(), numpy.array([3.4, 3.3, 5.0]))']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
652,Matt Gardner,mattg@allenai.org,2018-04-12 09:59:04-07:00,b72c838d5f2ba0ed980c2112ae91af05f83664f9,https://github.com/allenai/allennlp/commit/b72c838d5f2ba0ed980c2112ae91af05f83664f9,Adding an optional projection layer to ElmoTokenEmbedder (#1076),4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['embedded.shape == (1, 2, 20)', 'embedded.shape == (1, 1, 1, 20)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
653,Aaron Sarnat,aaronsarnat@users.noreply.github.com,2018-04-12 13:58:43-07:00,a92bf48a346ba3ce99d1f6a87ed181f908c42db7,https://github.com/allenai/allennlp/commit/a92bf48a346ba3ce99d1f6a87ed181f908c42db7,"Top menu -> Left menu (#1074)

* top menu -> side menu

* pane scrolling tweak",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
654,Michael Schmitz,michael@schmitztech.com,2018-04-12 15:47:46-07:00,14bb4e321c1e2ee0e64a2bdafa1044b4e9dda5ad,https://github.com/allenai/allennlp/commit/14bb4e321c1e2ee0e64a2bdafa1044b4e9dda5ad,"Revert ""Top menu -> Left menu (#1074)"" (#1081)

This reverts commit a92bf48a346ba3ce99d1f6a87ed181f908c42db7.",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
655,Michael Schmitz,michael@schmitztech.com,2018-04-13 07:36:52-07:00,6829edbe932f2f48d6c5f8dc15d16070bc1666c7,https://github.com/allenai/allennlp/commit/6829edbe932f2f48d6c5f8dc15d16070bc1666c7,Move the top nav bar to the left pane. (#1082),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
656,Matt Gardner,mattg@allenai.org,2018-04-13 11:20:56-07:00,78dc1df951be331f3f8519c6b87200e3eb821e9a,https://github.com/allenai/allennlp/commit/78dc1df951be331f3f8519c6b87200e3eb821e9a,"Data cleanup and additions from the wikitables branch (#1084)

* Data cleanup and additions from the wikitables branch

* Added docs",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['generated_dataset1[0][] == [0, 0, 0, 0, 0]', 'generated_dataset1[1][] == [1, 1, 1, 1, 1]', 'generated_dataset2[0][] == [0, 0, 0]', 'generated_dataset2[1][] == [1, 1, 1]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
657,Matt Gardner,mattg@allenai.org,2018-04-13 11:40:08-07:00,3ea82b1ff95de532d7624ed4c4488f72ec0f23bd,https://github.com/allenai/allennlp/commit/3ea82b1ff95de532d7624ed4c4488f72ec0f23bd,Moving over modifications to common / util modules (#1085),6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
658,Matt Gardner,mattg@allenai.org,2018-04-13 15:18:15-07:00,1655f229e8ce5ab2b705549435ab06e1541394f8,https://github.com/allenai/allennlp/commit/1655f229e8ce5ab2b705549435ab06e1541394f8,"Adding the decoding framework from the wikitables branch (#1086)

* Adding the decoding framework from the wikitables branch

* Fix docs

* Add test for MaximumMarginalLikelihood.decode()

* Added tests for BeamSearch

* Add test for ""keep final unfinished states"" case

* Improve docs from Michael's comments

* Minor docstring improvement",20,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(best_states) == 2', 'best_states[0][0].action_history[0] == [-1, 1, 3, 4]', 'best_states[1][0].action_history[0] == [3, 4]', 'len(best_states) == 4', 'best_states[0][0].action_history[0] == [-1, 1, 3, 4]', 'best_states[1][0].action_history[0] == [3, 4]', 'best_states[2][0].action_history[0] == [-18, -16, -14, -12, -10]', 'best_states[3][0].action_history[0] == [7, 9, 11, 13, 15]', 'len(finished_states) == 5', '([0, 2, 4], -2) in state_info', '([0, 1, 2, 4], -3) in state_info', '([0, 1, 3, 4], -3) in state_info', '([0, 2, 3, 4], -3) in state_info', '([0, 1, 2, 3, 4], -4) in state_info', 'decoded_info[][0] == [0, 2, 4]', 'len(result) == 2', 'len(result[0]) == 6', 'result[0][()] == {1, 2}', 'result[0][(1,)] == {2, 3}', 'result[0][(1, 2)] == {4}', 'result[0][(1, 3)] == {4}', 'result[0][(2,)] == {3}', 'result[0][(2, 3)] == {4}', 'len(result[1]) == 4', 'result[1][()] == {2, 3}', 'result[1][(2,)] == {3}', 'result[1][(2, 3)] == {4}', 'result[1][(3,)] == {4}', 'allowed_actions == [{2}, {4, 5}, {3}]', 'not state.is_finished()', 'state.is_finished()', 'state.get_valid_actions() == [1, 2]', 'state.get_valid_actions() == [3, 4]', 'state.get_valid_actions() == []', 'state.get_valid_actions() == [1, 2, 5]', 'state.get_valid_actions() == [1, 2, 5]', 'state.get_valid_actions() == [3, 4]', 'state.get_valid_actions() == [3, 4]', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__']",['(AssertionError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
659,Michael Schmitz,michael@schmitztech.com,2018-04-16 13:25:19-07:00,eb81ac907b1ad63618528afdb29f71a846550bcd,https://github.com/allenai/allennlp/commit/eb81ac907b1ad63618528afdb29f71a846550bcd,Update elmo.md (#1092),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
660,Matt Gardner,mattg@allenai.org,2018-04-18 18:10:21-07:00,2e6f2dd5c6b86ca7c35604dfb78a71ddc9c5a60b,https://github.com/allenai/allennlp/commit/2e6f2dd5c6b86ca7c35604dfb78a71ddc9c5a60b,"Adding the type system / logical form parsing code from the wikitables branch (#1087)

* Adding the type system / logical form parsing code from the wikitables branch

* Added data for NLVR and wikitables worlds

* Addressed Mark's comments

* Appease pylint",51,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,6,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,214,1,0,1,0,0,0,0,1,1,0,0,1,8,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('RaisesRegex', '(ParsingError, ):'), ('RaisesRegex', '(ParsingError, ):'), ('RaisesRegex', '(ParsingError, ):'), ('RaisesRegex', '(ParsingError, ):')]","['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[]', '[t.text for t in fields[,', 'len(black_logical_forms) == 25', 'shortest_logical_form == ', 'set(black_triangle_touch_forms) == set([', 'shortest_logical_form == ', 'set(length_three_logical_forms) == {,', 'graph.entities == [,', 'neighbors == {}', 'neighbors == {}', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.entities == [,', 'graph.entity_text[', 'graph.entities == [,', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.entity_text[', 'graph.entity_text[', 'TableQuestionKnowledgeGraph._get_cell_parts()]', 'TableQuestionKnowledgeGraph._get_cell_parts()]', 'TableQuestionKnowledgeGraph._get_cell_parts(,', 'set(parts) == {(),', 'set(parts) == {(),', 'set(parts) == {(),', 'TableQuestionKnowledgeGraph._should_split_column_cells([]) is False', 'TableQuestionKnowledgeGraph._should_split_column_cells([]) is True', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {', 'neighbors == {,', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {,', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'graph.entities == [,', 'numbers == [()]', 'numbers == [()]', 'numbers == [()]', 'numbers == [()]', 'numbers == [()]', 'type_a.resolve(type_b) is None', 'unary_type.resolve(ROW_TYPE) is None', 'unary_type.resolve(ComplexType(CELL_TYPE, ROW_TYPE)) is None', 'resolution == UnaryOpType(ROW_TYPE)', 'resolution == UnaryOpType(CELL_TYPE)', 'resolution == UnaryOpType(ComplexType(CELL_TYPE, ROW_TYPE))', 'binary_type.resolve(CELL_TYPE) is None', 'binary_type.resolve(ComplexType(CELL_TYPE, ROW_TYPE)) is None', 'binary_type.resolve(complex_type) is None', 'binary_type.resolve(complex_type) is None', 'binary_type.resolve(complex_type) is None', 'binary_type.resolve(complex_type) == BinaryOpType(ROW_TYPE)', 'binary_type.resolve(complex_type) == BinaryOpType(ROW_TYPE)', 'binary_type.resolve(complex_type) == BinaryOpType(ROW_TYPE)', 'len(valid_actions) == 3', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'len(valid_actions) == 5', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'len(valid_actions) == 5', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'valid_actions[,', 'REVERSE_TYPE.resolve(CELL_TYPE) is None', 'resolution == ReverseType(ComplexType(ROW_TYPE, CELL_TYPE), ComplexType(CELL_TYPE, ROW_TYPE))', 'resolution == ReverseType(ComplexType(ROW_TYPE, CELL_TYPE), ComplexType(CELL_TYPE, ROW_TYPE))', 'resolution == ReverseType(ComplexType(ROW_TYPE, ANY_TYPE), ComplexType(ANY_TYPE, ROW_TYPE))', 'resolution is None', ']', 'COUNT_TYPE.resolve(CELL_TYPE) is None', 'COUNT_TYPE.resolve(ComplexType(CELL_TYPE, ROW_TYPE)) is None', 'COUNT_TYPE.resolve(ComplexType(CELL_TYPE, ANY_TYPE)) == CountType(CELL_TYPE)', 'COUNT_TYPE.resolve(ComplexType(ANY_TYPE, ANY_TYPE)) == CountType(ANY_TYPE)', 'ARG_EXTREME_TYPE.resolve(ROW_TYPE) is None', 'ARG_EXTREME_TYPE.resolve(ComplexType(CELL_TYPE, ROW_TYPE)) is None', 'resolution == ArgExtremeType(CELL_TYPE)', 'expression == [[[]]]', 'expression == [[]]]]]', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'nlvr_world.execute(logical_form_true) is True', 'nlvr_world.execute(logical_form_false) is False', 'nlvr_world.execute(logical_form) is False', 'nlvr_world.execute(logical_form) is True', 'nlvr_world.execute(logical_form) is True', 'nlvr_world.execute(logical_form) is False', 'nlvr_world.execute(logical_form) is False', 'nlvr_world.execute(logical_form) is True', 'nlvr_world.execute(logical_form) is True', 'action_sequence == [,', 'action_sequence == [,', 'world.execute(', 'world.execute(', 'world.execute(logical_form) is True', 'world.execute(logical_form) is True', 'world.execute(', 'world.execute(', 'world.execute(', 'world.execute(', 'world.execute(', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([,', 'set(agenda) == set([])', 'set(agenda) == set([,', 'set(agenda) == set([,', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'set(actual_right_sides) == set(expected_right_sides)', 'set(valid_actions.keys()) == {', 'str(expression) == ', 'str(expression) == ', 'str(expression) == ', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', 'actions == target_action_sequence', 'actions == target_action_sequence', 'in actions_with_var', 'in actions_with_var', 'not in actions_without_var', 'in actions_without_var', 'argument_paths == [[],', 'unary_function_paths == [[,', 'binary_function_paths == [[,', 'argument_paths == [[],', 'identity_paths == [[,', 'in action_sequence', 'not in action_sequence_without_var', 'in action_sequence_with_var', 'parsed_logical_form == parsed_reconstructed_logical_form', 'parsed_logical_form == parsed_reconstructed_logical_form', 'logical_form == expected_logical_form', 'parsed_logical_form == parsed_reconstructed_logical_form', 'parsed_logical_form == parsed_reconstructed_logical_form', 'nlvr_world.execute(logical_form) == nlvr_world.execute(reconstructed_logical_form)', 'parsed_logical_form == parsed_reconstructed_logical_form', 'nlvr_world.execute(logical_form) == nlvr_world.execute(reconstructed_logical_form)', 'in logical_form', 'parsed_logical_form == parsed_expected_logical_form', 'parsed_logical_form == parsed_expected_logical_form']",['(ParsingError)'],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],['import pytest'],"['[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[]', '[t.text for t in fields[,']",[],[],[],[],[],[],[],[],[],[],[],[]
661,Mark Neumann,markn@allenai.org,2018-04-19 10:31:46-07:00,245a9af0ad1c2243b048ea0b43e014d507bea41d,https://github.com/allenai/allennlp/commit/245a9af0ad1c2243b048ea0b43e014d507bea41d,"add name argument to run_with_beaker.py (#1103)

* add name argument to run_with_beaker.py

* pr comments",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
662,Matt Gardner,mattg@allenai.org,2018-04-19 13:01:27-07:00,f7924bc07effd7ad20cd97a6056df0ca28352dee,https://github.com/allenai/allennlp/commit/f7924bc07effd7ad20cd97a6056df0ca28352dee,"Adding KnowledgeGraphField and ProductionRuleField (#1104)

* Adding KnowledgeGraphField and ProductionRuleField

* Fixed comment",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,43,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['namespace_token_counts[] == {', 'self.field._indexed_entity_texts.keys() == {}', 'self.field._indexed_entity_texts[] == expected_array', 'self.field.get_padding_lengths() == {: 3,', 'self.field.get_padding_lengths() == {: 3,', 'tensor_dict.keys() == {}', 'lemma_feature == 1', 'feature_values == [0, 0, 0, 1, 2/3, 1/3, 0, 0, 0]', 'batched_tensor_dict.keys() == {}', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 0', 'field._rule_id == self.s_rule_index', 'field.get_padding_lengths() == {}', 'isinstance(tensor_tuple, tuple)', 'len(tensor_tuple) == 3', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'isinstance(tensor_tuple, tuple)', 'len(tensor_tuple) == 3', 'tensor_tuple[0] == ', 'tensor_tuple[1] is False', 'tensor_tuple[2] is None', 'field.batch_tensors(tensor_list) == tensor_list', 'isinstance(tensors, list)', 'len(tensors) == 2', 'isinstance(tensors[0], list)', 'len(tensors[0]) == 3', 'isinstance(tensors[1], list)', 'len(tensors[1]) == 3', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'tensor_tuple[0] == ', 'tensor_tuple[1] is False', 'tensor_tuple[2] is None', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'tensor_tuple[0] == ', 'tensor_tuple[1] is False', 'tensor_tuple[2] is None']",['(AssertionError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
663,Matt Gardner,mattg@allenai.org,2018-04-19 13:20:11-07:00,cbe58971a15aaf6a80d3cc53b1e7c4a9ba4e089c,https://github.com/allenai/allennlp/commit/cbe58971a15aaf6a80d3cc53b1e7c4a9ba4e089c,Adding NLVR dataset reader (#1105),8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', 'instance.fields.keys() == {}', '[t.text for t in sentence_tokens] == expected_tokens', 'len(actions) == 115', 'set(agenda_strings) == set([,', 'isinstance(worlds[0], NlvrWorld)', 'label == ', 'expected_agenda_actions == agenda_actions', 'len(instances) == 2', 'instance.fields.keys() == {}', '[t.text for t in sentence_tokens] == expected_tokens', 'len(actions) == 115', 'set(agenda_strings) == set([,', 'all([isinstance(world, NlvrWorld) for world in worlds])', 'labels == []', 'len(instances) == 2', 'instance.fields.keys() == {,', 'len(all_action_sequence_indices) == 20', 'action_sequence == [,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
664,Matt Gardner,mattg@allenai.org,2018-04-20 12:57:53-07:00,bc8ac1a677957b810ad500dc03d45289e168b93d,https://github.com/allenai/allennlp/commit/bc8ac1a677957b810ad500dc03d45289e168b93d,Adding WikiTables dataset reader (#1106),7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'instance.fields.keys() == {', '[t.text for t in instance.fields[].tokens] == question_tokens', 'len(entities) == 59', 'sorted(entities) == [', 'isinstance(instance.fields[].as_tensor({}), WikiTablesWorld)', 'num_action_sequences == 10', 'actions == [', 'action_strings == [', 'example_info == {,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
665,Matt Gardner,mattg@allenai.org,2018-04-20 13:50:20-07:00,7dfc34247cedfe16c9d35a557855977fbd3df15c,https://github.com/allenai/allennlp/commit/7dfc34247cedfe16c9d35a557855977fbd3df15c,"Adding NLVR model (#1108)

* Adding NLVR model

* Add docs

* Fix docs

* Updated fixtures, and train_fixtures.py

* Add missing __init__.py",31,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(AssertionError, msg=f):')]","['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model._checklist_cost_weight == 0.8', 'mapping == expected_mapping', 'mapping == [(0, 0), (1, 1), (5, 2), (7, 3), (10, 4)]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
666,Iz Beltagy,iz@beltagy.net,2018-04-20 13:50:33-07:00,f7b736c2b8f515289e8c22839b468dc9242af614,https://github.com/allenai/allennlp/commit/f7b736c2b8f515289e8c22839b468dc9242af614,increase metrics logging precision (#1113),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
667,Matt Gardner,mattg@allenai.org,2018-04-21 08:47:07-07:00,0df8978073fe1ebe1af18af5cab48ce70eecca81,https://github.com/allenai/allennlp/commit/0df8978073fe1ebe1af18af5cab48ce70eecca81,"Adding the wikitables parser (#1114)

* Adding the wikitables parser

* Fix dockerfile and docs",30,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,3,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],"['def tearDown(self):', 'def tearDown(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['to_embed == expected_to_embed', 'to_link == expected_to_link', 'considered == expected_considered', 'to_embed == expected_to_embed', 'to_link is None', 'considered == expected_considered', 'tuple(embeddings.size()) == (3, 3, 4)', 'tuple(action_logits.size()) == (3, 3)', 'len(new_states) == 2', 'new_state.batch_indices == [0]', 'new_state.action_history == [[4]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.action_indices == self.action_indices', 'new_state.possible_actions == self.possible_actions', 'new_state.batch_indices == [1]', 'new_state.action_history == [[3, 4, 0]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.action_indices == self.action_indices', 'new_state.possible_actions == self.possible_actions', 'len(new_states) == 2', 'new_state.batch_indices == [0]', 'new_state.action_history == [[1, 1]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.action_indices == self.action_indices', 'new_state.possible_actions == self.possible_actions', 'new_state.batch_indices == [1]', 'new_state.action_history == [[3, 4, 0]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.action_indices == self.action_indices', 'new_state.possible_actions == self.possible_actions', 'action_indices[(0, 0)] == action_indices[(1, 2)]', 'action_indices[(1, 1)] == -1', 'len(set(action_indices.values())) == 4', 'actions_to_entities == {', 'wikitables_accuracy._count == 1', 'wikitables_accuracy._correct == 1', 'wikitables_accuracy._count == 2', 'wikitables_accuracy._correct == 1', 'wikitables_accuracy._count == 3', 'wikitables_accuracy._correct == 1', 'wikitables_accuracy._count == 4', 'wikitables_accuracy._correct == 1']",['(RuntimeError)'],[],[],[],[],[],[],[],[],[],[],[],[],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[]
668,Matt Gardner,mattg@allenai.org,2018-04-23 13:59:36-07:00,7627a099b0cd1c55c54607962cca3c71e098a262,https://github.com/allenai/allennlp/commit/7627a099b0cd1c55c54607962cca3c71e098a262,Use xavier_uniform for initializing embedding weights (#1120),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
669,Matt Gardner,mattg@allenai.org,2018-04-24 13:57:18-07:00,960f913dc92f35fdf7840174b4968599916630a6,https://github.com/allenai/allennlp/commit/960f913dc92f35fdf7840174b4968599916630a6,"Adding WikiTables and NLVR predictors (#1118)

* Adding WikiTables and NLVR predictors

* Fixed test paths and fixtures",11,False,True,True,True,False,False,False,False,False,False,False,False,False,False,False,[],1,0,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,['class TestWikiTablesParserPredictor(TestCase):'],[],"['def setUp(self):', 'def setUp(self):']",[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in result', 'in result', 'len(result[]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[]) == 2  # Because there are two worlds in the input.', 'len(action_sequence) > 1', 'all([isinstance(action, str) for action in action_sequence])', 'logical_form is not None', 'answer is not None']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
670,Matt Gardner,mattg@allenai.org,2018-04-25 13:25:05-07:00,2b81da75594e7c72932687fc905d538dbe2049e8,https://github.com/allenai/allennlp/commit/2b81da75594e7c72932687fc905d538dbe2049e8,"Remove the KeyError catch block in the server (#1130)

Several times I've run into an issue where I get a really weird error
message about some key being missing, where there was actually a
`KeyError` deep in my model code that was being caught at this point
and re-branded incorrectly.  I don't think trying to catch the
`KeyError` here is actually useful.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
671,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-04-25 14:22:28-07:00,812dfcf24e336e063e5e37ac3b1682f2cc49af61,https://github.com/allenai/allennlp/commit/812dfcf24e336e063e5e37ac3b1682f2cc49af61,"Added a script to generate data from an ERM trained model (#1115)

* added a script to generate data from erm and made related changes

* removed max_num_decoded_sequences from forward in models

* addressed other PR comments

* remaining pr comments",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['decoded_info[][0] == [[0, 2, 4]]', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'len(result[][0]) == 2  # Because there are two worlds in the input.']",[],[],[],[],[],[],[],[],[],[],[],[],"['decoded_info[][0] == [0, 2, 4]', 'len(result[]) == 2  # Because there are two worlds in the input.', 'len(result[]) == 2  # Because there are two worlds in the input.']",[],[],[],[],[],[],[],[],[],[],[],[]
672,Mark Neumann,markn@allenai.org,2018-04-25 14:46:44-07:00,53ae7356fbbf9c715f6c723f4e008fad96afd445,https://github.com/allenai/allennlp/commit/53ae7356fbbf9c715f6c723f4e008fad96afd445,"clean EVALB via make, add to Dockerfile (#1132)

* clean EVALB via make, add to Dockerfile

* shuffle dockerfile a bit",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
673,Matt Gardner,mattg@allenai.org,2018-04-25 15:34:52-07:00,a869e0b7c0c6eeadd2364b993a090b4e5bdd2412,https://github.com/allenai/allennlp/commit/a869e0b7c0c6eeadd2364b993a090b4e5bdd2412,Move imports to inside of CACHE_MODELS=true condition (#1133),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
674,Matt Gardner,mattg@allenai.org,2018-04-25 21:07:35-07:00,b9630e6b3ae1c562935fccbadb6863e2cfc93a8c,https://github.com/allenai/allennlp/commit/b9630e6b3ae1c562935fccbadb6863e2cfc93a8c,"Fix state scores in WikiTablesDecoderStep (#1129)

* Fix state scores in WikiTablesDecoderStep

I also added a convenience method for printing out the score and action
sequence in a WikiTablesDecoderState, which is helpful for examining
what's going on during decoding / beam search.

* Better comments, fix tests",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
675,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-04-26 10:32:27-07:00,bfff55f600e8dcda16bc90bb107fb106beda4813,https://github.com/allenai/allennlp/commit/bfff55f600e8dcda16bc90bb107fb106beda4813,bug fix for empty decoder outputs (#1141),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
676,Matt Gardner,mattg@allenai.org,2018-04-26 11:00:33-07:00,c684216b728c900bb54de42368b7a557346dac77,https://github.com/allenai/allennlp/commit/c684216b728c900bb54de42368b7a557346dac77,Streamlining the docker build a little bit (#1140),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
677,Matthew Peters,matt-peters@users.noreply.github.com,2018-04-26 13:48:46-07:00,6d15d17c95bfda9a73dbae694a319031826fcd34,https://github.com/allenai/allennlp/commit/6d15d17c95bfda9a73dbae694a319031826fcd34,"Allow to restart with optimizers on CUDA (#1144)

* Allow to restart with optimizers on CUDA

* pylint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
678,Michael Schmitz,michael@schmitztech.com,2018-04-26 14:43:04-07:00,645379e974d87ae8c33e324f3c290485b9fffcd9,https://github.com/allenai/allennlp/commit/645379e974d87ae8c33e324f3c290485b9fffcd9,"Allow default predictors when calling programatically (#1112)

* Modify Predictor.from_archive to use default predictors.

* Add predict method to predictors.",12,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
679,Matt Gardner,mattg@allenai.org,2018-04-26 15:49:01-07:00,55b0411bea8ae241332aa6c96cc9b4cf189afe20,https://github.com/allenai/allennlp/commit/55b0411bea8ae241332aa6c96cc9b4cf189afe20,Adding ReLUs after linear projections (#1150),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
680,Mark Neumann,markn@allenai.org,2018-04-27 11:36:42-07:00,121d3e8cc251292037453ca535bd8937000c9130,https://github.com/allenai/allennlp/commit/121d3e8cc251292037453ca535bd8937000c9130,unidecode in setup (#1148),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
681,Matt Gardner,mattg@allenai.org,2018-04-27 13:38:23-07:00,cc510fad09e98028d5c0b57aed434d4f9bf63251,https://github.com/allenai/allennlp/commit/cc510fad09e98028d5c0b57aed434d4f9bf63251,Allow ablation where linking features are removed (#1145),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
682,Matt Gardner,mattg@allenai.org,2018-04-28 12:39:44-07:00,f2257a67dafb50225584afc2030993c74f9b5379,https://github.com/allenai/allennlp/commit/f2257a67dafb50225584afc2030993c74f9b5379,"Use separate action embeddings for prediction vs. input feeding (#1153)

* Not clean yet, but working

* Added a bias too

* Update fixtures

* Fix decode

* mypy",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
683,Mark Neumann,markn@allenai.org,2018-04-30 10:53:16-07:00,f8d64efd002fd760b18ae7135cc431d47af109fd,https://github.com/allenai/allennlp/commit/f8d64efd002fd760b18ae7135cc431d47af109fd,"add stacked bilm (#1154)

* add stacked bilm

* add docs, remove comment

* add docs

* why is sphinx so hard

* rework comments",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['encoder.get_input_dim() == 5', 'encoder.get_output_dim() == 18', 'encoder.is_bidirectional']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
684,Matt Gardner,mattg@allenai.org,2018-04-30 13:56:08-07:00,281d032ea426ef3f97d30ad0aaecf48d7074e34d,https://github.com/allenai/allennlp/commit/281d032ea426ef3f97d30ad0aaecf48d7074e34d,"Added two feature extractors that were in PNP and not in our version (#1155)

* Added two feature extractors that were in PNP and not in our version

* Fix default number of linking features

* Fix tests (hopefully)

* Update train_fixtures.py

* Update fixtures",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
685,Michael Schmitz,michael@schmitztech.com,2018-04-30 15:05:40-07:00,d05673aae6f9ea6a67ce303dbf2c2385d7544231,https://github.com/allenai/allennlp/commit/d05673aae6f9ea6a67ce303dbf2c2385d7544231,Add a default cuda_device to model. (#1151),13,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
686,Mark Neumann,markn@allenai.org,2018-04-30 16:25:41-07:00,d4b286cf75501fc419b4393e5f306f8d49d8274f,https://github.com/allenai/allennlp/commit/d4b286cf75501fc419b4393e5f306f8d49d8274f,"Mattp/ner (#1162)

* WIP: NER model

* Add ner.json training config

* Use canonical ELMo location in training config

* Update ner.json

Use environment variables for unspecified paths.  This way, users get a clear error (such and such is undefined) when they try to train the model rather than a path doesn't exist error later on.

* Update ner.json

* add comments, fix tests

* update to new model",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(allowed) == {                         # Extra column for end tag.', 'set(allowed) == {                                                   # Extra column for end tag.']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(allowed) == {', 'set(allowed) == {']",[],[],[],[],[],[],[],[],[],[],[],[]
687,Joel Grus,joelgrus@gmail.com,2018-05-01 10:03:15-07:00,435280ec5e3092f682eac36435bbf0e01ba8f39c,https://github.com/allenai/allennlp/commit/435280ec5e3092f682eac36435bbf0e01ba8f39c,bump version number to 0.4.2,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
688,Joel Grus,joelgrus@gmail.com,2018-05-01 10:25:56-07:00,a1e727c1f3307ddbadcef778bb756b891cc87c27,https://github.com/allenai/allennlp/commit/a1e727c1f3307ddbadcef778bb756b891cc87c27,bump version to v0.5.0-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
689,Joel Grus,joelgrus@gmail.com,2018-05-01 10:44:46-07:00,60e03e3d7031ca801950e9d1cf7e90dd20df6464,https://github.com/allenai/allennlp/commit/60e03e3d7031ca801950e9d1cf7e90dd20df6464,remove spaces in SpacyWordSplitter.batch_tokenize (#1156),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(batch_split) == len(separately_split)', 'len(batch_sentence) == len(separate_sentence)', 'batch_word.text == separate_word.text']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
690,Joel Grus,joelgrus@gmail.com,2018-05-01 10:49:09-07:00,15f61028e63b600fc9f05d419e5afde801faaf99,https://github.com/allenai/allennlp/commit/15f61028e63b600fc9f05d419e5afde801faaf99,bump version numbers in README,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
691,Mark Neumann,markn@allenai.org,2018-05-01 15:27:11-07:00,af283d162778b9d41b92b7a24e6474f385fdb72f,https://github.com/allenai/allennlp/commit/af283d162778b9d41b92b7a24e6474f385fdb72f,hack to stop tqdm hanging (#1168),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
692,Joel Grus,joelgrus@gmail.com,2018-05-02 11:42:30-07:00,4f8834c7c2d388d2783fe3823ab095f4bf3bdbfa,https://github.com/allenai/allennlp/commit/4f8834c7c2d388d2783fe3823ab095f4bf3bdbfa,fix comment (#1171),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
693,Matthew Peters,matt-peters@users.noreply.github.com,2018-05-03 13:11:48-07:00,58f90337c2e5dd2344a438875fe719bf328ac912,https://github.com/allenai/allennlp/commit/58f90337c2e5dd2344a438875fe719bf328ac912,"Clarify the ELMo readme (#1167)

* Clarify the ELMo readme

* Cleanup

* Add note on statefulness to ELMo README

* Add comments to  command about statefulness

* pylint",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
694,Michael Schmitz,michael@schmitztech.com,2018-05-07 10:35:06-07:00,19980b523d143e1ad59c1f95642ee0a18b07f089,https://github.com/allenai/allennlp/commit/19980b523d143e1ad59c1f95642ee0a18b07f089,Add shebang to bin/allennlp (#1179),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
695,Michael Schmitz,MichaelS@allenai.org,2018-05-07 13:30:30-07:00,7cc4f72c9de9bc9f5ac598a21afa7e12ea237868,https://github.com/allenai/allennlp/commit/7cc4f72c9de9bc9f5ac598a21afa7e12ea237868,Update using_in_your_repo.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
696,Michael Schmitz,MichaelS@allenai.org,2018-05-07 13:31:11-07:00,ea2e431cf7672fd1d04bbd382141495bfbc021f7,https://github.com/allenai/allennlp/commit/ea2e431cf7672fd1d04bbd382141495bfbc021f7,Update using_in_your_repo.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
697,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-07 15:51:47-07:00,c369502a0722b1d5c4ea627404e1f5450ec212ad,https://github.com/allenai/allennlp/commit/c369502a0722b1d5c4ea627404e1f5450ec212ad,Add missing --all flag to ELMo howto (#1183),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
698,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-05-08 16:28:40-07:00,7142962d330ca5a95cade114c26a361c78f2042e,https://github.com/allenai/allennlp/commit/7142962d330ca5a95cade114c26a361c78f2042e,"ERM parser for wikitables (#1159)

* made erm parser for wikitables

* fixed a bug that was causing state.world to explode

* fixed some mypy issues

* minor fix in identifying lambda productions

* updated fixtures

* changed default num_linking features in mml and erm parsers

* updated srl fixture

* update metrics in erm parser and doc fixes

* added mml_model_init to from_params included it in test

* addressed pr comments",34,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
699,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-05-09 15:43:10-07:00,3add61dacada8788f08fe6d3515612843399f7d3,https://github.com/allenai/allennlp/commit/3add61dacada8788f08fe6d3515612843399f7d3,check for zero grads only if grad is not none (#1188),1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
700,Michael Schmitz,michael@schmitztech.com,2018-05-10 08:29:28-07:00,65aecdd7c77198328dbee244c9d0a9ecb604251c,https://github.com/allenai/allennlp/commit/65aecdd7c77198328dbee244c9d0a9ecb604251c,Add a tutorial for using the pre-trained models. (#1182),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
701,Michael Schmitz,michael@schmitztech.com,2018-05-10 09:01:45-07:00,69ae074e49bcccc50d8dddc288834eafb07635b1,https://github.com/allenai/allennlp/commit/69ae074e49bcccc50d8dddc288834eafb07635b1,Rename tutorials so they're clearly connected. (#1186),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
702,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-05-10 11:38:33-07:00,8ba58675175e91d306f55380833458acfcb38cdd,https://github.com/allenai/allennlp/commit/8ba58675175e91d306f55380833458acfcb38cdd,"Added coverage to WikiTables ERM parser (#1181)

* wikitables coverage parser

* minor comment updates and bug fixes

* updated table question kg test and coverage computation

* removed unused imports

* copy decoder step's output projection weights properly

* fixed new variable creation

* addressed pr comments

* mypy issues

* addressed remaining PR comments",20,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['graph.get_linked_agenda_items() == []', 'graph._get_longest_span_matching_entities() == []', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
703,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-11 07:50:46-07:00,63f2108e8926c627edbf1b4beae3b1c21b9b333d,https://github.com/allenai/allennlp/commit/63f2108e8926c627edbf1b4beae3b1c21b9b333d,Update ELMo command help docstring (#1195),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
704,Julian Michael,julianjohnmichael@gmail.com,2018-05-11 13:49:22-07:00,77b33fb7527f261682534cf0199e3b4b1ad351ef,https://github.com/allenai/allennlp/commit/77b33fb7527f261682534cf0199e3b4b1ad351ef,Add compute model number to Compile custom LSTM for Tesla V100 (#1198),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
705,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-05-12 11:13:33-07:00,b5af3e477a0a64178d2a1065c1c3c4df5e932932,https://github.com/allenai/allennlp/commit/b5af3e477a0a64178d2a1065c1c3c4df5e932932,"Prune finished states in ERM (#1187)

* prune finished states in erm

* addressed pr comments",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
706,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-05-13 00:42:46-07:00,a8f7adae8546cfac4473bd514b0070367d725f2e,https://github.com/allenai/allennlp/commit/a8f7adae8546cfac4473bd514b0070367d725f2e,"Added dropout to the NLVR parser (#1205)

* changed action projection in nlvr

* changed action projection in wikitables

* added dropout to nlvr parser",11,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
707,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-13 10:38:40-07:00,1554fb0306422a39d90eb85d791f78e0876d2310,https://github.com/allenai/allennlp/commit/1554fb0306422a39d90eb85d791f78e0876d2310,"Update test requirements in setup.py, remove pytest-pythonpath (#1207)

* Update test requirements in setup.py, remove pytest-pythonpath

* Add newline",3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
708,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-05-13 11:14:13-07:00,2dda95beede0322bf9bde1d99803113aaabf30bc,https://github.com/allenai/allennlp/commit/2dda95beede0322bf9bde1d99803113aaabf30bc,"Changed how checklist balance is used in action prediction (#1204)

* changed action projection in nlvr

* removed +=",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
709,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-14 08:59:13-07:00,7bd52cb7b00384fdc20c1488a9a875476ea07758,https://github.com/allenai/allennlp/commit/7bd52cb7b00384fdc20c1488a9a875476ea07758,Use README.md for PyPI long description (#1201),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
710,Matt Gardner,mattg@allenai.org,2018-05-14 09:34:05-07:00,e1fdad6ed97d1af40bca9d2112a257ab323ad27a,https://github.com/allenai/allennlp/commit/e1fdad6ed97d1af40bca9d2112a257ab323ad27a,"Added a ConstrainedBeamSearch, switched MML to use it (#1189)

* Added a ConstrainedBeamSearch, switched MML to use it

* Fixed tests and pylint

* Use constrained beam search in wikitables model

* Add docs

* Actually pass training_beam_size in from_params...  *grumble*

* Added a test for constrained beam search

* Pylint",13,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(best_states) == 1', 'best_states[0][0].action_history[0] == [-1, 1, 3, 4]', 'best_states[0][1].action_history[0] == [-1, 1, 2, 3, 4]', 'best_states[0][2].action_history[0] == [-1, 0, 1, 2, 3, 4]', 'len(best_states) == 1', 'best_states[0][0].action_history[0] == [-1, 1, 3, 4]', 'best_states[0][1].action_history[0] == [-2, 0, 2, 4]', 'len(prefix_tree) == 2', 'len(prefix_tree[0]) == 6', 'prefix_tree[0][()] == {1, 2}', 'prefix_tree[0][(1,)] == {2, 3}', 'prefix_tree[0][(1, 2)] == {4}', 'prefix_tree[0][(1, 3)] == {4}', 'prefix_tree[0][(2,)] == {3}', 'prefix_tree[0][(2, 3)] == {4}', 'len(prefix_tree[1]) == 4', 'prefix_tree[1][()] == {2, 3}', 'prefix_tree[1][(2,)] == {3}', 'prefix_tree[1][(2, 3)] == {4}', 'prefix_tree[1][(3,)] == {4}']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(result) == 2', 'len(result[0]) == 6', 'result[0][()] == {1, 2}', 'result[0][(1,)] == {2, 3}', 'result[0][(1, 2)] == {4}', 'result[0][(1, 3)] == {4}', 'result[0][(2,)] == {3}', 'result[0][(2, 3)] == {4}', 'len(result[1]) == 4', 'result[1][()] == {2, 3}', 'result[1][(2,)] == {3}', 'result[1][(2, 3)] == {4}', 'result[1][(3,)] == {4}', 'allowed_actions == [{2}, {4, 5}, {3}]']",[],[],[],[],[],[],[],[],[],[],[],[]
711,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-14 10:33:44-07:00,10e7e99e4ecee92f62e97acc499c87e8ad8ec81c,https://github.com/allenai/allennlp/commit/10e7e99e4ecee92f62e97acc499c87e8ad8ec81c,Remove argparse from requirements (#1202),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
712,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-14 11:27:28-07:00,70862e09eb9546f849334e4df4893d7597c9f1aa,https://github.com/allenai/allennlp/commit/70862e09eb9546f849334e4df4893d7597c9f1aa,Make pytest_runner a conditional requirement in setup.py (#1203),1,False,False,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
713,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-14 18:47:19-07:00,f246da737791ebe4fdbc6eca3119762eefa0c55b,https://github.com/allenai/allennlp/commit/f246da737791ebe4fdbc6eca3119762eefa0c55b,Add missing import to setup.py (#1215),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
714,murphp15,murphp15@tcd.ie,2018-05-15 17:27:55+01:00,b71ef434b310e9b1ba400b42c7334c794996b40e,https://github.com/allenai/allennlp/commit/b71ef434b310e9b1ba400b42c7334c794996b40e,"Fix for https://github.com/allenai/allennlp/issues/203 (#1210)

* Fix for https://github.com/allenai/allennlp/issues/203

* Fix for https://github.com/allenai/allennlp/issues/203

* Fix for https://github.com/allenai/allennlp/issues/203

* Fix for https://github.com/allenai/allennlp/issues/203

* Fix for https://github.com/allenai/allennlp/issues/203

* Fix for https://github.com/allenai/allennlp/issues/203",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ConfigurationError) as context:'), ('True', '(')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
715,murphp15,murphp15@tcd.ie,2018-05-16 15:49:07+01:00,10ea3b36eb24f1c48fc8c6ee4f64048427ffde6d,https://github.com/allenai/allennlp/commit/10ea3b36eb24f1c48fc8c6ee4f64048427ffde6d,"Add the attention visualization to the textual entailment demo (#1219)

* Fixes #1033

* changes following PR review.
1. The predictor is now responsible for tokenizing hypothesis and premise.
2. The model no longer takes the metadata parameter anymore.

* Removed some extra blank lines

* Fix spacing issues",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
716,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-16 13:49:31-07:00,3a8fdb0110464bff46625a66cd41084a8f346f76,https://github.com/allenai/allennlp/commit/3a8fdb0110464bff46625a66cd41084a8f346f76,Include tests in source distribution (#1208),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
717,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-16 14:20:19-07:00,820cbfba398a51a6c69f53a476cd2d4f1074c9c4,https://github.com/allenai/allennlp/commit/820cbfba398a51a6c69f53a476cd2d4f1074c9c4,gitignore EVALB generated files (#1214),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
718,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-16 14:51:31-07:00,356829d925da5eff058c3e89224384cd9c0bac67,https://github.com/allenai/allennlp/commit/356829d925da5eff058c3e89224384cd9c0bac67,"Add allennlp test-install command (#1213)

* Add allennlp test-install command

* Add back a newline that I accidentally removed

* Add small test for _get_project_root

* Fix typo in parens

* Remove erroneous copy/paste

* Add docs for test-install

* Remove some unused imports in commands.__init__.py

* Turn off notebook tests by default as well

* Raise informative error message if jupyter not found

* Move pytest, flaky, responses to requirements",9,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(os.path.join(project_root, ))', 'os.path.exists(os.path.join(project_root, ))', 'os.path.exists(os.path.join(project_root, ))']",[],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
719,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-16 15:43:59-07:00,d0bd42d59f1514c6d34fc17ce34088c43e272ec5,https://github.com/allenai/allennlp/commit/d0bd42d59f1514c6d34fc17ce34088c43e272ec5,edit project root test (#1227),1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(os.path.join(project_root, ,']",[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(os.path.join(project_root, ))', 'os.path.exists(os.path.join(project_root, ))']",[],[],[],[],[],[],[],[],[],[],[],[]
720,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-05-16 21:09:23-07:00,76a5a80a163c1661fcd51dd4455cb3a30d1d9855,https://github.com/allenai/allennlp/commit/76a5a80a163c1661fcd51dd4455cb3a30d1d9855,changed checklist cost computation (#1231),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
721,Gianluca,janLuke@users.noreply.github.com,2018-05-17 18:23:54+02:00,229361c6870cd5c224d122983308d737f9c9da33,https://github.com/allenai/allennlp/commit/229361c6870cd5c224d122983308d737f9c9da33,"In train_model(), load the best weights at the end so that: (#1234)

1. the best model (not the last) is evaluated on the test set if ""evaluate_on_test"";
this fixes https://github.com/allenai/allennlp/issues/1223

2. the best model (not the last) is returned by the function;
this is a more natural behaviour and incidentally solves https://github.com/allenai/allennlp/issues/1192",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
722,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-17 12:43:36-07:00,3dcde3233ae9e4e021ec0c0cbea4c1c5bc5252d6,https://github.com/allenai/allennlp/commit/3dcde3233ae9e4e021ec0c0cbea4c1c5bc5252d6,"Add custom extensions to distribution and install (#1229)

* Add custom extensions to source distribution / install

* Remove __pycache__ files and use recursive-include

* Add newline

* Alphabetical?",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
723,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-17 13:52:25-07:00,9ef013d3a8abee940dbe8e2300f79f8b48cbea42,https://github.com/allenai/allennlp/commit/9ef013d3a8abee940dbe8e2300f79f8b48cbea42,"Fix Constituency Parser / EVALB for pip-installed allennlp (#1233)

* Move EVALB from scripts to allennlp/tools

* Edit gitignore for new evalb path

* Fix EvalbBracketingScorer and test

* Edit DEFAULT_EVALB_DIR name

* Make constituency parser work under pip-install

* Remove extraneous newline

* Fix evalb compilation in dockerfile

* Remove COPY statement for evalb from dockerfile

* pushd and popd not in dockerfile

* Remove pushd and popd from evalb bracketing scorer as well

* Fix lint

* Remove ../'s in evalb dir that is returned on error

* Maintain option to not use evalb in constituency parser

* Fix import

* fix from_params",25,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
724,Michael Wayne Goodman,goodman.m.w@gmail.com,2018-05-18 10:00:18-07:00,a4f2fb8f2ed47768d70f80dcdf248f8a7d3111f0,https://github.com/allenai/allennlp/commit/a4f2fb8f2ed47768d70f80dcdf248f8a7d3111f0,"Cache remote datasets with fixed-length filenames (#1230)

* Implement a sha256 hash-based file caching method

Previously, remote dataset urls were base64-encoded to generate a
filename for a local cached version, but this caused issues when the
urls were long, as the resulting filenames grew to be greater than
the maximum filename length (255 generally, but only 143 if encryptfs
is used to encrypt a filesystem). This commit replaces the base64
encoding with a sha256 hash (which is always 64 characters; if an
ETag is used, which concatenates the url hash with the ETag hash
delimited by a ., the total is 129).

Resolves #1221",2,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['url_to_filename(baseurl + )'],"['(FileNotFoundError)', '(FileNotFoundError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],['import pytest']
725,Martin Tutek,martin.tutek@gmail.com,2018-05-18 19:40:19+02:00,4f2db42f4077942e0b012300b70807296d0a6b88,https://github.com/allenai/allennlp/commit/4f2db42f4077942e0b012300b70807296d0a6b88,"Replace slicing with chunk along the last dim (#1244)

* Replace slicing with chunk along the last dim

* Elaborate dim in docs

* Add test

* Minor docstring fixes",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['output.size() == (2, 2, 2)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
726,Vidur Joshi,vidurj@allenai.org,2018-05-18 11:55:26-07:00,d1c36de9ff7ad16fec977e895494a4cf6d881a55,https://github.com/allenai/allennlp/commit/d1c36de9ff7ad16fec977e895494a4cf6d881a55,Constituency Parser Demo Reference Update (#1248),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
727,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-05-18 15:03:35-07:00,eabb37fc95a9bc14f40155f01e0a4a4f0a8c8399,https://github.com/allenai/allennlp/commit/eabb37fc95a9bc14f40155f01e0a4a4f0a8c8399,"Output predictions in CSV format for official eval (#1249)

* output predictions in csv

* mypy fixes",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['instance.fields.keys() == {,', 'instance.fields.keys() == {,']",[],[],[],[],[],[],[],[],[],[],[],[],"['instance.fields.keys() == {}', 'instance.fields.keys() == {}']",[],[],[],[],[],[],[],[],[],[],[],[]
728,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-21 09:37:51-07:00,5ebe103d97e8c7201a2a86233998ae4fd1c24324,https://github.com/allenai/allennlp/commit/5ebe103d97e8c7201a2a86233998ae4fd1c24324,"Add missing close brace, standardize indentation in ELMo howto (#1252)

first code block was missing a `}`, and i took the opportunity to make the spacing for all of them uniform.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
729,Joel Grus,joelgrus@gmail.com,2018-05-21 10:10:13-07:00,906b26f1ece3ebfafda13db5d44d3c5c7f8f370f,https://github.com/allenai/allennlp/commit/906b26f1ece3ebfafda13db5d44d3c5c7f8f370f,"make it OK if serialization_dir exists but is empty (#1251)

* relax serialization dir check to ok if empty

* oops",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not os.path.exists(serialization_dir2)', 'not os.path.exists(serialization_dir3)']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
730,Mark Neumann,markn@allenai.org,2018-05-21 14:14:40-07:00,c2b61c600559dc38eb87800b7f723c97c6c5e451,https://github.com/allenai/allennlp/commit/c2b61c600559dc38eb87800b7f723c97c6c5e451,make evalb use unique temporary directories per process (#1254),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
731,Michael Schmitz,michael@schmitztech.com,2018-05-22 11:30:51-07:00,622ea1bf59ff7832189af894ada359913586641e,https://github.com/allenai/allennlp/commit/622ea1bf59ff7832189af894ada359913586641e,"Tutorial cleanup (#1260)

* Amend installation instructions.

* Update allennlp usage.

* Small improvements.",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
732,Michael Schmitz,michael@schmitztech.com,2018-05-22 15:44:39-07:00,7b9d6a25b93ad95fae675a9403d939330524df51,https://github.com/allenai/allennlp/commit/7b9d6a25b93ad95fae675a9403d939330524df51,"Consolidate installation instructions (#1261)

* Remove installation tutorial as it's inaccurate.

* Update README.md",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
733,Michael Schmitz,michael@schmitztech.com,2018-05-22 16:35:02-07:00,ed3697c35cf6f39418f5cf80d41293d21922ce1d,https://github.com/allenai/allennlp/commit/ed3697c35cf6f39418f5cf80d41293d21922ce1d,"Remove most mentions of python -m allennlp.run (#1264)

* Remove most mentions of python -m allennlp.run

* Print 'allennlp' as program in run.",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
734,Mark Neumann,markn@allenai.org,2018-05-23 15:38:23-07:00,40691d3f2017d3ca78dcf2d9235024e80a3e7b9c,https://github.com/allenai/allennlp/commit/40691d3f2017d3ca78dcf2d9235024e80a3e7b9c,"Fix LR scheduler and test usage inside Trainer (#1255)

Fixes #1226",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
735,murphp15,murphp15@tcd.ie,2018-05-24 16:33:36+01:00,6b5b01729ef506c499d7b09f96225eb75a48c161,https://github.com/allenai/allennlp/commit/6b5b01729ef506c499d7b09f96225eb75a48c161,"`allennlp train` should fail faster if trainer.cuda_device >= 0 (#1196)

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185

* `allennlp train` should fail faster if trainer.cuda_device >= 0 but no GPU is available #1185",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
736,Voja K,biginbox@zoho.com,2018-05-24 08:54:01-07:00,b4c9fe4143cc0ec1bafb0b58fc63a9e3c5655bd1,https://github.com/allenai/allennlp/commit/b4c9fe4143cc0ec1bafb0b58fc63a9e3c5655bd1,"Migrate gevent's wsgi to pywsgi (#1272)

Since gevent 1.0a1 was released in 2011, wsgi is just an alias for pywsgi.
In version 1.3 wsgi is completely removed, causing allennlp to break.
For more info check  http://www.gevent.org/api/gevent.wsgi.html

Test plan:
run scripts/verify.py on trunk, all test pass.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
737,Matt Gardner,mattg@allenai.org,2018-05-24 13:35:49-07:00,1c8b1492920de9451730d6cd8e8945ad04740117,https://github.com/allenai/allennlp/commit/1c8b1492920de9451730d6cd8e8945ad04740117,Fix crash when validation metric is 0 (#1274),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
738,Michael Schmitz,michael@schmitztech.com,2018-05-24 09:58:17-07:00,66da4eedb0a1a830d6a47cc8c2054b9876780daf,https://github.com/allenai/allennlp/commit/66da4eedb0a1a830d6a47cc8c2054b9876780daf,Update version numbers referred to in tutorials.,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
739,Michael Schmitz,michael@schmitztech.com,2018-05-24 09:58:24-07:00,d711e405cd4de55873718751e7c7192b5be20a16,https://github.com/allenai/allennlp/commit/d711e405cd4de55873718751e7c7192b5be20a16,Bump version number to v0.4.3,3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
740,Maksym Del,max.del.edu@gmail.com,2018-05-25 00:50:26+03:00,3c623c56419821060fb26ab198db1ab5c82e114c,https://github.com/allenai/allennlp/commit/3c623c56419821060fb26ab198db1ab5c82e114c,"Fix links to the allennlp-as-a-library tutorials (#1279)

* Fix links to the allennlp-as-a-library tutorials

* Update README.md",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
741,Michael Schmitz,michael@schmitztech.com,2018-05-24 19:39:03-07:00,7e1080e44a65650610f7194cca2d49b135c9ca60,https://github.com/allenai/allennlp/commit/7e1080e44a65650610f7194cca2d49b135c9ca60,Uptick version to unreleased. (#1281),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
742,Michael Schmitz,michael@schmitztech.com,2018-05-25 08:13:34-07:00,20da3fdce7be81d576f324c0e087e22dc8566fcd,https://github.com/allenai/allennlp/commit/20da3fdce7be81d576f324c0e087e22dc8566fcd,Set long_description_content_type to markdown in setup.py. (#1284),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
743,Michael Schmitz,michael@schmitztech.com,2018-05-25 08:22:44-07:00,5c06914bc6bd622ce51e1bfb3ea119b3b7040dde,https://github.com/allenai/allennlp/commit/5c06914bc6bd622ce51e1bfb3ea119b3b7040dde,Use full version in docs. (#1283),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
744,Michael Schmitz,michael@schmitztech.com,2018-05-25 09:24:41-07:00,1f8125c32560d7db4a1dc77238772b6618443bb4,https://github.com/allenai/allennlp/commit/1f8125c32560d7db4a1dc77238772b6618443bb4,Update the version of twine. (#1285),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
745,Michael Schmitz,michael@schmitztech.com,2018-05-25 12:24:34-07:00,c0afe31bed463657239a0ec69c7a7ad87c399056,https://github.com/allenai/allennlp/commit/c0afe31bed463657239a0ec69c7a7ad87c399056,"Insteall psycopg2-binary (#1286)

This is in response to the following message when running `allennlp`:

```
/Users/michaels/miniconda3/envs/cleaner/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use ""pip install psycopg2-binary"" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
```",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
746,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-25 14:04:35-07:00,59a0e5a86b6294c2b0d6d9e1e32c10bccacfa883,https://github.com/allenai/allennlp/commit/59a0e5a86b6294c2b0d6d9e1e32c10bccacfa883,"Fix test-install by moving tests into module (#1232)

fixes https://github.com/allenai/allennlp/issues/1228

Goals of this PR:
1. [x] 1. Prevent tests from being installed as a module in `python setup.py` . Currently, pip copies them to `site-packages`, which is definitely not intended behavior.

2. [x] 2. installation method-invariant way to load and run tests, especially those that depend on files outside of the module (e.g. `scripts` or `tutorials`). The issue is that files can be in different places depending on if allennlp is installed with `pip` or `setup.py install`. This is done by moving the tests within the module and using os.chdir to make the paths in the fixtures properly resolve.",315,False,True,True,False,True,True,True,True,False,False,False,False,False,False,False,[],0,0,3,0,1,0,0,0,0,0,0,7,0,1,0,1,0,0,0,0,0,0,15,0,0,0,0,0,0,0,0,0,0,0,1,15,0,0,0,0,0,0,0,0,0,0,0,1,[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],['def tearDown(self):'],[],[],[],[],[],[],"['class TestBidafPredictor(TestCase):', 'class TestConstituencyParserPredictor(TestCase):', 'class TestCorefPredictor(TestCase):', 'class TestDecomposableAttentionPredictor(TestCase):', 'class TestSimpleSeq2SeqPredictor(TestCase):', 'class TestSrlPredictor(TestCase):', 'class TestWikiTablesParserPredictor(TestCase):']",[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],"['os.path.exists(self.output_path)', 'os.path.exists(self.output_path)', 'os.path.exists(self.output_path)', 'os.path.exists(self.output_path)', 'os.path.exists(self.output_path)', 'os.path.exists(self.output_path)', 'os.path.exists(self.outfile)', 'os.path.exists(self.outfile)', 'os.path.exists(self.outfile)', 'os.path.exists(self.outfile)', 'os.path.exists(self.outfile)', 'os.path.exists(os.path.join(project_root, ))', 'os.path.exists(os.path.join(project_root, ))', 'cached_path(self.glove_file) == str(self.glove_file)', 'params.get()']",[],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['os.path.exists(output_path)', 'os.path.exists(output_path)', 'os.path.exists(output_path)', 'os.path.exists(output_path)', 'os.path.exists(output_path)', 'os.path.exists(output_path)', 'os.path.exists(outfile)', 'os.path.exists(outfile)', 'os.path.exists(outfile)', 'os.path.exists(outfile)', 'os.path.exists(outfile)', 'cached_path(self.glove_file) == self.glove_file', 'params.get(', 'os.path.exists(os.path.join(project_root, ))', 'os.path.exists(os.path.join(project_root, ,']",[],[],[],[],[],[],[],[],[],[],[],['import pytest']
747,Mark Neumann,markn@allenai.org,2018-05-25 16:05:11-07:00,c26a51387fc758a62bd08c1e0f6e077f04f73d0c,https://github.com/allenai/allennlp/commit/c26a51387fc758a62bd08c1e0f6e077f04f73d0c,Noam lr schedule (#1258),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
748,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-26 09:49:28-07:00,9cb0ea3e012ba5954536818dabfb3d4b60e61896,https://github.com/allenai/allennlp/commit/9cb0ea3e012ba5954536818dabfb3d4b60e61896,Add LICENSE to source distribution (#1291),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
749,Gianluca,janLuke@users.noreply.github.com,2018-05-27 19:59:33+02:00,69b9af322ad62403e509d3d28dfb708afab0fd44,https://github.com/allenai/allennlp/commit/69b9af322ad62403e509d3d28dfb708afab0fd44,"In Trainer, require ""patience"" to be a positive integer or None (meaning ""no early stopping""). Set patience=None by default. (#1271)

* In Trainer, raise ValueError if patience==0, disable early stopping if
patience < 0 or patience == None.

* In Trainer, default patience to None and require patience > 0.

* Pylint",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not trainer._should_stop_early(decreasing_history)  # pylint: disable=protected-access', 'not trainer._should_stop_early(increasing_history)  # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
750,murphp15,murphp15@tcd.ie,2018-05-27 19:28:42+01:00,986cf17d8bc4747309bfba1a7aaf2b018770da5f,https://github.com/allenai/allennlp/commit/986cf17d8bc4747309bfba1a7aaf2b018770da5f,"Improve performance of attention modules (#1235)

* Related to #768
This is an initial POC for getting feedback before proceeding with the entire refactor.
In this PR
1. I added implementations of MatrixAttention. The there is one for dot product, one for cosine product, etc.
2. There is an implementation of MatrixAttention called LegacyMatrixAttention used to support backwards compatibility and use already trained models.
3. There is a class called AttentionMatrixFactory which can be used to create an instance of MatrixAttention. it will determine whether to use the legacy impl or the newer impl based on the name.

* changes following review.

* changes following review.

* changes following review.

* changes following review.

* changes following review.

* changes following review.

* changes following review.

* changes following review.

* changes following review.

* changes following review.

* changes following review.

* add test

* add linear attention module to get feedback on it.

* split tests into separate files.

* add linear tests.

* adding linear and dot product attention.

* adding linear and dot product attention.

* adding linear and dot product attention.

* adding linear and dot product attention.

add cosine attention.
fix typing issue.
add doc

* changes following PR.
1. Changing documentation layout
2. Moving files
3. cleanup

* changes following PR.
1. Changing documentation layout
2. Moving files
3. cleanup

* changes following PR.
1. Changing documentation layout
2. Moving files
3. cleanup

* included in this commit:
1. remove incorrect comment
2. import baseclass into init files in same package and also in parent package.

* Update matrix_attention.py

* Moved tests after merging master

* Pylint (is wasn't run previously due to no __init__.py)",32,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
751,Matt Gardner,mattg@allenai.org,2018-05-27 11:53:50-07:00,b26031db4f27d606146f7d5820b1e884559bd4d4,https://github.com/allenai/allennlp/commit/b26031db4f27d606146f7d5820b1e884559bd4d4,Ignore tests in coverage metrics (#1293),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
752,Joel Grus,joelgrus@gmail.com,2018-05-29 11:51:52-07:00,ed63b7ee9e68ba120893aaaaca0d4525a56ed484,https://github.com/allenai/allennlp/commit/ed63b7ee9e68ba120893aaaaca0d4525a56ed484,"upgrade to pytorch 0.4.0 (#1126)

* bump pytorch to 0.4 + fix sanitize

* remove check for Variable in block_orthogonal

* rename parameter split_size=

* remove checks for Variable

* fix more tests

* fixes

* get tests to pass

* fix warnings

* get rid of some of the Variables

* more tests passing

* more elimination of variables

* finish removing all Variables

* pylint and such

* a few fixes

* move torch.no_grad into model.forward_on_instances

* more pytorch 0.4 changes

* detach() -> data

* pylint

* fix bad tensor creation

* fix types

* remove print statement

* more 0.4 goodness

* factor out is_tensor

* add no_grad to elmo command

* cleanup

* remove TODO

* address PR feedback

* replace all() with item()

* more cleanup

* further cleanup

* remove Variable

* really fix merge conflict

* fix pylint",140,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,[],"[('AlmostEqual', '(grad._values().norm(2.0).item(), 1.5, places=5) # pylint: disable=protected-access')]",[],[],[],[],[],[],[],[],[],[],"[('AlmostEqual', '(grad._values().norm(2.0), 1.5, places=5) # pylint: disable=protected-access')]",[],[],[],[],[],[],[],[],[],"['manual_log_likelihood.item() == approx(log_likelihood)', 'manual_log_likelihood.item() == approx(log_likelihood)']",[],[],[],[],[],[],[],[],[],[],[],[],"['manual_log_likelihood == approx(log_likelihood)', 'manual_log_likelihood == approx(log_likelihood)']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[]
753,murphp15,murphp15@tcd.ie,2018-05-29 22:29:06+01:00,200b27e4a1f8545d648286a3fca3554b6a8f85c1,https://github.com/allenai/allennlp/commit/200b27e4a1f8545d648286a3fca3554b6a8f85c1,"A new model is only considered the best if it is better than others and not simply better or equal (#1246)

* Check that a model is actually an improvement on the current best and not just equal to it.

fixes : #1237

* add test

* add test

* changes following PR.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['new_trainer._is_best_so_far(1, [])  # pylint: disable=protected-access', 'not new_trainer._is_best_so_far(.3, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'new_trainer._is_best_so_far(13.00, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'not new_trainer._is_best_so_far(.0013, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'new_trainer._is_best_so_far(1, [])  # pylint: disable=protected-access', 'not new_trainer._is_best_so_far(.3, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'new_trainer._is_best_so_far(.013, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'not new_trainer._is_best_so_far(13.00, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'Trainer(self.model, self.optimizer,  # pylint: disable=protected-access', 'Trainer(self.model, self.optimizer,  # pylint: disable=protected-access', 'new_trainer._should_stop_early([.1, .3, .2, .1, .4, .5])  # pylint: disable=protected-access', 'restore_trainer._batch_num_total == 2  # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[],['restore_trainer._batch_num_total == 2 # pylint: disable=protected-access'],[],[],[],[],[],[],[],[],[],[],[],[]
754,Joel Grus,joelgrus@gmail.com,2018-05-29 14:53:34-07:00,504964b58bdfe9cef3f9be321d268dcbc5d8d043,https://github.com/allenai/allennlp/commit/504964b58bdfe9cef3f9be321d268dcbc5d8d043,allow sanitize to work on custom classes (#1307),2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['util.sanitize(Sanitizable()) == {: True}'],['(ValueError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
755,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-05-29 15:26:39-07:00,48495898f48475c5b296635ec04989f1555792eb,https://github.com/allenai/allennlp/commit/48495898f48475c5b296635ec04989f1555792eb,"Script for generating logical forms from ERM model for wikitables (#1247)

* data generation script and bug fix in lf percent metric

* minor bug fixes

* add logical forms to output only if no error

* addressed pr comments",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
756,Mark Neumann,markn@allenai.org,2018-05-29 15:50:45-07:00,5352a198e1831e63c76ee8e51694c1bf6b63b1b1,https://github.com/allenai/allennlp/commit/5352a198e1831e63c76ee8e51694c1bf6b63b1b1,make predictors more discoverable (#1302),42,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
757,Mark Neumann,markn@allenai.org,2018-05-30 11:07:51-07:00,26e7f411edb94cfcd7f4adb87d757051b83e1c38,https://github.com/allenai/allennlp/commit/26e7f411edb94cfcd7f4adb87d757051b83e1c38,"add user contributed models blurb (#1306)

![image](https://user-images.githubusercontent.com/16001974/40686402-0eca1dd4-634c-11e8-853b-9c8a1c0f5c3c.png)",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
758,Evan Pete Walsh,epwalsh10@gmail.com,2018-05-30 17:16:32-05:00,097ccd7c2642ba554d140c7c37377bd63fd2b096,https://github.com/allenai/allennlp/commit/097ccd7c2642ba554d140c7c37377bd63fd2b096,"Update torch and tensorboard versions in setup.py (#1311)

The torch and tensorboard versions in `setup.py` referenced older versions that were not consistent with `requirements.txt`. This mixup led to several `pip` warnings after installing from source:

```
allennlp 0.4.4-unreleased has requirement tensorboardX==1.0, but you'll have tensorboardx 1.2 which is incompatible.
allennlp 0.4.4-unreleased has requirement torch==0.3.1, but you'll have torch 0.4.0 which is incompatible.
```",1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
759,Nelson Liu,nelson-liu@users.noreply.github.com,2018-05-30 15:40:39-07:00,0db4bc544808216a6ff7a948d5888200cab54763,https://github.com/allenai/allennlp/commit/0db4bc544808216a6ff7a948d5888200cab54763,"Add ELMo to BCN (#1308)

* Add ELMo to BCN

* Fix paths

* Move fixtures to proper place

* Change dir so model is properly created with fixture paths

* Edit usage comment in training config

* Fix lint",8,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
760,Michael Schmitz,michael@schmitztech.com,2018-05-30 18:01:09-07:00,e37a68edc1c9187c9d2ea2657a63f8d9e7644d3a,https://github.com/allenai/allennlp/commit/e37a68edc1c9187c9d2ea2657a63f8d9e7644d3a,"Add ""Citing"" section to README.md (#1305)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
761,Mark Neumann,markn@allenai.org,2018-05-31 10:28:46-07:00,cebf719c4645bd6660e14a499c48e23fbe272e1c,https://github.com/allenai/allennlp/commit/cebf719c4645bd6660e14a499c48e23fbe272e1c,"SRL elmo 5b (#1310)

New SRL model using ELMo - this moves our F1 from 78.9(boo) to 84.97 (84.93 on test).

I used a bit of a hacky repackaging method here so that we can distribute it - it basically involves loading in the GPU specific model, copying the config and weights into a new model which doesn't have the GPU only LSTM implementation.

Full results below for posterity:

```
              corr.  excess  missed    prec.    rec.      F1
------------------------------------------------------------
   Overall    70191   12778   12062    84.60   85.34   84.97
----------
      ARG0    16309    1586    1327    91.14   92.48   91.80
      ARG1    25106    3566    3123    87.56   88.94   88.24
      ARG2     7735    1642    1795    82.49   81.16   81.82
      ARG3      402     186     274    68.37   59.47   63.61
      ARG4      446     121     137    78.66   76.50   77.57
      ARG5        7       4       9    63.64   43.75   51.85
      ARGA        0       0       4     0.00    0.00    0.00
  ARGM-ADJ      162     131      92    55.29   63.78   59.23
  ARGM-ADV     2085    1135    1083    64.75   65.81   65.28
  ARGM-CAU      401     145     151    73.44   72.64   73.04
  ARGM-COM       19      27      15    41.30   55.88   47.50
  ARGM-DIR      316     217     233    59.29   57.56   58.41
  ARGM-DIS     2445     580     555    80.83   81.50   81.16
  ARGM-DSP        0       0       2     0.00    0.00    0.00
  ARGM-EXT      126     120     147    51.22   46.15   48.55
  ARGM-GOL       16      49      81    24.62   16.49   19.75
  ARGM-LOC     1572     718     605    68.65   72.21   70.38
  ARGM-LVB       47      10       8    82.46   85.45   83.93
  ARGM-MNR     1389     608     604    69.55   69.69   69.62
  ARGM-MOD     2776      72      48    97.47   98.30   97.88
  ARGM-NEG     1501      83      60    94.76   96.16   95.45
  ARGM-PNC       23      79      90    22.55   20.35   21.40
  ARGM-PRD       72     176     344    29.03   17.31   21.69
  ARGM-PRP      336     244     192    57.93   63.64   60.65
  ARGM-REC        4       2       9    66.67   30.77   42.11
  ARGM-TMP     5186    1011     814    83.69   86.43   85.04
    R-ARG0      917      80      85    91.98   91.52   91.75
    R-ARG1      632      99      82    86.46   88.52   87.47
    R-ARG2       34      16      23    68.00   59.65   63.55
    R-ARG3        0       0       7     0.00    0.00    0.00
    R-ARG4        1       0       1   100.00   50.00   66.67
R-ARGM-ADV        0       1       3     0.00    0.00    0.00
R-ARGM-CAU        1       3       1    25.00   50.00   33.33
R-ARGM-COM        0       1       0     0.00    0.00    0.00
R-ARGM-DIR        0       0       1     0.00    0.00    0.00
R-ARGM-EXT        0       0       2     0.00    0.00    0.00
R-ARGM-LOC       68      42      21    61.82   76.40   68.34
R-ARGM-MNR        9       3       5    75.00   64.29   69.23
R-ARGM-PRP        0       0       1     0.00    0.00    0.00
R-ARGM-TMP       48      21      28    69.57   63.16   66.21
------------------------------------------------------------
         V    34783       0       0   100.00  100.00  100.00
------------------------------------------------------------
```",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
762,Joel Grus,joelgrus@gmail.com,2018-05-31 11:36:46-07:00,50fcb0cefc70d970de664206cb6e342d486b0600,https://github.com/allenai/allennlp/commit/50fcb0cefc70d970de664206cb6e342d486b0600,"how to for debugging using pycharm (#1312)

* add debugging how to

* clean up

* add line to delete serialization directory

* include code as code not as png

* add VSCode section

* formatting

* pr feedback

* allow allennlp command",13,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
763,Michael Schmitz,michael@schmitztech.com,2018-05-31 14:12:46-07:00,62f701e0ea88fcafdcc79f84b3f72ade43622116,https://github.com/allenai/allennlp/commit/62f701e0ea88fcafdcc79f84b3f72ade43622116,Remove default arguments from the simple server. (#1319),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
764,Evan Pete Walsh,epwalsh10@gmail.com,2018-05-31 16:55:09-05:00,245698302b6b300cc7ee2179759ee16f8e921641,https://github.com/allenai/allennlp/commit/245698302b6b300cc7ee2179759ee16f8e921641,"Add option to keep Viterbi scores when predicting (#1314)

* fix torch version

* fix tensorboard version

* add keep_scores option

* remove extra space

* change to always return scores

* rename to avoid type conflict",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['viterbi_scores == best_scores'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
765,Michael Schmitz,michael@schmitztech.com,2018-05-31 15:09:11-07:00,427a319e3048da1eb9d2ff92cec85fa7f07bf581,https://github.com/allenai/allennlp/commit/427a319e3048da1eb9d2ff92cec85fa7f07bf581,Add version to AllenNLP command. (#1322),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
766,Michael Schmitz,michael@schmitztech.com,2018-05-31 15:26:08-07:00,8eb358b415ec1aea3b321f3e903b99d5911ce384,https://github.com/allenai/allennlp/commit/8eb358b415ec1aea3b321f3e903b99d5911ce384,Convert run_with_beaker.py to use Blueprints. (#1199),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
767,Michael Schmitz,michael@schmitztech.com,2018-05-31 16:04:57-07:00,765dc2078d8e924bcde7fca75627fe94f8c34d65,https://github.com/allenai/allennlp/commit/765dc2078d8e924bcde7fca75627fe94f8c34d65,Add logging for the original path in load_archive. (#1323),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
768,Joel Grus,joelgrus@gmail.com,2018-05-31 17:15:31-07:00,b0d0d942197d9959eeb9bec6018d0db25b5772d4,https://github.com/allenai/allennlp/commit/b0d0d942197d9959eeb9bec6018d0db25b5772d4,"LabelField.as_tensor returns 0-tensor (#1320)

* LabelField.as_tensor returns 0-tensor

* add ignore for spurious pylint warning

* remove unused numpy import",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tensor.item() == 5', 'tensor.item() == 0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
769,Joel Grus,joelgrus@gmail.com,2018-05-31 17:54:58-07:00,03d6fadbc4fcb61caa5980ab61d1ca673fc0922b,https://github.com/allenai/allennlp/commit/03d6fadbc4fcb61caa5980ab61d1ca673fc0922b,"command-line configuration explorer (#1309)

* config explorer

* wip

* wip

* progress

* work

* config tool

* configuration

* configuration command line tool

* add test for configure command

* fix test collisions

* fix docs

* scope suppress FutureWarning to only h5py imports

* fix import ordering

* fix docs

* fix docs (again)",17,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in output', 'config == BASE_CONFIG', 'isinstance(config, list)', 'in config', 'isinstance(config, Config)', 'len(items) == 3', 'in items', 'token_indexers.default_value is None', 'in items', 'domain_identifier.annotation == str', 'domain_identifier.default_value is None', 'in items', 'lazy.annotation == bool', 'not lazy.default_value']","['(ModuleNotFoundError)', '(AttributeError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
770,Max Friedrich,hallo@maxfriedrich.de,2018-06-04 16:42:27+02:00,4326b59b18c5f3f1eb29b1b3dfe330660d292d39,https://github.com/allenai/allennlp/commit/4326b59b18c5f3f1eb29b1b3dfe330660d292d39,Fix link to installation instructions (#1335),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
771,Max Friedrich,hallo@maxfriedrich.de,2018-06-04 17:42:32+02:00,b6b8955de74b02fbdd67ebe1444cdf86acaf30fd,https://github.com/allenai/allennlp/commit/b6b8955de74b02fbdd67ebe1444cdf86acaf30fd,Fix link to demo.allennlp.org page (#1336),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
772,Joel Grus,joelgrus@gmail.com,2018-06-04 10:26:21-07:00,0c2d5c77f3ee7a48693af822fa74b2dfe3eaa184,https://github.com/allenai/allennlp/commit/0c2d5c77f3ee7a48693af822fa74b2dfe3eaa184,"config explorer webapp (#1329)

* config explorer

* wip

* wip

* progress

* work

* config tool

* configuration

* configuration command line tool

* add test for configure command

* fix test collisions

* fix docs

* scope suppress FutureWarning to only h5py imports

* fix import ordering

* fix docs

* fix docs (again)

* add web based config explorer

* add test for include-packages

* rename new package to avoid collision with other tests

* fix config explorer on initializers and regularizers (via some nasty hacks)

* fix test for _init_function now being a class method

* fix some tests

* revert some initializer changes

* reorder

* fix pylint issues

* fix mypy",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'not in html', 'in html', 'in html']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
773,Liyuan Liu,llychinalz@gmail.com,2018-06-05 13:11:06-07:00,6c87ff59c478c47ba03d4ac0ea693ac7b0fd80b6,https://github.com/allenai/allennlp/commit/6c87ff59c478c47ba03d4ac0ea693ac7b0fd80b6,"Make vocab (#1339)

* fix bug: complete comments for make-vocab; allso make-vocab to take other vocabulary options

* fix bug for config pop

* add test case for make vocab, hvnt tried though

* debugged the test case...

* add test case without modifying previous ones; debugged

* add default value to be None

* add missing final newline",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(vocab_files) == {}', 'tokens == []', 'labels == []']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
774,Maxwell Forbes,mbforbes@users.noreply.github.com,2018-06-06 13:01:41-07:00,f6d9ba318a643e42bae597fd2b71d336aa290a1f,https://github.com/allenai/allennlp/commit/f6d9ba318a643e42bae597fd2b71d336aa290a1f,Remove what appears to be outdated line (#1348),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
775,Matt Gardner,mattg@allenai.org,2018-06-07 11:09:44-07:00,6aaeb70670d4540900e55f4ac532546656447bd2,https://github.com/allenai/allennlp/commit/6aaeb70670d4540900e55f4ac532546656447bd2,"Add bilinear attention (#1349)

* Add bilinear attention, some code cleanup, make semantic parsers use new attention

* Fix pylint and docs

* Increase beam size for wikitables ERM parser, so test doesn't fail",46,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['result.shape == (1, 2)', 'result.shape == (1, 2, 2)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
776,Matt Gardner,mattg@allenai.org,2018-06-07 11:37:49-07:00,b556e5339fc8ea2e3005725af479b28967d41e24,https://github.com/allenai/allennlp/commit/b556e5339fc8ea2e3005725af479b28967d41e24,Format pytest logging correctly (#1351),2,False,True,True,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
777,Matt Gardner,mattg@allenai.org,2018-06-07 14:03:10-07:00,2cddc69336e0955eab58a17fa65b0fd1c849b0e8,https://github.com/allenai/allennlp/commit/2cddc69336e0955eab58a17fa65b0fd1c849b0e8,"Add ability to add tokens to vocabulary namespaces (#1352)

* Add ability to add tokens to vocabulary namespaces

* Add a test

* Updated the docstring",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab.get_index_to_token_vocabulary(,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
778,Matt Gardner,mattg@allenai.org,2018-06-08 09:05:37-07:00,ca4d26234b3777e7dc54218ad6ff6687be464bcc,https://github.com/allenai/allennlp/commit/ca4d26234b3777e7dc54218ad6ff6687be464bcc,Remove norm from question / table similarity computation (#1354),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
779,Mark Neumann,markn@allenai.org,2018-06-08 12:48:24-07:00,97484fb8a1d2389fd12485f166bc7ca4f6438548,https://github.com/allenai/allennlp/commit/97484fb8a1d2389fd12485f166bc7ca4f6438548,"Faster Elmo (#1347)

* make it feasible for elmo to use single id indexers

* working version, much better than before

* add test

* wow that was hard to find, remove padding symbols when caching words

* support higher dim input for single_id_indexers

* pylint etc

* thread caching through the token embedder

* some PR comments

* refactor to pass both character and word ids

* modify textfield embedder to take an optional embedder -> indexer map

* add initial definitions of bos eos

* add comment about type",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
780,Michael Schmitz,michael@schmitztech.com,2018-06-11 08:11:59-07:00,a08e7fdf30e38c29612a99c5d72595797c7e018f,https://github.com/allenai/allennlp/commit/a08e7fdf30e38c29612a99c5d72595797c7e018f,"Move serve functionality out of allennlp command. (#1317)

* Move serve functionality out of allennlp command.

The `allennlp` command currently requires dependencies that few of our
users will use and that increase the time it takes to run `allennlp`.
Furthermore, the serve command does not work from pip installs, which is
the main way our users install AllenNLP.

* Add pylint spaces.

* Remove serve from docs.

* Add DemoModel import to preserve compatibility.",13,False,True,False,False,True,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],['class TestServe(TestCase):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.func.__name__ == ', 'args.port == 8000']",[],[],[],[],[],[],[],[],[],[],[],[]
781,Michael Schmitz,michael@schmitztech.com,2018-06-11 15:27:16-07:00,ac2e0b9b6e4668984ebd8c05578d9f4894e94bee,https://github.com/allenai/allennlp/commit/ac2e0b9b6e4668984ebd8c05578d9f4894e94bee,"Make optional args actually optional. (#1357)

* Make optional args actually optional.

* Set default gpu count to 1.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
782,Nelson Liu,nelson-liu@users.noreply.github.com,2018-06-12 11:04:32-07:00,6739c314263669dc656deabd81f89cf399b3b7a0,https://github.com/allenai/allennlp/commit/6739c314263669dc656deabd81f89cf399b3b7a0,Make test_trainer_respects_keep_serialized_model_every_num_seconds more patient (#1358),1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
783,Joel Grus,joelgrus@gmail.com,2018-06-12 15:01:13-07:00,d844a9ac592f4396e4f0b991d5891b5dd6c32964,https://github.com/allenai/allennlp/commit/d844a9ac592f4396e4f0b991d5891b5dd6c32964,"fancy version of the configuration wizard (#1344)

* initial version

* progress

* more features

* progress

* clean up

* add docstring

* provide type annotations for Dicts and Lists

* rewrite

* rewrite the whole thing

* fix bugs

* fix tests + final touches

* add tutorial

* fix broken link

* fix typo",11,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['html.strip() == _HTML.strip()', 'in html', 'data[', 'items[0] == {', ']', 'config[', 'items[0][', 'config[', 'any(item[ for item in items)', 'config[', 'any(item[ for item in items)', ']', ']', 'config[', 'any(item[ for item in items)', ']', 'config[', 'any(item[ for item in items)', ']', ']', ']', ']']",[],[],[],[],[],[],[],[],[],[],[],[],"['in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'in html', 'not in html', 'in html', 'in html']",[],[],[],[],[],[],[],[],[],[],[],[]
784,Joel Grus,joelgrus@gmail.com,2018-06-12 19:26:08-07:00,691af4e45e9cd69a6cd1c9f73240af059552c59d,https://github.com/allenai/allennlp/commit/691af4e45e9cd69a6cd1c9f73240af059552c59d,"address PR comments (#1362)

this commit was supposed to be in the last PR, but my push got rejected and I didn't notice and merged without it, so I'm just force merging it now",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
785,Joel Grus,joelgrus@gmail.com,2018-06-13 10:18:17-07:00,e17cbd18f6d9bc4bf7d033048f98105c5d963861,https://github.com/allenai/allennlp/commit/e17cbd18f6d9bc4bf7d033048f98105c5d963861,fix bug (#1363),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
786,Joel Grus,joelgrus@gmail.com,2018-06-13 10:33:18-07:00,712832424d1d8cab59d98ed3c2a5d30ca465a927,https://github.com/allenai/allennlp/commit/712832424d1d8cab59d98ed3c2a5d30ca465a927,bump version number to v0.5.0,5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
787,Joel Grus,joelgrus@gmail.com,2018-06-13 10:45:24-07:00,29752f6f1b47520cf2bf88007e53ebe57163b418,https://github.com/allenai/allennlp/commit/29752f6f1b47520cf2bf88007e53ebe57163b418,bump version numbers to v0.5.1-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
788,Mark Neumann,markn@allenai.org,2018-06-13 16:25:54-07:00,a1247b681f88b7fb8c43114a94353d50867bad4a,https://github.com/allenai/allennlp/commit/a1247b681f88b7fb8c43114a94353d50867bad4a,"UD dataset reader (#1370)

* add conllu lib to requirements

* rough reader sketch

* working dependency parsing reader

* added test

* cleanup

* add doc, fix imports

* fix up style",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[,', 'fields[]', 'fields[]', 'fields[].labels == [0, 4, 4, 1, 6, 4, 4]', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 4, 4, 1, 15, 15, 9, 9, 15, 9, 13, 13,', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [4, 4, 4, 0, 6, 4, 6, 6, 4]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
789,Joel Grus,joelgrus@gmail.com,2018-06-13 16:53:55-07:00,59020bb2cd882896b3f5a3f4cfd32be86746d965,https://github.com/allenai/allennlp/commit/59020bb2cd882896b3f5a3f4cfd32be86746d965,add numpydocs to requirements (#1372),3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
790,Joel Grus,joelgrus@gmail.com,2018-06-13 16:56:32-07:00,6b55193fcb932f86f30b09a560e0a33143fd7e80,https://github.com/allenai/allennlp/commit/6b55193fcb932f86f30b09a560e0a33143fd7e80,bump version number to v0.5.1,5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
791,Joel Grus,joelgrus@gmail.com,2018-06-13 17:11:11-07:00,4f55c03d7bf2846a07c7eedc59e04f43e5734b2d,https://github.com/allenai/allennlp/commit/4f55c03d7bf2846a07c7eedc59e04f43e5734b2d,bump version numbers to v0.5.2-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
792,Joel Grus,joelgrus@gmail.com,2018-06-13 17:14:34-07:00,70c33ee353b68c44e7fed94ac7283f6d567ee77c,https://github.com/allenai/allennlp/commit/70c33ee353b68c44e7fed94ac7283f6d567ee77c,"Release v0.5.1 (#1373)

* bump version number to v0.5.1

* bump version numbers to v0.5.2-unreleased",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
793,Joel Grus,joelgrus@gmail.com,2018-06-13 17:16:53-07:00,e1a725bf30ecd88812b53c4448f8ce95d194b344,https://github.com/allenai/allennlp/commit/e1a725bf30ecd88812b53c4448f8ce95d194b344,"Revert ""Release v0.5.1 (#1373)"" (#1374)

This reverts commit 70c33ee353b68c44e7fed94ac7283f6d567ee77c.",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
794,Joel Grus,joelgrus@gmail.com,2018-06-13 17:19:08-07:00,220773d3b7ed7a91681f5f0407033722b1aac626,https://github.com/allenai/allennlp/commit/220773d3b7ed7a91681f5f0407033722b1aac626,"Release v0.5.1 (#1375)

* bump version number to v0.5.1

* bump version numbers to v0.5.2-unreleased",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
795,Joel Grus,joelgrus@gmail.com,2018-06-14 12:03:02-07:00,a8072394cb8838408717f2f49b116dc7ac307e1a,https://github.com/allenai/allennlp/commit/a8072394cb8838408717f2f49b116dc7ac307e1a,"create ccgbank dataset reader (#1381)

* add dataset reader

* add ccgbank reader

* update class documentation",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'tokens == [,', 'ccg_categories == [,', 'original_pos_tags == [,', 'modified_pos_tags == [,', 'predicate_arg_categories == [,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
796,Joel Grus,joelgrus@gmail.com,2018-06-14 12:21:25-07:00,a1dc458f3a4da7a0aba4ce90ca4e591731b4515d,https://github.com/allenai/allennlp/commit/a1dc458f3a4da7a0aba4ce90ca4e591731b4515d,Update issue templates,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
797,Joel Grus,joelgrus@gmail.com,2018-06-14 12:23:10-07:00,2893460f250160c7ee13935500f5288077ae2dac,https://github.com/allenai/allennlp/commit/2893460f250160c7ee13935500f5288077ae2dac,Update issue templates,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
798,Joel Grus,joelgrus@gmail.com,2018-06-14 12:23:48-07:00,60e95d829d559e77491c53b0f7c5340358a652c3,https://github.com/allenai/allennlp/commit/60e95d829d559e77491c53b0f7c5340358a652c3,Update issue templates,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
799,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-06-15 13:52:54-07:00,f4d8d0730b826b221398d8d32c91e233b2b25e76,https://github.com/allenai/allennlp/commit/f4d8d0730b826b221398d8d32c91e233b2b25e76,"Output answers in wikitables predictor when inputs are batched (#1384)

* override predict_batch_json

* added a test for batch predict",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['answer is not None'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
800,Gianluca,janLuke@users.noreply.github.com,2018-06-18 15:08:38+02:00,3aa81e719efad262461555467065a1d232c7762f,https://github.com/allenai/allennlp/commit/3aa81e719efad262461555467065a1d232c7762f,"In get_from_cache(), allow redirections in head requests (#1387)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
801,mpagli,mpagli@users.noreply.github.com,2018-06-18 18:13:50+02:00,bab565a06b74b66037d3c0757d6ae30024eab550,https://github.com/allenai/allennlp/commit/bab565a06b74b66037d3c0757d6ae30024eab550,"Update elmo.py (#1388)

There might be a mistake line 144: `elif self._has_cached_vocab is not None:` should be `elif not self._has_cached_vocab:` as we try to check the existence of a cached vocabulary and the flag is defined in `__init__` as a boolean: `self._has_cached_vocab = vocab_to_cache is not None`.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
802,Michael Schmitz,michael@schmitztech.com,2018-06-18 15:10:11-07:00,bb08b0650c82aea17595f48dc58d8c947d88aafe,https://github.com/allenai/allennlp/commit/bb08b0650c82aea17595f48dc58d8c947d88aafe,Add a Dockerfile for downstream usage of AllenNLP. (#1389),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
803,Michael Schmitz,michael@schmitztech.com,2018-06-18 15:41:27-07:00,2b32a867a132b591666de78b9afb51843d233b60,https://github.com/allenai/allennlp/commit/2b32a867a132b591666de78b9afb51843d233b60,Update Dockerfile.pip,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
804,Michael Schmitz,michael@schmitztech.com,2018-06-18 15:57:39-07:00,da429d6dd505a940a525f9b774fec406f6b3d95b,https://github.com/allenai/allennlp/commit/da429d6dd505a940a525f9b774fec406f6b3d95b,Update Dockerfile.pip,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
805,Michael Schmitz,michael@schmitztech.com,2018-06-18 16:17:11-07:00,5e38a081ce06b702c823b2810ce9058163c841b4,https://github.com/allenai/allennlp/commit/5e38a081ce06b702c823b2810ce9058163c841b4,Update Dockerfile.pip,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
806,Gianluca,janLuke@users.noreply.github.com,2018-06-19 02:41:18+02:00,6da17d67b9202ad3681618051ddaa4ff1eff51c0,https://github.com/allenai/allennlp/commit/6da17d67b9202ad3681618051ddaa4ff1eff51c0,"Adds support for reading pretrained embeddings (text format) from uncompressed files and archives (#1364)

* Adds support for reading pretrained embeddings (text format) from:

    * an uncompressed text file

    * a text file compressed with zip, gzip, bz2, lzma

    * file inside a zip or tar archive containing multiple files;
      in this case, the parameter ``pretrained_file`` must be a pair
      ``[path_to_archive, path_to_file_inside_archive]``, e.g.:
      ```
        ""pretrained_file"": [
            ""http://nlp.stanford.edu/data/glove.twitter.27B.zip"",
            ""glove.twitter.27B.200d.txt""]
      ```
      If an archive contains a single file, this is not needed and a string is enough.

Improved feedback to the user:

* Number of vocab tokens present in the pretrained embedding file

* progress bars; read the number of tokens if declared in the first row

New test fixtures was included. The glove files and several new compressed versions of
fake embeddings were put inside the folder ``fixtures/embeddings`` to not clutter
the fixtures folder.

* * Addressed MyPy errors
    * [Bug fix] Check if the tarball contains the file
* Fixed some docs and message strings

* PyLint. Replaced tqdm with allennlp.common.Tqdm.

* Use URI (path_to_archive)#path_to_member instead of pair of strings
to locate embeddings files inside archives.

* * [Optimization] When reading embedding file, read the token at the beginning
of the line with and then split the line only if the token is in the vocabulary.

* Polished the function for reading embeddings from text
    * renamed ""word"" to ""token"" for coherence
    * removed old comments

* Fixed some type annotations. Fixed and added some docstrings.

* Pylint and Sphinx.

* Fixed exception name in read_num_pretrained_tokens_if_present. Polished the function

* Read and parse the file first line without re-opening the file.

The function read_num_pretrained_tokens_if_present(uri) parsed
the first line of the file to see if it was a header. This was
done just before re-opening the file and reading it entirely.

With tar files this is slow (no problem with zip), because the file
gets entirely extracted two times.

I could have just make read_num_pretrained_tokens_if_present accept
an opened file, but because the file is not seekable nor it's easy
to make an independent copy of the iterator I preferred another
approach.

* Typos

* Fixed docstring in Embedding.from_params

* Just moved ""import itertools"" to the first group of imports.

* Changed return type of open_embeddings_text_file (input to @contextmanager)
from ContextManager[TextIO] to Iterator[TextIO].

* remove get_embeddings_file_iterator_with_progbar, add EmbeddingsTextFile

* fix mypy stuff

* Changes to EmbeddingsTextFile:

* put the code for opening the stream inside ``__init__`` and added a ``close()`` method so that it works similarly to ``open / ZipFile`` (even outside ``with`` clauses)

* kept an (optional) handle to the eventual archive file so I can close that too (even if that may not be strictly necessary given that we are only reading...)

* put the code for zip and tar in separate private methods (e.g. ``_open_inside_zip``)

* made ``_get_num_tokens_from_first_line`` and ``_get_the_only_file_in_the_archive`` static methods of ``EmbeddingsTextFile``

* [Minor] Typo in one test, added missing types

* Replaced test for checking num_tokens is correctly read:
test public property, not private helper method.

* Fixed exception message _get_the_only_file_in_the_archive
Removed accidentally committed __len__ method in EmbeddingTextFile

* Moved constant EMBEDDINGS_FILE_ENCODING inside EmbeddingsTextFile as
DEFAULT_ENCODING.

* Moved EmbeddingsTextFile and uri-related functions to the bottom of the
file

* Use itertools.chain instead of self._buffer

Implement Iterator[str]

Add readline() method

Put private fields declarations on top in __init__

* Renamed (get / decode)_embeddings_file_uri() to  (format / parse)_embeddings_file_uri().
Made parse_embeddings_file_uri() return a named tuple.

* Fixed some docstrings.

* Shortened ``embeddings_file_uri`` vars/args to ``file_uri``.
I think the type of the file is clear from the context and
short variables improve readability.

* Removed EmbeddingsTextFile field (type) declarations.

* Replaced properties ""uri"" and ""num_tokens"" with public fields.

* Implement __len__ so that is returns num_tokens.
No need for passing ""total"" argument to tqdm anymore.

* In __len__, raise AttributeError with a proper error message if self.num_tokens is None.

Before this commit, it raised:
""TypeError: 'NoneType' object cannot be interpreted as an integer""",27,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['words_read == words, f \\', 'words_read == words, f \\', 'in words', 'not in words', 'not in words', 'in words', 'in words', 'not in words', 'torch.equal(embeddings[i], vec),  + archive_path', 'text == correct_text,  + path', 'text == correct_text,  + archive_path', 'f.num_tokens == expected_num_tokens, f', 'parse_embeddings_file_uri(simple_path) == (simple_path, None)', 'decoded == (path1, path2)']","['(ValueError, message=)', '(ValueError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
807,Joel Grus,joelgrus@gmail.com,2018-06-18 18:01:13-07:00,3dff9c7a5f06c23977041e15218c7bf50f953af4,https://github.com/allenai/allennlp/commit/3dff9c7a5f06c23977041e15218c7bf50f953af4,"remove demo (#1338)

* remove demo

* make tests pass

* fix broken sniff test",15,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('Raises', '(SystemExit) as cm:')]",['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['])', 'response.status_code == 400', 'b in data', 'response.status_code == 200', 'in results', 'response.status_code == 200', 'in results', 'response.status_code == 200', 'in results', 'not predictor.calls', 'response.status_code == 200', 'json.loads(response.get_data()) == data', 'predictor.calls.get(key) == 1', 'len(predictor.calls) == 1', 'response.status_code == 200', 'json.loads(response.get_data()) == noyes', 'predictor.calls[key] == 1', 'predictor.calls[json.dumps(noyes)] == 1', 'len(predictor.calls) == 2', 'response.status_code == 200', 'json.loads(response.get_data()) == data', 'predictor.calls[key] == 1', 'predictor.calls[json.dumps(noyes)] == 1', 'len(predictor.calls) == 2', 'not predictor.calls', 'response.status_code == 200', 'json.loads(response.get_data()) == data', 'predictor.calls[key] == i + 1', 'len(predictor.calls) == 1', 'cm.code == -1  # pylint: disable=no-member', 'response.status_code == 200', 'not in result', 'response.status_code == 400', 'response.status_code == 200', 'slug is not None', 'response.status_code == 400', 'response.status_code == 200', 'set(result2.keys()) == {}', 'result2[', 'result2[] == data', 'result2[] == result']",[],[],[],[],[],[],[],[],[],[],[],[]
808,,ihcaoe@gmail.com,2018-06-19 23:42:57+08:00,db519aff544c4685fc10581febf0da7ecadfa097,https://github.com/allenai/allennlp/commit/db519aff544c4685fc10581febf0da7ecadfa097,Update README.md with ./allennlp/run.py (#1395),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
809,Matthew Peters,matt-peters@users.noreply.github.com,2018-06-20 15:22:42-07:00,e903018915ee94f50988ee43f8825ba6127cd4ce,https://github.com/allenai/allennlp/commit/e903018915ee94f50988ee43f8825ba6127cd4ce,Fix multiple GPU training after upgrading to pytorch 0.4 (#1401),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
810,Mark Neumann,markn@allenai.org,2018-06-20 20:28:30-07:00,6800d76a7e6c4e53ec10733371ab464938da0794,https://github.com/allenai/allennlp/commit/6800d76a7e6c4e53ec10733371ab464938da0794,"fix elmo command to use line indices and disallow empty lines (#1397)

Fixes #1396 Fixes #1257 

- Replaces sentence indexes with integer line indices
- Doesn't ignore duplicate lines in the dataset
- raises an error if your input file contains blank lines, rather than silently creating a dataset which doesn't align with the input file",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,1,0,0,0,0,0,0,0,0,0,0,1,9,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(h5py_file.keys()) == []', 'list(h5py_file.keys()) == []', 'list(h5py_file.keys()) == []', 'set(h5py_file.keys()) == {}', 'h5py_file.get(sentence_id).shape == (3, len(sentence.split()), 32)', 'os.path.exists(self.output_path)', 'len(h5py_file.keys()) == 2', 'set(h5py_file.keys()) == {}', 'h5py_file.get(sentence_id).shape == (3, len(sentence.split()), 32)']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['list(h5py_file.keys()) == [sentence]', 'list(h5py_file.keys()) == [sentence]', 'list(h5py_file.keys()) == [sentence]', 'len(h5py_file.keys()) == 1', 'set(h5py_file.keys()) == set(sentences)', 'h5py_file.get(sentence).shape == (3, len(sentence.split()), 32)', 'os.path.exists(self.output_path)', 'len(h5py_file.keys()) == 2', 'set(h5py_file.keys()) == set([])']",[],[],[],[],[],[],[],[],[],[],[],[]
811,Mark Neumann,markn@allenai.org,2018-06-21 10:59:09-07:00,76deabb507490d8277a6d295df9f381ebc0f8554,https://github.com/allenai/allennlp/commit/76deabb507490d8277a6d295df9f381ebc0f8554,Remove frontend (#1407),45,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
812,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-06-21 18:08:38-04:00,4bd8e7f2d6f3b3edd29e40f5295ab811df99b30a,https://github.com/allenai/allennlp/commit/4bd8e7f2d6f3b3edd29e40f5295ab811df99b30a,"Add support for prevention of parameter initialization which match the given regexes (#1405)

Add support for overrided prevention of parameter initialization which match the given regexes

## Commit Summary

- Makes following scenario easy to handle: continue with all other configured initialization schemes for various networks but skip parameters matching `"".*transfer.*""`
- Add `PreventRegexInitializer` and register it with `""prevent""`. 
- Allow `InitializerApplicator` to apply any `initializer` to any parameter only if prevention regexes are not matched.
- Add unit tests with example usage

## Need for this feature:

- If one wants to transfer modules from pretrained model, one would want to initialzie weights of new model preventing the transfered modules from this initialization. 
- Negative matching regex give a easy selective handle on which parameters are transferred and must not be initialized. Eg. continue with all other configured initialization schemes for various networks but skip parameters matching `"".*(transfer)|(pretrained).*""`.
- Also note that given regex A and regex B, in general it is not easy to write regex that matches A but not B. So bringing the required effect with plain regex can be quite tedious.


## Example Usage


```python
class MyNet(torch.nn.Module):
    # Typically, transfer_model s would loaded with trained weights by : 
    # eg. transfer_mode1 = load_archive(params.pop(""model1.tar.gz""))  
    # in from_params of main MyModel of which MyNet is part of.
    def __init__(self, transfer_model1, transfer_model2):
        super(Net, self).__init__()
        self.linear_1 = torch.nn.Linear(5, 10)
        self.linear_2 = torch.nn.Linear(10, 5)
        self.linear_3_transfer = transfer_model1.linear_3 	 # Note this
        self.linear_4_transfer = transfer_model2.linear_4        # Note this
        self.pretrained_conv = transfer_model2.conv 	         # Note this
    def forward(self, inputs):  # pylint: disable=arguments-differ
        pass
```

```
// experiment.json
...
    {""initializer"": [
        ["".*linear.*"", {""type"": ""xavier_normal""}], ...
        ["".*conv.*"", {""type"": ""kaiming_normal""}],
        ["".*_transfer.*"", ""prevent""],                           // Note this
        ["".*pretrained.*"",{""type"": ""prevent""}]                 // Note this
    ]}
...
```
The following would initialize linear and conv layers except `linear_3_transfer`, 
`linear_4_transfer`, `pretrained_conv` which match regexes corresponding to ""prevent"" type.

```python
net = MyNet()
# load initializer from above configs
initializer(net)
```",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.equal(parameter.data, torch.ones(parameter.size())*10)', 'not torch.equal(parameter.data, torch.ones(parameter.size())*10)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
813,Nelson Liu,nelson-liu@users.noreply.github.com,2018-06-21 17:09:28-07:00,8a314940a06473e719a64ab3d13d31950659d039,https://github.com/allenai/allennlp/commit/8a314940a06473e719a64ab3d13d31950659d039,"Add --include-sentence-indices flag to ELMo command (#1404)

Since #1397 , it's no longer possible to use the HDF5 files generated by the elmo command unless you have the original dataset of sentences. This PR adds a flag to the elmo command that writes a JSON-serialized mapping of sentence->key to the `sentence_indices` key, so the HDF5 file can be useful even without the original dataset.

The typical use will be something like this, if you're interested in getting the embeddings for a particular sentence in reasonable time:

```
import json

sentence = something

with h5py.File(hdf5_path, 'r') as h5py_file:
    sentence_to_index = json.loads(h5py_file.get(""sentence_to_index"")[0])
    embedding = h5py_file[sentence_to_index[sentence]]
```",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(h5py_file.keys()) == {}', 'json.loads(h5py_file.get(}', 'set(h5py_file.keys()) == {}', 'json.loads(h5py_file.get(}', 'set(h5py_file.keys()) == {}', 'json.loads(h5py_file.get(}', 'set(h5py_file.keys()) == {}', '(json.loads(h5py_file.get()[0]) ==', 'os.path.exists(self.output_path)', 'set(h5py_file.keys()) == {}', 'h5py_file.get(sentence_id).shape == (3, len(sentence.split()), 32)', 'len(h5py_file.keys()) == 3', 'set(h5py_file.keys()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],"['list(h5py_file.keys()) == []', 'list(h5py_file.keys()) == []', 'list(h5py_file.keys()) == []', 'set(h5py_file.keys()) == {}', 'len(h5py_file.keys()) == 2', 'set(h5py_file.keys()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[]
814,Joel Grus,joelgrus@gmail.com,2018-06-22 11:22:51-07:00,70b4ffb0d14395828fb0268965db28548a0fb56f,https://github.com/allenai/allennlp/commit/70b4ffb0d14395828fb0268965db28548a0fb56f,"replace hocon with jsonnet (#1409)

* remove pyhocon, replace with jsonnet

* clean up configs

* remove pyhocon from test",21,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,2,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model_params[', 'unflattened == {', 'unflatten(unflattened) == unflattened', 'merged == {: 2}', 'merged == {: 2}', 'merged == {: 2}}', 'parse_overrides() == {}', 'parse_overrides() == {}', 'override_dict == {', 'params == {', 'alice.as_dict() == {}', 'bob.as_dict() == {}', 're.match(regex, )', 'not re.match(regex, )', 'params.as_dict() == params2.as_dict()', 'os.environ.get(key) is None', 'params[']","['(RuntimeError)', '(RuntimeError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],['model_params['],[],[],[],[],[],[],[],[],[],[],[],[]
815,Matthew Peters,matt-peters@users.noreply.github.com,2018-06-23 01:29:02-07:00,e16a6b5b3676fe3567fded6074e9cf2b53221d8f,https://github.com/allenai/allennlp/commit/e16a6b5b3676fe3567fded6074e9cf2b53221d8f,"Split off function to find latest checkpoint in Trainer (#1414)

Quick refactor to expose the functionality to find the latest checkpoint in the serialization directory in `Trainer`.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
816,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-06-24 00:23:14-04:00,2bf1e28b9bf15acd24bc8e3eac1be725cedd23f7,https://github.com/allenai/allennlp/commit/2bf1e28b9bf15acd24bc8e3eac1be725cedd23f7,"fix a minor typo in docstring causing wrong api usage docs of vocabulary config. (#1415)

- Change expected key in docstring from 'vocabulary_directory' to 'directory_path'",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
817,Joel Grus,joelgrus@gmail.com,2018-06-25 08:27:03-07:00,1031815afe2ccc599a4d230825983a096e672a1a,https://github.com/allenai/allennlp/commit/1031815afe2ccc599a4d230825983a096e672a1a,duplicate config in Predictor.from_archive (#1413),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
818,Nelson Liu,nelson-liu@users.noreply.github.com,2018-06-25 13:21:13-07:00,9dbba33806a65e8a1fe7ab54e0683d7adcbedd99,https://github.com/allenai/allennlp/commit/9dbba33806a65e8a1fe7ab54e0683d7adcbedd99,"Fix chdir in ModelTestCase breaking downstream models (#1418)

ModelTestCase has a few `chdir`s since after we moved the tests into the module, all the relative paths in the test fixtures were broken (since they assumed that we were running the tests in the same directory as the `tests` folder). I got around this by using `os.chdir`, but did not realize that this would break models that import and use `ModelTestCase` (see #1417 ).

I think a reasonable solution to this is to simply remove all the `chdir` calls and add a symbolic link in the project root called `tests` that links to the tests folder (in the module root). This means that the relative paths in the fixtures don't need to be redone and downstream clients using `ModelTestCase` won't deal with issues from `os.chdir`.",34,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(not os.path.exists(AllenNlpTestCase.PROJECT_ROOT / )'],[],[],[],"['xfail(not os.path.exists(AllenNlpTestCase.PROJECT_ROOT / ),']","['mark.xfail(not os.path.exists(AllenNlpTestCase.PROJECT_ROOT / ),']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
819,Mark Neumann,markn@allenai.org,2018-06-25 14:41:50-07:00,70d4d3c3e204808b412eebcf260ac0ddadf58143,https://github.com/allenai/allennlp/commit/70d4d3c3e204808b412eebcf260ac0ddadf58143,use sensible default for num_serialised_models_to_keep (#1420),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
820,Nelson Liu,nelson-liu@users.noreply.github.com,2018-06-26 13:34:53-07:00,36d91fd1c7833f3b284afb463c7bb2b5600e253f,https://github.com/allenai/allennlp/commit/36d91fd1c7833f3b284afb463c7bb2b5600e253f,"Make tqdm description ignore metrics starting with _ (#1425)

* Make tqdm description ignore metrics starting with _

* Add notes about this functionality

* fix typo and lint

* Lint , vol II",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
821,Nelson Liu,nelson-liu@users.noreply.github.com,2018-06-26 14:41:34-07:00,872acf94c17b355e55874f85d5fd2a4c920d0091,https://github.com/allenai/allennlp/commit/872acf94c17b355e55874f85d5fd2a4c920d0091,"Make evaluation tqdm description ignore metrics starting with _ (#1430)

Continuation of #1425 , missed one",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
822,Matthew Peters,matt-peters@users.noreply.github.com,2018-06-26 17:00:53-07:00,eaf5b7e132d975a8e15e29be640b7605e082c978,https://github.com/allenai/allennlp/commit/eaf5b7e132d975a8e15e29be640b7605e082c978,Call  before logging to tensorboard (#1423),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
823,Mark Neumann,markn@allenai.org,2018-06-26 18:15:34-07:00,5d3828219d1afc9c6018a9f3779a7a7768ed7e15,https://github.com/allenai/allennlp/commit/5d3828219d1afc9c6018a9f3779a7a7768ed7e15,"Avoid non-model state in predictors (#1422)

* new api for predictors

* remove union interface

* refactor predictors which are stateless

* make coref predictor stateless

* make decomposable attention predictor stateless

* make crf tagger and simple tagger predictors stateless

* make wikitables predictors stateless

* tweaks

* fix tests

* cleanup, remove new predictor api for later PR

* refactor SRL predictor to have no state

* lint

* fix srl test

* keep tags optional in sequence_tagger reader",23,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
824,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-06-27 13:09:58-04:00,0312b16e23263d24401d7d89b8c327fa0b7259c3,https://github.com/allenai/allennlp/commit/0312b16e23263d24401d7d89b8c327fa0b7259c3,"Add support for configurable vocabulary extension (#1416)

* Add support for configurable vocabulary extension.

* Add extensive test cases for new vocab extension api.

* Add vocabulary extension (as default) in fine-tune command.

* Add missing parameter information in docstring. Make namespace incompatibility error message more informative.

* cleanup api for vocabulary extension

* Update tests for cleaned vocab extension api

* Add support for default vocab extension in fine-tune command with fixed api

* Change non_padded_namespaces from list to set

* Cleanup code to check compatibility of vocab namespace extension.

* Make 'non_padded_namespaces' Sets instead of Sequences throughout vocabulary.py and fix all mypy, pylint issues.

* Use namespace_match method to check padded / not instead of string function.

* Change non_padded_namespace annotation from Set[str] to Iterable[str] and consequent code cleanup changes.

* Update docstring to allow set/list/tuple for non_padded_namespaces",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,6,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab2._non_padded_namespaces == {}', 'extended_vocab.get_token_index() == 0 + extra_count', 'extended_vocab.get_token_index() == 1 + extra_count', 'extended_vocab.get_token_index() == 2 + extra_count', 'extended_vocab.get_token_index() # should be present', 'extended_vocab.get_token_index() # should be present', 'extended_vocab.get_vocab_size() == 5 + extra_count', 'len(extended_vocab.get_all_namespaces()) == 2', 'extended_vocab.get_vocab_size() == 1 + extra_count', 'extended_vocab.get_vocab_size() == 1 + extra_count', 'extended_vocab.get_all_namespaces() \\', 'extended_vocab.get_non_padded_namespaces() \\', 'extended_vocab.get_vocab_size() == 6', 'extended_vocab.get_vocab_size() == 8 # 2 extra overlapping because padded', 'extended_vocab.get_vocab_size()', 'extended_vocab.get_vocab_size()', 'extended_vocab.get_vocab_size() == 6 # l,m,n,o + oov + padding', 'extended_vocab.get_vocab_size() == 3 # x,y,z', 'vocab_index == extended_vocab_index', 'vocab_token == extended_vocab_token']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[],['vocab2._non_padded_namespaces == []'],[],[],[],[],[],[],[],[],[],[],[],[]
825,Mark Neumann,markn@allenai.org,2018-06-27 10:53:38-07:00,18d4fee329d62685ef88afaf9c6d274292047825,https://github.com/allenai/allennlp/commit/18d4fee329d62685ef88afaf9c6d274292047825,"remove adaptive iterator (#1433)

* remove adaptive iterator

* remove name from registerable",5,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['DataIterator.by_name(', 'grouped_instances == [[self.instances[4], self.instances[2], self.instances[0]],', 'grouped_instances == [[self.instances[4], self.instances[2]],', 'grouped_instances == [[self.instances[3]],', 'iterator._adaptive_memory_usage_constant == 10', 'iterator._padding_memory_scaling({}) == 2.4', 'iterator._maximum_batch_size == 10000']",[],[],[],[],[],[],[],[],[],[],[],[]
826,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-06-28 12:32:27-04:00,a0c368a79db4fa1421822d09b8b7ca868137613e,https://github.com/allenai/allennlp/commit/a0c368a79db4fa1421822d09b8b7ca868137613e,"Fix an edge case for incompatible vocabulary extension. (#1435)

* Fix an edge case for incompatible vocabulary extension.

* Clean up extend(..) from removable indentation",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
827,Joel Grus,joelgrus@gmail.com,2018-06-28 10:46:06-07:00,8855042fe6f4739b94c5397572024e4915051640,https://github.com/allenai/allennlp/commit/8855042fe6f4739b94c5397572024e4915051640,"eliminate or make private most of the new Vocabulary methods (#1436)

* remove unnecessarily public methods

* remove unused function",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(extended_vocab._token_to_index) == 2', 'extended_namespaces == {.format(i) for i in range(6)}', 'extended_vocab._non_padded_namespaces == {}']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(extended_vocab.get_all_namespaces()) == 2', 'extended_vocab.get_all_namespaces() \\', 'extended_vocab.get_non_padded_namespaces() \\']",[],[],[],[],[],[],[],[],[],[],[],[]
828,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-06-28 14:47:18-04:00,7664b12117511d05ad48bbbe9336b5cd9de51960,https://github.com/allenai/allennlp/commit/7664b12117511d05ad48bbbe9336b5cd9de51960,"Add support for selective finetune (freeze parameters by regex from config file) (#1427)

* Add support in fine_tune to selectively tune (freeze some parameters set through config file)

* Add tests for selective fine tuning.

* Allow for turning off gradients in train command (since in fine-tune as well this is happening with ""trainer"" configs).

* Add missing imports in fine_tune_test.py

* add tests for using 'no_grad' config with train command

* Code cleanup: 1. for regex matches 2. follow import convention

* Add logging statements for knowing tunable and frozen parameters.",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not parameter.requires_grad', 'parameter.requires_grad \\', 'not parameter.requires_grad', 'parameter.requires_grad']","['(Exception)', '(Exception)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
829,Mark Neumann,markn@allenai.org,2018-06-28 13:40:11-07:00,d2e3035f1b294b72da3350150a4571e5f32e2164,https://github.com/allenai/allennlp/commit/d2e3035f1b294b72da3350150a4571e5f32e2164,enable mypy on tests (#1437),5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
830,Mark Neumann,markn@allenai.org,2018-06-28 14:09:42-07:00,43fc89ee59944dca0de01ca5ab2843c9926323d6,https://github.com/allenai/allennlp/commit/43fc89ee59944dca0de01ca5ab2843c9926323d6,"Enables Predict to use dataset readers from models (#1434)

* refactor wikitables reader to have concrete types

* new predict_instance api

* constituency parser predictor

* sketch of new predict function

* big refactor of Predict

* mypy

* added test, discovered bug in forward_on_instances from pytorch 0.4

* fix lint

* tidy up, refresh docs

* more robustly address issue with loss shape

* add test for single dim tensor handling

* PR comments

* use keys to decide whether to warn

* mypy",10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.output_file == ', 'os.path.exists(self.outfile)', 'len(results) == 5', 'set(result.keys()) == {,', 'not  in output.keys()', 'in single_output.keys()']",[],[],[],[],[],[],[],[],[],[],[],[],['args.output_file.name == '],[],[],[],[],[],[],[],[],[],[],[],[]
831,Joel Grus,joelgrus@gmail.com,2018-06-29 06:26:10-07:00,fa34344baffe2f8e2a50d5353a6e05f1ef668b8f,https://github.com/allenai/allennlp/commit/fa34344baffe2f8e2a50d5353a6e05f1ef668b8f,"refactor iterators (#1157)

* first attempt at refactoring iterators

* final cleanup

* move more stuff into the base class

* move more stuff into base class

* fix typo

* remove duplicate functions

* remove newline

* address PR comments",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
832,jonborchardt,jonborchardt@users.noreply.github.com,2018-06-29 07:54:40-07:00,74a30d08b91c0ac8fac7ad33e127c019749dfa80,https://github.com/allenai/allennlp/commit/74a30d08b91c0ac8fac7ad33e127c019749dfa80,"update the look and feel of the config explorer (#1412)

* update to look and feel

there should be no functional changes

* updated code in python script

* make formatting consistent

* pr fix

* pr fix

* pr fixes

* pr fix",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
833,Matthew Peters,matt-peters@users.noreply.github.com,2018-06-29 14:21:36-07:00,f0ed1d457447c122f8ba59abfc8fe8f6de1ae869,https://github.com/allenai/allennlp/commit/f0ed1d457447c122f8ba59abfc8fe8f6de1ae869,"Few feature additions (#1438)

* Allow vocabulary to be registrable

* Allow vocabulary to be registrable

* Add a method to Instance that allows adding a field to an already constructed object

* Add ability to restrict batches to a maximum number of tokens

* bug fixes

* Update test case

* remove print statement

* clean up after merge conflict

* pylint

* mypy

* fix the docs

* Fix merge conflict

* pylint

* mypy

* Make type for Vocabulary optional

* Add logging in trainer if skipping parameter with sparse gradients

* pylint",11,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['num_instances == len(self.instances)', 'batch_sequence_length * len(batch.instances) <= 9']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
834,Matthew Peters,matt-peters@users.noreply.github.com,2018-06-29 15:48:10-07:00,d4ee5db1c630d6c631a828ee12fcbf6154de288c,https://github.com/allenai/allennlp/commit/d4ee5db1c630d6c631a828ee12fcbf6154de288c,Make bucket iterator respect maximum_samples_per_batch (#1446),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['num_instances == len(self.instances)', 'batch_sequence_length * len(batch.instances) <= 9']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
835,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-03 11:29:34-04:00,f136ae001eb7bf3d44b03882a56ec84aab430503,https://github.com/allenai/allennlp/commit/f136ae001eb7bf3d44b03882a56ec84aab430503,"Fix a typo in embedding_tokens notebook. (#1449)

Fix a typo in embedding_tokens notebook : The vocabulary is `token_ids` and not `tokens_ids`.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
836,Joel Grus,joelgrus@gmail.com,2018-07-03 11:44:11-07:00,a56fa40fa93b983aa06bfa7aa2a74628843e76d3,https://github.com/allenai/allennlp/commit/a56fa40fa93b983aa06bfa7aa2a74628843e76d3,"remove RegistrableVocabulary (#1454)

* remove RegistrableVocabulary

* add comment about special from_params logic

* fix pylint",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(vocab, MyVocabulary)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
837,Matthew Peters,matt-peters@users.noreply.github.com,2018-07-03 14:05:59-07:00,f09ff87e687833a7760784c7d226ea86978b34fd,https://github.com/allenai/allennlp/commit/f09ff87e687833a7760784c7d226ea86978b34fd,"Allow to use a different validation iterator from training iterator (#1455)

* Allow to use a different validation iterator from training iterator

* Use validation iterator

* Use validation iterator for evaluate, if present

* pylint",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
838,Nelson Liu,nelson-liu@users.noreply.github.com,2018-07-03 16:55:50-07:00,59ecd3b7410e2a655f970ab0bd3f0bd9ae10ce18,https://github.com/allenai/allennlp/commit/59ecd3b7410e2a655f970ab0bd3f0bd9ae10ce18,Fix conll2003.from_params incorrect default (#1453),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
839,Joel Grus,joelgrus@gmail.com,2018-07-05 19:15:03-07:00,7cc3db1339b030e4d2086a72f208f7b0b11c5048,https://github.com/allenai/allennlp/commit/7cc3db1339b030e4d2086a72f208f7b0b11c5048,"fix Vocabulary.from_params to accept a dict for max_vocab_size (#1460)

* fix Vocabulary.from_params to accept a dict for max_vocab_size

* pylint",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['len(words) == 3'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
840,VictorSanh,victorsanh@gmail.com,2018-07-06 00:19:41-04:00,bef52ed74fa67c62ba11a62d5f8425c2216e7cfb,https://github.com/allenai/allennlp/commit/bef52ed74fa67c62ba11a62d5f8425c2216e7cfb,Fix call to vocab.token_from_index -> self.label_namespace (#1459),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
841,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-06 12:48:50-04:00,77298a975a8edf8032723a140f4137a0fd326e61,https://github.com/allenai/allennlp/commit/77298a975a8edf8032723a140f4137a0fd326e61,"Fix logging of no-grad parameters. (#1448)

Fix issue in no-grad parameters logging as mentioned by @rulai-huajunzeng in (#1427).

If parameters were already set `requires_grad=False` not through no through nograd regex but other means then they were logged as Tunable instead of Frozen. This pr fixes that.

I have made the headings capitalized. They are more distinguishable this way amidst a long list of parameters.",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(frozen_parameter_names) == {}', 'set(tunable_parameter_names) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
842,Mark Neumann,markn@allenai.org,2018-07-09 10:06:17-07:00,e2edc9b26a7e2b8f27563485cf2faf03a1ab6d39,https://github.com/allenai/allennlp/commit/e2edc9b26a7e2b8f27563485cf2faf03a1ab6d39,"unwrap tensors in avg metric (#1463)

* unwrap tensors in avg metric

* fix for generator",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
843,Matthew Peters,matt-peters@users.noreply.github.com,2018-07-09 17:05:49-07:00,ff41dda4828969c75445dc50903549554e106cbf,https://github.com/allenai/allennlp/commit/ff41dda4828969c75445dc50903549554e106cbf,"Implementation of ESIM model (#1469)

* WIP: ESIM model

* WIP: ESIM model for SNLI

* WIP: ESIM

* WIP: ESIM

* WIP: ESIM

* WIP: ESIM

* ESLM model with ELMo

* Add a ESIM predictor that works with SNLI formatted files

* Move ESIM predictor

* Clean up

* Add test for ESIM

* Add predictor for ESIM

* pylint

* pylint

* mypy

* fix the docs

* ESIM predictor

* Add comment to esim training config

* Move InputVariationalDropout

* pylint

* Fix the docs

* fix the docs

* Remove ESIM predictor

* Scrub all of ESIMPredictor",12,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
844,Joel Grus,joelgrus@gmail.com,2018-07-10 12:42:41-07:00,580dc8b0e2c6491d4d75b54c3b15b34b462e0c67,https://github.com/allenai/allennlp/commit/580dc8b0e2c6491d4d75b54c3b15b34b462e0c67,"(mostly) remove from_params (#1191)

* remove from_params

* more progress on merge

* still not working

* get more tests to pass

* more work

* fixing tests

* more

* progress

* yo

* all tests passing

* remove print statements

* get things working

* oops

* more cleanup

* pylint cleanup

* break stuff out

* add some from_params tests

* add missing api doc

* appease the CI overlords

* remove weird empty file

* address pr feedback

* more PR feedback

* remove from_params from ESIM model

* mypy and pylint

* sphinx",129,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['takes_arg(bare_function, )', 'not takes_arg(bare_function, )', 'takes_arg(SomeClass, )', 'takes_arg(SomeClass, )', 'not takes_arg(SomeClass, )', 'takes_arg(SomeClass.check_param, )', 'not takes_arg(SomeClass.check_param, )', 'takes_arg(SomeClass.set_total, )', 'not takes_arg(SomeClass.set_total, )', 'bare_type == Dict[str, str]', 'bare_bare_type == Dict[str, str]', 'remove_optional(Optional[str]) == str', 'remove_optional(str) == str', 'isinstance(my_class, MyClass)', 'my_class.my_int == 10', 'my_class.my_bool', 'kwargs == {', 'b.name == ', 'b.size == 10', 'b.name == ', 'b.size == 10', 'c.name == ', 'c.size == 20', 'c.name == ', 'c.size == 20']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
845,Joel Grus,joelgrus@gmail.com,2018-07-11 15:40:09-07:00,52c08355fd27e497d6f442c8b46ee732599302df,https://github.com/allenai/allennlp/commit/52c08355fd27e497d6f442c8b46ee732599302df,instantiate default activation functions in constructor (#1478),7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
846,Joel Grus,joelgrus@gmail.com,2018-07-12 10:13:48-07:00,d9e98610a9d7365e10d8d407cac890e64aff3823,https://github.com/allenai/allennlp/commit/d9e98610a9d7365e10d8d407cac890e64aff3823,"don't call create_kwargs  for a class that has no constructor (#1481)

* don't call  for a class that has no constructor

* add type annotation to make mypy happy",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
847,Mark Neumann,markn@allenai.org,2018-07-12 15:56:50-07:00,e50b1027721395d6bd6156dc07b19eab3002a2e1,https://github.com/allenai/allennlp/commit/e50b1027721395d6bd6156dc07b19eab3002a2e1,"fine grained ner reader (#1483)

* fine grained ner reader

* tweak",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == [,', 'fields[]', 'tokens == [,', 'fields[,', 'tokens == []', 'fields[]', 'len(instances) == 1']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
848,Mark Neumann,markn@allenai.org,2018-07-13 09:36:19-07:00,f5bbe5924dcde75932e4fa729374d3913f2515fb,https://github.com/allenai/allennlp/commit/f5bbe5924dcde75932e4fa729374d3913f2515fb,"Move param import (#1484)

* move import inside path manipulation

* remove print",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
849,Mark Neumann,markn@allenai.org,2018-07-13 12:56:30-07:00,ba6f3451480f42ba046d2cfcc84eb332f4c15ce3,https://github.com/allenai/allennlp/commit/ba6f3451480f42ba046d2cfcc84eb332f4c15ce3,"Crf ner tweaks (#1488)

* couple of fine-grained NER training tweaks

* indentation",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
850,Mark Neumann,markn@allenai.org,2018-07-13 17:43:56-07:00,01ddd126e339971eb752ec32ba024ba1734e3b71,https://github.com/allenai/allennlp/commit/01ddd126e339971eb752ec32ba024ba1734e3b71,make tables nice in validation summary (#1490),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
851,Nelson Liu,nelson-liu@users.noreply.github.com,2018-07-16 11:10:13+10:00,5fc7a00dee3a2c10834ac3c45019eb68d9f42ea0,https://github.com/allenai/allennlp/commit/5fc7a00dee3a2c10834ac3c45019eb68d9f42ea0,"Fix SpanBasedF1Measure for tags without conll labels (#1491)

Fixes `SpanBasedF1Measure` to work if the tags don't have conll labels (i.e., the labels are simply `{B, I, O}`).

The only thing that had to be changed was the check to see whether the `active_conll_tag` is not `None`, since `""""` is `False`.",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(spans) == {(, (7, 7))}', 'set(spans) == {(, (7, 9))}', 'spans == [(, (4, 4))]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
852,jzhou316,31744226+jzhou316@users.noreply.github.com,2018-07-16 11:33:14-04:00,74577103bc716117659c3dbdf74778ae53bed056,https://github.com/allenai/allennlp/commit/74577103bc716117659c3dbdf74778ae53bed056,Update elmo.py (#1496),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
853,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-16 12:27:37-04:00,5f2f539a0a890f3beac0a32f3e80a0f8561e6748,https://github.com/allenai/allennlp/commit/5f2f539a0a890f3beac0a32f3e80a0f8561e6748,"Add option to have tie breaking in Categorical Accuracy (#1485)

* Add tie-breaking support in Categorical Accuracy.

* Add tests for tie-breaking in categorical accuracy.

* Remove redundant expand_as and add some comments for complex indexing.",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['accuracy.get_metric(reset=True) == (0.25 + 1 + 0.5)/3.0', 'accuracy.get_metric(reset=True) == (0.25 + 0.5)/2.0']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
854,Liyuan Liu,llychinalz@gmail.com,2018-07-16 11:49:18-07:00,9c21696d060924799fab354321596031857dfff7,https://github.com/allenai/allennlp/commit/9c21696d060924799fab354321596031857dfff7,"fixing a bug in trainer for histograms (#1498)

otherwise it would raise an error in line 505 (expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'other')",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
855,Nelson Liu,nelson-liu@users.noreply.github.com,2018-07-17 15:04:32+10:00,d307a253647567720e06be9ac6591c1df6a043e3,https://github.com/allenai/allennlp/commit/d307a253647567720e06be9ac6591c1df6a043e3,"Add IOB1 support to SpanBasedF1Metric (#1494)

This PR adds IOB1 support to the SpanBasedF1Metric. This was a bit tricky to write, so I'll add some details about my thought process below (might help in review).

So we've got 3 tags (B, I, O), meaning that there are 3^2 = 9 possible transitions between tags. We also have to take into account whether the current conll tag differs from the previous conll tag, bringing up the total to 9 * 2 = 18.

Here are the expected outcomes for each of the cases:

<img width=""333"" alt=""screen shot 2018-07-16 at 1 40 27 pm"" src=""https://user-images.githubusercontent.com/7272031/42742422-d547960e-88fd-11e8-81d3-fca6e146e7db.png"">

Here's where I believe they're each accounted for in the code (based on which branch they fall into of the main if-elif-else)

<img width=""311"" alt=""screen shot 2018-07-16 at 1 46 18 pm"" src=""https://user-images.githubusercontent.com/7272031/42742525-9cd41472-88fe-11e8-9194-d5efec7f6799.png"">

In particular, the else could also be written as `bio_tag == ""I"" and conll_tag == active_conll_tag`, and nothing would change (any and all combinations would still fall into one of these 3 categories).",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(spans) == {(, (7, 7))}', 'set(spans) == {(, (7, 9))}', 'set(spans) == {(, (4, 5)),', 'set(spans) == {(, (5, 6)),']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
856,Nelson Liu,nelson-liu@users.noreply.github.com,2018-07-18 03:36:19+10:00,ee003d247563ec0cc980562a976afcc418eabc32,https://github.com/allenai/allennlp/commit/ee003d247563ec0cc980562a976afcc418eabc32,Fix SpanBasedF1Measure allowed label encodings comment (#1501),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
857,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-17 14:37:36-04:00,9ec3aa644ac4a2c544ca9e9c81d83f52fc4c864d,https://github.com/allenai/allennlp/commit/9ec3aa644ac4a2c544ca9e9c81d83f52fc4c864d,Fix start of tqdm logging in training. (#1492),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
858,Joel Grus,joelgrus@gmail.com,2018-07-17 12:12:13-07:00,f4eef6eeb5e11cc0464d01dd812b6a869405e8d0,https://github.com/allenai/allennlp/commit/f4eef6eeb5e11cc0464d01dd812b6a869405e8d0,"[for discussion] change token_to_indices -> tokens_to_indices (in preparation for byte pair encoding) (#1499)

* replace token_to_indices with tokens_to_indices

* fix broken test

* remove _merge

* fix test

* fix lint",17,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['field._indexed_tokens == {', 'indices == {: [[3, 4, 5, 6, 4, 5, 6, 1, 1, 1]]}', 'indexer.tokens_to_indices([tokens[1]], vocab, : [root_index]}', 'indexer.tokens_to_indices([tokens[-1]], vocab, : [none_index]}', 'indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'indexer.tokens_to_indices([tokens[1]], vocab, : [person_index]}', 'indexer.tokens_to_indices([tokens[-1]], vocab, : [none_index]}', 'len(indices) == 1', 'in indices', 'indices[][1] == verb_index', 'indices[][-1] == none_index', 'indexer.tokens_to_indices([tokens[1]], vocab, : [cop_index]}']",[],[],[],[],[],[],[],[],[],[],[],[],"['indices == [3, 4, 5, 6, 4, 5, 6, 1, 1, 1]', 'indexer.token_to_indices(tokens[1], vocab) == root_index', 'indexer.token_to_indices(tokens[-1], vocab) == none_index', 'indices == expected_indices', 'indices == expected_indices', 'indices == expected_indices', 'indexer.token_to_indices(tokens[1], vocab) == person_index', 'indexer.token_to_indices(tokens[-1], vocab) == none_index', 'indexer.token_to_indices(tokens[1], vocab) == verb_index', 'indexer.token_to_indices(tokens[-1], vocab) == none_index', 'indexer.token_to_indices(tokens[1], vocab) == cop_index']",[],[],[],[],[],[],[],[],[],[],[],[]
859,Mark Neumann,markn@allenai.org,2018-07-17 12:37:19-07:00,66b2c1c344f7d55a353f7ad90804d47359fd2066,https://github.com/allenai/allennlp/commit/66b2c1c344f7d55a353f7ad90804d47359fd2066,"Bio to bioul (#1497)

* refactor to_bioul to accept BIO tags

* add option to use BIOUL to ontonotes NER

* exclude new and old testament sections of ontonotes

* fix merge",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(span_utils.InvalidTagSequence):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['bioul_sequence == []'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
860,Tam Dang,dangitstam@users.noreply.github.com,2018-07-17 13:14:08-07:00,8a20820358e8f0af524e127819245c8715d014b3,https://github.com/allenai/allennlp/commit/8a20820358e8f0af524e127819245c8715d014b3,"Ensure Contiguous Hidden State Tensors in Encoders  (#1493)

*  doesn't ensure a contiguous tensor, causes runtime exception

* adding test for robustness against non-contiguous input states",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not initial_states[0].is_contiguous() and not initial_states[1].is_contiguous()', 'initial_states[0].size() == torch.Size([6, 5, 7])', 'initial_states[1].size() == torch.Size([6, 5, 7])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
861,Mark Neumann,markn@allenai.org,2018-07-17 16:14:13-07:00,8e5ee656573df13c7bdb59ebc8c57d1288237e27,https://github.com/allenai/allennlp/commit/8e5ee656573df13c7bdb59ebc8c57d1288237e27,fix dumb domain filtering (#1505),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
862,Michael Schmitz,michael@schmitztech.com,2018-07-18 13:56:02-07:00,34a92d0db43660b7fd7db21a3c89d0134f66ae68,https://github.com/allenai/allennlp/commit/34a92d0db43660b7fd7db21a3c89d0134f66ae68,Update using_as_a_library_pt1.md (#1509),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
863,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-19 15:43:19-04:00,88c381a15dc57adcc41dd5d43fdd71ecdcecb6cd,https://github.com/allenai/allennlp/commit/88c381a15dc57adcc41dd5d43fdd71ecdcecb6cd,"Make usage of make-vocab, dry-run consistent with train and allow 'extend' to be used by both (#1487)

* Make usage of make-vocab consistent with other commands and allow 'extend' to be used by make-vocab.

* Update and add tests.

* Add test for make-vocab with extend=False.

* Add test for args parsing (mainly to increase coverage).

* Cleanup dry-run and sync its behavior with train and make-vocab and handle `vocab_params` interpretation only at one place.

1. Cleanup unsynced code duplication of Vocab.from_params in dry-run and its bad side-effects.
2. Make behvaiour of vocab_params in dry-run consistent with train and make-vocab

* Add tests for dry-run and remove test_dry_run_doesnt_overwrite_vocab temporarily.

* Make sure vocabulary does not get overridden by dry-run. Add test for it.

* Make make_vocab_from_params and dry_run_from_params similar except the verbose statistics printing.

1. make function arguments of make_vocab_from_params and dry_run_from_params same
2. make sure make-vocab doesn't accidently overwrite something.

* pylint check and rephrase error.

* Fix PR suggestions

- preset _retained_counter in init
- log warnings for printing vocabulary statistics
- add needed spaces in log statements
- remove empty tests for print statistics methods

* Change confusing log message in train.py and reflect the same in make-vocab and dry-run.

- Earlier log message hinted that vocabulary will be created from dataset, though it might not be the case.

* Add appropriate ConfigurationError in dataset print_statistics. Remove redundant space.

* Make mypy happy!

* Add model loading and parameter inspecting in dry-run.",7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,29,1,0,0,0,0,0,0,0,0,0,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'tokens == [,', 'labels == []', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'len(tokens) == 3', 'args.func == dry_run_from_args', 'args.param_path == ', 'args.serialization_dir == ', 'set(vocab_files) == {}', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'tokens == [,', 'labels == []', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'len(tokens) == 3', 'args.func == make_vocab_from_args', 'args.param_path == ', 'args.serialization_dir == ']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['set(predefined_vocab_files) == {}', 'set(new_vocab_files) == {}']",[],[],[],[],[],[],[],[],[],[],[],[]
864,Matthew Peters,matt-peters@users.noreply.github.com,2018-07-19 13:47:50-07:00,7df8275e7f70013185f1afeaa2779c2abce4492d,https://github.com/allenai/allennlp/commit/7df8275e7f70013185f1afeaa2779c2abce4492d,"Text field updates to support multiple arrays in TokenIndexer (#1506)

* WIP: more general token indexers

* Text field updates

* Fix tests

* Allow to overwrite mask in get_text_field_mask

* clean up

* fix tests after merge

* pad_token_sequence accepts and returns Dict

* allow unmatched keys in text field embedder

* allow unmatched keys in text field embedder

* pylint

* mypy

* mypy

* mypy

* cleanupg

* fix test

* PR comments

* pylint

* mypy

* cleanup

* Third refactoring",25,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['padding_lengths == {', 'list(tensors[].shape) == [7]', 'list(tensors[].shape) == [3]', 'list(tensors[].shape) == [4]', 'list(tensors[].shape) == [4, 8]', 'padded_tokens == {: [[1, 2, 3, 4, 5, 0, 0, 0, 0, 0],', 'padded_tokens == {: [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]}', 'padded_tokens[] == expected_padded_tokens', 'padded_tokens == {: [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]}', 'padded_tokens == {: [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]}', 'padded_tokens == {: [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]}']",[],[],[],[],[],[],[],[],[],[],[],[],"['field._indexed_tokens == {', 'padded_tokens == [[1, 2, 3, 4, 5, 0, 0, 0, 0, 0],', 'padded_tokens == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'padded_tokens == expected_padded_tokens', 'padded_tokens == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'padded_tokens == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'padded_tokens == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]']",[],[],[],[],[],[],[],[],[],[],[],[]
865,Matt Gardner,mattg@allenai.org,2018-07-20 23:34:05+10:00,be0f0c2528cd03c04454362cd257b72b54613f0e,https://github.com/allenai/allennlp/commit/be0f0c2528cd03c04454362cd257b72b54613f0e,"Remove extra .params (#1513)

Fixes #1447

I knew I saw this somewhere...",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
866,Mark Neumann,markn@allenai.org,2018-07-20 11:05:44-07:00,de0d3f7329c9c4f0204d87e76b6a956b0930ef3e,https://github.com/allenai/allennlp/commit/de0d3f7329c9c4f0204d87e76b6a956b0930ef3e,"Dependency parser (#1465)

* model shell

* add test fixture for dependency parser

* make batch model test ignore any key containing 'loss'

* add dummy root node so we can predict an arc for it

* mostly functional forward pass

* checkpoint, added a better split out structure for inference

* docs for loss

* add greedy decoding to parser

* add MST decoding

* add decode for dependency parser

* tweaks

* add dependency parsing metric and integrate into dependency parser

* cleanup

* add docs

* clean up biaffine attention

* add edmonds algorithm for decoding

* clean up

* refactor

* some initial tests for edmonds alg

* docs

* tidy up more

* add some tests for edmonds alg, remove symbolic labels from args

* add some more tests

* add some more docs

* fix typo

* m-m-m-more typos

* make pos tags optional so we can crush them with elmo

* add edmonds alg to docs

* cleanup

* explain complicated indexing thing, more docs

* remove from_params from dependency parser

* pylint

* superficial PR coments

* change name of model

* use range vec instead of arange

* metrics tweaks

* fix lint

* more tweaks

* fix docs

* appease sphinx

* add bias option to bilinear matrix attention

* refactor bilinear matrix attention to use matmuls

* remove biaffine attention

* more documentation about the model

* remove unecessary calls to .data

* simplify advanced indexing, replace use of timesteps",18,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,34,2,0,0,0,0,0,0,0,0,0,0,1,12,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[,', 'fields[]', 'fields[,', 'fields[].labels == [0, 0, 4, 4, 1, 6, 4, 4]', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 0, 4, 4, 1, 15, 15, 9, 9, 15, 9, 13, 13,', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 4, 4, 4, 0, 6, 4, 6, 6, 4]', 'set(decode_output_dict.keys()) == set([,', 'result.shape == (1, 2, 2)', 'not has_cycle', 'not cycle', 'has_cycle', 'cycle == [1, 2, 3]', 'not has_cycle', 'cycle == []', 'has_cycle', 'cycle == [3, 4]', 'not _find_cycle(heads, 5, [True] * 5)[0]', 'not _find_cycle(heads, 5, [True] * 5)[0]', 'types[child] == label_id_matrix[parent, child]', 'value == 1.0', 'metrics[] == 1.0', 'metrics[] == 1.0', 'metrics[] == 0.6', 'metrics[] == 0.0', 'metrics[] == 0.6', 'metrics[] == 0.6', 'metrics[] == 0.0', 'metrics[] == 0.0']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],"['[t.text for t in fields[,', 'fields[]', 'fields[]', 'fields[].labels == [0, 4, 4, 1, 6, 4, 4]', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 4, 4, 1, 15, 15, 9, 9, 15, 9, 13, 13,', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [4, 4, 4, 0, 6, 4, 6, 6, 4]']",[],[],[],[],[],[],[],[],[],[],[],[]
867,Mark Neumann,markn@allenai.org,2018-07-20 15:18:50-07:00,e0581b61c637cb2df6ea0fd178d571fb47dfd39e,https://github.com/allenai/allennlp/commit/e0581b61c637cb2df6ea0fd178d571fb47dfd39e,"Preserve best metrics (#1504)

* save the best validation metrics for all metrics

* lint

* remove print",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
868,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-22 15:12:29-04:00,1402b7c02aede1a8f832f64cdfb2e9ef1157faca,https://github.com/allenai/allennlp/commit/1402b7c02aede1a8f832f64cdfb2e9ef1157faca,"Add to_file method in Params and default preference ordering. (#1517)

* Add as_ordered_dict, as_file in Params and test for as_ordered_dict.

* Add to_file to take preference_orders arguments.

* Use params.to_file to save config file in train command.

* Add test for to_file and simplify test for as_ordered_dict.

* Remove unused import, correct docstring indentation, fix typo in default preference_orders

* Incorporate PR suggestions:

1. Add return type annotations
2. refactor order_func
3. Remove extra blank
4. refactor docstring
5. Use OrderedDict everywhere

* Revert back extra blank space for class separation.",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['json.dumps(ordered_params_dict) == json.dumps(expected_ordered_params_dict)', 'json.dumps(expected_ordered_params_dict) == json.dumps(ordered_params_dict)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
869,Mark Neumann,markn@allenai.org,2018-07-23 11:43:03-07:00,0722d7f199ec43af791870dbe741eec3e3103c69,https://github.com/allenai/allennlp/commit/0722d7f199ec43af791870dbe741eec3e3103c69,"DenseSparseAdam + CRF Feedforward layer (#1519)

Adds:
- DenseSparseAdam - this is just the dense and sparse versions of adam in pytorch combined, which makes it a lot less annoying to handle. I'll probably submit a PR to Pytorch with this at somepoint. I didn't modify the source at all apart from docstrings, so it needed a lot of `pylint: ignore`s.

- Ability to add a `Feedforward` layer after the encoder part in the CRF model (I needed this to reproduce some fine-grained NER results).",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
870,jzhou316,31744226+jzhou316@users.noreply.github.com,2018-07-23 15:22:30-04:00,2c9abf9a0fccff0957843b7a600a796097fe6933,https://github.com/allenai/allennlp/commit/2c9abf9a0fccff0957843b7a600a796097fe6933,"Minor change of a comment (#1500)

Original comment here about tensor size was a bit confusing.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
871,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-23 18:44:05-04:00,e4b86b0e6d803c451bba8170866c3b288824c079,https://github.com/allenai/allennlp/commit/e4b86b0e6d803c451bba8170866c3b288824c079,Show warning before ignoring key with unseparable batches from model.forward. (#1520),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
872,Mark Neumann,markn@allenai.org,2018-07-23 16:58:25-07:00,be69e52a0a2abfc4f6af20c9e45e25942c2b4ab0,https://github.com/allenai/allennlp/commit/be69e52a0a2abfc4f6af20c9e45e25942c2b4ab0,"Parser improvements (#1515)

- Add dropout (The original Dozat and Manning (2017) paper use variational dropout everywhere, which i've duplicated here.)
- Add ability to ignore labels in parser (originally I thought this was required for eval, but actually the parser evaluation ignores words on the basis of their POS tags, not dependency arcs, but I left it in because I thought it could be useful.)

- punctuation is ignored in most dependency parser evaluation by ignoring the scoring of words with punctuation based POS tags.

- Switch some keys when reading CONLLU data so that 1) the dataset reader could also read the PTB dependency parsing data and 2) so that head information for some of the tags was not included (this was an error because I wasn't so familiar with the format).

- Use the correct `reset=False` default value in `get_metrics`

- Transpose a score in the MST decoding so that the energy is correctly normalised wrt to the arcs.


With all these changes I can reproduce the original result ",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['fields[,', 'fields[,', 'value == 1.0']",[],[],[],[],[],[],[],[],[],[],[],[],"['fields[,', 'fields[,']",[],[],[],[],[],[],[],[],[],[],[],[]
873,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-24 15:21:13-04:00,8cf893e776df7be095f3660e4ec5f1a3719a0216,https://github.com/allenai/allennlp/commit/8cf893e776df7be095f3660e4ec5f1a3719a0216,"Add a scirpt to report broken links in all markdowns. (#1522)

This PR adds a script to report broken links in all markdowns in the project.

```
time python scripts/verify.py --checks check-links
UnReachable Links:
Verifying with ['check-links']
LinksValidity (check):

UnReachable Links:

0.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_as_a_library_pt2.md
Name: on GitHub
Link: https://github.com/allenai/allennlp-as-a-library-example/tree/0.5.1

1.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_as_a_library_pt2.md
Name: `static_html`
Link: https://github.com/allenai/allennlp-as-a-library-example/tree/0.5.1/static_html

2.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_as_a_library_pt2.md
Name: its own file
Link: https://github.com/allenai/allennlp-as-a-library-example/blob/0.5.1/static_html/demo.css

3.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_as_a_library_pt2.md
Name: add a `script` tag to load chart.js
Link: https://github.com/allenai/allennlp-as-a-library-example/blob/0.5.1/static_html/index.html#L47

4.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_as_a_library_pt2.md
Name: `my_library/__init__.py`
Link: https://github.com/allenai/allennlp-as-a-library-example/blob/0.5.1/my_library/__init__.py

5.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_as_a_library_pt2.md
Name: can be very simple
Link: https://github.com/allenai/allennlp-as-a-library-example/blob/0.5.1/my_library/predictors/paper_classifier_predictor.py

6.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_as_a_library_pt2.md
Name: placing that inside our `output` div
Link: https://github.com/allenai/allennlp-as-a-library-example/blob/0.5.1/static_html/index.html#L61

7.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_pretrained_models.md
Name: Named Entity Recognition model
Link: http://allennlp.org/models/#named-entity-recognition

8.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_as_a_library_pt2.md
Name: as a test fixture
Link: https://github.com/allenai/allennlp-as-a-library-example/tree/0.5.1/tests/fixtures

9.
Source: /Users/harshtrivedi/allennlp/tutorials/getting_started/using_as_a_library_pt2.md
Name: `text_to_instance`
Link: https://github.com/allenai/allennlp-as-a-library-example/blob/0.5.1/my_library/dataset_readers/semantic_scholar_papers.py#L68

python scripts/verify.py --checks check-links  2.97s user 0.70s system 34% cpu 10.761 total
```

Takes about 10 seconds.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
874,Andrej Zukov Gregoric,andrejzukovgregoric@gmail.com,2018-07-25 09:18:18+10:00,c9385e78b8ba033792738e346697e283363c8c73,https://github.com/allenai/allennlp/commit/c9385e78b8ba033792738e346697e283363c8c73,"Fixed broken link (#1508)

""Using AllenNLP as a Library (Part 1) - Datasets and Models"" links to part 2, ""Using AllenNLP as a Library (Part 2) - Predictions and Demos"" but the link was broken and needed fixing.",0,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
875,Michael Schmitz,michael@schmitztech.com,2018-07-24 18:02:59-07:00,f3fce4c99be5424f25c869bd64aa9b6287d4518b,https://github.com/allenai/allennlp/commit/f3fce4c99be5424f25c869bd64aa9b6287d4518b,Move cache breaker to the end. (#1527),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
876,Joel Grus,joelgrus@gmail.com,2018-07-24 18:56:03-07:00,c37ff2ca877585b11f62705637becd600aa7383a,https://github.com/allenai/allennlp/commit/c37ff2ca877585b11f62705637becd600aa7383a,"update config files to jsonnet format (#1479)

* update config files to jsonnet format

* rename json -> jsonnet",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
877,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-25 16:14:48-04:00,ad265f85e8d9668338c7e09ed564777f1a8a914e,https://github.com/allenai/allennlp/commit/ad265f85e8d9668338c7e09ed564777f1a8a914e,"Add output-file option in evaluate to save the computed metrics (#1512)

* Add output-file option in evaluate to save the computed metrics.

* Add missing --weights-file in evaluate docstring.

* Make usage of evaluate consistent with predict: same 1st and 2nd arguments.",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['computed_metrics == saved_metrics'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
878,Mark Neumann,markn@allenai.org,2018-07-25 15:53:03-07:00,e049afc0a6a53432074843cae8556f4cbe64bc9f,https://github.com/allenai/allennlp/commit/e049afc0a6a53432074843cae8556f4cbe64bc9f,"fix ud reader in case of implicit references (#1529)

Some UD annotations have automatically ""fixed"" implicit references, which have no head and are unattached to the the rest of the tree. They should just be ignored.

Also updates a pos tag I should have ignored for UD.",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 2, 3, 5, 5, 0, 5, 8, 5, 8, 11, 5, 11, 5]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
879,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-26 13:09:43-04:00,dc1ff363213afbb90dab8af7d756fbf1df33fa41,https://github.com/allenai/allennlp/commit/dc1ff363213afbb90dab8af7d756fbf1df33fa41,"Fix the reported broken links. (#1533)

Fixes the unreachable links reported by `check-links` (#1522). Please consider merging this after `check-links` has been added to CI so as to make sure CI fails without it.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
880,Joel Grus,joelgrus@gmail.com,2018-07-27 15:16:11-07:00,e32f486573adfb00dfb6396742ac5f8675908e86,https://github.com/allenai/allennlp/commit/e32f486573adfb00dfb6396742ac5f8675908e86,"fix BasicTextFieldEmbedder.from_params to reflect the constructor (#1474)

* fix BasicTextFieldEmbedder.from_params to reflect the constructor structure

* remove print statement

* use FromParams.from_params directly

* add a type ignore

* explicit is better than implicit",33,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['token_embedder(self.inputs).size() == (1, 4, 10)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
881,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-07-30 12:09:23-04:00,2154e7264f920042c43834b01910fc39c189aa83,https://github.com/allenai/allennlp/commit/2154e7264f920042c43834b01910fc39c189aa83,"Allow server start without field-names. (#1523)

* Allow server start without field-names.

* Allow server to turn ON w/o field-name, static_dir

* Fix a typo.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
882,Michael Schmitz,michael@schmitztech.com,2018-07-30 10:03:25-07:00,1c2a0deb2c32bb7294db0ae3a406a0d07f38e150,https://github.com/allenai/allennlp/commit/1c2a0deb2c32bb7294db0ae3a406a0d07f38e150,Remove requirements_test.txt (merge into requirements.txt) (#1541),4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
883,Michael Schmitz,michael@schmitztech.com,2018-07-30 10:04:37-07:00,10ac9ede83df2bb6747b42731e0a2fbabb680d61,https://github.com/allenai/allennlp/commit/10ac9ede83df2bb6747b42731e0a2fbabb680d61,Update install_requirements.sh,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
884,Mark Neumann,markn@allenai.org,2018-07-30 16:20:23-07:00,2ec4c5c2342935611f7346d45e40d51c6ad874c4,https://github.com/allenai/allennlp/commit/2ec4c5c2342935611f7346d45e40d51c6ad874c4,re-work dependency parser to use HEAD sentinel inside model (#1544),3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[,', 'fields[]', 'fields[,', 'fields[].labels == [0, 4, 4, 1, 6, 4, 4]', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 4, 4, 1, 15, 15, 9, 9, 15, 9, 13, 13,', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [4, 4, 4, 0, 6, 4, 6, 6, 4]', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [2, 3, 5, 5, 0, 5, 8, 5, 8, 11, 5, 11, 5]']",[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[,', 'fields[]', 'fields[,', 'fields[].labels == [0, 0, 4, 4, 1, 6, 4, 4]', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 0, 4, 4, 1, 15, 15, 9, 9, 15, 9, 13, 13,', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 4, 4, 4, 0, 6, 4, 6, 6, 4]', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 2, 3, 5, 5, 0, 5, 8, 5, 8, 11, 5, 11, 5]']",[],[],[],[],[],[],[],[],[],[],[],[]
885,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-07-30 21:23:55-07:00,c000ae224b563e70cf6142d0a26de48ba74b9349,https://github.com/allenai/allennlp/commit/c000ae224b563e70cf6142d0a26de48ba74b9349,made checklist updates more efficient (#1552),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
886,Joel Grus,joelgrus@gmail.com,2018-07-30 22:26:52-07:00,c2e70ca76872daf5c975bf8256a210938eaf3599,https://github.com/allenai/allennlp/commit/c2e70ca76872daf5c975bf8256a210938eaf3599,"upgrade to pytorch 0.4.1 + make work with python 3.7 (but still 3.6 also) (#1543)

* changes for pytorch 0.4.1

* increase tolerance for srl test

* update versions in setup.py

* add script to check requirements.txt vs setup.py + fix setup.py

* loosen bounds on pytorch version",13,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
887,Mark Neumann,markn@allenai.org,2018-07-31 09:16:09-07:00,09c2cc5616a8aec897f8fe06fda13179955bec69,https://github.com/allenai/allennlp/commit/09c2cc5616a8aec897f8fe06fda13179955bec69,"Dependency parser predictor (#1538)

completely boilerplate predictor",29,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['heads is not None', 'isinstance(heads, list)', 'all(isinstance(x, int) for x in heads)', 'head_tags is not None', 'isinstance(head_tags, list)', 'all(isinstance(x, int) for x in head_tags)', 'len(predicted_heads) == len(heads) - 1', 'len(predicted_dependencies) == len(head_tags) - 1', 'isinstance(predicted_dependencies, list)', 'all(isinstance(x, str) for x in predicted_dependencies)', 'result.get() is not None', 'result.get() is not None', 'result.get() is not None', 'len(results) == 2', 'heads is not None', 'isinstance(heads, list)', 'all(isinstance(x, int) for x in heads)', 'head_tags is not None', 'isinstance(head_tags, list)', 'all(isinstance(x, int) for x in head_tags)', 'len(predicted_heads) == sequence_length', 'len(predicted_dependencies) == sequence_length', 'isinstance(predicted_dependencies, list)', 'all(isinstance(x, str) for x in predicted_dependencies)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
888,Michael Schmitz,michael@schmitztech.com,2018-07-31 12:54:11-07:00,8438f91fe8691017aa81ad04ee3af238304fdabc,https://github.com/allenai/allennlp/commit/8438f91fe8691017aa81ad04ee3af238304fdabc,Remove the unused NltkWordSplitter and punkt model. (#1548),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
889,Michael Schmitz,michael@schmitztech.com,2018-07-31 16:13:11-07:00,dcba726a7c3f2b17be256d419df29a8b1c17d7b7,https://github.com/allenai/allennlp/commit/dcba726a7c3f2b17be256d419df29a8b1c17d7b7,"WIP: Skip tests that require Java in test-install (#1551)

* Skip java tests in test-install

* CD to the parent directory in test_install.  This addresses a regression introduced in https://github.com/allenai/allennlp/pull/1418.

* Exit with the same exit code as pytest.",6,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,4,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['java', 'java', 'java', 'java']","['mark.java', 'mark.java', 'mark.java', 'mark.java']",[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
890,Mark Neumann,markn@allenai.org,2018-08-01 11:43:15-07:00,6f0fec1336d351e6141c692be1f6e4d0bf4c21dc,https://github.com/allenai/allennlp/commit/6f0fec1336d351e6141c692be1f6e4d0bf4c21dc,"make passing different feedforward modules more flexible (#1555)

Just shuffling how I create feedforward layers so they aren't hardcoded.",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
891,Kevin Lin,kl2806@columbia.edu,2018-08-01 13:03:10-07:00,089d16dc4e57d70b06b7d23528c49cba54dda406,https://github.com/allenai/allennlp/commit/089d16dc4e57d70b06b7d23528c49cba54dda406,"SQL action sequences and Atis World (#1524)

- Add a module for generating action sequences from SQL queries
- Add functionality for generating numbers and strings for valid actions for the ATIS dataset
- Add a world module that will be used for the dataset reader",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(valid_actions.keys()) == {,', 'set(valid_actions[}', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == set()', 'set(valid_actions[]) == set()', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'action_sequence == [,', 'action_sequence == [,', 'action_sequence == \\', 'action_sequence == \\', 'action_sequence == \\', 'action_sequence is not None', 'possible_actions == \\']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
892,Kevin Lin,kl2806@columbia.edu,2018-08-01 18:32:20-07:00,52f44e245cc4f64df5a8211828f86f8583adb386,https://github.com/allenai/allennlp/commit/52f44e245cc4f64df5a8211828f86f8583adb386,Add parsimonious for SQL parsing to setup.py (#1558),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
893,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-02 10:05:37-07:00,87b32bb3f891f6520f36469de0af8840d46b02e2,https://github.com/allenai/allennlp/commit/87b32bb3f891f6520f36469de0af8840d46b02e2,"Expose iterator shuffling through Trainer config (#1557)

* Expose iterator shuffling through Trainer config

* Add shuffle to Trainer.from_params",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
894,Joel Grus,joelgrus@gmail.com,2018-08-02 10:52:45-07:00,15e36458b1f6a7452492bd107cd631fede3617a8,https://github.com/allenai/allennlp/commit/15e36458b1f6a7452492bd107cd631fede3617a8,"openai transformer LM embedder (#1525)

* add token indexer

* first pass at embedder

* work on test

* get embedder working

* add another test

* get things working correctly

* address PR comments

* truncate offsets

* make byte pair indexer fail for too long inputs

* fix linting + docs

* address pr feedback",14,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,1,0,1,0,0,0,0,1,1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'set(indices.keys()) == {}', 'text_tokens[:6] == [', 'offsets == [', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}']",['(RuntimeError)'],[],['()'],[],[],[],[],['skip()'],['mark.skip()'],[],[],"['import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
895,Michael Schmitz,michael@schmitztech.com,2018-08-03 07:38:43-07:00,d2c02742ea0f147366d51a73ecb1c209e61425c6,https://github.com/allenai/allennlp/commit/d2c02742ea0f147366d51a73ecb1c209e61425c6,Don't use a hard-coded temp directory. (#1564),1,False,True,True,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
896,Michael Schmitz,michael@schmitztech.com,2018-08-03 07:40:15-07:00,025b5e7c39ebb06b9fc34f9b96943f5fa292238d,https://github.com/allenai/allennlp/commit/025b5e7c39ebb06b9fc34f9b96943f5fa292238d,Remove a step from verify. (#1565),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
897,Mark Neumann,markn@allenai.org,2018-08-06 09:13:20-07:00,07bfc31299b48a05ef89cd9e35cd121742224797,https://github.com/allenai/allennlp/commit/07bfc31299b48a05ef89cd9e35cd121742224797,"Demo features for the dependency parser (#1560)

* wire words through the model

* add function to create hierplane trees from model output

* shuffle

* tidy up

* don't recompute child indices in recursion

* fix index offset

* fix type annotation

* test tree creation

* undo 'optimisation'

* span highlighting on fleek

* add styling and fix span highlighting

* fix tests

* really fix test

* add overrides",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['result.get() == {'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
898,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-06 11:34:35-07:00,6b37dd2be54c0ac178feee2d4428ac9f07d4c5a6,https://github.com/allenai/allennlp/commit/6b37dd2be54c0ac178feee2d4428ac9f07d4c5a6,Turn off shuffling during evaluation (#1578),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
899,Mark Neumann,markn@allenai.org,2018-08-06 12:58:39-07:00,4fa4dc23ccc5a0f5332d73e8da7688d343296f82,https://github.com/allenai/allennlp/commit/4fa4dc23ccc5a0f5332d73e8da7688d343296f82,fix and pin conllu dependency == 1.0 (#1581),3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
900,Joel Grus,joelgrus@gmail.com,2018-08-07 08:01:10-07:00,bf760b040d913674591613e3e6faa2cb859121c6,https://github.com/allenai/allennlp/commit/bf760b040d913674591613e3e6faa2cb859121c6,"be friendlier to windows users (#1572)

* be friendlier to windows users

* conditional import for resource

* get things in the right order",5,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
901,Mark Neumann,markn@allenai.org,2018-08-07 10:57:31-07:00,9194b30bb77b6011e92572551c873d65d10c0554,https://github.com/allenai/allennlp/commit/9194b30bb77b6011e92572551c873d65d10c0554,"copy bin/ into image (#1587)

Our instructions for command line usage didn't work in a docker image because we didn't copy `bin/` into the image.
Fixes #1582",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
902,Michael Schmitz,michael@schmitztech.com,2018-08-07 13:22:28-07:00,12b74e5a91ef52bea2c1574fc76b52e8f78f86ac,https://github.com/allenai/allennlp/commit/12b74e5a91ef52bea2c1574fc76b52e8f78f86ac,Add some debugging echo commands to pip. (#1579),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
903,Joel Grus,joelgrus@gmail.com,2018-08-07 14:11:38-07:00,068407e3d476750ee75fd52840be7a160b693760,https://github.com/allenai/allennlp/commit/068407e3d476750ee75fd52840be7a160b693760,"make --include-package include all submodules (#1586)

* make import_submodules go more than one level deep

* remove assert False",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['in sys.modules'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
904,Michael Schmitz,michael@schmitztech.com,2018-08-08 08:58:44-07:00,152b590caab8732792689b85686788f2197b93c4,https://github.com/allenai/allennlp/commit/152b590caab8732792689b85686788f2197b93c4,Output details when running check-links. (#1569),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
905,Michael Schmitz,michael@schmitztech.com,2018-08-08 10:32:49-07:00,b79d500108f61f42319910afb08cf9e98ea7dea5,https://github.com/allenai/allennlp/commit/b79d500108f61f42319910afb08cf9e98ea7dea5,"Add file friendly logging for elmo. (#1593)

* Add file friendly logging for elmo.

* Fixup

* Pylint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
906,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-10 23:36:56-07:00,4fca0287cb1374e36bf8a12e61f5fafc0825a5e5,https://github.com/allenai/allennlp/commit/4fca0287cb1374e36bf8a12e61f5fafc0825a5e5,"Log number of parameters in optimizers (#1598)

Logs the number of parameters used when building optimizers `from_params`",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
907,Joel Grus,joelgrus@gmail.com,2018-08-13 09:34:30-07:00,49626cc1fae904bdaff32cbe9d28a8e930c108d1,https://github.com/allenai/allennlp/commit/49626cc1fae904bdaff32cbe9d28a8e930c108d1,filter out numpy 'size changed' warnings (#1601),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
908,Mark Neumann,markn@allenai.org,2018-08-13 10:41:10-07:00,e0e5f4a87333785f982577fde4abb9e56aa696bd,https://github.com/allenai/allennlp/commit/e0e5f4a87333785f982577fde4abb9e56aa696bd,revert conllu changes (#1600),3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
909,Joel Grus,joelgrus@gmail.com,2018-08-13 11:06:44-07:00,45fff838ba3fa8d85daba3482b30fd681a0eb3e0,https://github.com/allenai/allennlp/commit/45fff838ba3fa8d85daba3482b30fd681a0eb3e0,use empty list for no package not empty string (#1602),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
910,Evan Pete Walsh,epwalsh10@gmail.com,2018-08-14 08:11:29-07:00,982ceddfeb4e44333e1019927a162056931e7d2a,https://github.com/allenai/allennlp/commit/982ceddfeb4e44333e1019927a162056931e7d2a,"Small typo fixes in tutorial (#1603)

* update evaluate command

* fix

* update using_pretrained_models.md",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
911,Matt Gardner,mattg@allenai.org,2018-08-14 13:52:01-07:00,4eaeff727b528169541e429b582fc444f26600c0,https://github.com/allenai/allennlp/commit/4eaeff727b528169541e429b582fc444f26600c0,"Fix use of scalar tensors in ConllCorefScores (#1604)

* Added test for #1545, fixed test, and improved documentation

* pylint

* mypy",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(clusters) == 1', 'set(clusters[0]) == {(4, 6), (8, 9)}', 'mention_to_cluster == {(4, 6): clusters[0], (8, 9): clusters[0]}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
912,Mark Neumann,markn@allenai.org,2018-08-14 19:00:12-07:00,954012557ab2488bebda4101d81357ae9a6d02ce,https://github.com/allenai/allennlp/commit/954012557ab2488bebda4101d81357ae9a6d02ce,"Tree decoding fix (#1606)

* initial fix

* correct approach

* fix and test

* fix predictor test

* fix pylint

* use unique edge weights",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['heads.tolist()[0] == [-1, 0, 0]', 'heads.tolist()[0] == [-1, 0, 1]', 'list(heads) == [-1, 2, 0]', 'result.get(,']",[],[],[],[],[],[],[],[],[],[],[],[],['result.get() == {'],[],[],[],[],[],[],[],[],[],[],[],[]
913,Joel Grus,joelgrus@gmail.com,2018-08-15 09:29:44-07:00,e84826d8a6fbe437968fad281a1967e4f6fba943,https://github.com/allenai/allennlp/commit/e84826d8a6fbe437968fad281a1967e4f6fba943,bump version number to v0.6.0,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
914,Joel Grus,joelgrus@gmail.com,2018-08-15 09:42:29-07:00,b20fa1dccf225e46e97dba41107c877f6eff97db,https://github.com/allenai/allennlp/commit/b20fa1dccf225e46e97dba41107c877f6eff97db,Bump version numbers to vv0.6.1-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
915,Matthew Peters,matt-peters@users.noreply.github.com,2018-08-16 10:22:33-07:00,59132d2be0e871b512c03a08fe80eb41ef7418a9,https://github.com/allenai/allennlp/commit/59132d2be0e871b512c03a08fe80eb41ef7418a9,Avoid divide by zero in CategoricalAccuracy (#1617),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('AlmostEqual', '(accuracy.get_metric(), 0.0)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
916,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-16 13:05:04-07:00,82686c10bdca062a7e41825000c39372de354479,https://github.com/allenai/allennlp/commit/82686c10bdca062a7e41825000c39372de354479,"Add IOB1 as allowed CRF constraint (#1615)

* Add IOB1 as allowed CRF constraint

* Fix spacing

* Add is_transition_allowed function

* Replace token with label

* Replace n_tags with num_tags

* Consolidate everything except START and END tags

* Handle boundary tags in is_transition_allowed

* Fix lint, clean up conditional branching",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['set(allowed) == {                            # Extra column for end tag.'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
917,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-17 08:27:15-07:00,3107a0c84f6ad098e0ac44f03d5de26a026d58cd,https://github.com/allenai/allennlp/commit/3107a0c84f6ad098e0ac44f03d5de26a026d58cd,"Don't error if fine-tune serialization dir already exists (#1622)

Changing this to match the behavior of other commands, like [`train`](https://github.com/allenai/allennlp/blob/82686c10bdca062a7e41825000c39372de354479/allennlp/commands/train.py#L222) and [`make-vocab`](https://github.com/allenai/allennlp/blob/1402b7c02aede1a8f832f64cdfb2e9ef1157faca/allennlp/commands/make_vocab.py#L83). 

This causes `fine-tune` to fail with beaker at the moment.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
918,Joel Grus,joelgrus@gmail.com,2018-08-17 10:56:33-07:00,58119c038b07ee5de2c6b0b9f0c6c7d505857ba9,https://github.com/allenai/allennlp/commit/58119c038b07ee5de2c6b0b9f0c6c7d505857ba9,"make fine-tune not expand vocabulary by default (#1623)

* make fine-tune not expand vocabulary by default

* fix comment

* address PR comments + add a test for vocab expansion",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(RuntimeError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
919,Handsome Zebra,handsomezebra@users.noreply.github.com,2018-08-17 12:04:31-07:00,76a65a8f6bee52356bfa6767d2f4799798521c62,https://github.com/allenai/allennlp/commit/76a65a8f6bee52356bfa6767d2f4799798521c62,"BiMPM model (#1594)

* Adding Quora data reader and BiMPM model.

* Refactoring and renaming to pass pylint.

* Reduce batch size.

* Adding docs.

* Make title underline longer.

* Adding doc toctree.

* Various improvements to speed and memory.

* Improve comments.

* 1. Remove zip file handling.
2. Use allennlp s3 for quora data download.
3. Move masked_max, masked_mean to nn.util
4. Various variable renaming, comments improvements, etc.

* Remove unused url pattern match and change num_perspective to num_perspectives.",20,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', '[t.text for t in fields[]', '[t.text for t in fields[]', 'fields[]', 'in output_dict', 'vecs_p.size() == torch.Size([batch, len1, 10 + 10 * l])', 'vecs_h.size() == torch.Size([batch, len2, 10 + 10 * l])', 'ml_fw.get_output_dim() == ml_bw.get_output_dim() == vecs_p.size(2) // 2 == vecs_h.size(2) // 2', 'not numpy.isnan(vector_1d_maxed).any()', 'not numpy.isnan(vector_1d_mean).any()']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
920,Evan Pete Walsh,epwalsh10@gmail.com,2018-08-17 14:54:59-07:00,659bf2562b3fc8524477368bd0f72bbfd0832cbc,https://github.com/allenai/allennlp/commit/659bf2562b3fc8524477368bd0f72bbfd0832cbc,"Allow files to be downloaded from S3 (#1620)

* handle s3 files

* pull in to file object

* get s3 etag

* add some tests

* better unit tests

* added test for etag

* add a few more tests

* add status code to error msg

* fix unit tests

* add a few comments",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['split_s3_path()', 'split_s3_path()', 'len(buckets) == 1', 'buckets[0][', 'get_file_info(', 'isinstance(etag, str)', 'etag.startswith()', 'os.stat(temp_file.name).st_size != 0']","['(ValueError)', '(FileNotFoundError)', '(FileNotFoundError)', '(FileNotFoundError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
921,Kevin Lin,kl2806@columbia.edu,2018-08-17 17:44:05-07:00,0a5aea7ae8a8fad56773d8234301427867507496,https://github.com/allenai/allennlp/commit/0a5aea7ae8a8fad56773d8234301427867507496,"atis dataset reader (#1577)

* Add a dataset reader for ATIS
* Add binary linking scores between each utterance token and each entity
* Refactor some of how we get numbers to reduce the number of false positives",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 12', 'instance.fields.keys() == \\', '[t.text for t in instance.fields[].tokens] == \\', 'isinstance(instance.fields[].as_tensor({}), AtisWorld)', 'valid_strs == set(world.valid_actions[])', 'world.valid_actions[] == \\', 'world.valid_actions[] == \\', 'world.linking_scores.shape[0] == \\', 'world.linking_scores.shape[1] == \\', 'world.linking_scores[entity_index][question_index] == \\', 'set(valid_actions[]) == \\']",[],[],[],[],[],[],[],[],[],[],[],[],['set(valid_actions[]) == set()'],[],[],[],[],[],[],[],[],[],[],[],[]
922,Handsome Zebra,handsomezebra@users.noreply.github.com,2018-08-19 09:07:26-07:00,7a9975eb1cb945405d057a15c1a40c4c56b687b2,https://github.com/allenai/allennlp/commit/7a9975eb1cb945405d057a15c1a40c4c56b687b2,Fix bimpm config file for names num_perspective(s). (#1627),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
923,Mark Neumann,markn@allenai.org,2018-08-20 12:22:36-07:00,8c89b08a9ee11f62d86a007cee42e5c68afa3d02,https://github.com/allenai/allennlp/commit/8c89b08a9ee11f62d86a007cee42e5c68afa3d02,"Parser decoding fix 2 (#1619)

* decode the labels using the un-modified scores

* add test, fix root head index to be 0 not -1

* labels -> tags

* fix tests

* improve comment

* clarify comments

* add sniff test, de-verbose parser output

* remove useless test",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(decode_output_dict.keys()) == set([,', 'list(heads) == [-1, 0, 0]', 'heads_model.tolist()[0] == [0, 0, 1]', 'heads.tolist()[0] == [0, 0, 1]', 'tags.tolist()[0] == [0, 1, 0]', 'result[]', 'result[]', 'result[]', 'result[] == [3, 0, 2, 3, 4, 2]', 'len(predicted_heads) == len(words)', 'len(predicted_dependencies) == len(words)']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(decode_output_dict.keys()) == set([,', 'heads.tolist()[0] == [-1, 0, 0]', 'heads.tolist()[0] == [-1, 0, 1]', 'set(DEFAULT_MODELS.keys()) == {', 'heads is not None', 'isinstance(heads, list)', 'all(isinstance(x, int) for x in heads)', 'head_tags is not None', 'isinstance(head_tags, list)', 'all(isinstance(x, int) for x in head_tags)', 'len(predicted_heads) == len(heads) - 1', 'len(predicted_dependencies) == len(head_tags) - 1', 'heads is not None', 'isinstance(heads, list)', 'all(isinstance(x, int) for x in heads)', 'head_tags is not None', 'isinstance(head_tags, list)', 'all(isinstance(x, int) for x in head_tags)']",[],[],[],[],[],[],[],[],[],[],[],[]
924,Evan Pete Walsh,epwalsh10@gmail.com,2018-08-20 14:11:32-07:00,14aee14e854e00d8c8ca77eeed8db3aa05091898,https://github.com/allenai/allennlp/commit/14aee14e854e00d8c8ca77eeed8db3aa05091898,fix calculation of estimated time remaining (#1631),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
925,Nicholas A. Lourie,nicholasl@allenai.org,2018-08-20 14:16:31-07:00,4c6731b91a946653988a9d016b2b6aae1900e999,https://github.com/allenai/allennlp/commit/4c6731b91a946653988a9d016b2b6aae1900e999,"Pip install the library in editable mode (-e) (#1592)

* Expand and organize the .gitignore file

* Update the readme to suggest installing the library in editable mode

* `pip install` the library in editable mode (-e) so people can get
a development environment closer to what actual users experience",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
926,Matthew Peters,matt-peters@users.noreply.github.com,2018-08-20 17:15:32-07:00,bf75c9bb549c00e62032bb865de9db7692ce396c,https://github.com/allenai/allennlp/commit/bf75c9bb549c00e62032bb865de9db7692ce396c,"Allow configurable label namespaces (#1621)

* Add optional label namespace for CoNLL 2003 dataset reader

* Allow to specify vocabulary namespace for CCGBank

* Allow CoNLL 2003 dataset reader to also read ConLL 2000

* Allow optional label namespace for Penn Treebank reader

* Allow to change the POS namespace in PTB reader

* pylint

* mypy

* End CCGBank reader namespace with labels",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('SetEqual', '(')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['len(instances) == 2'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
927,Eunsol,high07@gmail.com,2018-08-20 20:02:01-07:00,4df4638b186554c994e7fd841a766e992ee81ba1,https://github.com/allenai/allennlp/commit/4df4638b186554c994e7fd841a766e992ee81ba1,"Data reader for QUAC (#1624)

* quac initial commit

* random files

* l

* pull

*  pushing

* Attention version, but seems to be buggy.. ( no effect on scores )

* all

*  pushing

* upload

* DQA SEQ working version

* Added followup info

* fixed V2 bug

* fixed V2 bug

* question num marker

* push to taranis

* fix eval to match official script

* fixing eval script

* fixing eval

*  eval mismatch bug

*  push to taranis

*  final?

* remote data

* removing

* preparing pull request

* removing diffs

* removing query addition

* mask bug fixed

* cpu support

* fixed cuda

* making dataset only pull request

* adding back some files

*  removing tag

* moved

* added api doc

* adding dataset rst

* addressed comments from deneutoy

* fixed some lint errors

* fixed doc api, wrong continuation from pylint

* fixing mypy errors

* fixing one more mypy error

* removing repeated doc

* fixed mypy error

* last minute changes

* indented the data",7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['instances[0].fields[].sequence_length() == 6', 'instances[0].fields[].sequence_length() == 6', '[t.text for t in instances[0].fields[]', 'len(instances) == 1', '[t.text for t in instances[0].fields[]', '[x.label for x in instances[0].fields[]', '[x.label for x in instances[0].fields[]', 'instances[0].fields[] * passage_length', 'instances[0].fields[].field_list[1].labels == prev_1_list', 'instances[0].fields[].field_list[2].labels == prev_2_list']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
928,Martino Mensio,martinomensio@outlook.it,2018-08-21 14:27:37+01:00,2e47ac48530fc2f9aafc179c4c6fefe4a8cb714d,https://github.com/allenai/allennlp/commit/2e47ac48530fc2f9aafc179c4c6fefe4a8cb714d,"typing is part of standard library from python3.6 (gives errors on python3.7) (#1638)

* typing is part of standard library from python3.6
installing it on python3.7 causes AttributeError: type object 'Callable' has no attribute '_abc_registry'
refers #1457 and python/typing/issues/573

* remove typing backport because is part of python3.6 natively and allennlp requires python3.6",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
929,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-08-21 11:43:43-04:00,be76b5c0d987238a090c754d4d4ea3a17ee94387,https://github.com/allenai/allennlp/commit/be76b5c0d987238a090c754d4d4ea3a17ee94387,Add missing --recover flag to train docs (#1640),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
930,Matt Gardner,mattg@allenai.org,2018-08-21 12:41:44-07:00,b70e026702c590618552ab857fc6661662ab72f2,https://github.com/allenai/allennlp/commit/b70e026702c590618552ab857fc6661662ab72f2,"Make LinearAttention and LinearMatrixAttention memory-efficient (#1632)

* Make LinearAttention and LinearMatrixAttention memory efficient

* Added a sanity check test for when dimension to multiply on is ambiguous

* Switched from sum to matmul, which should reduce memory usage

* Rename function, improve a bit of documentation",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
931,Evan Pete Walsh,epwalsh10@gmail.com,2018-08-21 18:30:13-07:00,1d431885b436fb0a6bebaf5478030f033bca0a07,https://github.com/allenai/allennlp/commit/1d431885b436fb0a6bebaf5478030f033bca0a07,"Add learning rate to logs (#1641)

* log learning rate

* use `add_train_scalar` instead of modifying metrics

* rename",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
932,Kaj Bostrom,bostromkaj@gmail.com,2018-08-22 10:03:45-07:00,bca6c2a17741468b0d202c7a986ed1e407f507d2,https://github.com/allenai/allennlp/commit/bca6c2a17741468b0d202c7a986ed1e407f507d2,"make max_vocab_size default to None for a given namespace in Vocabulary._extend (#1643)

* make max_vocab_size default to None in Vocabulary._extend

* add regression test for max_vocab_size change

* fix max_vocab_size default_dict case, revise unit test

* Appease pylint

Sorry to directly update your master branch; it's better to create a branch in your fork when making a PR.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(vocab.get_index_to_token_vocabulary().values()) == 3 # 1 + 2', 'len(vocab.get_index_to_token_vocabulary().values()) == 28 # 26 + 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
933,Mark Neumann,markn@allenai.org,2018-08-22 15:53:47-07:00,681a9cfee26b6a0bccb4d4671e64e5fb9f84475e,https://github.com/allenai/allennlp/commit/681a9cfee26b6a0bccb4d4671e64e5fb9f84475e,"make pos selection an option in dataset reader, use in predictor (#1648)

* make pos selection an option in dataset reader, use in predictor

* remove print

* fix docs, skip sniff test for dependency parser temporarily

* add comment",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[,', 'fields[]', 'fields[,', 'fields[].labels == [0, 4, 4, 1, 6, 4, 4]', 'tags == []', 'tags == []']",[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
934,Evan Pete Walsh,epwalsh10@gmail.com,2018-08-22 16:27:33-07:00,301f2d68b100683c04693669c7b1157fd8a16d6b,https://github.com/allenai/allennlp/commit/301f2d68b100683c04693669c7b1157fd8a16d6b,"Implement cosine with restarts (#1647)

* implement cosine with restarts

* update

* address comments by @matt-gardner",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(TypeError):')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['sched.t_max == 5', 'sched._initialized is True', 'optim.param_groups[0][] == 1.0', 'lrs[it] == lr']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
935,Evan Pete Walsh,epwalsh10@gmail.com,2018-08-23 08:55:49-07:00,4ade6e4b587690454cf8cc6ef72f7a1066184fd7,https://github.com/allenai/allennlp/commit/4ade6e4b587690454cf8cc6ef72f7a1066184fd7,"Fix module docstring for training.learning_rate_schedulers (#1649)

* fix module docstring for learning rate schedulers

* fix line-too-long",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
936,Matt Gardner,mattg@allenai.org,2018-08-23 10:53:37-07:00,d27770a7c9e275a3b3f52e90619bbc5f851754ae,https://github.com/allenai/allennlp/commit/d27770a7c9e275a3b3f52e90619bbc5f851754ae,Make replace_masked_values more efficient by using masked_fill (#1651),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
937,Michael Schmitz,michael@schmitztech.com,2018-08-23 13:39:22-07:00,fea0d0a2a61b9688c698fd1696442e0d7ef806e2,https://github.com/allenai/allennlp/commit/fea0d0a2a61b9688c698fd1696442e0d7ef806e2,"Upgrade flask to avoid security vulnerability. (#1653)

GitHub reported a security vulnerability",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
938,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-23 15:37:44-07:00,5e13d24c5794d48720d6390975f9a126f0122770,https://github.com/allenai/allennlp/commit/5e13d24c5794d48720d6390975f9a126f0122770,"Fix Conll2003 reader docs to reflect true label namespace names (#1655)

The docs for the conll2003 reader say:

```
    feature_labels: ``Sequence[str]``, optional (default=``()``)
        These labels will be loaded as features into the corresponding instance fields:
        ``pos`` -> ``pos_tags``, ``chunk`` -> ``chunk_tags``, ``ner`` -> ``ner_tags``
        Each will have its own namespace: ``pos_labels``, ``chunk_labels``, ``ner_labels``.
        If you want to use one of the labels as a `feature` in your model, it should be
        specified here.
```

however, the namespaces are improperly named `pos_tags`, `chunk_tags`, etc. This fixes them.

cc @matt-peters this might affect you?",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
939,Mark Neumann,markn@allenai.org,2018-08-23 16:11:31-07:00,362060ac513c7bbb82d075a9304637a9bbbebbc5,https://github.com/allenai/allennlp/commit/362060ac513c7bbb82d075a9304637a9bbbebbc5,"add back sniff test for parser (#1654)

* add back sniff test for parser

* pylint",1,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,1,0,0,0,0,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['result[]', 'result[] == [2, 0, 2, 2, 4, 2]']",[],[],[],[],[],[],[],[],[],[],[],[],"['result[]', 'result[] == [3, 0, 2, 3, 4, 2]']",[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],['import pytest']
940,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-23 17:13:21-07:00,75abebb437042e4709ecf4e9af770df6a4912896,https://github.com/allenai/allennlp/commit/75abebb437042e4709ecf4e9af770df6a4912896,"Standardize tagging datasets (#1656)

* Modify CCGBank dataset reader to match Conll2003

* Fix typo

* Correct IOB1 vs BIO explanation for NER vs. chunking

* Fix tag_label default in docs for ccgbank reader

* Remove BIO note in docs, move _VALID_LABELS into Conll2003DatasetReader

* Fix lint",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
941,Matt Gardner,mattg@allenai.org,2018-08-24 10:24:46-07:00,abfb32dd9303358c670a7567df445de02f560868,https://github.com/allenai/allennlp/commit/abfb32dd9303358c670a7567df445de02f560868,"Refactoring how actions are handled in the semantic parsing code (#1294)

* Saving state; getting close to done with the action refactoring

* Got initial test passing

* Remove old unnecessary test

* Got the simple training test passing

* Small bug fix

* Added bilinear attention, changed the parser to use it, other tweaks

* Updating training config

* Un-comment-out an essential bit of code, update test configs

* Added back in action bias

* Pass the right parameters to the decoder step in the NLVR parser

* Make activation configurable, use tanh for NLVR

* Update training config

* Comment out broken code for a minute

* Move action bias to its own parameter again

* Fix bug where state was modified when there was a lambda

* Remove Nlvr state and step, update coverage parser to use WikiTables state and step

* Splitting things up into separate methods; not quite done with that

* Fixing mypy issues

* Fix chunking bug

* Starting to rename the State and Step objects

* Splitting up DecoderStep into multiple TransitionFunctions; getting close to done

* Got all NLVR tests passing

* Fix evalb stuff

* Got WikiTables ERM parser working.  I think I'm done...

* Increase tolerance

* Fix BasicTransitionFunctionTest

* Trying to appease mypy...

* Fixed GrammarState tests

* Pylint

* More pylint

* mypy

* docs

* Increase tolerance

* Fix ERM test

* Increase tolerance in RnnState comparison

* Increase tolerance on debug info

* Addressed PR comments",47,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,17,0,0,0,0,0,0,0,0,0,0,0,0,43,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],"['field1 == field2, f', 'len(new_states) == 2', 'new_state.batch_indices == [0]', 'actual in expected_possibilities', 'new_state.possible_actions == self.possible_actions', 'new_state.batch_indices == [1]', 'new_state.action_history == [[3, 4, 0]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.possible_actions == self.possible_actions', 'best_state.action_history[0] == [0, 2, 4]', 'state.get_valid_actions() == s_actions', 'state.get_valid_actions() == t_actions', 'state.get_valid_actions() == e_actions', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [3, 4]', 'actions[][2] == [3, 4]']",[],[],[],[],[],[],[],[],[],[],[],[],"['field1 == field2', 'to_embed == expected_to_embed', 'to_link == expected_to_link', 'considered == expected_considered', 'to_embed == expected_to_embed', 'to_link is None', 'considered == expected_considered', 'tuple(embeddings.size()) == (3, 3, 4)', 'tuple(action_logits.size()) == (3, 3)', 'len(new_states) == 2', 'new_state.batch_indices == [0]', 'new_state.action_history == [[4]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.action_indices == self.action_indices', 'new_state.possible_actions == self.possible_actions', 'new_state.batch_indices == [1]', 'new_state.action_history == [[3, 4, 0]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.action_indices == self.action_indices', 'new_state.possible_actions == self.possible_actions', 'len(new_states) == 2', 'new_state.batch_indices == [0]', 'new_state.action_history == [[1, 1]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.action_indices == self.action_indices', 'new_state.possible_actions == self.possible_actions', 'new_state.batch_indices == [1]', 'new_state.action_history == [[3, 4, 0]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.action_indices == self.action_indices', 'new_state.possible_actions == self.possible_actions', 'action_indices[(0, 0)] == action_indices[(1, 2)]', 'action_indices[(1, 1)] == -1', 'len(set(action_indices.values())) == 4', 'actions_to_entities == {', 'decoded_info[][0] == [[0, 2, 4]]', 'state.get_valid_actions() == [1, 2]', 'state.get_valid_actions() == [3, 4]', 'state.get_valid_actions() == []', 'state.get_valid_actions() == [1, 2, 5]', 'state.get_valid_actions() == [1, 2, 5]', 'state.get_valid_actions() == [3, 4]', 'state.get_valid_actions() == [3, 4]']",[],[],[],[],[],[],[],[],[],[],[],[]
942,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-24 13:40:56-07:00,c31d5f9c0f356c5345de8b0afb5f3866b269caa1,https://github.com/allenai/allennlp/commit/c31d5f9c0f356c5345de8b0afb5f3866b269caa1,"Fix conll2000 data reading (#1657)

* Remove ability of conll2003 reader to read conll2000

* Add Conll2000 dataset reader and test

* Fix lint

* Fix typo in explanation of BIO coding

* Add docs

* Make CRFTagger work with extra inputs to forward()

* Test Conll2000 chunking in CrfTagger

* Fix lint

* fix conditional",10,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,2,2,2,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'tokens == [,', 'fields[].labels == expected_labels', 'tokens == [,', 'fields[].labels == expected_labels']",[],[],[],[],[],[],"['(, (True, False))', '())']","['parametrize(, (True, False))', 'parametrize())']","['mark.parametrize(, (True, False))', 'mark.parametrize())']",[],[],['import pytest'],['len(instances) == 2'],[],[],[],[],[],[],[],[],[],[],[],[]
943,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-24 16:04:22-07:00,994b996f9f56e36a39a5feca3d149bcccda13afd,https://github.com/allenai/allennlp/commit/994b996f9f56e36a39a5feca3d149bcccda13afd,"Make CrfTagger work with non-BIO tagging tasks (#1661)

Would recommend looking at #1657 first, but this makes the `CrfTagger` work on non bio-tagging tasks like CCG supertagging and POS tagging.

TODO:
- [x] This is a breaking change, do we want to leave the `constraint_type` argument around for a few more versions?
- [x] Fix the training configs that use this tagger (e.g. `ner.jsonnet`)",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model._f1_metric is not None', 'model._f1_metric._label_encoding == ', 'model.label_encoding == ', 'model.crf._constraint_mask.sum().item() != (model.num_tags + 2)**2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
944,Eunsol,high07@gmail.com,2018-08-27 08:46:43-07:00,0b3ebcf978997eb99f95dbf0ffb0fc36b6c2b47a,https://github.com/allenai/allennlp/commit/0b3ebcf978997eb99f95dbf0ffb0fc36b6c2b47a,"Reading comprehension model for QUAC dataset (#1625)

* quac initial commit

* random files

* l

* pull

*  pushing

* Attention version, but seems to be buggy.. ( no effect on scores )

* all

*  pushing

* upload

* DQA SEQ working version

* Added followup info

* fixed V2 bug

* fixed V2 bug

* question num marker

* push to taranis

* fix eval to match official script

* fixing eval script

* fixing eval

*  eval mismatch bug

*  push to taranis

*  final?

* remote data

* removing

* preparing pull request

* removing diffs

* removing query addition

* mask bug fixed

* cpu support

* fixed cuda

* making dataset only pull request

* adding back some files

* model only

* adding modules needed for the model

* remove tagger

* before merging

* preparing release, writing test...

* added dataset reader test, refactored some codes after pylint..

* adding api docs

* fixed missing reference

* fixing prev_a incoherent reference

* removed some irrelevant file not belongs to this pull request

* fixing some pylint comments

* Delete allennlp.data.dataset_readers.dqa.rst

* Delete allennlp.models.reading_comprehension.dqa.rst

* Delete variational_dropout.py

* before merging

* r

* in the process of modifying quac model

* check if working properly after swapping tri_linear_attention to linear_attention

* fixed some names

* fixed datareader bug

* changing

* fetched new linear

* roughly working version, needs checking

* fixed turn number attention for context = 0

* addressed some of matt's points

* merging the right linear attention files

* fixed residual dropout to be applied everywhere

* pulling

* fixed text field embedder

* quacmodel

* quacmodel

* Delete kk

* addressed most of the comments, test still needs some work

* Update model_test_case.py

* Delete quac.json

* Update dialog_qa.py

* for merge

*  pulling the test

* made test smaller

* made test smaller

* Update __init__.py

* ;

* Update dialog_qa.py

* added config file

* Update dialog_qa.py",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'in output_dict', 'in output_dict']",[],[],[],[],[],[],[],[],[],[],[],[],['len(instances) == 1'],[],[],[],[],[],[],[],[],[],[],[],[]
945,Matt Gardner,mattg@allenai.org,2018-08-27 09:13:02-07:00,9caac661e1e15510ac7f035965a22a53ac65a482,https://github.com/allenai/allennlp/commit/9caac661e1e15510ac7f035965a22a53ac65a482,Fix lazy dataset reader bug in ModelTestCase (#1668),1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
946,Handsome Zebra,aaahchi@gmail.com,2018-08-27 09:32:00-07:00,6c7c807220be45e106bde12c0e6d128a70ca32c8,https://github.com/allenai/allennlp/commit/6c7c807220be45e106bde12c0e6d128a70ca32c8,"Adding decoder to bimpm and improve demo server. (#1665)

* Adding decoder to bimpm and add model weights and overrides to flask server.

* Refine comments for pylint.",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['in decode_output_dict'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
947,Evan Pete Walsh,epwalsh10@gmail.com,2018-08-27 09:36:51-07:00,5a305e3065829eff0a99118336c3275670a501f7,https://github.com/allenai/allennlp/commit/5a305e3065829eff0a99118336c3275670a501f7,"improve API, update tests (#1664)",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['sched.t_initial == 5'],[],[],[],[],[],[],[],[],[],[],[],[],['sched.t_max == 5'],[],[],[],[],[],[],[],[],[],[],[],[]
948,Joel Grus,joelgrus@gmail.com,2018-08-27 10:27:47-07:00,fcdbbd386fc13ca8b5fdd48edf7ac9793665b06f,https://github.com/allenai/allennlp/commit/fcdbbd386fc13ca8b5fdd48edf7ac9793665b06f,"require Python 3.6.1 (#1667)

* require python 3.6.1 or later

* more updates

* add README",4,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
949,Joel Grus,joelgrus@gmail.com,2018-08-27 11:25:17-07:00,45e6a0f1292cbbf82399a8f3da89f119dd1358ea,https://github.com/allenai/allennlp/commit/45e6a0f1292cbbf82399a8f3da89f119dd1358ea,"pin boto3 + awscli (#1671)

* pin boto3

* pin awscli too",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
950,Kevin Lin,kl2806@columbia.edu,2018-08-27 15:36:27-07:00,279f325950bf48582cd9fc499ade89155db5a5f0,https://github.com/allenai/allennlp/commit/279f325950bf48582cd9fc499ade89155db5a5f0,"SQL semantic parser entity improvements (#1658)

* initial attempt

* test

* column strings working

* remove string heuristics

* add database directory as a parameter

* share sqlcontext

* sqlite file

* tests

* docs

* construct sqlcontexttable inside atis world

* pylint",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['len(instances) == 14'],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 12', 'valid_strs == set(world.valid_actions[])', 'world.valid_actions[] == \\', 'world.linking_scores[entity_index][question_index] == \\', 'set(valid_actions[]) == set()', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\']",[],[],[],[],[],[],[],[],[],[],[],[]
951,Eunsol,high07@gmail.com,2018-08-27 19:22:16-07:00,cbeef924a448cb9f8dfb7b5832d5d5f98d8262fc,https://github.com/allenai/allennlp/commit/cbeef924a448cb9f8dfb7b5832d5d5f98d8262fc,"Predictor for QUAC models (#1674)

* quac initial commit

* random files

* l

* pull

*  pushing

* Attention version, but seems to be buggy.. ( no effect on scores )

* all

*  pushing

* upload

* DQA SEQ working version

* Added followup info

* fixed V2 bug

* fixed V2 bug

* question num marker

* push to taranis

* fix eval to match official script

* fixing eval script

* fixing eval

*  eval mismatch bug

*  push to taranis

*  final?

* remote data

* removing

* preparing pull request

* removing diffs

* removing query addition

* mask bug fixed

* cpu support

* fixed cuda

* making dataset only pull request

* adding back some files

* model only

* adding modules needed for the model

* predictor

* remove tagger

* before merging

* preparing release, writing test...

* added dataset reader test, refactored some codes after pylint..

* adding api docs

* fixed missing reference

* fixing prev_a incoherent reference

* removed some irrelevant file not belongs to this pull request

* fixing some pylint comments

* Delete allennlp.data.dataset_readers.dqa.rst

* Delete allennlp.models.reading_comprehension.dqa.rst

* Delete variational_dropout.py

* before merging

* r

* in the process of modifying quac model

* check if working properly after swapping tri_linear_attention to linear_attention

* fixed some names

* fixed datareader bug

* changing

* fetched new linear

* roughly working version, needs checking

* fixed turn number attention for context = 0

* addressed some of matt's points

* merging the right linear attention files

* fixed residual dropout to be applied everywhere

* pulling

* fixed text field embedder

* quacmodel

* quacmodel

* Delete kk

* addressed most of the comments, test still needs some work

* Update model_test_case.py

* Delete quac.json

* Update dialog_qa.py

* for merge

*  pulling the test

* made test smaller

* made test smaller

* Update __init__.py

* ;

* Update dialog_qa.py

* Fixed predictor to match the up to date name

* l

* added config file

* Update dialog_qa.py

* l

* before pulling master

* predictor

* predictor

* added api

* fixed config

* fixed doc error (documentation string)

* fixing doc string error",14,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(best_span_str, str)', 'best_span_str != ', 'len(results) == 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
952,Evan Pete Walsh,epwalsh10@gmail.com,2018-08-28 16:51:45-07:00,e9710c8a4c5c85bb0de7ce55d49aa861683d7ce6,https://github.com/allenai/allennlp/commit/e9710c8a4c5c85bb0de7ce55d49aa861683d7ce6,"Fix links in docs and improve check_links.py (#1680)

* fix links and improve check_links.py

* address comment by @matt-gardner",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
953,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-28 20:27:34-07:00,1b31320a6bb8bac6eca0ab222c45fa5db6bfe515,https://github.com/allenai/allennlp/commit/1b31320a6bb8bac6eca0ab222c45fa5db6bfe515,"Add MeanAbsoluteError metric (#1683)

Adds the mean absolute error metric.",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['mae.get_metric() == 21.0 / 12.0', 'mae.get_metric() == (21.0 + 3.5) / (12.0 + 8.0)', 'mae.get_metric() == (21.0 + 3.5 + 32.0) / (12.0 + 8.0 + 12.0)', 'mae.get_metric() == 32.0 / 12.0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
954,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-29 08:44:32-07:00,2a45f44f1f96aafe220b611ea1d70367e55b4194,https://github.com/allenai/allennlp/commit/2a45f44f1f96aafe220b611ea1d70367e55b4194,"Add Covariance and PearsonCorrelation metrics (#1684)

This PR implements an online algorithm for calculating Covariance and the sample Pearson correlation coefficient.

This was actually nontrivial, I mostly referenced the tensorflow [streaming_covariance metric](https://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/contrib/metrics/python/ops/metric_ops.py#L3127-L3264) in implementing this. Their implementation is a vectorized version of the weighted algorithm [on this wikipedia page](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Online)

The tests simply ensure that the streaming Covariance and PearsonCorrelation match up with what numpy would calculate, which I believe is a reasonable correctness check.",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
955,LauraRuis,lauraruis@Live.nl,2018-08-29 17:48:32+02:00,d1f6748120abc8b1b0bfccd2e6ccc4142ba127d0,https://github.com/allenai/allennlp/commit/d1f6748120abc8b1b0bfccd2e6ccc4142ba127d0,"minor memory improvements in _joint_likelihood() of ConditionalRandomField with advanced indexing (#1686)

* optimize memory/speed _joint_likelihood() function with new PyTorch features

* remove redundant var and change .view(-1) to .squeeze()

* Use tags.gather(...) instead of torch.gather(tags, ...)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
956,Matt Gardner,mattg@allenai.org,2018-08-29 10:14:02-07:00,3df54c8e7dfbae71cfa98652241ae27436b99385,https://github.com/allenai/allennlp/commit/3df54c8e7dfbae71cfa98652241ae27436b99385,"Removing last_dim_*softmax (#1687)

* Removing last_dim_*softmax

* Remove unused import

* Fix sum dimension",13,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['softmax_tensor.shape == (batch_size, length_1, length_2, num_options)', 'softmax_tensor.shape == (batch_size, length_1, length_2, num_options)']",[],[],[],[],[],[],[],[],[],[],[],[]
957,Haoxun Zhan,huntzhan.dev+github@gmail.com,2018-08-30 01:25:59+08:00,89729e041f9163988c9fd6f5592258e11956c431,https://github.com/allenai/allennlp/commit/89729e041f9163988c9fd6f5592258e11956c431,"Add BMES constrain to is_transition_allowed function (#1688)

* Add BMES support to .

* Fix testcase of BMES.

* Fix typo in test data.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['set(allowed) == {'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
958,Joel Grus,joelgrus@gmail.com,2018-08-29 13:44:18-07:00,a0506a73ee6b56a3a79c329e0ca5f3cbfcb22268,https://github.com/allenai/allennlp/commit/a0506a73ee6b56a3a79c329e0ca5f3cbfcb22268,remove print statement (#1690),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
959,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-29 14:13:46-07:00,4b6f8d165115997c2319918f956fd1e38f40d583,https://github.com/allenai/allennlp/commit/4b6f8d165115997c2319918f956fd1e38f40d583,"Remove inplace modification in Covariance (#1691)

this was modifying the labels inplace, which led to problems if you called something like

```
loss = some_function(pred, labels)
covariance(pred, labels)
```

This makes pytorch complain in the following way:

```
=============================================== FAILURES ================================================
___________ TestEventFactualityRegression.test_selective_tagger_role_can_train_save_and_load ____________

self = <tests.models.selective_regressor.event_factuality_test.TestEventFactualityRegression testMethod=test_selective_tagger_role_can_train_save_and_load>

    def test_selective_tagger_role_can_train_save_and_load(self):
>       self.ensure_model_can_train_save_and_load(self.param_file)

tests/models/selective_regressor/event_factuality_test.py:20:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
contexteval/common/model_test_case.py:46: in ensure_model_can_train_save_and_load
    model = train_model_from_file(param_file, save_dir)
../../../miniconda3/envs/elmo_eval/lib/python3.6/site-packages/allennlp/commands/train.py:132: in train_model_from_file
    return train_model(params, serialization_dir, file_friendly_logging, recover)
../../../miniconda3/envs/elmo_eval/lib/python3.6/site-packages/allennlp/commands/train.py:320: in train_model
    metrics = trainer.train()
../../../miniconda3/envs/elmo_eval/lib/python3.6/site-packages/allennlp/training/trainer.py:720: in train
    train_metrics = self._train_epoch(epoch)
../../../miniconda3/envs/elmo_eval/lib/python3.6/site-packages/allennlp/training/trainer.py:487: in _train_epoch
    loss.backward()
../../../miniconda3/envs/elmo_eval/lib/python3.6/site-packages/torch/tensor.py:93: in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

tensors = (tensor(1.9771, grad_fn=<AddBackward>),), grad_tensors = (tensor(1.),), retain_graph = False
create_graph = False, grad_variables = None

    def backward(tensors, grad_tensors=None, retain_graph=None, create_graph=False, grad_variables=None):
        r""""""Computes the sum of gradients of given tensors w.r.t. graph leaves.

        The graph is differentiated using the chain rule. If any of ``tensors``
        are non-scalar (i.e. their data has more than one element) and require
        gradient, the function additionally requires specifying ``grad_tensors``.
        It should be a sequence of matching length, that contains gradient of
        the differentiated function w.r.t. corresponding tensors (``None`` is an
        acceptable value for all tensors that don't need gradient tensors).

        This function accumulates gradients in the leaves - you might need to zero
        them before calling it.

        Arguments:
            tensors (sequence of Tensor): Tensors of which the derivative will be
                computed.
            grad_tensors (sequence of (Tensor or None)): Gradients w.r.t.
                each element of corresponding tensors. None values can be specified for
                scalar Tensors or ones that don't require grad. If a None value would
                be acceptable for all grad_tensors, then this argument is optional.
            retain_graph (bool, optional): If ``False``, the graph used to compute the grad
                will be freed. Note that in nearly all cases setting this option to ``True``
                is not needed and often can be worked around in a much more efficient
                way. Defaults to the value of ``create_graph``.
            create_graph (bool, optional): If ``True``, graph of the derivative will
                be constructed, allowing to compute higher order derivative products.
                Defaults to ``False``.
        """"""
        if grad_variables is not None:
            warnings.warn(""'grad_variables' is deprecated. Use 'grad_tensors' instead."")
            if grad_tensors is None:
                grad_tensors = grad_variables
            else:
                raise RuntimeError(""'grad_tensors' and 'grad_variables' (deprecated) ""
                                   ""arguments both passed to backward(). Please only ""
                                   ""use 'grad_tensors'."")

        tensors = (tensors,) if isinstance(tensors, torch.Tensor) else tuple(tensors)

        if grad_tensors is None:
            grad_tensors = [None] * len(tensors)
        elif isinstance(grad_tensors, torch.Tensor):
            grad_tensors = [grad_tensors]
        else:
            grad_tensors = list(grad_tensors)

        grad_tensors = _make_grads(tensors, grad_tensors)
        if retain_graph is None:
            retain_graph = create_graph

        Variable._execution_engine.run_backward(
            tensors, grad_tensors, retain_graph, create_graph,
>           allow_unreachable=True)  # allow_unreachable flag
E       RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation

../../../miniconda3/envs/elmo_eval/lib/python3.6/site-packages/torch/autograd/__init__.py:90: RuntimeError
----------------------------------------- Captured stdout call ------------------------------------------
<class 'contexteval.contextualizers.contextualizer.Contextualizer'>
<class 'contexteval.contextualizers.contextualizer.Contextualizer'>
----------------------------------------- Captured stderr call ------------------------------------------
15it [00:00, 85.22it/s]
100%|| 15/15 [00:00<00:00, 258907.65it/s]
15it [00:00, 85.53it/s]
15it [00:00, 80.51it/s]
30it [00:00, 319363.25it/s]
  0%|          | 0/1 [00:00<?, ?it/s]
===Flaky Test Report===

test_batch_classifications_are_consistent passed 1 out of the required 1 times. Success!

===End Flaky Test Report===
========================== 1 failed, 1 passed, 1160 deselected in 6.36 seconds ==========================
```",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
960,Michael Schmitz,michael@schmitztech.com,2018-08-29 14:33:09-07:00,d16f6c08f7be7f6c306e6cb33149006f43ca34c1,https://github.com/allenai/allennlp/commit/d16f6c08f7be7f6c306e6cb33149006f43ca34c1,Add a default predictor for biaffine-parser. (#1677),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
961,Haoxun Zhan,huntzhan.dev+github@gmail.com,2018-08-31 01:41:35+08:00,335d8996a0ab6a2a3ea6ce323f57d2e76d9ddf1a,https://github.com/allenai/allennlp/commit/335d8996a0ab6a2a3ea6ce323f57d2e76d9ddf1a,"Make SpanBasedF1Measure support BMES  (#1692)

* Make SpanBasedF1Measure support BMES.

* Decoration change.

* Fix code style.

* Add test for SpanBasedF1Measure(label_encoding=""BMES"").

* Bugfix.

* Fix testcase.

* Sse text[2:] instead of text.partition('-')[2]",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(spans) == {(, (5, 5))}', 'set(spans) == {(, (3, 3))}', 'set(spans) == {(, (5, 5))}', 'set(spans) == {(, (3, 3))}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
962,Evan Pete Walsh,epwalsh10@gmail.com,2018-08-30 11:49:04-07:00,e027478fdf08b7704f21ba37230596ea6d3ff2e2,https://github.com/allenai/allennlp/commit/e027478fdf08b7704f21ba37230596ea6d3ff2e2,"Upgrade Flask to 0.12.4 (fixes bug) (#1694)

* upgrade to 0.12.4

* add to setup.py",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
963,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-30 13:56:03-07:00,863ded89844256d3cd054de7fec30de0b7038b00,https://github.com/allenai/allennlp/commit/863ded89844256d3cd054de7fec30de0b7038b00,Add option to keep sentence boundaries in Elmo (#1695),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(elmo_representations) == 2', 'list(elmo_representations[0].size()) == [2, 7+2, 32]', 'list(elmo_representations[1].size()) == [2, 7+2, 32]', 'list(mask.size()) == [2, 7+2]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
964,Joel Grus,joelgrus@gmail.com,2018-08-30 16:03:57-07:00,ec2d5a1c072d25c61d15e5ac7a2ad7d2ce9f4a5b,https://github.com/allenai/allennlp/commit/ec2d5a1c072d25c61d15e5ac7a2ad7d2ce9f4a5b,"skip moto tests, unpin dependencies (#1697)",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,4,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(reason=)', '(reason=)', '(reason=)', '(reason=)']",[],[],[],[],"['skip(reason=)', 'skip(reason=)', 'skip(reason=)', 'skip(reason=)']","['mark.skip(reason=)', 'mark.skip(reason=)', 'mark.skip(reason=)', 'mark.skip(reason=)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
965,Michael Schmitz,michael@schmitztech.com,2018-08-30 16:07:46-07:00,4920249af097d1557be6ece3e5ce80d1f6ea0333,https://github.com/allenai/allennlp/commit/4920249af097d1557be6ece3e5ce80d1f6ea0333,bump version number to v0.6.1,3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
966,Michael Schmitz,michael@schmitztech.com,2018-08-30 16:28:29-07:00,9bcbf1144a06f8cdc59dbfaabd6fe3a9dc7f3847,https://github.com/allenai/allennlp/commit/9bcbf1144a06f8cdc59dbfaabd6fe3a9dc7f3847,Bump version numbers to vv0.6.2-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
967,Matt Gardner,mattg@allenai.org,2018-08-31 10:23:37-07:00,5e68d045506420b9cb069a17556cda2aa201caa2,https://github.com/allenai/allennlp/commit/5e68d045506420b9cb069a17556cda2aa201caa2,"Rename SpanPruner -> Pruner, remove -infs (#1703)

* Rename SpanPruner -> Pruner, remove -infs

* Pylint and docs

* Actually fix docs...

* Make the deprecation warning better, better preserve compatibility, try to fix flaky test

* Remove unused import",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
968,Nelson Liu,nelson-liu@users.noreply.github.com,2018-08-31 13:20:02-07:00,6cb70051e6f92d709c5caee617418c6945589690,https://github.com/allenai/allennlp/commit/6cb70051e6f92d709c5caee617418c6945589690,"Add average parameter to sequence cross entropy (#1702)

- Deprecates the `batch_average` param and replaces it with the much more flexible `average` param.
- token-level averaging of losses. This is useful for language modeling / when you have a sequence of independent and unrelated decisions.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
969,Evan Pete Walsh,epwalsh10@gmail.com,2018-09-04 10:24:41-07:00,ef72e2e6a0f3956ac22a2c68060318d9b9688195,https://github.com/allenai/allennlp/commit/ef72e2e6a0f3956ac22a2c68060318d9b9688195,"Save learning rate scheduler to training state (#1650)

* save learning rate scheduler to training state

* fixes and add unit tests

* fix and add tests for trainer

* add more tests",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(TypeError):')]",[],[],[],[],[],[],[],[],[],[],"[('Raises', '(TypeError):')]",[],[],[],[],[],[],[],[],[],"['sched.t_initial == 5', 'sched._initialized is True', 'optim.param_groups[0][] == 1.0', 'lrs[it] == lr', 'epoch == 2', 'new_trainer._learning_rate_scheduler.lr_scheduler.last_epoch == 1']",[],[],[],[],[],[],[],[],[],[],[],[],"['sched.t_initial == 5', 'sched._initialized is True', 'optim.param_groups[0][] == 1.0']",[],[],[],[],[],[],[],[],[],[],[],[]
970,Mark Neumann,markn@allenai.org,2018-09-04 15:40:16-07:00,f2884ad64dc018bbba9518002a7cb7d15e8ca952,https://github.com/allenai/allennlp/commit/f2884ad64dc018bbba9518002a7cb7d15e8ca952,require torch 0.4.1 (#1708),2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
971,Nelson Liu,nelson-liu@users.noreply.github.com,2018-09-05 14:46:47-07:00,c47318b43ceb8f38e648380c2a5618cfde8adb3b,https://github.com/allenai/allennlp/commit/c47318b43ceb8f38e648380c2a5618cfde8adb3b,"Add configs for tasks in ELMo paper, with and without ELMo (#1626)

* Add training config for coref with ELMo

* Rename esim.json to esim_elmo.json

* Add baseline ESIM

* Rename ner.jsonnet to ner_elmo.jsonnet

* Add baseline, elmo-less NER

* Add SRL model with original elmo

* update README

* update README

* readme

* NER config without ELMo

* NER elmo notes

* cuda

* NER details

* readme

* add SST details

* SST config with ELMo

* Add details about SST with ELMo

* Add note about the CUDA SRL model

* readme

* modify comment

* PR comments",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
972,Michael Schmitz,michael@schmitztech.com,2018-09-06 14:25:41-07:00,0b7bb205a78cfef32e9122057df7fe46568a2f0d,https://github.com/allenai/allennlp/commit/0b7bb205a78cfef32e9122057df7fe46568a2f0d,Fixes and updates to README.md (#1718),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
973,Matt Gardner,mattg@allenai.org,2018-09-06 22:23:40-07:00,a61aa67e363aef99bd4ae43af92bc8a2b3378de2,https://github.com/allenai/allennlp/commit/a61aa67e363aef99bd4ae43af92bc8a2b3378de2,"Moving allennlp.nn.decoding to allennlp.state_machines (#1714)

* Moving allennlp.nn.decoding to allennlp.state_machines

* Fixing docs

* Updated TODO",55,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
974,Michael Schmitz,michael@schmitztech.com,2018-09-07 09:36:58-07:00,a585994332b503b2a2d87c08c664efb9309da2fb,https://github.com/allenai/allennlp/commit/a585994332b503b2a2d87c08c664efb9309da2fb,Update configuration.md (#1722),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
975,Michael Schmitz,michael@schmitztech.com,2018-09-07 09:38:51-07:00,647e53e945c7764860c43db6aa01040ee0ecb741,https://github.com/allenai/allennlp/commit/647e53e945c7764860c43db6aa01040ee0ecb741,"Removing contents of requirements.txt file (#1729)

This should help this tutorial stay in sync with allennlp-as-a-library-example.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
976,Michael Schmitz,michael@schmitztech.com,2018-09-07 13:49:36-07:00,ec25acd0eb20c9b9ae674262ed2a36d2dd646c49,https://github.com/allenai/allennlp/commit/ec25acd0eb20c9b9ae674262ed2a36d2dd646c49,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
977,Mark Neumann,markn@allenai.org,2018-09-07 14:43:22-07:00,72c9e98c2a56094f713c6090805fd10c677c0b95,https://github.com/allenai/allennlp/commit/72c9e98c2a56094f713c6090805fd10c677c0b95,"Sql text utils (#1717)

Some utility functions for reading in the text2sql data. These are going to be iteratively improved (e.g there is some deduplication that can be done when reading the data, etc), but this is functional so I thought improve on it iteratively afterward.

This is abstracted from a specific data reader because there may well be several dataset readers associated with these datasets, for baselines etc.",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['sql_data.text == []', 'sql_data.text_with_variables == []', 'sql_data.sql == [,', 'sql_data.text_variables == {}', 'sql_data.sql_variables == {}', 'sql_data.sql == [,', 'sql_data.text_variables == {}', 'sql_data.sql_variables == {}', 'sql_data.text == correct_text[i][0]', 'sql_data.text_with_variables == correct_text[i][1]', 'text2sql_utils.replace_variables(sentence, sentence_variables) == [,', 'cleaned == [,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
978,Michael Schmitz,michael@schmitztech.com,2018-09-07 15:00:22-07:00,934ee17952d8e49eb532ab475ab452027edb224a,https://github.com/allenai/allennlp/commit/934ee17952d8e49eb532ab475ab452027edb224a,"Update training_and_evaluating.md (#1721)

Use relative paths instead of links back to master.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
979,Joel Grus,joelgrus@gmail.com,2018-09-07 16:55:05-07:00,6c1607e22e2c43b1bcc3b9216985d2ffcf5317b2,https://github.com/allenai/allennlp/commit/6c1607e22e2c43b1bcc3b9216985d2ffcf5317b2,bump gevent to 1.3.6 (#1732),2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
980,Gabriel Stanovsky,gabriel.satanovsky@gmail.com,2018-09-07 17:53:51-07:00,7bf930f48ff8a72611db61301268b058e5cbaf48,https://github.com/allenai/allennlp/commit/7bf930f48ff8a72611db61301268b058e5cbaf48,"Add Open Information Extraction (#1726)

* adding Open IE

* adding Open IE

* adding Open IE

* fixing typo

* Using SRL model instead of a duplicated OIE model, adding an `ignore_span_metric` parameter to the SRL model to accomodate for Open IE

* adding conversion script from open ie extractions to conll format

* minor fixes

* style fixes

* fixing naming convention

* fixing naming convention

* returning empty dictionary when in get_metrics when ignoring span loss

* minor

* minor

* adding Open IE predictor to docs

* fixing comments for docs",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['words == [,', 'verbs is not None', 'isinstance(verbs, list)', 'predicates == []', 'tags is not None', 'isinstance(tags, list)', 'all(isinstance(tag, str) for tag in tags)', 'len(tags) == num_words', 'result == {: []}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
981,Joel Grus,joelgrus@gmail.com,2018-09-10 12:58:51-07:00,3f54fc85a3d10ec4b793c32a25e950c7139cbb83,https://github.com/allenai/allennlp/commit/3f54fc85a3d10ec4b793c32a25e950c7139cbb83,"make openai transformer byte pair indexer add to the vocab (#1705)

fixes #1700",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not in self.vocab._index_to_token', 'not in self.vocab._token_to_index', 'len(i2t) == 5 * 5 * 2', 'len(t2i) == 5 * 5 * 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
982,Matthew Peters,matt-peters@users.noreply.github.com,2018-09-10 13:53:03-07:00,8bbde0d358d428d43f03fac17ef7ffe139fc0e34,https://github.com/allenai/allennlp/commit/8bbde0d358d428d43f03fac17ef7ffe139fc0e34,"Fix index_with bug in basic iterator (#1715)

* Fix index_with bug in basic iterator

* fix test

* Move index_fields to ensure_batch_is_sufficiently_small

* Add comment",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
983,Harsh Trivedi,harshjtrivedi94@gmail.com,2018-09-10 18:16:00-04:00,72f7b4b1a9ff96f88c10263b46b48690294000a3,https://github.com/allenai/allennlp/commit/72f7b4b1a9ff96f88c10263b46b48690294000a3,"Remove bucket iterator shuffle warning. (#1742)

* Remove bucket iterator shuffle warning.

From discussion here: #1578. Let me know if I should remove the code instead of commenting it.

* Remove the warning and add comment instead.

* Add a period.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
984,Michael Schmitz,michael@schmitztech.com,2018-09-10 15:16:17-07:00,1532886909e3a083966971289ff2ecc73a75fb6c,https://github.com/allenai/allennlp/commit/1532886909e3a083966971289ff2ecc73a75fb6c,Rename and organize tutorials (#1741),11,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
985,Sebastian Ruder,sebastian@ruder.io,2018-09-11 00:54:00+02:00,06648938cd1b6386a1d4d92633bad8604dd1aaaf,https://github.com/allenai/allennlp/commit/06648938cd1b6386a1d4d92633bad8604dd1aaaf,"Discriminative fine-tuning, gradual unfreezing, slanted triangular learning rates (ULMFiT) (#1636)

* Created a STLR schedule with gradual unfreezing

* Fixed parameter groups regex example

* Added splitting of parameters into param groups, discriminative fine-tuning

* Added splitting of predefined modules

* Created a STLR schedule with gradual unfreezing

* Fixed parameter groups regex example

* Added splitting of parameters into param groups, discriminative fine-tuning

* Fix a typo in embedding_tokens notebook. (#1449)

Fix a typo in embedding_tokens notebook : The vocabulary is `token_ids` and not `tokens_ids`.

* remove RegistrableVocabulary (#1454)

* remove RegistrableVocabulary

* add comment about special from_params logic

* fix pylint

* Allow to use a different validation iterator from training iterator (#1455)

* Allow to use a different validation iterator from training iterator

* Use validation iterator

* Use validation iterator for evaluate, if present

* pylint

* Fix conll2003.from_params incorrect default (#1453)

* fix Vocabulary.from_params to accept a dict for max_vocab_size (#1460)

* fix Vocabulary.from_params to accept a dict for max_vocab_size

* pylint

* Fix call to vocab.token_from_index -> self.label_namespace (#1459)

* Added splitting of predefined modules

* Fixed off-by-one-error as suggested by Matthew

* Modified SlantedTriangular learning rate schedule name and id

* Renamed epoch_no to num_layers_to_unfreeze

* Addressed pylint issues

* Replaced print with logger.info

* Moved specification of discriminative fine-tuning from trainer to learning rate scheduler

* Added pylint: disable=protected-access

* Added handling when optimizer is a string

* Fixed bug with negative lr due to frozen_steps > 0 when not freezing; removed lr argument; added modification of base_lrs

* Added test for slanted triangular learning rate schedule

* Removed automatic assignment to param_groups in trainer.py, added check in STLR

* nits and pylint",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(TypeError):')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['sched.num_epochs == 5', 'sched.num_steps_per_epoch == 10', 'sched.gradual_unfreezing is True', 'sched.freezing_current is True', 'len(optim.param_groups) == 3', 'not optim.param_groups[-1][]', 'optim.param_groups[-2][] == 1.0', 'optim.param_groups[-3][] == 0.5', 'scheduler.freezing_current', 'lr == lr_check, f']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
986,Joel Grus,joelgrus@gmail.com,2018-09-10 16:25:25-07:00,8867f2f3eeb6a0ea7677d59d8644e19681ecdf70,https://github.com/allenai/allennlp/commit/8867f2f3eeb6a0ea7677d59d8644e19681ecdf70,"create tensors on cpu, move them to gpu later (#1731)

* create tensors on cpu, move them to gpu later

* reorder isinstance checks from more common to less common

* add has_tensor check

* add tuple test",21,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['has_tensor([, 10, tensor])', 'not has_tensor([, 10])', 'has_tensor((, 10, tensor))', 'not has_tensor((, 10))', 'has_tensor({: 1})', 'not has_tensor({: 1})', 'has_tensor(tensor)', 'not has_tensor(3)', 'has_tensor({']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
987,Mark Neumann,markn@allenai.org,2018-09-10 18:42:37-07:00,4c99f8e82f7fd70c86652109bfca5282d470e981,https://github.com/allenai/allennlp/commit/4c99f8e82f7fd70c86652109bfca5282d470e981,"Text2sql reader (#1738)

- Moves all semantic parsing dataset readers into their own folder.
- Adds a dataset reader for the text2sql baseline which can read any of the 8 datasets.

I also refactored the sql utils a bit to read from my new directory format, for which I added a script in the previous PR. This includes adding functionality to de-duplicate the questions in a given dataset, not just the SQL. This PR looks massive, but I only added `template_text2sql.py` and modified `text2sql_utils.py` - all the rest are just moving folders around and adding depreciation warnings.",21,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataset) == 1', 'sql_data.text == []', 'sql_data.text_with_variables == []', 'sql_data.sql == [,', 'sql_data.text_variables == {}', 'sql_data.sql_variables == {}', 'len(dataset) == 3', 'tokens == []', 'tags == []', 'tokens == []', 'tags == []', 'fields[ \\', 'tokens == []', 'tags == []', 'fields[\\', 'tokens == []', 'tags == []', 'fields[\\', 'tokens == []', 'tags == []', 'fields[\\', 'tokens == []', 'tags == []', 'fields[\\']",[],[],[],[],[],[],[],[],[],[],[],[],"['sql_data.text == []', 'sql_data.text_with_variables == []', 'sql_data.sql == [,', 'sql_data.text_variables == {}', 'sql_data.sql_variables == {}', 'text2sql_utils.replace_variables(sentence, sentence_variables) == [,']",[],[],[],[],[],[],[],[],[],[],[],[]
988,Haoxun Zhan,huntzhan.dev+github@gmail.com,2018-09-11 23:59:58+08:00,4674b0182187ef10c54d0578d97f4ba9769a2863,https://github.com/allenai/allennlp/commit/4674b0182187ef10c54d0578d97f4ba9769a2863,"Make bmes_tags_to_spans support ill-formed spans. (#1710)

* Make bmes_tags_to_spans support ill-formed spans.

* Make pylint & mypy happy.

* Apply @DeNeutoy 's Method.

* Make mypy happy.

* Now make pylint happy.",2,True,True,False,False,False,False,False,False,True,False,False,False,False,False,False,['assert_migration'],0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):')]",[],[],[],[],[],[],[],[],[],"['set(spans) == {(, (1, 1))}', 'set(spans) == {(, (1, 1))}', 'set(spans) == {(, (2, 2))}', 'set(spans) == {(, (2, 2))}', 'set(spans) == {(, (1, 1))}', 'set(spans) == {(, (1, 1))}', 'set(spans) == {(, (1, 2))}', 'set(spans) == {(, (1, 1))}', 'set(spans) == {(, (1, 2))}', 'set(spans) == {(, (2, 2))}', 'set(spans) == {(, (2, 3))}', 'set(spans) == {(, (2, 2))}', 'set(spans) == {(, (1, 1))}', 'set(spans) == {(, (1, 1))}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
989,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-09-11 11:56:04-07:00,1d81d8bc97a971b8ec2d8a6e3124ca75ff7099e4,https://github.com/allenai/allennlp/commit/1d81d8bc97a971b8ec2d8a6e3124ca75ff7099e4,"Grammar for a variable free language for WikiTableQuestions (#1709)

* grammar for a variable free language for wikitables

* removed execute method and fixed docs

* removed unused imports

* addressed pr comments

* fixed mypy issue

* Added a todo

* changed import",13,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(actual_right_sides) == set(expected_right_sides)', 'set(valid_actions.keys()) == {', 'str(expression) == ', 'self.world.get_action_sequence(expression) == expected_sequence', 'logical_form == reconstructed_logical_form', 'str(expression) == ', 'str(expression) == ', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
990,Matthew Peters,matt-peters@users.noreply.github.com,2018-09-11 13:48:49-07:00,eda2ba5506d8f375f661381018ec8f44ea966827,https://github.com/allenai/allennlp/commit/eda2ba5506d8f375f661381018ec8f44ea966827,"Set up `SlantedTriangular` for first batch (#1744)

* call step_batch in SlantedTriangular rate scheduler before starting training

* 32 -> sched.ratio",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['optim.param_groups[-2][] == 1.0 / sched.ratio', 'optim.param_groups[-3][] == 0.5 / sched.ratio', 'scheduler.lr_scheduler.freezing_current']",[],[],[],[],[],[],[],[],[],[],[],[],"['optim.param_groups[-2][] == 1.0', 'optim.param_groups[-3][] == 0.5', 'scheduler.freezing_current']",[],[],[],[],[],[],[],[],[],[],[],[]
991,Matthew Peters,matt-peters@users.noreply.github.com,2018-09-11 14:06:40-07:00,609babecd7e74853c0b1ce671307394739d5691c,https://github.com/allenai/allennlp/commit/609babecd7e74853c0b1ce671307394739d5691c,"Add logging of learning rates to tensorboard (#1745)

* Add logging of learning rates to tensorboard

* make  default False

* Remove un-needed learning rate logging

* Add learning rate logging test",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
992,Gabriel Stanovsky,gabriel.satanovsky@gmail.com,2018-09-11 17:06:00-07:00,49f43ec91fd9cc73ee5e231b9f2659d82c57b950,https://github.com/allenai/allennlp/commit/49f43ec91fd9cc73ee5e231b9f2659d82c57b950,"Remove large openie model file (#1756)

* removing large file

* using srl test model instead of the large Open IE file",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
993,Joel Grus,joelgrus@gmail.com,2018-09-12 10:03:10-07:00,606a61abf04e3108949022ae1bcea975b2adb560,https://github.com/allenai/allennlp/commit/606a61abf04e3108949022ae1bcea975b2adb560,"output metrics.json every epoch (#1755)

* work

* cleanup

* fix a few things

* revamp

* revert test

* different metrics.json every epoch

* only log the metrics after training is over

* remove extra comma

* pylint + mypy",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['epoch_file.exists()', 'in metrics', 'in metrics', 'metrics.get() == epoch']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
994,Maksym Del,max.del.edu@gmail.com,2018-09-13 19:43:57+03:00,ffe037d6f4e9f8777fe1724840df08fe060396fc,https://github.com/allenai/allennlp/commit/ffe037d6f4e9f8777fe1724840df08fe060396fc,"Update README.md (#1763)

Seems like Pytorch now installs for  CUDA 9 by default",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
995,Alessandro Suglia,alessandro.suglia@gmail.com,2018-09-13 21:38:28+02:00,17616848405ecf5af55317b8800e2954b38f3f33,https://github.com/allenai/allennlp/commit/17616848405ecf5af55317b8800e2954b38f3f33,"Fixed bug in _get_combination_and_multiply for batch size equal to 1 (#1764)

* Fixed bug in _get_combination_and_multiply for batch size equal to 1.

* Fixed copy-paste bug and reverted indentation changes.

* Minor fixes",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
996,Joel Grus,joelgrus@gmail.com,2018-09-13 14:07:35-07:00,b5087e76d5127960e8ec64a1a7bd521f7f0c175b,https://github.com/allenai/allennlp/commit/b5087e76d5127960e8ec64a1a7bd521f7f0c175b,"multiprocess dataset reader and iterator (#1760)

* multiprocess dataset reader

* multiprocess iterator

* add multiprocess + multiprocess test

* remove list()

* create tensors on cpu, move them to gpu later

* reorder isinstance checks from more common to less common

* add has_tensor check

* add tuple test

* more work on multiprocess iterator

* cleanup

* wrap any data iterator

* forgot to delete

* fix things up

* fix race condition

* share iterator

* pass shuffle parameter to base iterators

* fix comment

* rename iterator -> base_iterator",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(all_instances) == 100 * 4', 'len(counts) == 4', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'len(all_instances) == 100 * 4 * 3', 'len(counts) == 4', 'counts[()] == 300', 'counts[()] == 300', 'counts[()] == 300', 'counts[()] == 300', 'sizes == [16] + 12 * [32]', 'len(instances) == 5', 'sum(sizes) == 400']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
997,Evan Pete Walsh,epwalsh10@gmail.com,2018-09-13 14:09:49-07:00,64f253faa5aeb42edff1cb367b8e1fbb96da2931,https://github.com/allenai/allennlp/commit/64f253faa5aeb42edff1cb367b8e1fbb96da2931,Add a requirements check to scripts/verify.py (#1699),4,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
998,Joel Grus,joelgrus@gmail.com,2018-09-14 08:03:14-07:00,e4f41e7883a54bc6773617f6267b435f5c31413e,https://github.com/allenai/allennlp/commit/e4f41e7883a54bc6773617f6267b435f5c31413e,use managers for queues (#1769),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
999,Michael Schmitz,michael@schmitztech.com,2018-09-14 10:29:09-07:00,b9cbfd6e07a5ca745d82d6d3d6a520f1a47bf1e3,https://github.com/allenai/allennlp/commit/b9cbfd6e07a5ca745d82d6d3d6a520f1a47bf1e3,Add an example of how to read ELMo embeddings with h5py (#1772),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1000,Mark Neumann,markn@allenai.org,2018-09-14 11:08:12-07:00,421f9a4639cd2a8abd8e94f044dae84cee7cba61,https://github.com/allenai/allennlp/commit/421f9a4639cd2a8abd8e94f044dae84cee7cba61,"add simplest possible pretrained model interface (#1768)

* add simplest possible pretrained model interface

* more specific predictors

* undo specific predictor types, add esim model

* Revert ""undo specific predictor types, add esim model""

This reverts commit 6ca8921eb319d7e3b0d314a6aa4c81e6925051e2.

* ignore types rather than using base class",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1001,Matthew Peters,matt-peters@users.noreply.github.com,2018-09-14 13:05:55-07:00,898cfed157fbb7dc90acad7d1114077e35ec3512,https://github.com/allenai/allennlp/commit/898cfed157fbb7dc90acad7d1114077e35ec3512,"BiattentiveClassificationNetwork with ELMo and without GloVe (#1767)

* allow to use biattentive classification network with ELMo and without word embeddings

* lint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1002,Evan Pete Walsh,epwalsh10@gmail.com,2018-09-14 14:06:14-07:00,c5501c70ba936b057cf3ee2f1e35cdd35169a8a4,https://github.com/allenai/allennlp/commit/c5501c70ba936b057cf3ee2f1e35cdd35169a8a4,fix trainer initialization (#1761),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1003,Brendan Roof,brendanr@allenai.org,2018-09-14 14:57:20-07:00,8759ea393bf0c27380c4d33e0f15938f68f4ce35,https://github.com/allenai/allennlp/commit/8759ea393bf0c27380c4d33e0f15938f68f4ce35,"Event2Mind (#1679)

- Forks SimpleSeq2Seq.
- New metrics SequenceAccuracy and UnigramRecall.
- Includes beam search to compute recall@10.
- Parameterized to easily handle xintent, xreact and so on.",21,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 12', 'get_text(,', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(,', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(,', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(,', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(,', 'get_text(]', 'get_text(]', 'get_text(]', 'logits.size()[0] == 10', 'cur_logit <= prev_logit', 'beam_tokens == greedy_tokens', 'accuracy.correct_count == 0', 'accuracy.total_count == 0', 'recall.correct_count == 0', 'recall.total_count == 0']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1004,Joel Grus,joelgrus@gmail.com,2018-09-14 16:29:43-07:00,63dbdf1f8e16186b10274012281c769215182a2f,https://github.com/allenai/allennlp/commit/63dbdf1f8e16186b10274012281c769215182a2f,"one tutorial to rule them all (#1613)

* tutorials two ways

* stuff

* progress

* progress on tutorials

* remove unnecessary files

* getting started tutorial

* small changes

* more progress

* fixes

* add demo

* add a table of contents

* minor fixes

* second try

* fix convert.py

* address pr feedback

* fix cached_path issue + type annotation",13,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1005,Brendan Roof,brendanr@allenai.org,2018-09-17 15:12:04-07:00,cca99b9191fe1787c34c1cc361c05e09d15bdbfe,https://github.com/allenai/allennlp/commit/cca99b9191fe1787c34c1cc361c05e09d15bdbfe,"Add a predictor for Event2Mind. (#1779)

- Needed by the demo.
- Initially left out as it was redundant with the `simple_seq2seq` predictor. However, the demo assumes that a registered predictor is available.",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(predicted_tokens, list)', 'all(isinstance(x, str) for x in predicted_tokens)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1006,Gabriel Stanovsky,gabriel.satanovsky@gmail.com,2018-09-17 16:07:28-07:00,ae72f792ff9ecdd0e449281d049eb306219f76f2,https://github.com/allenai/allennlp/commit/ae72f792ff9ecdd0e449281d049eb306219f76f2,"Better multi-word predicates in Open IE predictors (#1759)


* merging overlapping predicates",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(pred_dict) == 1', 'get_predicate_text(sent_tokens, tags) == ', 'len(pred_dict) == 1', 'get_predicate_text(sent_tokens, tags) == ']",[],[],[],[],[],[],[],[],[],[],[],[],['predicates == []'],[],[],[],[],[],[],[],[],[],[],[],[]
1007,Michael Schmitz,michael@schmitztech.com,2018-09-18 10:35:13-07:00,9306e97a43b1502b557f15c89b5f77ec91cf9d6d,https://github.com/allenai/allennlp/commit/9306e97a43b1502b557f15c89b5f77ec91cf9d6d,Add minimal configuration to existing models. (#1770),15,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1008,Michael Schmitz,michael@schmitztech.com,2018-09-18 11:53:40-07:00,0b44bceba0b604822b8dc576a8ed2a99e7bd83a9,https://github.com/allenai/allennlp/commit/0b44bceba0b604822b8dc576a8ed2a99e7bd83a9,Rename SOURCE_COMMIT to ALLENNLP_SOURCE_COMMIT. (#1784),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1009,Mark Neumann,markn@allenai.org,2018-09-18 14:47:31-07:00,6039ac001945458ebb9bbd5aa984be2a4817007f,https://github.com/allenai/allennlp/commit/6039ac001945458ebb9bbd5aa984be2a4817007f,"SQL Coverage script (#1750)

Adding this now and tweaking a little of the pre-processing to break up the PR stream for these parsers - obviously this won't be the final grammar, because I need to modify it depending on the table, but it will be good to keep around a grammar which parses the raw dataset, because I _do not_ want to have to debug that thing twice.",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1010,Matt Gardner,mattg@allenai.org,2018-09-18 15:46:14-07:00,7647de8c384e6a16babebe30cae438b1d7bd2f37,https://github.com/allenai/allennlp/commit/7647de8c384e6a16babebe30cae438b1d7bd2f37,Fixing the table format for the WikiTables executor (#1785),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1011,Matt Gardner,mattg@allenai.org,2018-09-19 10:04:47-07:00,39069813e3f8b17162b42e6a58672af65e00529f,https://github.com/allenai/allennlp/commit/39069813e3f8b17162b42e6a58672af65e00529f,"Moving the WikiTables executor into semparse.executors (#1786)

* Moving the WikiTables executor into semparse.executors

* Update docs",12,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['executor.evaluate_logical_form(logical_form, example_string) is True', 'executor.evaluate_logical_form(None, example_string) is False', 'executor.evaluate_logical_form(, example_string) is False', 'executor.evaluate_logical_form(logical_form, example_string) is False']",[],[],[],[],[],[],[],[],[],[],[],[],"['wikitables_accuracy._count == 1', 'wikitables_accuracy._correct == 1', 'wikitables_accuracy._count == 2', 'wikitables_accuracy._correct == 1', 'wikitables_accuracy._count == 3', 'wikitables_accuracy._correct == 1', 'wikitables_accuracy._count == 4', 'wikitables_accuracy._correct == 1']",[],[],[],[],[],[],[],[],[],[],[],[]
1012,Haoxun Zhan,huntzhan.dev@gmail.com,2018-09-20 01:38:00+08:00,01d29069dd321956fcbc5831acee14d725b77569,https://github.com/allenai/allennlp/commit/01d29069dd321956fcbc5831acee14d725b77569,"Add tags_to_spans_function param to SpanBasedF1Measure. (#1783)

* Add tags_to_spans_function param to SpanBasedF1Measure.

* Fix style issue.

* Fix style issue.

* Add test.",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1013,Michael Schmitz,michael@schmitztech.com,2018-09-19 10:55:51-07:00,e64373c7ba959d10b1d5445fedaee51b27439f9a,https://github.com/allenai/allennlp/commit/e64373c7ba959d10b1d5445fedaee51b27439f9a,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1014,Matthew Peters,matt-peters@users.noreply.github.com,2018-09-20 17:37:34-07:00,c78bb36a58701f26a5db20f1685ec7029993cf24,https://github.com/allenai/allennlp/commit/c78bb36a58701f26a5db20f1685ec7029993cf24,"Add a correctness test for Open AI transformer (#1801)

* Add a correctness check for OpenAI BPE encoding

* add test fixtures

* Add correctness test for open ai

* pylint",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,2,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['non_padded_indices == expected_indices[k]'],[],[],"['()', '()']",[],[],[],[],"['skip()', 'skip()']","['mark.skip()', 'mark.skip()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1015,Matthew Peters,matt-peters@users.noreply.github.com,2018-09-21 10:02:02-07:00,7833447ab8eaff717ff363e8ecb308b3a7e1d047,https://github.com/allenai/allennlp/commit/7833447ab8eaff717ff363e8ecb308b3a7e1d047,Load the pre-trained embeddings for all NER tokens (#1806),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1016,Matt Gardner,mattg@allenai.org,2018-09-21 13:48:19-07:00,63fcada5dcef17d03f0a2ccfd050e464af509777,https://github.com/allenai/allennlp/commit/63fcada5dcef17d03f0a2ccfd050e464af509777,Make num_start_types optional in transition functions (#1811),4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1017,Brendan Roof,brendanr@allenai.org,2018-09-24 12:05:32-07:00,546242fd45ddff1e6e2815be64d3910ce1518ca2,https://github.com/allenai/allennlp/commit/546242fd45ddff1e6e2815be64d3910ce1518ca2,"Fixes for seq2seq model (#1808)

- Addresses:
  - https://github.com/allenai/allennlp/issues/1713, ""possible masking bug in simple_seq2seq""
  - https://github.com/allenai/allennlp/issues/1134, ""Simple Seq2Seq Computes Incorrect Dev Log Loss""",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1018,Kevin Lin,kl2806@columbia.edu,2018-09-24 13:52:59-07:00,0459261c388bec72937e0268c4316b85279d0bac,https://github.com/allenai/allennlp/commit/0459261c388bec72937e0268c4316b85279d0bac,"Atis model action refactored (#1792)

Summary:

- Add AtisSemanticParser model, which implements a baseline model that applies type-constrained decoding for SQL.
- Reverts all entities to be linked actions with linking scores.
- Changes the base definition of the SQL grammar from a string to dictionary, so that it is easier for models to modify binary expressions, etc. for additional constraints.

Other minor changes:

- Add time_range_start and time_range_end as two new types in the grammar. This allows the model to disambiguate between start times and end times for constraints like BETWEEN 0 and 1200.
- Add a reverse_productions flag to the GrammarStatelet; we need this because we want to expand the right-most nonterminal first in our production rules.
- Allow nonterminals with only linked actions
- Read all SQL query labels for an utterance and execute each when evaluating denotation accuracy",23,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 13', 'set(instance.fields.keys()) == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'sql_query ==  \\', 'grammar_state._nonterminal_stack == []', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'date_binary_expression in world.valid_actions[]', 'approximate_times == [1830, 1930]', 'approximate_times == [445, 545]', 'pm_times == [[1200], [1300], [2030], [1230], [1315]]']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 14', 'instance.fields.keys() == \\', 'world.linking_scores.shape[0] == \\', 'world.linking_scores.shape[1] == \\', 'possible_actions == \\']",[],[],[],[],[],[],[],[],[],[],[],[]
1019,Michael Schmitz,michael@schmitztech.com,2018-09-25 08:05:19-07:00,f65ced56afff6afe4d91aaf0cc1af1bbc05c2675,https://github.com/allenai/allennlp/commit/f65ced56afff6afe4d91aaf0cc1af1bbc05c2675,Add an example of using ELMo interactively (#1771),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1020,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2018-09-25 11:40:28-07:00,02e2930b38a3dbf321d738e51b9a10c569973197,https://github.com/allenai/allennlp/commit/02e2930b38a3dbf321d738e51b9a10c569973197,"Model can store extra pretained embeddings (#1817)

This adds a `min_pretrained_embeddings` parameter to the `""embedding""` token embedder which will keep at least that many embeddings from the top of an embedding text file (like Glove). This is useful as a pragmatic way to support unseen words, say in a demo, at a cost of larger model size (e.g., specifying 200k here will increase model.tar.gz by about 75MB). This leverages the fact that at least for Glove files, the words are ordered by frequency, so by the time you get to, say, 200k, you're mostly missing out on rare words where the embeddings are less useful anyway. I'd use this in the QuaRel demo.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab.get_vocab_size() >= 50', 'vocab.get_token_index() > 1  # not @@UNKNOWN@@']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1021,Brendan Roof,brendanr@allenai.org,2018-09-25 15:35:07-07:00,8be358e9a495b0fad6202cca89ce29a5f07dc504,https://github.com/allenai/allennlp/commit/8be358e9a495b0fad6202cca89ce29a5f07dc504,"Seq2Seq Test Cleanup (#1814)

- Followup from https://github.com/allenai/allennlp/pull/1808.",1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1022,Kevin Lin,kl2806@columbia.edu,2018-09-26 11:33:58-07:00,53bba3db6a0796a908417e05ba8e9e413ac096c1,https://github.com/allenai/allennlp/commit/53bba3db6a0796a908417e05ba8e9e413ac096c1,"SQL Executor (#1815)

* sql executor

* docs

* add test

* docs

* mark wikitables erm test as flaky",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['executor.evaluate_sql_query(postprocessed_sql_query_label,', 'executor.evaluate_sql_query(postprocessed_predicted_sql_query,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1023,Kevin Lin,kl2806@columbia.edu,2018-09-26 15:34:57-07:00,b1db1c9de5cb9e443f87a73a42b95419e1cea405,https://github.com/allenai/allennlp/commit/b1db1c9de5cb9e443f87a73a42b95419e1cea405,"ATIS Predictor (#1818)

* predictor

* pylint

* add docs

* use the train_fixtures.py script

* make model slightly large to avoid 0 gradients",13,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(action_sequence) > 1', 'all([isinstance(action, str) for action in action_sequence])', 'predicted_sql_query is not None', 'predicted_sql_query is not None', 'predicted_sql_query is not None']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1024,Mark Neumann,markn@allenai.org,2018-09-27 09:38:38-07:00,9c7d0d0a1946953fe19c76a899c105bdf96f4bf9,https://github.com/allenai/allennlp/commit/9c7d0d0a1946953fe19c76a899c105bdf96f4bf9,"sql data updates (#1827)

* add analysis of AS to script

* add functionality to remove aliases, split tokens on . as well as spaces

* update tests to account for spitting on .

* fix up cleaning proceedure

* lint

* add way to read dataset schema

* fix lint

* mypy

* fix splitting of decimals, duh

* lint

* pr comments",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['cleaned == [,', 'text2sql_utils.clean_unneeded_aliases([]', 'text2sql_utils.clean_unneeded_aliases(sql) == sql', 'schema == {']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1025,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2018-09-27 10:39:53-07:00,e84e4961ff25d4a02a127e7502c033cd76ff1a6d,https://github.com/allenai/allennlp/commit/e84e4961ff25d4a02a127e7502c033cd76ff1a6d,"Support adding to vocabulary from pretrained embeddings (#1822)

* Revert ""Model can store extra pretained embeddings (#1817)""
This reverts commit 02e2930b38a3dbf321d738e51b9a10c569973197.
* Support adding to vocabulary from embedding file",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab.get_vocab_size() >= 50', 'vocab.get_token_index() > 1  # not @@UNKNOWN@@']",[],[],[],[],[],[],[],[],[],[],[],[],"['vocab.get_vocab_size() >= 50', 'vocab.get_token_index() > 1  # not @@UNKNOWN@@']",[],[],[],[],[],[],[],[],[],[],[],[]
1026,Mark Neumann,markn@allenai.org,2018-09-27 12:44:04-07:00,63ba3fb28897578d4798039d1713e2b7995eb753,https://github.com/allenai/allennlp/commit/63ba3fb28897578d4798039d1713e2b7995eb753,"make some sql context code more generic (#1831)

* shuffle things around, extract pieces of sql code which can be reused

* fix test, lint

* extract initialize valid actions as well

* fix docs",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1027,Evan Pete Walsh,epwalsh10@gmail.com,2018-09-27 23:27:35-07:00,a6b4c3009678be0195b408b7be6facce06e59191,https://github.com/allenai/allennlp/commit/a6b4c3009678be0195b408b7be6facce06e59191,"Add per node beam size option to beam search (#1835)

* add per_node_beam_size option

* remove executability",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1028,Mark Neumann,markn@allenai.org,2018-09-28 17:00:19-07:00,a1ec53dd864ca78fbb48b6eae4cfc3cb662f29cc,https://github.com/allenai/allennlp/commit/a1ec53dd864ca78fbb48b6eae4cfc3cb662f29cc,initial text2sql grammar with unconstrained context (#1834),7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['grammar_dictionary[]', 'grammar_dictionary[,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1029,Kevin Lin,kl2806@columbia.edu,2018-09-28 20:19:55-07:00,f7c4195ce5ec66c2be7551d14b191204d3b64f27,https://github.com/allenai/allennlp/commit/f7c4195ce5ec66c2be7551d14b191204d3b64f27,"Faster data loading for SQL Context (#1838)

* share sqlcontext

* pylint, update experiment configs

* fix grammar statelet test

* update docs

* format

* initialize things in constructor",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1030,Matthew Peters,matt-peters@users.noreply.github.com,2018-09-30 20:49:27-07:00,0b852fb2ef1000fa6209815d1c91171a9b093fef,https://github.com/allenai/allennlp/commit/0b852fb2ef1000fa6209815d1c91171a9b093fef,"Add Open AI tokenizer, and ability to add special tokens to token indexer (#1836)

* Add open ai tokenizer

* Allow to add special tokens for open ai

* ftfy in requirements

* Add a test for OpenAISplitter

* Add test for open ai with extra tokens

* add ftfy to setup.py

* pylint

* doc

* doc

* ftfy

* try to get the notebooks passing

* add option to only use top layer

* n_special and n_ctx

* n_ctx

* return all byte pairs

* lint

* n_ctx",10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indices[][:9] == [50, 4, 21, 31, 4, 0, 1, 51, 0]', 'tokens == expected_tokens', 'list(output.shape) == [2, 7, 10]', 'list(output.shape) == [2, 2, 10]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1031,Kevin Lin,kl2806@columbia.edu,2018-10-01 13:18:02-07:00,38c87e03adc782db66bb4f19b761a150883f7b48,https://github.com/allenai/allennlp/commit/38c87e03adc782db66bb4f19b761a150883f7b48,fix network issue (#1844),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1032,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-10-01 15:31:37-07:00,53b166ec49b3ba6d621915406f21cb61e4937d48,https://github.com/allenai/allennlp/commit/53b166ec49b3ba6d621915406f21cb61e4937d48,"Executor for WikiTables variable free language (#1762)

* changed some type signatures to be consistent, added several new functions in the executor

* added two more filtering operations

* refactored executors, and made a new wikitables executor

* added more tests, fixed a few bugs, added docs

* better date handling

* deal with dates

* added date filters

* increased test coverage and fixed mypyissues

* added couple more tests

* adressed most of the pr comments

* made function arguments more explicit

* removed obsolete test

* added more tests to increase coverage

* even more tests

* More tests!!

* addressed pr comments

* undid assert not changes",22,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,26,2,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,67,0,0,0,0,0,0,0,0,0,0,0,0,21,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Logs', '() as log:'), ('Equal', '(log.output,'), ('Logs', '() as log:'), ('Equal', '(log.output,'), ('Logs', '() as log:'), ('Equal', '(log.output,'), ('Logs', '() as log:'), ('Equal', '(log.output,'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):')]","['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],"[('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):')]",[],[],[],[],[],[],[],[],[],"['executor.execute(logical_form_true) is True', 'executor.execute(logical_form_false) is False', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is True', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'self.custom_executor.execute(logical_form) is True', 'self.custom_executor.execute(logical_form) is True', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'set(cell_list) == {}', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_value_list == []', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'count_result == 0', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'sum_value == 13197', 'sum_value == 13197', 'avg_value == 6598.5', 'avg_value == 6598.5', 'avg_value == 1141', 'Date(2013, 12, 31) > Date(2013, 12, 30)', 'Date(2013, 12, 31) == Date(2013, 12, -1)', 'Date(2013, -1, -1) >= Date(2013, 12, 31)', '(Date(2013, 12, -1) > Date(2013, 12, 31)) == False', '(Date(2013, 12, 31) > 2013) == False', '(Date(2013, 12, 31) >= 2013) == False', 'Date(2013, 12, 31) != 2013', '(Date(2018, 1, 1) >= Date(-1, 2, 1)) == False', '(Date(2018, 1, 1) < Date(-1, 2, 1)) == False', 'Date(-1, 2, 1) < Date(-1, 2, 3)', '(Date(-1, -1, 1) < Date(-1, -1, 3)) == False', '(Date(-1, -1, 1) >= Date(-1, -1, 3)) == False', '(Date(2018, -1, 1) < Date(2018, -1, 3)) == False', '(Date(2018, -1, 1) >= Date(2018, -1, 3)) == False', 'str(expression) == ', 'str(expression) == ', 'str(expression) == ']",[],[],[],[],[],[],[],[],[],[],[],[],"['nlvr_world.execute(logical_form_true) is True', 'nlvr_world.execute(logical_form_false) is False', 'nlvr_world.execute(logical_form) is False', 'nlvr_world.execute(logical_form) is True', 'nlvr_world.execute(logical_form) is True', 'nlvr_world.execute(logical_form) is False', 'nlvr_world.execute(logical_form) is False', 'nlvr_world.execute(logical_form) is True', 'nlvr_world.execute(logical_form) is True', 'world.execute(', 'world.execute(', 'world.execute(logical_form) is True', 'world.execute(logical_form) is True', 'world.execute(', 'world.execute(', 'world.execute(', 'world.execute(', 'world.execute(', 'str(expression) == ', 'str(expression) == ', 'str(expression) == ']",[],[],[],[],[],[],[],[],[],[],[],[]
1033,Mark Neumann,markn@allenai.org,2018-10-01 22:32:57-07:00,99308f64ef7ecd5abf5bb7edae0911f75f35423a,https://github.com/allenai/allennlp/commit/99308f64ef7ecd5abf5bb7edae0911f75f35423a,"Structured sql data (#1845)

This PR does a few things:

- Strips out registerable `SqlTableContexts`, they weren't a useful abstraction because i'm going to implement different constraints as functions which mutate the grammar, and just pass a list of functions to apply in. They don't have enough differently implemented functionality to make this useful, and it was confusing to have different contexts not be usable in different ... contexts (e.g you couldn't use the `AtisContext` in a `Text2SqlDatasetReader`, but according to the class hierarchy, you could).
- Adds a `GrammarBasedText2Sql` dataset reader.
- Adds a pre-processing step to the Text2Sql data to replace column references which use `ID` (sql syntactic sugar for the primary key of a table) with the actual column name of the primary key (this was so annoying haha)
- Adds `wsp` to non-terminals which are ignored when producing action sequences
- Adds a very basic `Text2SqlWorld` which currently just delegates all of its work to the `Text2SqlContext`, but I will add in linking etc in future PRs.
- Documents a few assumptions we were making about `ws` and `wsp` nodes in grammars which wasn't super obvious.

Note that to make this PR smaller, some of the tests are just dummy shells which just test that things run - this is because it is required that we add in strings to the grammar from the tables, but I want to do that in a separate PR because it will be complicated.",13,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['resolved == []', 'action_sequence == []', 'all_actions is not None']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1034,Kathryn Chan,kathrync@allenai.org,2018-10-02 15:42:58-07:00,358c36bab3a91d0f97c6f27af18797953752c5bd,https://github.com/allenai/allennlp/commit/358c36bab3a91d0f97c6f27af18797953752c5bd,"Raise RuntimeError if java is not available (#1856)

* add check function in verify.py

* move function into check.py

* call the check fucntion

* return boolean instead of raising error directly",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1035,Kathryn Chan,kathrync@allenai.org,2018-10-02 17:58:37-07:00,6183c90a121eb4a38f68ab726805698384452f08,https://github.com/allenai/allennlp/commit/6183c90a121eb4a38f68ab726805698384452f08,"Remove wget in wikitables tests by using requests (#1854)

* first try

* remove comments

* fix style

* change temp_file to downloaded_file",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1036,Evan Pete Walsh,epwalsh10@gmail.com,2018-10-02 18:57:34-07:00,09345129b975069c120d158a6e768db72e554d11,https://github.com/allenai/allennlp/commit/09345129b975069c120d158a6e768db72e554d11,"move ftfy to right section, fix req. check script (#1858)",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1037,Matt Gardner,mattg@allenai.org,2018-10-02 19:23:51-07:00,1d5029245aa44111e8149d5b215df8dc51aead31,https://github.com/allenai/allennlp/commit/1d5029245aa44111e8149d5b215df8dc51aead31,Use current_log_probs instead of log_probs in debug_info (#1855),4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1038,Matt Gardner,mattg@allenai.org,2018-10-02 19:27:12-07:00,d8b13e01e4d85742d3c3e34aaa598e48a21b446a,https://github.com/allenai/allennlp/commit/d8b13e01e4d85742d3c3e34aaa598e48a21b446a,"Simplified GrammarStatelet, made a new LambdaGrammarStatelet class for WikiTables (#1829)

* Simplified GrammarStatelet, made a new LambdaGrammarStatelet class for WikiTables

* Fixed tests, docs and imports (I think...)

* Fix ATIS test

* Fix other atis test

* Fix BasicTransitionFunctionTest

* Fix mypy and pylint

* Use the right pylint command...",14,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,1,0,0,0,0,0,0,0,0,0,0,1,11,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not state.is_finished()', 'state.is_finished()', 'state.get_valid_actions() == s_actions', 'state.get_valid_actions() == t_actions', 'state.get_valid_actions() == e_actions', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [3, 4]', 'actions[][2] == [3, 4]', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__']",['(AssertionError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['actions[][2] == [1, 2, 5]', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [3, 4]', 'actions[][2] == [3, 4]', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__']",[],[],[],[],[],[],[],[],[],[],[],[]
1039,Kevin Lin,kl2806@columbia.edu,2018-10-02 22:21:07-07:00,a7da2abf248def9db2dc66a02c973c0e5cf270e3,https://github.com/allenai/allennlp/commit/a7da2abf248def9db2dc66a02c973c0e5cf270e3,"Fast grammar generation (#1852)

* 1 grammar object

* test, pylint

* fix typo

* pylint

* remove pos from spacey model

* private method, decrease max_decoding_steps

* test helper methods",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(world.valid_actions[]) == \\', 'world.dates == [datetime(1993, 6, 4, 0, 0)]', 'world._get_numeric_database_values(] # pylint: disable=protected-access', 'world._get_sequence_with_spacing(world.grammar, # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[],['world.valid_actions[] == \\'],[],[],[],[],[],[],[],[],[],[],[],[]
1040,Ben Eyal,bene@post.bgu.ac.il,2018-10-03 18:50:55+03:00,3de6943b8044a8ab3310705065b33404b36b7ebd,https://github.com/allenai/allennlp/commit/3de6943b8044a8ab3310705065b33404b36b7ebd,Avoid deprecation warnings (#1861),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1041,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-10-03 10:31:33-07:00,c7289513f9fc93b37cecc28ce1e8d4ece7f84956,https://github.com/allenai/allennlp/commit/c7289513f9fc93b37cecc28ce1e8d4ece7f84956,"Integrate new table context in variable free world (#1832)

* All of Shikhar's commits, squashed into one

* added column types to type declaration

* made minimal changes to table question context to pass lint, mypy and doc build

* misc changes missing from previous commits

* undo changes made to table question knowledge graph

* fixed misc issues from rebase

* misc fixes to tests for new context

* addressed PR comments",20,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ParsingError):')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['number_entities == [(, 16)]', 'number_entities == [(, 11)]', 'number_entities == [(, 12)]', 'entities == []', 'numbers == [(, 9)]', 'entities == []', 'numbers == []', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'str(expression) == ', 'self.world_with_usl_a_league.get_action_sequence(expression) == expected_sequence', 'str(expression) == ', 'str(expression) == ', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],"['str(expression) == ', 'self.world.get_action_sequence(expression) == expected_sequence', 'str(expression) == ', 'str(expression) == ', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,']",[],[],[],[],[],[],[],[],[],[],[],[]
1042,Mark Neumann,markn@allenai.org,2018-10-03 11:19:04-07:00,c635bc4747b5ee5f14d7a31602010d4892e6e27e,https://github.com/allenai/allennlp/commit/c635bc4747b5ee5f14d7a31602010d4892e6e27e,Graph parser for semantic dependencies (#1743),18,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,3,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == [,', 'arcs.indices == [(1, 0), (1, 5), (1, 8), (4, 3), (5, 4),', 'arcs.labels == [,', 'tokens == [,', 'arcs.indices == [(1, 0), (1, 2), (3, 2), (3, 4), (5, 4), (5, 6),', 'arcs.labels == [,', 'empty_field.indices == []', 'set(decode_output_dict.keys()) == set([,']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1043,Michael Schmitz,michael@schmitztech.com,2018-10-04 08:58:42-07:00,21114288e8a4244b70a0fd2d91fc8c3b29de1cd4,https://github.com/allenai/allennlp/commit/21114288e8a4244b70a0fd2d91fc8c3b29de1cd4,Use test-install rather than verify.py (#1849),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1044,Michael Schmitz,michael@schmitztech.com,2018-10-04 09:53:05-07:00,5172c852b2d8c692aca4cd6daf1a2cec3f0a6fc6,https://github.com/allenai/allennlp/commit/5172c852b2d8c692aca4cd6daf1a2cec3f0a6fc6,Create a markdown file that enumerates available models (#1802),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1045,Kevin Lin,kl2806@columbia.edu,2018-10-04 11:31:47-07:00,8236624d226ef378db7322000a2aa7abeb24bc3f,https://github.com/allenai/allennlp/commit/8236624d226ef378db7322000a2aa7abeb24bc3f,"Compile and fix warning for regex in SQL action seq formatting (#1864)

* compile regex

* replace the other regex too",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1046,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2018-10-04 14:38:30-07:00,8ff832471364b09278d5863f31c47fa32662dd08,https://github.com/allenai/allennlp/commit/8ff832471364b09278d5863f31c47fa32662dd08,Add QuaRel semantic parser (#1857),41,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['feature_values == [0, 0, 0, 1, 1, 1, 0, 0, 0]', 'worlds[]', 'worlds[]', 'qr_spec_string == ', 'answer_index is not None', 'answer_index is not None']",[],[],[],[],[],[],[],[],[],[],[],[],"['feature_values == [0, 0, 0, 1, 2/3, 1/3, 0, 0, 0]']",[],[],[],[],[],[],[],[],[],[],[],[]
1047,Brendan Roof,brendanr@allenai.org,2018-10-04 15:13:53-07:00,c530fde2c7896914992716e75d7cf7a690a78e5e,https://github.com/allenai/allennlp/commit/c530fde2c7896914992716e75d7cf7a690a78e5e,Update MODELS.md for Event2Mind. (#1866),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1048,Matt Gardner,mattg@allenai.org,2018-10-04 15:48:44-07:00,3d78e46cf8758d810c0ab27271e6e3ba4fc54833,https://github.com/allenai/allennlp/commit/3d78e46cf8758d810c0ab27271e6e3ba4fc54833,"Tutorial for the semantic parsing framework (#1853)

* Initial work on a tutorial for the semantic parsing framework

* Saving state

* Getting close to done

* Done, except for adding links and such

* Addressed most of the current feedback

* Minor wording changes.

* Starting adding links, making sure image works

* Adding footnotes and section links

* Move links

* Done with adding links, I think

* Final fixes

* Ok, one more, adding a contributions welcome statement

* Add a hint about where to start with a new task",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1049,Kevin Lin,kl2806@columbia.edu,2018-10-05 09:57:10-07:00,3989000e97844bf783caa9301b6902aa2585ab18,https://github.com/allenai/allennlp/commit/3989000e97844bf783caa9301b6902aa2585ab18,"Bug fix binary expression in updates to grammar (#1869)

* fix biexpr

* docs

* pylint

* fix types",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1050,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-10-05 12:03:30-07:00,7ddc7f16740a8c1b618f08a8afdf86042ad0bee1,https://github.com/allenai/allennlp/commit/7ddc7f16740a8c1b618f08a8afdf86042ad0bee1,"Automatically map function names to aliases for NLTK's logic parser (#1870)

* added a name mapper to take care of alias automatically

* removed obsolete lines",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['str(expression) == f', 'str(expression) == f', 'str(expression) == \\', 'str(expression) == f', 'str(expression) == \\', 'str(expression) == f']",[],[],[],[],[],[],[],[],[],[],[],[],"['str(expression) == ', 'str(expression) == ', 'str(expression) == ', 'str(expression) == ', 'str(expression) == ', 'str(expression) == ']",[],[],[],[],[],[],[],[],[],[],[],[]
1051,Matt Gardner,mattg@allenai.org,2018-10-05 14:20:11-07:00,8071f48febc8d5ba480fe222c2e2aadd3bcef791,https://github.com/allenai/allennlp/commit/8071f48febc8d5ba480fe222c2e2aadd3bcef791,bump version number to v0.7.0,5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1052,Matt Gardner,mattg@allenai.org,2018-10-05 14:58:33-07:00,51d20c54cdbb147f63285b4e20a3ab5b6ba5fa73,https://github.com/allenai/allennlp/commit/51d20c54cdbb147f63285b4e20a3ab5b6ba5fa73,Bump version numbers to vv0.7.1-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1053,WrRan,wrran@outlook.com,2018-10-07 01:36:15+08:00,371fd807876a3ca162e3980cb505feaf8c2b8cc4,https://github.com/allenai/allennlp/commit/371fd807876a3ca162e3980cb505feaf8c2b8cc4,"input_size of phrase_layer: 1144 -> 1124 (#1875)

fix wrong config of `input_size` of `phrase_layer`",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1054,Andrew Moore,andrew.p.moore94@gmail.com,2018-10-06 18:37:12+01:00,c1dcd0ff6bc3da1b5bc6c20383af96f82f6b03de,https://github.com/allenai/allennlp/commit/c1dcd0ff6bc3da1b5bc6c20383af96f82f6b03de,"Reflects the updated code (#1873)

The changes reflect the changes that have been made to the test case code.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1055,WrRan,wrran@outlook.com,2018-10-08 22:43:37+08:00,043ff07c6f0e0f95b71fe3463f86b722f871a6ad,https://github.com/allenai/allennlp/commit/043ff07c6f0e0f95b71fe3463f86b722f871a6ad,"allow Model to use custom Vocabulary subclasses

* Update model.py

decide class type of `vocabulary` from config_file

* Update vocabulary.py

make classmethod `from_instances` and `from_files` to be real classmethods

* Update model.py

make the model can load custom vocabulary subclass

* Update vocabulary.py

make `Vocabulary` be the default implementation of Vocabulary class

* add a newline at end-of-file

add a new line to avoid EOF error when building docs

* minor bug-fix

my bad: ignore a ""

* remove trailing whitespace",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1056,Mark Neumann,markn@allenai.org,2018-10-08 18:56:48-07:00,ffab3201c14bf0f4ce04a4c6b1e77b10c20020fd,https://github.com/allenai/allennlp/commit/ffab3201c14bf0f4ce04a4c6b1e77b10c20020fd,"strings in sql/prelinked entities (#1876)

- Makes `ProductionRuleFields` printable
- Removes SqlTableContext, it had no value - moved everything into `World`
- Added a method to link entities directly
- Added a test for the reader",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,13,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],"['len(instances) == 5', 'tokens == []', 'indices == [101, 75, 81, 124, 33, 5, 33, 5, 33, 5, 33, 5, 33, 5,', 'production_rules == [(, True),', 'grammar_dictionary[]', 'grammar_dictionary[,', 'not world.is_global_rule()', 'in action_sequence', 'in action_sequence', 'in actions', 'in actions', 'world.base_grammar_dictionary[,', 'world.base_grammar_dictionary[,']",[],[],[],[],[],[],[],[],[],[],[],[],"['grammar_dictionary[]', 'grammar_dictionary[,', 'action_sequence == []', 'all_actions is not None']",[],[],[],[],[],[],[],[],[],[],[],[]
1057,Mark Neumann,markn@allenai.org,2018-10-10 11:18:56-07:00,91bfb4c0f55a1de59b587ffbeb4d751f66281abf,https://github.com/allenai/allennlp/commit/91bfb4c0f55a1de59b587ffbeb4d751f66281abf,Global grammar values (#1888),5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indices == [101, 75, 81, 125, 33, 5, 33, 5, 33, 5, 33, 5,', 'grammar_dictionary[,']",[],[],[],[],[],[],[],[],[],[],[],[],"['indices == [101, 75, 81, 124, 33, 5, 33, 5, 33, 5, 33, 5, 33, 5,']",[],[],[],[],[],[],[],[],[],[],[],[]
1058,WrRan,wrran@outlook.com,2018-10-11 04:23:58+08:00,24e5547b55e26d8a6b36ef32c1e965f24f0970a1,https://github.com/allenai/allennlp/commit/24e5547b55e26d8a6b36ef32c1e965f24f0970a1,"feature-enhancement: make trainer registrable (#1884)

* Update trainer.py

I make `Trainer` be `Registrable` and make itself be the default_implementation.

* Update trainer.py

I modify the classmethod `from_params` of Trainer to return a `cls(...)` instead of `Trainer(...)`.

* decide Trainer class by config_file

* minor-bug-fix: do not pop trainer twice

* minor-bug-fix: do not pop `trainer` twice.

* add `type` and `pylint` comments to pass them

* call Trainer.from_params using keyword arguments

* call Trainer.from_params using keyword arguments

* remove unnecessary whitespace

* Pylint and mypy, minor other fixes",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1059,Mark Neumann,markn@allenai.org,2018-10-10 14:22:30-07:00,0d9ad6553326ae79a904fdfc5ab265479476c163,https://github.com/allenai/allennlp/commit/0d9ad6553326ae79a904fdfc5ab265479476c163,"Var free grammar (#1893)

- Modifies the grammar to remove some stuff which is not needed if we don't have table aliases.
- Wires it into the World",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ParseError):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indices == [93, 75, 78, 117, 34, 5, 34, 5, 34, 5, 34, 5, 34, 5, 39, 107, 13,', 'not in productions']",[],[],[],[],[],[],[],[],[],[],[],[],"['indices == [101, 75, 81, 125, 33, 5, 33, 5, 33, 5, 33, 5,']",[],[],[],[],[],[],[],[],[],[],[],[]
1060,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-10-10 14:58:04-07:00,1691cb3a61740fbbc8305d52d4e830c79302a666,https://github.com/allenai/allennlp/commit/1691cb3a61740fbbc8305d52d4e830c79302a666,"Run ActionSpaceWalker on the new variable free language for WikiTables (#1860)

* couple of changes related to multimatch type for the action space walker t work

* checking in the official evaluator

* Added string rep for dates

* misc fixes to make action space walker work

* updated test with new data format

* offline search script for wikitables and a couple of other bug fixes

* pending changes from #1832

* return all logical forms if agenda is empty

* fixed a bug in column name matching for agenda

* couple of other agenda related changes

* minor bug fix

* number comparison and oter fixes in the executor

* agenda selection fixes

* string constants should now have a prefix string: in logical forms

* fix the agenda strings too

* moved evaluator to tools

* fixed docs and moved squad_eval to tools

* moved simple lisp parser to util and a couple of other bug fixes

* couple more path fixes

* minor fixes

* column type aware entity extraction from questions

* added type annotation

* updated comment

* addressed pr comments",32,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,4,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,32,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Logs', '() as log:'), ('Equal', '(log.output,'), ('Logs', '() as log:'), ('Equal', '(log.output,')]",[],[],[],[],[],[],[],[],[],[],"[('Raises', '(ExecutionError):')]",[],[],[],[],[],[],[],[],[],"['set(first_four_logical_forms) == {,', 'set(yellow_black_triangle_touch_forms) == set([', 'table_question_context.table_data == [{,', 'string_entities == []', 'number_entities == [(, 7)]', 'set(cell_list) == {}', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'result == []', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(cell_list) == {}', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[]
1061,Mark Neumann,markn@allenai.org,2018-10-11 13:26:00-07:00,ae9c9c836891a10d221691df266d754b6557c644,https://github.com/allenai/allennlp/commit/ae9c9c836891a10d221691df266d754b6557c644,"try to do some type inference on variables (#1898)

* try to do some type inference on variables

* fix tests",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['sql_data.sql_variables == {},', 'sql_data.sql_variables == {},', 'indices ==[93, 75, 78, 118, 34, 5, 34, 5, 34, 5, 34, 5, 34, 5, 39, 116,', 'production_rules == [(, True) ,', 'in action_sequence', 'in action_sequence', 'in actions', 'in actions']",[],[],[],[],[],[],[],[],[],[],[],[],"['sql_data.sql_variables == {}', 'sql_data.sql_variables == {}', 'indices == [93, 75, 78, 117, 34, 5, 34, 5, 34, 5, 34, 5, 34, 5, 39, 107, 13,', 'production_rules == [(, True),', 'in action_sequence', 'in action_sequence', 'in actions', 'in actions']",[],[],[],[],[],[],[],[],[],[],[],[]
1062,Matt Gardner,mattg@allenai.org,2018-10-11 13:59:17-07:00,dc66c8f98d4613537d33520dc326841a2ff88f88,https://github.com/allenai/allennlp/commit/dc66c8f98d4613537d33520dc326841a2ff88f88,Fix QuaRel reference (#1899),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1063,Kevin Lin,kl2806@columbia.edu,2018-10-11 19:09:27-07:00,27fab848380e41c9a35caad14f8f3b5777b48fb6,https://github.com/allenai/allennlp/commit/27fab848380e41c9a35caad14f8f3b5777b48fb6,"Add more configuration options for ATIS semantic parser (#1821)

* costs

* add keep if unparseable flag

* keep unparseable in dev

* pylint

* add one direction cost

* fix test

* retrain fixture

* docs

* read unparseable

* add concat based context

* fix imports

* heuristics

* heuristics

* unparseable queries

* turn off info logging in subprocess

* fix flight numbers

* fix dates

* fix tokenization

* heuristics

* more epochs

* reverse the productions, predict the leftmost nonterminal first

* left first model 44

* add helper functions for numbers

* fix global rules test

* fix tests

* clean up

* grammar statelet test

* dates

* rename

* pylint

* remove debug tests

* retrain fixture

* fix action sequence test

* change text2sql test to also left first

* add another test extraction test

* experiment config

* user numeric nonterminals

* docs",19,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indices == [93, 75, 78, 88, 86, 82, 39, 113, 48, 42, 2, 46, 91, 90, 102, 92, 90, 103, 118, 34, 5,', 'set(valid_actions.keys()) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'action_sequence == \\', 'world._get_numeric_database_values(] # pylint: disable=protected-access', 'world.dates == [datetime(1993, 7, 10, 0, 0)]']",[],[],[],[],[],[],[],[],[],[],[],[],"['indices ==[93, 75, 78, 118, 34, 5, 34, 5, 34, 5, 34, 5, 34, 5, 39, 116,', 'set(valid_actions.keys()) == {,', 'date_binary_expression in world.valid_actions[]', 'action_sequence == [,', 'world._get_numeric_database_values(] # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[]
1064,tuvuumass,tuvu@cs.umass.edu,2018-10-12 16:25:06-04:00,4a22c29208ac33e5a3133f75a259d46168de73f2,https://github.com/allenai/allennlp/commit/4a22c29208ac33e5a3133f75a259d46168de73f2,# added optimizer parameter (#1766),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1065,Matthew Peters,matt-peters@users.noreply.github.com,2018-10-12 17:51:24-07:00,7a707ea200aaf45f4e780e0c1bbedd9bb177b18d,https://github.com/allenai/allennlp/commit/7a707ea200aaf45f4e780e0c1bbedd9bb177b18d,"Make `SlantedTriangular` a little more robust (#1751)

Covers some edge cases where `num_batches_per_epoch` passed to `SlantedTriangular` doesn't match exactly the actual number of batches.",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['scheduler.lr_scheduler.freezing_current', 'not is_hat_shaped([0.0] * 10)', 'not is_hat_shaped([float(k) for k in range(10)])', 'not is_hat_shaped([float(10 - k) for k in range(10)])', 'is_hat_shaped([float(k) for k in range(10)] +', 'not is_hat_shaped([float(k) for k in range(10)] +', 'max(first_layer_lrs[:num_actual_steps_per_epoch]) < 1e-8', 'min(first_layer_lrs[:num_actual_steps_per_epoch]) > -1e-8', 'is_hat_shaped(first_layer_lrs[num_actual_steps_per_epoch:])', 'is_hat_shaped(second_layer_lrs[:num_actual_steps_per_epoch])', 'is_hat_shaped(second_layer_lrs[num_actual_steps_per_epoch:])', 'is_hat_shaped(first_layer_lrs)', 'is_hat_shaped(second_layer_lrs)']",[],[],[],[],[],[],[],[],[],[],[],[],['scheduler.lr_scheduler.freezing_current'],[],[],[],[],[],[],[],[],[],[],[],[]
1066,Kevin Lin,kl2806@columbia.edu,2018-10-12 23:26:00-07:00,3753b0b223c731c3361f39bd994b1cd297f54cd1,https://github.com/allenai/allennlp/commit/3753b0b223c731c3361f39bd994b1cd297f54cd1,"Multilayer decoder for semantic parsing framework (#1902)

* first pass

* clean up

* rename

* keep final states false

* fix test

* use lstm cell if only 1 layer

* comment

* remove commented out code

* lint, make model compatible with 1 layer decoder

* test multi layers",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1067,Michael Schmitz,michael@schmitztech.com,2018-10-15 10:43:59-07:00,c450565957546f496d210335ca32d5e3ade87422,https://github.com/allenai/allennlp/commit/c450565957546f496d210335ca32d5e3ade87422,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1068,Kevin Lin,kl2806@columbia.edu,2018-10-15 13:01:34-07:00,d3a8f4f699c1af672ac555ba0df12cbc62369808,https://github.com/allenai/allennlp/commit/d3a8f4f699c1af672ac555ba0df12cbc62369808,"Track dev loss in ATIS model (#1907)

* get dev loss

* add test",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instance.fields[].field_list) == 1', 'instance.fields[].field_list[0].sequence_index == -1']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1069,Brendan Roof,brendanr@allenai.org,2018-10-15 18:30:10-07:00,a94a23ebfd7425ee94fdb5a4c2352e45e7b84baa,https://github.com/allenai/allennlp/commit/a94a23ebfd7425ee94fdb5a4c2352e45e7b84baa,"More closely emulate original Event2Mind implementation. (#1903)

- Use word2vec instead of glove.
- Fix bugs in vocabulary configuration.
  1. Place namespace under `min_count`.
  2. Unify source and target namespaces.
  3. Generate vocabulary with `dry-run` to correctly count tokens, i.e. without multiplicity from the combinations of intents and reactions.
- Training is now a two-step process:
```
        allennlp dry-run -o '{""dataset_reader"": {""dummy_instances_for_vocab_generation"": true}} {""vocabulary"": {""min_count"": {""source_tokens"": 2}}}' training_config/event2mind.json --serialization-dir vocab_output_path
        allennlp train -o '{""vocabulary"": {""directory_path"": ""vocab_output_path/vocabulary/""}}' training_config/event2mind.json --serialization-dir output_path
```",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,30,0,0,0,0,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 13', 'get_text(,', 'get_text(]', 'get_text(]', 'get_text(]', 'len(instances) == 21', 'get_text(,', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(,', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(,', 'get_text(]', 'get_text(]', 'get_text(]']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],[],['len(instances) == 12'],[],[],[],[],[],[],[],[],[],[],[],[]
1070,Michael Schmitz,michael@schmitztech.com,2018-10-16 10:35:21-07:00,ae7b9a733c4e605accd01193cb74ee822eca9d13,https://github.com/allenai/allennlp/commit/ae7b9a733c4e605accd01193cb74ee822eca9d13,Move 'What is AllenNLP' from README to docs. (#1909),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1071,Brendan Roof,brendanr@allenai.org,2018-10-16 12:06:22-07:00,158a29c197056ef9c692926f4d0871bbea1f8925,https://github.com/allenai/allennlp/commit/158a29c197056ef9c692926f4d0871bbea1f8925,"Tentative port of `LMDatatsetReader` (#1881)

- Based off of https://github.com/allenai/calypso/blob/master/calypso/data.py.
- Principal differences:
  - Relies on standard AllenNLP batching, iterators and indexing.
  - No sharding or looping indefinitely.
  - Does not port `AsyncLMDataset` in anticipation of using `MultiprocessDatasetReader`.",16,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Equal', '(text, [])'), ('Equal', '(sorted(list(expected_batch.fields.keys())),'), ('True', '(str(expected_batch.fields[k]) == str(batch.fields[k]))'), ('Equal', '(k, 99)'), ('Equal', '(k, 11)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1072,Joel Grus,joelgrus@gmail.com,2018-10-16 12:37:53-07:00,0e47d1605fa9b8ffb8285825a365e71963a80aa4,https://github.com/allenai/allennlp/commit/0e47d1605fa9b8ffb8285825a365e71963a80aa4,"bidirectional LM + cnn highway encoder + gated cnn encoder (#1787)

* first stab at contextual encoder wrappers

* contextual encoders

* remove sru encoder

* pr comments

* replace _ElmoCharacterEncoder with CharacterEncoder

* docs

* sphinx stuff

* address pr comments

* address more PR comments

* make sphinx happy

* iterate

* make parameters required

* this is still wip

* wip

* bidirectional-lm proof of concept

* progress

* revert elmo

* revert elmo test

* revert elmo token embedder

* cnn_highway_encoder -> seq2vec

* remove contextual encoders

* fix docs

* remove print

* address more feedback

* replace none with identity function

* fix docs + checks

* fix tests

* add comments

* add top level imports

* fix imports

* unused import

* progress

* Move 'What is AllenNLP' from README to docs. (#1909)

* use brendan's dataset reader

* Tentative port of `LMDatatsetReader` (#1881)

- Based off of https://github.com/allenai/calypso/blob/master/calypso/data.py.
- Principal differences:
  - Relies on standard AllenNLP batching, iterators and indexing.
  - No sharding or looping indefinitely.
  - Does not port `AsyncLMDataset` in anticipation of using `MultiprocessDatasetReader`.",23,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indices == {: [[8, 3, 9],', 'set(result) == {}', 'tuple(embeddings.shape) == (2, 6, 14)', 'np.allclose(normed_x.data.numpy(), expected)', 'list(output.size()) == [5, 10, 64]', 'list(output.size()) == [5, 10, 64]', 'len(output) == 3', 'list(concat_layers.size()) == [5, 3, 10, 64]', 'list(token_embedding.size()) == [5, 6, 16]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1073,Michael Schmitz,michael@schmitztech.com,2018-10-16 14:01:36-07:00,2ec52a5df030983cefc71e7657ce4a31a9ca2e3d,https://github.com/allenai/allennlp/commit/2ec52a5df030983cefc71e7657ce4a31a9ca2e3d,Uptick cffi to 1.11.5 (#1846),2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,3,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(reason=)', '(reason=)', '(reason=)']",[],[],[],[],"['skip(reason=)', 'skip(reason=)', 'skip(reason=)']","['mark.skip(reason=)', 'mark.skip(reason=)', 'mark.skip(reason=)']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1074,Shikhar Murty,shikhar.murty@gmail.com,2018-10-16 20:15:46-04:00,f224c628025c8c26b5fc7e4a74b7663422fcc301,https://github.com/allenai/allennlp/commit/f224c628025c8c26b5fc7e4a74b7663422fcc301,"Agenda improvements (#1897)

* fix merge

* all agenda changes in one commit

* tab fix

* fix minor bug and extra newlines

* added tests",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1075,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2018-10-17 00:36:04-04:00,63836c421a30bcbc62159efffae1523005eff30f,https://github.com/allenai/allennlp/commit/63836c421a30bcbc62159efffae1523005eff30f,"Adding support for list, tuple, and set in from_params (#1914)",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(d.items, dict)', 'len(d.items) == 2', 'all(isinstance(key, str) for key in d.items.keys())', 'all(isinstance(value, B) for value in d.items.values())', 'd.items[].size == 1', 'd.items[].size == 2', 'isinstance(d.items, list)', 'len(d.items) == 2', 'all(isinstance(item, B) for item in d.items)', 'd.items[0].size == 1', 'd.items[1].size == 2', 'isinstance(f.items, tuple)', 'len(f.items) == 2', 'isinstance(f.items[0], B)', 'isinstance(f.items[1], D)', 'f.items[0].size == 1', 'f.items[1].name == ', 'isinstance(d.items, set)', 'len(d.items) == 2', 'all(isinstance(item, B) for item in d.items)', 'any(item.name ==  for item in d.items)', 'any(item.name ==  for item in d.items)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1076,Sai,sai-prasanna@users.noreply.github.com,2018-10-17 22:09:33+05:18,9fcc79566cc148cce9f967a7962ac03bc300f011,https://github.com/allenai/allennlp/commit/9fcc79566cc148cce9f967a7962ac03bc300f011,"Learning Rate Finder (#1776)

Adds a new command `find-lr` that allows one to search for learning rate range where loss drops rapidly. This addresses feature request https://github.com/allenai/allennlp/issues/537 . Refer the following [blog post](https://medium.com/@surmenok/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0) linked in that issue for overview of how the finder works.

The major changes are making few of the fields in `Trainer` ""public"" (ie remove underscore from names). I have used matplotlib to plot learning rate vs loss graph.

I haven't written unit tests, if the current code is ok, will do. I am a little unsure on what to test exactly.",8,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name'), ('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name')]","['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not os.path.exists(serialization_dir2)', 'not os.path.exists(serialization_dir3)', 'args.func == find_learning_rate_from_args', 'args.param_path == ', 'args.serialization_dir == ', 'cm.exception.code == 2  # argparse code for incorrect usage', 'cm.exception.code == 2  # argparse code for incorrect usage', 'len(learning_rates_losses) > 1', 'len(learning_rates) == 101', 'len(losses) == 101']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1077,Nelson Liu,nelson-liu@users.noreply.github.com,2018-10-18 14:30:15-07:00,404b5296c2d2b2287b96cd102acc48cb19b8df52,https://github.com/allenai/allennlp/commit/404b5296c2d2b2287b96cd102acc48cb19b8df52,Enable setting scalar mix parameters for ScalarMix and Elmo (#1921),3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['scalar_mix_parameter.requires_grad is False', 'scalar_mix_parameter.item() == initial_scalar_parameters[i]']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1078,Thomas Wolf,thomwolf@users.noreply.github.com,2018-10-19 16:52:55+02:00,f29839e0dcdac53175107b00f5c05b98c3b214bf,https://github.com/allenai/allennlp/commit/f29839e0dcdac53175107b00f5c05b98c3b214bf,fix BiMPM url in MODEL.md (#1923),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1079,Mark Neumann,markn@allenai.org,2018-10-19 12:10:47-07:00,360c3e10d40a1e9e64085be571eeed4725c53095,https://github.com/allenai/allennlp/commit/360c3e10d40a1e9e64085be571eeed4725c53095,"Text2sql model (#1905)

- Rename `ProductionRuleArray` -> `ProductionRule`
- Make it a namedtuple (It threw me that this wasn't a tensor which made me super confused about how we were indexing into it.)
- Add a `Text2SqlParser` which currently will only support global actions",22,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,1,0,0,0,0,1,1,0,0,1,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['production_rules == [(, True),', 'len(tensor_tuple) == 4', 'len(tensor_tuple) == 4', 'grammar_state._nonterminal_stack == [] # pylint: disable=protected-access']",[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],['import pytest'],"['production_rules == [(, True) ,', 'len(tensor_tuple) == 3', 'len(tensor_tuple) == 3']",[],[],[],[],[],[],[],[],[],[],[],[]
1080,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2018-10-19 15:45:52-04:00,188e06d7e951fcd95a6fcbbe9a70e8fccc4a8a6a,https://github.com/allenai/allennlp/commit/188e06d7e951fcd95a6fcbbe9a70e8fccc4a8a6a,"Passing the 'stateful' parameter to the 'PytorchSeq2SeqWrapper' (#1925)

Addresses #1924",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['encoder.stateful is True'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1081,Mark Neumann,markn@allenai.org,2018-10-19 13:26:11-07:00,b0ade1bfa79d9efa8e52fb5a28d578c5b2d94595,https://github.com/allenai/allennlp/commit/b0ade1bfa79d9efa8e52fb5a28d578c5b2d94595,"add matplotlib to setup.py (#1919)

 ",1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1082,Evan Pete Walsh,epwalsh10@gmail.com,2018-10-19 14:11:03-07:00,b529f6df91ac13992171f3e73d6eb232e8e6110c,https://github.com/allenai/allennlp/commit/b529f6df91ac13992171f3e73d6eb232e8e6110c,"Generalize beam search, improve simple_seq2seq (#1841)

Updates to `simple_seq2seq`:
- supports attention module
- utilizes beam search for decoding

~~@brendan-ai2 I didn't want to end up re-implementing beam search again, so I used the existing system by defining a simple state class, and then just implementing the `take_step` method within `SimpleSeq2Seq`. Let me what you think!~~

~~@DeNeutoy the test `allennlp/tests/predictors/simple_seq2seq_test.py` is failing because it depends on an old archived model fixture at `allennlp/tests/fixtures/encoder_decoder/simple_seq2seq/serialization`. I'm not sure if you needed that exact model for something else, or if I could just replace it with another trained model.~~

**TODO:**
- [x] pull out and generalize beam search from `event2mind`
- [x] replace `state_machine.beam_search` in `simple_seq2seq` with more efficient version
- [x] update model that predictor test depends on
- [x] add unit tests for new beam search",20,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in decode_output_dict', 'output_dict_greedy[]', 'list(top_k.size())[:-1] == [batch_size, beam_size]', 'list(log_probs.size()) == [batch_size, beam_size]']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1083,Evan Pete Walsh,epwalsh10@gmail.com,2018-10-21 10:25:52-07:00,0e82106cdfc8d6c7b8459ffa3c7bcc7bd146812e,https://github.com/allenai/allennlp/commit/0e82106cdfc8d6c7b8459ffa3c7bcc7bd146812e,clean up simple_seq2seq tests (#1928),5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1084,Joel Grus,joelgrus@gmail.com,2018-10-22 10:53:47-07:00,947bd16521dd31bc79f7499ec17a07acf15a89a1,https://github.com/allenai/allennlp/commit/947bd16521dd31bc79f7499ec17a07acf15a89a1,"make api more pythonic (#1926)

* first stab at contextual encoder wrappers

* contextual encoders

* remove sru encoder

* pr comments

* replace _ElmoCharacterEncoder with CharacterEncoder

* docs

* sphinx stuff

* address pr comments

* address more PR comments

* make sphinx happy

* iterate

* make parameters required

* this is still wip

* wip

* bidirectional-lm proof of concept

* progress

* revert elmo

* revert elmo test

* revert elmo token embedder

* cnn_highway_encoder -> seq2vec

* remove contextual encoders

* fix docs

* remove print

* address more feedback

* replace none with identity function

* fix docs + checks

* fix tests

* add comments

* add top level imports

* fix imports

* unused import

* progress

* use brendan's dataset reader

* make data interface more pythonic

* remove unused import

* fix pytest + pylint",15,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,3,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['index_field1 == 4', 'index_field1 == index_field1', 'index_field1 != index_field2', 'len(list_field) == 3', 'list_field[1] == self.field2', '[f for f in list_field] == [self.field1, self.field2, self.field3]', 'in field', 'field[] == 1', 'len(field) == 2', 'keys == {}', 'len(values) == 2', '1 in values', '[0] in values', 'len(sequence_label_field) == 5', 'sequence_label_field[1] == ', '[label for label in sequence_label_field] == tags', 'span_field1 == (2, 3)', 'span_field1 == span_field1', 'span_field1 != span_field2', 'len(field) == 5', 'field[1].text == ', '[token.text for token in field] == []', 'instance[] == words_field', 'instance[] == label_field', 'len(instance) == 2', 'keys == {}', 'words_field in values', 'label_field in values']","['(TypeError)', '(TypeError)', '(TypeError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1085,Michael Schmitz,michael@schmitztech.com,2018-10-22 13:33:57-07:00,afc36eb116455d8ec39153220add37859b3af2d1,https://github.com/allenai/allennlp/commit/afc36eb116455d8ec39153220add37859b3af2d1,Add a --force command to train (#1913),2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1086,jchl,luo_smart@163.com,2018-10-23 04:50:02+08:00,53a555c4f4b2e9dcd69c2cd8906bbc4c2ca9da91,https://github.com/allenai/allennlp/commit/53a555c4f4b2e9dcd69c2cd8906bbc4c2ca9da91,Update training_and_evaluating.md (#1837),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1087,Michael Schmitz,michael@schmitztech.com,2018-10-22 15:40:41-07:00,3e2d7959efa1704f8b22ed0601b8d72eed52937d,https://github.com/allenai/allennlp/commit/3e2d7959efa1704f8b22ed0601b8d72eed52937d,Remove the report from pylint. (#1932),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1088,Matt Gardner,mattg@allenai.org,2018-10-23 07:30:14-07:00,d089d52f5c39dab5e694cf0006ad297581bf4b72,https://github.com/allenai/allennlp/commit/d089d52f5c39dab5e694cf0006ad297581bf4b72,"Add a dimension check to DialogQA, fix example configuration (#1934)

* Add a dimension check to DialogQA, fix example configuration

* Add comment",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1089,christine betts,chrstn@uw.edu,2018-10-23 09:58:44-07:00,aeb2fc30b13f5afb491e94177082c43cb7e1f32c,https://github.com/allenai/allennlp/commit/aeb2fc30b13f5afb491e94177082c43cb7e1f32c,Fix small typo (#1939),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1090,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-10-23 16:28:18-07:00,c6fb86d26cba3781a8937a87641a1236794c3146,https://github.com/allenai/allennlp/commit/c6fb86d26cba3781a8937a87641a1236794c3146,"Various fixes related to the variable free wikitables world (#1917)

* wikitables variable free reader

* misc lost changes

* fix world test

* dataset reader and related changes

* mml model passing tests

* fixed script

* misc type and doc fixes

* fixed tests and changed logic for adding -1

* make separate files only if logical forms were found

* misc fixes to get the model running

* add column type specific functions to local name mapping

* correct multi match substitution in get_comple_type_production

* fixed tests

* added an example without lf output

* removed parts that will go into the research repo pr

* removed action space walker outputs for tests

* added a test for evaluate logical form",12,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['entities == [(),', 'string_entities == [()]', 'sorted(entities) == [,', 'neighbors == {],', 'entity_text == {,', 'set(neighbors.keys()) == {,', 'set(neighbors[}', 'neighbors[]', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[]', 'set(neighbors[,', 'neighbors[]', 'self.executor.evaluate_logical_form(logical_form, [,', 'not self.executor.evaluate_logical_form(logical_form, [,', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'set([str(type_) for type_ in world.get_basic_types()]) == {,', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'set([str(type_) for type_ in world.get_basic_types()]) == {,', 'not in table_context.column_types.values()', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'set([str(type_) for type_ in world.get_basic_types()]) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],"['entities == []', 'string_entities == []']",[],[],[],[],[],[],[],[],[],[],[],[]
1091,Nelson Liu,nelson-liu@users.noreply.github.com,2018-10-24 09:58:53-07:00,ce0bc55b06f1c4338be4f3875119263c3352fbb8,https://github.com/allenai/allennlp/commit/ce0bc55b06f1c4338be4f3875119263c3352fbb8,Add training config for bidaf with elmo (#1953),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1092,Nelson Liu,nelson-liu@users.noreply.github.com,2018-10-24 13:22:14-07:00,02640024f2927f2dbb753263ba315c1ba265498e,https://github.com/allenai/allennlp/commit/02640024f2927f2dbb753263ba315c1ba265498e,Add scalar_mix_parameters to ElmoTokenEmbedder (#1955),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1093,Nelson Liu,nelson-liu@users.noreply.github.com,2018-10-24 14:02:57-07:00,4e4409708b2bfe85603e67a5fd2f2f176b41f2d8,https://github.com/allenai/allennlp/commit/4e4409708b2bfe85603e67a5fd2f2f176b41f2d8,"Add scalar_mix_parameters to ElmoTokenEmbedder.from_params (#1956)

Sorry, continuation of #1955 . Was able to run a model with this setting, so pretty sure I got it right this time around...",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1094,Pradeep Dasigi,pradeep.dasigi@gmail.com,2018-10-24 21:08:31-07:00,19d106e7d0a0b8a5111294d66743515f7f9c0626,https://github.com/allenai/allennlp/commit/19d106e7d0a0b8a5111294d66743515f7f9c0626,minor bug fix in get_agenda (#1959),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1095,Michael Schmitz,michael@schmitztech.com,2018-10-25 08:07:30-07:00,a3bd4759fb55951dcf598a0bd8d7a4b4807e9124,https://github.com/allenai/allennlp/commit/a3bd4759fb55951dcf598a0bd8d7a4b4807e9124,Update elmo.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1096,Oz Anani,ozanani94@gmail.com,2018-10-25 19:17:01+03:00,9a3e4b6b5923dbc623bb449de396db860445928c,https://github.com/allenai/allennlp/commit/9a3e4b6b5923dbc623bb449de396db860445928c,Add Windows support info to README.md (#1962),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1097,Mark Neumann,markn@allenai.org,2018-10-25 13:03:20-04:00,26f09cff87fd3f2aebb3b1a89b1f50a4abcb0b16,https://github.com/allenai/allennlp/commit/26f09cff87fd3f2aebb3b1a89b1f50a4abcb0b16,Disable tqdm when there isn't a TTY (#1927),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1098,Nelson Liu,nelson-liu@users.noreply.github.com,2018-10-25 10:30:27-07:00,dedc4cef57211d3f5c8f5fa4904c720135d52994,https://github.com/allenai/allennlp/commit/dedc4cef57211d3f5c8f5fa4904c720135d52994,"Try compiling EVALB in metric if it doesn't exist (#1964)

This is necessary in order to get it to work on beaker, since otherwise the evaluation binary is never produced.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1099,Nelson Liu,nelson-liu@users.noreply.github.com,2018-10-25 10:59:51-07:00,5512a8fbef6a95e84712a82959783e81b970e145,https://github.com/allenai/allennlp/commit/5512a8fbef6a95e84712a82959783e81b970e145,"Add config for non-elmo constituency parser, rename existing parser config (#1965)",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1100,Michael Schmitz,michael@schmitztech.com,2018-10-25 15:12:02-07:00,b553c0689916cfb90082c147344f8657a91c57f3,https://github.com/allenai/allennlp/commit/b553c0689916cfb90082c147344f8657a91c57f3,bump version number to v0.7.1,3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1101,Michael Schmitz,michael@schmitztech.com,2018-10-25 15:21:59-07:00,be1ff9fa641451afbee1c64c4b5fc05427d779c8,https://github.com/allenai/allennlp/commit/be1ff9fa641451afbee1c64c4b5fc05427d779c8,Bump version numbers to v0.7.2-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1102,Brendan Roof,brendanr@allenai.org,2018-10-25 17:03:00-07:00,2a8bd63829ed6e84ecd011e9dd8d134db41d93dd,https://github.com/allenai/allennlp/commit/2a8bd63829ed6e84ecd011e9dd8d134db41d93dd,"Extend GPU fixes from vidurj and MaxMotovilov (#1944)

- Builds on https://github.com/allenai/allennlp/pull/1724 and https://github.com/allenai/allennlp/pull/1445 in order to fix https://github.com/allenai/allennlp/issues/1439.
- Differences:
  - Use a `scatter` analogous to the PyTorch implementation.
  - Identify metadata that needs to be scattered with a dummy `ScatterableList` subclass.
  - Dispatch to PyTorch's underlying tensor scatter to precisely match behavior.
- Minor fixes to parallelize `Event2Mind` model. (Used to help develop the rest.)",12,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in kwargs, \\', 'len(kwargs[]) == batch_size, \\']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1103,Brendan Roof,brendanr@allenai.org,2018-10-26 09:55:37-07:00,ad729e37380bcbee6cabd58f49cdd2788fcc2609,https://github.com/allenai/allennlp/commit/ad729e37380bcbee6cabd58f49cdd2788fcc2609,"Link tutorial site from tutorials/README.md. (#1972)

Previously ctrl-f on https://github.com/allenai/allennlp for ""tutorial"" would send you first to `tutorials/README.md` which had no mention of Joel and Aaron's fancy new tutorial.

Should now be impossible to miss.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1104,WrRan,wrran@outlook.com,2018-10-27 01:19:26+08:00,39e16c419f8572395779823fea6017a4d0fb20e8,https://github.com/allenai/allennlp/commit/39e16c419f8572395779823fea6017a4d0fb20e8,"delete swp file (#1975)

* delete swp file

* add *.swp to .gitignore",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1105,WrRan,wrran@outlook.com,2018-10-27 03:07:14+08:00,02317e12c39fb57b5d7c7715cc03f49143f557ef,https://github.com/allenai/allennlp/commit/02317e12c39fb57b5d7c7715cc03f49143f557ef,"add min_padding_length to TokenCharactersIndexer (#1954) (#1967)

* add min_padding_length to TokenCharactersIndexer (#1954)

* mv min_padding_length to arg-list's end

* add test_case for character_token_indexer_test
 * test min_padding_length

* add test_case for character_token_indexer_test
 * test min_padding_length

* delete annoying DOS crlf

* delete unused variable

* Remove trailing newlines",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['padded == {: [[2, 3, 3, 4, 5, 6, 7, 8, 0, 0],']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1106,Matt Gardner,mattg@allenai.org,2018-10-26 14:08:06-07:00,5aa1c8f0cc770493ba843f5cb7a4ac3221cddc3a,https://github.com/allenai/allennlp/commit/5aa1c8f0cc770493ba843f5cb7a4ac3221cddc3a,"Fix for import_submodules (#1976)

* Fix for import_submodules

* Use != instead of ""not in""

* Pylint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1107,WrRan,wrran@outlook.com,2018-10-28 05:54:58+08:00,bc97ce873ff148b09d2eabbd53fdaa2fc88ba335,https://github.com/allenai/allennlp/commit/bc97ce873ff148b09d2eabbd53fdaa2fc88ba335,"combine_tensors_and_multiply_with_batch_size_one_and_seq_len_one (#1980)

* patch to #1979

* patch to #1979",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1108,Brendan Roof,brendanr@allenai.org,2018-10-29 12:10:29-07:00,c262ef5a0f805d7f0fd7ef52b2ab382a43a0b972,https://github.com/allenai/allennlp/commit/c262ef5a0f805d7f0fd7ef52b2ab382a43a0b972,"Match vocab generation in currently online Event2Mind model. (#1978)

- I noticed this difference while retraining the model to account for https://github.com/allenai/allennlp/pull/1944.
- With this change we generate the exact same vocab as was used for the 10/5 model and now the new 10/26 model.
- In the long run we'll want to be more principled with our vocab. In the short term I'm more concerned with ensuring that we can retrain consistently.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 17', 'get_text(,', 'get_text(]']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 21', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(,', 'get_text(]']",[],[],[],[],[],[],[],[],[],[],[],[]
1109,WrRan,wrran@outlook.com,2018-10-30 23:45:34+08:00,021f8bb1b98a70fec2ed02f6ace6a403ddece9f3,https://github.com/allenai/allennlp/commit/021f8bb1b98a70fec2ed02f6ace6a403ddece9f3,"use wordsplit with taggers (#1981)

* make pos_tag/ner_tag consistent checking empty/missing value

* add test case: blank ner-/pos-tag

* rename namespace of ner-/pos-tag-indexer

* modify previous test-cases related to `namespace`

* minor fix

* Update pos_tag_indexer_test.py

add a trailing newline",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['counter[: 6}', 'counter[] == 4', '{: [none_index, none_index, none_index, none_index]} == indices', 'counter[: 2}', 'counter[: 2}', 'counter[] == 4', '{: [none_index, none_index, none_index, none_index]} == indices']",[],[],[],[],[],[],[],[],[],[],[],[],"['counter[: 6}', 'counter[: 2}', 'counter[: 2}']",[],[],[],[],[],[],[],[],[],[],[],[]
1110,Evan Pete Walsh,epwalsh10@gmail.com,2018-10-30 13:05:24-07:00,1f782d33974504bdf6386f26c34bb09cd0c2a215,https://github.com/allenai/allennlp/commit/1f782d33974504bdf6386f26c34bb09cd0c2a215,"Add --force option to find-lr command (#1991)

* add --force option

* fix tests",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1111,Nelson Liu,nelson-liu@users.noreply.github.com,2018-10-30 17:10:41-07:00,a4b885cd1b8a57b958581d522b756d149a1e698d,https://github.com/allenai/allennlp/commit/a4b885cd1b8a57b958581d522b756d149a1e698d,Add scalar_mix_parameters to Elmo.from_params (#1992),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1112,Mark Neumann,markn@allenai.org,2018-11-01 16:39:42+01:00,e4f9131c0d75fdeab6ababe31e955a7d1d256de9,https://github.com/allenai/allennlp/commit/e4f9131c0d75fdeab6ababe31e955a7d1d256de9,"Untyped grammar (#1986)

* rework grammar a bit so we can have untyped variables

* add a way to make the grammar variable free

* refactor contextual modifications out

* pylint",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['key not in {}', 'all([ not in production for production in value])', 'all([ not in production for production in value])', 'all([ not in production for production in value])', 'all([ not in production for production in value])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1113,Michael Schmitz,michael@schmitztech.com,2018-11-01 14:15:27-07:00,6af83e7ce3c01c991d4b7d0305e5ae8a9d75e708,https://github.com/allenai/allennlp/commit/6af83e7ce3c01c991d4b7d0305e5ae8a9d75e708,"Prevent inspect_cache from swallowing exception. (#1999)

* Prevent inspect_cache from swallowing exception.

* Don't resolve files that end with 'json'.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1114,Michael Schmitz,michael@schmitztech.com,2018-11-01 14:36:58-07:00,7751799280c3169b4c0daeb73f5b2a12ad0670d1,https://github.com/allenai/allennlp/commit/7751799280c3169b4c0daeb73f5b2a12ad0670d1,Ignore hidden files in vocabulary/ (#2002),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1115,ananda seelan,ananda.seelan@gmail.com,2018-11-05 14:04:11+05:18,1406a85638c4c195ea7f9b5a255e30c0e0fb8b8e,https://github.com/allenai/allennlp/commit/1406a85638c4c195ea7f9b5a255e30c0e0fb8b8e,Added default predictor for bimpm model (#2014),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1116,Michael Schmitz,michael@schmitztech.com,2018-11-05 09:20:45-08:00,bae7758111ad66d4af769221bc28d0d264f9cdd3,https://github.com/allenai/allennlp/commit/bae7758111ad66d4af769221bc28d0d264f9cdd3,Change log level to clean up allennlp command. (#2004),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1117,Michael Schmitz,michael@schmitztech.com,2018-11-06 07:55:43-08:00,3ca694200f94cda3ad7da76363ea02b0f289a68f,https://github.com/allenai/allennlp/commit/3ca694200f94cda3ad7da76363ea02b0f289a68f,Support stdin for prediction jsonl. (#2003),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1118,Michael Schmitz,michael@schmitztech.com,2018-11-06 13:48:14-08:00,b919f5ae679c8cf3c87e4f0e69bd72c513552e1d,https://github.com/allenai/allennlp/commit/b919f5ae679c8cf3c87e4f0e69bd72c513552e1d,Add logging statement when EVALB is compiled. (#2018),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1119,Evan Pete Walsh,epwalsh10@gmail.com,2018-11-06 17:19:07-08:00,be36374e9403e50e45cc99ccb2ab15b586bf57f7,https://github.com/allenai/allennlp/commit/be36374e9403e50e45cc99ccb2ab15b586bf57f7,change stopping factor default (#2021),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1120,Santiago Castro,bryant@montevideo.com.uy,2018-11-06 20:20:13-05:00,481c181786486d157986fcf65ab4eba80b58e4d9,https://github.com/allenai/allennlp/commit/481c181786486d157986fcf65ab4eba80b58e4d9,"Fix ArrayField.to_tensor not working with a scalar (#2008)

* Add test to get tensor of a scalar ArrayField

* Fix ArrayField.to_tensor not working with a scalar

* Fix line too long

* Add assert to test",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1121,WrRan,wrran@outlook.com,2018-11-07 21:26:56+08:00,68cbfb800fbf173fd6a1c097c6dd73530065ae1d,https://github.com/allenai/allennlp/commit/68cbfb800fbf173fd6a1c097c6dd73530065ae1d,modify training_configs related issue #1954 (#1997),6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1122,Michael Schmitz,michael@schmitztech.com,2018-11-08 08:16:15-08:00,82bbee7da2de5f227f2abe0d3a8b4b5b416c246b,https://github.com/allenai/allennlp/commit/82bbee7da2de5f227f2abe0d3a8b4b5b416c246b,Add link to EMNLP tutorial from tutorial README.,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1123,Evan Pete Walsh,epwalsh10@gmail.com,2018-11-09 13:17:01-08:00,a5c2d9eb89014712aab7dc89f2f020af1be9f89c,https://github.com/allenai/allennlp/commit/a5c2d9eb89014712aab7dc89f2f020af1be9f89c,"Catch nan loss in training loop (#2029)

* catch nan loss

* small fix",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1124,Mark Neumann,markn@allenai.org,2018-11-10 01:07:37+00:00,aa1b774ed8de31ec04bebf9f054200bc2507e0c5,https://github.com/allenai/allennlp/commit/aa1b774ed8de31ec04bebf9f054200bc2507e0c5,Test sql decoding (#2030),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1125,Suchin,github@suchin.io,2018-11-11 18:38:10-08:00,0701dbdc79892c8354d2a175f06455a4121b2143,https://github.com/allenai/allennlp/commit/0701dbdc79892c8354d2a175f06455a4121b2143,"Dynamic stopwords (#2037)

* added stopword filehandling, regex word filter

* formatting

* addressed matt comments

* addressed matt comments round 2

* added read_set_from_file to file_utils

* pylint fixes

* pylint fix",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1126,Suchin,github@suchin.io,2018-11-11 18:38:27-08:00,de7c013e72f321f8b4faffa6b90e3dcc7f0d0872,https://github.com/allenai/allennlp/commit/de7c013e72f321f8b4faffa6b90e3dcc7f0d0872,"Sentence splitter (#2036)

* tests pass

* changed text of tests

* updated docstrings

* addressed matt's comments

* small typo fixes

* updated test

* small formatting update

* addressed matt comments round 2

* bug fix

* pylint fixes

* sentence splitter docs",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == expected_tokens', 'tokens == expected_tokens', 'len(batch_split) == len(separately_split)', 'len(batch_doc) == len(separate_doc)', 'batch_sentence == separate_sentence', 'len(batch_split) == len(separately_split)', 'len(batch_doc) == len(separate_doc)', 'batch_sentence == separate_sentence']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1127,Michael Schmitz,michael@schmitztech.com,2018-11-12 11:06:43-08:00,43243acf4e91ba471923624bd48c9c9ec72332bf,https://github.com/allenai/allennlp/commit/43243acf4e91ba471923624bd48c9c9ec72332bf,Update issue templates,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1128,P R Gurunath,gurunathpr@gmail.com,2018-11-14 21:18:34+05:18,07b574912af3f6049f95851d0886c19c41e5d6ad,https://github.com/allenai/allennlp/commit/07b574912af3f6049f95851d0886c19c41e5d6ad,"Enable multi-gpu training in find_learning_rate.py (#2045)

* Enable multi-gpu training in find_learning_rate.py

* Added test for multi-gpu training

* Minor changes in tests

* Change in indentation

* Changes in testing multi-gpu usage

Removed new class for testing multi-gpu usage and moved the testing function to existing class `TestFindLearningRate`

* Changes in find_learning_rate_test.py

* Minor changes in find_learning_rate_test.py

* Remove redundant code",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['if(torch.cuda.device_count()'],[],[],[],[],"['skipif(torch.cuda.device_count() < 2,']","['mark.skipif(torch.cuda.device_count() < 2,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1129,Joel Grus,joelgrus@gmail.com,2018-11-15 12:15:01-08:00,86da88098edba318b8e6f19f33e3670967dee24f,https://github.com/allenai/allennlp/commit/86da88098edba318b8e6f19f33e3670967dee24f,"add sampled softmax loss (#2042)

* first stab at contextual encoder wrappers

* contextual encoders

* remove sru encoder

* pr comments

* replace _ElmoCharacterEncoder with CharacterEncoder

* docs

* sphinx stuff

* address pr comments

* address more PR comments

* make sphinx happy

* iterate

* make parameters required

* this is still wip

* wip

* bidirectional-lm proof of concept

* progress

* revert elmo

* revert elmo test

* revert elmo token embedder

* cnn_highway_encoder -> seq2vec

* remove contextual encoders

* fix docs

* remove print

* address more feedback

* replace none with identity function

* fix docs + checks

* fix tests

* add comments

* add top level imports

* fix imports

* unused import

* progress

* use brendan's dataset reader

* checkpoint

* fun

* remove tie_embeddings code paths + fast_sampler

* fix tests

* revert setup.py

* address PR feedback

* address pr feedback",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(set(sample)) == 50', 'all(0 <= x < 1000 for x in sample)', 'num_tries >= 50', 'abs(pct_error) < 0.01']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1130,Joel Grus,joelgrus@gmail.com,2018-11-15 13:02:03-08:00,888c11a3651f2709db9dac4655603444628218a4,https://github.com/allenai/allennlp/commit/888c11a3651f2709db9dac4655603444628218a4,"add flaky decorator + increase tolerance (#2060)

* add flaky decorator + increase tolerance

* skip test",1,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,1,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['abs(pct_error) < 0.02'],[],[],['()'],[],[],[],[],['skip()'],['mark.skip()'],[],[],['import pytest'],['abs(pct_error) < 0.01'],[],[],[],[],[],[],[],[],[],[],[],[]
1131,Michael Schmitz,michael@schmitztech.com,2018-11-15 13:07:38-08:00,6ecd1932481b8dc9639db1805904afde951cc316,https://github.com/allenai/allennlp/commit/6ecd1932481b8dc9639db1805904afde951cc316,Fix logging statement so it has the proper scope. (#2059),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1132,Evan Pete Walsh,epwalsh10@gmail.com,2018-11-15 14:12:39-08:00,19c784fa353ec7dcd71d0ae761c0c6683bf5e35d,https://github.com/allenai/allennlp/commit/19c784fa353ec7dcd71d0ae761c0c6683bf5e35d,"Add BLEU metric (#2001)

- AllenNLP native version of BLEU. This can be used without first converting the tensors to lists as would be required by, e.g., NLTK.
- Current limitation: Only accepts one reference per candidate.",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['counts == unigram_check', 'counts == bigram_check', 'counts == trigram_check', 'counts == {}', 'self.metric._prediction_lengths == 6', 'self.metric._reference_lengths == 5', 'self.metric._precision_matches[1] == (', 'self.metric._precision_totals[1] == (', 'self.metric._precision_matches[2] == (', 'self.metric._precision_totals[2] == (', 'self.metric._get_brevity_penalty() == 1.0', 'self.metric.get_metric()[] == 0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1133,Handsome Zebra,aaahchi@gmail.com,2018-11-16 18:42:07-08:00,2a2d9c94f875d7775f4cf63fec63017d8199473d,https://github.com/allenai/allennlp/commit/2a2d9c94f875d7775f4cf63fec63017d8199473d,"Improve server_simple by adding predict_batch and adding GPU option (#2064)

* Adding batch prediction and add gpu for server simple.

* Adding test for batch predict.

* Remove trailing spaces.",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(data_list) == batch_size', 'in data', 'in data', 'len(data_list) == batch_size', 'in data', 'not in data']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1134,Darren Zhao,ernestzhao1223@gmail.com,2018-11-18 03:17:21+08:00,d50408963d86981dfdbb6ef2c490459196d88b2d,https://github.com/allenai/allennlp/commit/d50408963d86981dfdbb6ef2c490459196d88b2d,"Add wikitables predicator to the default predicators (#2071)

* all wikitables predicator to default predicators

* all wikitables predicator to default predicators",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1135,marice0819,marices.railgunppp@gmail.com,2018-11-18 15:06:04+09:00,e3e8e1cb99d9fc6047070c55dfaf7a2c09316612,https://github.com/allenai/allennlp/commit/e3e8e1cb99d9fc6047070c55dfaf7a2c09316612,"Fix typo in IntraSentenceAttentionEncoder docstring (#2072)

In docstring,
type of ``output_dim`` 'bool' -> 'int'",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1136,Alon Eirew,alon.eirew@intel.com,2018-11-19 01:17:51+02:00,af902a3f2776b31d36d089c8c49d8f024da1bb07,https://github.com/allenai/allennlp/commit/af902a3f2776b31d36d089c8c49d8f024da1bb07,"Add support of tokenized input for coref and srl predictors (#2076)

* add support of tokenized input for coref and srl predictors

* change method signature

* fix PR review comments",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('_predict_result', '(result)'), ('_predict_result', '(result_doc_words)'), ('_predict_result', '(result_json)'), ('_predict_result', '(result_words)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1137,Michael Schmitz,michael@schmitztech.com,2018-11-19 08:23:19-08:00,193bb04ddae7d89ee63005b898a01641447d6074,https://github.com/allenai/allennlp/commit/193bb04ddae7d89ee63005b898a01641447d6074,Specify path at which to compile evalb. (#2027),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1138,Matt Gardner,mattg@allenai.org,2018-11-20 19:14:13-08:00,5890111b6a05dcda929c6a1c35dc31dfb084f251,https://github.com/allenai/allennlp/commit/5890111b6a05dcda929c6a1c35dc31dfb084f251,"Separate calculation of num_tokens per TokenIndexer (#2080)

* Separate calculation of num_tokens per TokenIndexer

* Fix other tests

* Fix mypy",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['padding_lengths == {: 5},', 'lengths == {: 5}', 'padding_lengths == {: 5}', 'padding_lengths == {: 8}', 'padding_lengths == {: 5,']",[],[],[],[],[],[],[],[],[],[],[],[],"['padding_lengths == {: 6}}', 'lengths == {: 5}', 'padding_lengths == {: 5}', 'padding_lengths == {: 8}', 'padding_lengths == {: 8}']",[],[],[],[],[],[],[],[],[],[],[],[]
1139,Joel Grus,joelgrus@gmail.com,2018-11-21 07:01:15-08:00,6b16222b72596ebe7b809dea26cc253195e02590,https://github.com/allenai/allennlp/commit/6b16222b72596ebe7b809dea26cc253195e02590,"calypso transformer (#2049)

* bidirectional transformer encoder

* factoring

* address PR feedback",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(output.size()) == [5, 10, 64]', 'len(output) == 2', 'list(concat_layers.size()) == [5, 2, 10, 64]', '(forward_mask[0].data == torch.IntTensor([[1, 0, 0, 0, 0, 0],', '(forward_mask[1].data == torch.IntTensor([[1, 0, 0, 0, 0, 0],', '(forward_mask[2].data == torch.IntTensor([[1, 0, 0, 0, 0, 0],', '(backward_mask[0].data == torch.IntTensor([[1, 1, 1, 0, 0, 0],', '(backward_mask[1].data == torch.IntTensor([[1, 1, 1, 1, 1, 0],', '(backward_mask[2].data == torch.IntTensor([[1, 1, 1, 1, 1, 1],']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1140,Nelson Liu,nelson-liu@users.noreply.github.com,2018-11-22 16:40:29-08:00,d78daa44cc90b3ea9090fe6c24e788ebafe84496,https://github.com/allenai/allennlp/commit/d78daa44cc90b3ea9090fe6c24e788ebafe84496,"Fix EVALB compilation by cd to directory path instead of binary path (#2090)

Previously, the code would try to change directories to the expected path of the EVALB binary, which doesn't work since it doesn't exist --- the right thing to do is to change directories to the location of the EVALB source files, and run `make` in there.

fyi @schmmd",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1141,Joel Grus,joelgrus@gmail.com,2018-11-26 11:10:09-08:00,582d0e4fda34ab44d8a8ae739fbce09bddb3e9f5,https://github.com/allenai/allennlp/commit/582d0e4fda34ab44d8a8ae739fbce09bddb3e9f5,"add BERT token embedder  (#2067)

* bert wip

* update pylintrc

* bert

* debugging test

* fix bug in token indexer

* get end to end test working

* remove print statements

* add back missing line

* use pip installed bert version

* clean up class hierarchy

* keep working on BERT

* fix bert tests

* fix mypy + pylint

* add comments

* address PR feedback

* address PR feedback",17,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed_tokens[] == [2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1]', 'indexed_tokens[] == [0, 1, 2, 3, 4, 5, 6, 9, 10, 11]', 'indexed_tokens[] == [2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1]', 'indexed_tokens[] == [0, 1, 2, 3, 4, 5, 6, 7, 10, 11]', 'list(result.shape) == [2, 5, 12]', 'list(result.shape) == [2, 3, 12]', 'tokens[].tolist() == [', 'tokens[].tolist() == [', 'list(bert_vectors.shape) == [2, 12, 12]', 'list(bert_vectors.shape) == [2, 10, 12]', 'list(bert_vectors.shape) == [2, 12, 12]', 'list(bert_vectors.shape) == [2, 10, 12]', 'tokens[].tolist() == [', 'tokens[].tolist() == [']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1142,Evan Pete Walsh,epwalsh10@gmail.com,2018-11-26 13:45:00-08:00,2648d952c5f74acb728f50f8d9fc0b447a949a49,https://github.com/allenai/allennlp/commit/2648d952c5f74acb728f50f8d9fc0b447a949a49,Add BLEU metric to simple_seq2seq (#2063),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1143,Michael Schmitz,michael@schmitztech.com,2018-11-27 14:56:45-08:00,dcd1d25e3f3dd0f672de32403080d75bcfe005b9,https://github.com/allenai/allennlp/commit/dcd1d25e3f3dd0f672de32403080d75bcfe005b9,Resolve some of the token_embedders warnings. (#2100),27,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1144,Joel Grus,joelgrus@gmail.com,2018-11-27 15:57:34-08:00,42d076ee65b1e996ba63bc33b08bb7f4c44c902f,https://github.com/allenai/allennlp/commit/42d076ee65b1e996ba63bc33b08bb7f4c44c902f,"modify BERT embedder to deal with higher order inputs (#2104)

* modify BERT embedder to deal with higher order inputs

* fix indents that sphinx didn't like

* make2d and unmake2d raise on 1d or 0d tensors

* rename make2d -> combine_initial_dims",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(bert_vectors.shape) == [2, 2, 12, 12]', 'list(bert_vectors.shape) == [2, 2, 10, 12]', 'list(bert_vectors.shape) == [2, 2, 12, 12]', 'list(bert_vectors.shape) == [2, 2, 10, 12]', 'list(tensor2d.size()) == [4 * 10 * 20 * 17, 5]', 'list(embedding.size()) == [4, 10, 20, 17, 5, 12]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1145,Brendan Roof,brendanr@allenai.org,2018-11-28 22:59:53-08:00,240974fc52de93f1040d37ef6f87798a6d53e9fe,https://github.com/allenai/allennlp/commit/240974fc52de93f1040d37ef6f87798a6d53e9fe,"Pack batches more tightly with maximum_samples_per_batch. (#2111)

- Previously when maximum_samples_per_batch was used overly large batches would be split into equal sizes.
- This could lead to a certain degree of fragmentation.
- This change packs batches until just before maximum_samples_per_batch (or batch_size) is exceeded.",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['stats[] == len(self.instances)', 'stats[] == [2, 1, 1, 1]', 'stats[] == [8, 3, 9, 1]', 'stats[] == len(token_counts)', 'stats[] == [1, 2]', 'stats[] == [10, 8]', 'stats[] == len(self.instances)', 'stats[] == [2, 2, 1]', 'stats[] == [6, 8, 9]', 'stats[] == len(test_instances)', 'stats[] == [2, 1]', 'stats[] == [8, 10]']",[],[],[],[],[],[],[],[],[],[],[],[],"['num_instances == len(self.instances)', 'batch_sequence_length * len(batch.instances) <= 9', 'num_instances == len(self.instances)', 'batch_sequence_length * len(batch.instances) <= 9']",[],[],[],[],[],[],[],[],[],[],[],[]
1146,Michael Schmitz,michael@schmitztech.com,2018-11-29 08:35:46-08:00,92c71a172e3db498b22fdd052f56e23d9506a49b,https://github.com/allenai/allennlp/commit/92c71a172e3db498b22fdd052f56e23d9506a49b,Upgrade flask to remove werkzeug warning. (#2107),2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1147,Michael Schmitz,michael@schmitztech.com,2018-11-29 09:36:46-08:00,3842820ca4c3f3b463f3015787a8ed3c87eb5f97,https://github.com/allenai/allennlp/commit/3842820ca4c3f3b463f3015787a8ed3c87eb5f97,Fix span pruner warning. (#2113),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1148,Michael Schmitz,michael@schmitztech.com,2018-11-29 09:47:02-08:00,44269a1d3717c649c353d24aba25d7cde9cbbed9,https://github.com/allenai/allennlp/commit/44269a1d3717c649c353d24aba25d7cde9cbbed9,"Rename DATASET_CACHE to CACHE_DIRECTORY. (#2000)

This also moves `~/.allennlp/datasets` to `~/.allennlp/cache` since we use it as a general caching mechanism (not just for datasets).",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1149,Michael Schmitz,michael@schmitztech.com,2018-11-29 11:43:32-08:00,f757f7a02dba47d45d9ee4f0698ed10b66d34fa5,https://github.com/allenai/allennlp/commit/f757f7a02dba47d45d9ee4f0698ed10b66d34fa5,"Fix epoch tracking bucket iterator warnings. (#2108)

* Fix epoch tracking bucket iterator warnings.

* Move the epoch tracking test to bucket iterator.",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['generated_dataset1[0][] == [0, 0, 0, 0, 0]', 'generated_dataset1[1][] == [1, 1, 1, 1, 1]', 'generated_dataset2[0][] == [0, 0, 0]', 'generated_dataset2[1][] == [1, 1, 1]']",[],[],[],[],[],[],[],[],[],[],[],[]
1150,Michael Schmitz,michael@schmitztech.com,2018-11-29 12:54:06-08:00,db0096f1a0ba4c99c05042482cfbc76b2ddcbaa9,https://github.com/allenai/allennlp/commit/db0096f1a0ba4c99c05042482cfbc76b2ddcbaa9,Fix more BasicTextFieldEmbedder warnings (#2114),1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['old_embedder._token_embedders.keys() == new_embedder._token_embedders.keys() #pylint: disable=protected-access', 'new_embedder(self.inputs).size() == (1, 4, 10)']",[],[],[],[],[],[],[],[],[],[],[],[],"['token_embedder(self.inputs).size() == (1, 4, 10)']",[],[],[],[],[],[],[],[],[],[],[],[]
1151,Joel Grus,joelgrus@gmail.com,2018-11-29 22:54:17-08:00,3a7e0659124f2351e1748305bec533a77ed4fd13,https://github.com/allenai/allennlp/commit/3a7e0659124f2351e1748305bec533a77ed4fd13,"fix epoch tracking (#2121)

* fix epoch tracking

* fix pylint",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['all(epoch_num == epoch for epoch_num in batch[])', 'len(all_batches) == 10 * 3', 'all(epoch_num == epoch for epoch_num in batch[])', 'len(all_batches) == 30', 'all(epoch_num == epoch for epoch_num in batch[])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1152,Joel Grus,joelgrus@gmail.com,2018-11-30 11:38:17-08:00,3eecd1aa7a5da3636fce021e603f8219bbc816d8,https://github.com/allenai/allennlp/commit/3eecd1aa7a5da3636fce021e603f8219bbc816d8,"more informative message for BasicTextFieldEmbedder mismatched keys (#2124)

* more informative message for BasicTextFieldEmbedder mismatched keys

* update error message",2,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['exc.match()', 'exc.match()']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[],[],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[]
1153,Joel Grus,joelgrus@gmail.com,2018-11-30 14:09:10-08:00,27830443ec5e8b00b5b7ac18c467db69cddcf7ec,https://github.com/allenai/allennlp/commit/27830443ec5e8b00b5b7ac18c467db69cddcf7ec,pin msgpack (#2125),2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1154,Joel Grus,joelgrus@gmail.com,2018-12-03 08:54:35-08:00,ca7e3cf37025bb1320c2e938e17db2b7c7381779,https://github.com/allenai/allennlp/commit/ca7e3cf37025bb1320c2e938e17db2b7c7381779,"release config explorer (#2118)

* change configuration command to run wizard

* working on config explorer

* update config explorer

* config explorer

* address pylint issues

* change test

* remove hardcoded html",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in choices', 'isinstance(config, Config)', 'len(items) == 9', 'in items', 'in items', 'ja == {', 'in data', 'not in data', 'not in data', 'in data', 'in data', 'not in data']",[],[],[],[],[],[],[],[],[],[],[],[],"['in output', 'html.strip() == _HTML.strip()']",[],[],[],[],[],[],[],[],[],[],[],[]
1155,Michael Schmitz,michael@schmitztech.com,2018-12-03 10:54:09-08:00,bf04f1dae80eba09ac7f260873ff3ab277698370,https://github.com/allenai/allennlp/commit/bf04f1dae80eba09ac7f260873ff3ab277698370,bump version number to v0.7.2,4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1156,Michael Schmitz,michael@schmitztech.com,2018-12-03 11:18:41-08:00,69483ed5a9ab330d23089692564a6e6678d76b37,https://github.com/allenai/allennlp/commit/69483ed5a9ab330d23089692564a6e6678d76b37,Bump version numbers to v0.7.3-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1157,Joel Grus,joelgrus@gmail.com,2018-12-03 20:19:34-08:00,411b5a2f3a9151b19805d60369e50c82f8d87b39,https://github.com/allenai/allennlp/commit/411b5a2f3a9151b19805d60369e50c82f8d87b39,upgrade pytorch-pretrained-bert + fix kwarg (#2130),3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1158,Joel Grus,joelgrus@gmail.com,2018-12-05 11:06:36-08:00,7dbd7d34a2f1390d1ff01f2e9ed6f8bdaaef77eb,https://github.com/allenai/allennlp/commit/7dbd7d34a2f1390d1ff01f2e9ed6f8bdaaef77eb,"add [CLS] and [SEP] tags to bert indexer (#2142)

* add [CLS] and [SEP] tags to bert indexer

* one token at a time

* make pylint happy",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [1, 2, 3, 4, 5, 6, 7, 10, 11, 12]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [1, 2, 3, 4, 5, 6, 7, 8, 11, 12]', 'list(bert_vectors.shape) == [2, 14, 12]', 'list(bert_vectors.shape) == [2, 14, 12]', 'list(bert_vectors.shape) == [2, 2, 14, 12]', 'list(bert_vectors.shape) == [2, 2, 14, 12]']",[],[],[],[],[],[],[],[],[],[],[],[],"['indexed_tokens[] == [2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1]', 'indexed_tokens[] == [0, 1, 2, 3, 4, 5, 6, 9, 10, 11]', 'indexed_tokens[] == [2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1]', 'indexed_tokens[] == [0, 1, 2, 3, 4, 5, 6, 7, 10, 11]', 'list(bert_vectors.shape) == [2, 12, 12]', 'list(bert_vectors.shape) == [2, 12, 12]', 'list(bert_vectors.shape) == [2, 2, 12, 12]', 'list(bert_vectors.shape) == [2, 2, 12, 12]']",[],[],[],[],[],[],[],[],[],[],[],[]
1159,Michael Schmitz,michael@schmitztech.com,2018-12-07 12:59:57-08:00,a75cb0a9ddedb23801db74629c3a3017dafb375e,https://github.com/allenai/allennlp/commit/a75cb0a9ddedb23801db74629c3a3017dafb375e,Update the elmo command help text. (#2143),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1160,Evan Pete Walsh,epwalsh10@gmail.com,2018-12-08 20:26:22-08:00,2e412e33c2e5bbc60b4440c9b060779165622f03,https://github.com/allenai/allennlp/commit/2e412e33c2e5bbc60b4440c9b060779165622f03,fix mismatches (#2157),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1161,Mark Yatskar,my89@cs.washington.edu,2018-12-09 19:44:05-08:00,140c3ec5f5bc83a25050ba844e8162f3639cdb77,https://github.com/allenai/allennlp/commit/140c3ec5f5bc83a25050ba844e8162f3639cdb77,make max dialog length configurable through json file (#2160),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1162,Harsh Rangwani,harsh.rangwani.cse15@itbhu.ac.in,2018-12-10 20:52:49+05:18,a8adc6c1b476b6f19b625ca300ce75ca59ac9886,https://github.com/allenai/allennlp/commit/a8adc6c1b476b6f19b625ca300ce75ca59ac9886,Fixes broken link and rephrasing visualizing_model_internals.md (#2162),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1163,Joel Grus,joelgrus@gmail.com,2018-12-10 10:45:31-08:00,6c33005c5c383dc7e6718efd50ad29e13eaaf361,https://github.com/allenai/allennlp/commit/6c33005c5c383dc7e6718efd50ad29e13eaaf361,"fix bert input order (#2145)

* add [CLS] and [SEP] tags to bert indexer

* one token at a time

* make pylint happy

* change order of arguments

* give bert inputs in right order",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1164,Brendan Roof,brendanr@allenai.org,2018-12-10 11:57:25-08:00,021471a9579216b845f02b8beb8e33211df55019,https://github.com/allenai/allennlp/commit/021471a9579216b845f02b8beb8e33211df55019,"Transformer ELMo (#2119)

- Configuration for training a transformer based bidirectional LM.
  - Sampled loss on train after four epochs was 3.384.
- Minor fixes to CnnHighwayEncoder.
  - LayerNorm was needed instead of MaskedLayerNorm.
- Log average batch size during training.",15,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Equal', '(text, [])'), ('Equal', '(k, 7)')]",[],[],[],[],[],[],[],[],[],[],"[('Equal', '(text, [])'), ('Equal', '(k, 11)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1165,Joel Grus,joelgrus@gmail.com,2018-12-10 20:17:16-08:00,41c71960d8a3a231dc4ace5c9676cd654d97b83d,https://github.com/allenai/allennlp/commit/41c71960d8a3a231dc4ace5c9676cd654d97b83d,instantiate multiprocessing.log_to_stderr lazily (#2166),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1166,Kathryn Chan,kathrync@allenai.org,2018-12-12 09:58:31-08:00,da761e8f596e2e12fce926d90ee0c68c9ecc1405,https://github.com/allenai/allennlp/commit/da761e8f596e2e12fce926d90ee0c68c9ecc1405,"pre commit hook to verify file sizes (#2151)

* pre commit hook to verify file sizes

* put test in verify.py instead of hook

* renamed

* rename/compare master

* add size

* commit file > 2MB to test

* change git diff

* fix file missing

* after teamcity run verify.py

* remove get branch

* remove large files",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1167,Brendan Roof,brendanr@allenai.org,2018-12-12 14:06:00-08:00,a89aebaede1608fa584925f16e15155ebd05c220,https://github.com/allenai/allennlp/commit/a89aebaede1608fa584925f16e15155ebd05c220,"Minor fixes to help evaluate ELMo port. (#2172)

- Display loss when running evaluate.
  - Fixes https://github.com/allenai/allennlp/issues/1241
- Log when sentences are dropped due to exceeding the maximum length.",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['metrics.keys() == {}'],[],[],[],[],[],[],[],[],[],[],[],[],['metrics.keys() == {}'],[],[],[],[],[],[],[],[],[],[],[],[]
1168,Raphal Courivaud,r.courivaud@gmail.com,2018-12-13 17:41:54+01:00,d0d6310b688438ac3a1559e1d2e15d7d8209d3eb,https://github.com/allenai/allennlp/commit/d0d6310b688438ac3a1559e1d2e15d7d8209d3eb,"add default argument for SpacyWordSplitter (#2174)

* add default argument for SpacyWordSplitter

* fix pylint

* remove trailing whitespace

* Fix mypy",6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1169,Joel Grus,joelgrus@gmail.com,2018-12-13 09:23:14-08:00,8e861e75ed9afee06a046c24539fad5535e5c578,https://github.com/allenai/allennlp/commit/8e861e75ed9afee06a046c24539fad5535e5c578,"pytorch 1.0 (#2165)

* fixes

* allenlp

* fix bug

* reduce=False -> reduction='none'

* fix _sparse_mask

* remove print statement

* fix more tests",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tags.tolist()[0] in ([0, 1, 0], [0, 1, 1])', 'loss.data.numpy() == vector_loss.sum().item() / 4']",[],[],[],[],[],[],[],[],[],[],[],[],"['tags.tolist()[0] == [0, 1, 0]', 'loss.data.numpy() == vector_loss.data.sum() / 4']",[],[],[],[],[],[],[],[],[],[],[],[]
1170,Kathryn Chan,kathrync@allenai.org,2018-12-13 15:27:54-08:00,0ae699a540322a296e23f846d8185d15bda8a037,https://github.com/allenai/allennlp/commit/0ae699a540322a296e23f846d8185d15bda8a037,"empty time stamp should be a str instead of int 0 (#2153)

* empty time stamp should be a str instead of int 0

* reverse

* fixed",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1171,Valthor Halldorsson,vlthrh@gmail.com,2018-12-14 19:07:02+02:00,89cef2f08c97510c6f098e9381fdc22116ad5b1a,https://github.com/allenai/allennlp/commit/89cef2f08c97510c6f098e9381fdc22116ad5b1a,"Clean up temporary archive directory at exit (#2184)

* clean up temporary archive directory at exit

* add test for archive cleanup",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['os.path.exists(params.get())'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1172,brett koonce,koonce@hello.com,2018-12-16 12:52:31-06:00,a558f7f4982d6a996d5397c7ff7a500cb0251577,https://github.com/allenai/allennlp/commit/a558f7f4982d6a996d5397c7ff7a500cb0251577,minor spelling tweaks (#2192),36,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1173,Matt Gardner,mattg@allenai.org,2018-12-17 09:59:59-08:00,12d32972a05036f5be7cf152a00afad02da8cd16,https://github.com/allenai/allennlp/commit/12d32972a05036f5be7cf152a00afad02da8cd16,"Make bz2 and lzma optional dependencies (#2196)

* Made bz2 an optional dependency

bz2 was a hard dependency and it was throwing an ""ModuleNotFoundError: No module named '_bz2'."" for me. 

This fixes the issue #2178

* Minor spacing issue

* Fixed imports",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1174,Kathryn Chan,kathrync@allenai.org,2018-12-17 11:49:30-08:00,7e22b861d305e3201bb7923ffbf82f820a75fcae,https://github.com/allenai/allennlp/commit/7e22b861d305e3201bb7923ffbf82f820a75fcae,"add CPU/GPU usage in metrics.json (#2136)

* add CPU/GPU usage in metrics.json

* re-organized

* fix name

* add test to make sure cpu/gpu in metrics.json

* fixed

* fix pylint error

* add > 0 check",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1175,Santiago Castro,bryant@montevideo.com.uy,2018-12-17 17:47:22-05:00,30612985af484fe5b6be34d0f6a0c01cf2f34761,https://github.com/allenai/allennlp/commit/30612985af484fe5b6be34d0f6a0c01cf2f34761,"Fix loaded model not taken to cuda device (#2190)

* Fix loaded model not taken to cuda device

* Check that cuda_device is int before >=

* Add comment

* Handle multi-gpu case",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1176,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2018-12-17 19:03:01-05:00,c66635795622785313cc29fb8da41731a1a809ab,https://github.com/allenai/allennlp/commit/c66635795622785313cc29fb8da41731a1a809ab,"Adding an initializer to initialize a model to pretrained weights (#2043)

* Adding an initializer to initalize weights to a pretrained model

* Actually adding the pretrained initializer file

* Refactoring the PretrainedModelInitializer, making style compliant, adding docs, unit tests

* Removing unnecessary super parameters

* Switching lambda constant initializers to actually use the constant initializer

* Removing PretrainedModelInitializer from imports

* Fixing service test

* Moving asserts out of setUp()

* Removing tempfile usage

* Removing from_params

* Removing unused import

* Removing Init from_params

* Adding pylint override

* Handle plain str in base FramParams.from_params",10,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,29,1,0,3,0,0,0,0,3,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not self._are_equal(self.net1.linear_1, self.net2.linear_1)', 'not self._are_equal(self.net1.linear_2, self.net2.linear_3)', 'initializer.weights', 'initializer.parameter_name_overrides == {}', 'initializer.weights', 'initializer.parameter_name_overrides == name_overrides', 'self._are_equal(self.net1.linear_1, self.net2.linear_1)', 'not self._are_equal(self.net1.linear_2, self.net2.linear_3)', 'self._are_equal(self.net1.linear_1, self.net2.linear_1)', 'self._are_equal(self.net1.linear_2, self.net2.linear_3)', 'self.net1.linear_1.weight.is_cuda is True', 'self.net1.linear_1.bias.is_cuda is True', 'self.net2.linear_1.weight.is_cuda is True', 'self.net2.linear_1.bias.is_cuda is True', 'self.net1.linear_1.weight.is_cuda is True', 'self.net1.linear_1.bias.is_cuda is True', 'self.net2.linear_1.weight.is_cuda is True', 'self.net2.linear_1.bias.is_cuda is True', 'self._are_equal(self.net1.linear_1, self.net2.linear_1)', 'self.net2.linear_1.weight.is_cuda is True', 'self.net2.linear_1.bias.is_cuda is True', 'self.net1.linear_1.weight.is_cuda is False', 'self.net1.linear_1.bias.is_cuda is False', 'self._are_equal(self.net1.linear_1, self.net2.linear_1.cpu())', 'self.net1.linear_1.weight.is_cuda is True', 'self.net1.linear_1.bias.is_cuda is True', 'self.net1.linear_1.weight.is_cuda is True', 'self.net1.linear_1.bias.is_cuda is True', 'self._are_equal(self.net1.linear_1.cpu(), self.net2.linear_1)']",['(ConfigurationError)'],[],"['if(not torch.cuda.is_available(), reason=)', 'if(not torch.cuda.is_available(), reason=)', 'if(not torch.cuda.is_available(), reason=)']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)', 'skipif(not torch.cuda.is_available(), reason=)', 'skipif(not torch.cuda.is_available(), reason=)']","['mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.skipif(not torch.cuda.is_available(), reason=)']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1177,Matt Gardner,mattg@allenai.org,2018-12-17 16:43:44-08:00,0663762960a4522d4740eea460f63a06eeba126d,https://github.com/allenai/allennlp/commit/0663762960a4522d4740eea460f63a06eeba126d,"Fix (most?) warnings from BasicTextFieldEmbedder (#2117)

* Working on warnings

* Fix fixtures

* Revert weight changes in a few models, but keep config changes

* Fix serialized dependency parser

* Fix serialized dependency parser",69,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1178,Michael Schmitz,michael@schmitztech.com,2018-12-18 10:51:26-08:00,d1bae5ced7072e3947be68e9c8ac6859239d189f,https://github.com/allenai/allennlp/commit/d1bae5ced7072e3947be68e9c8ac6859239d189f,"Remove deprecated dataset_readers.{nlvr, wikitables} components. (#2206)",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1179,Michael Schmitz,michael@schmitztech.com,2018-12-18 10:51:39-08:00,a2084fd3c7c808da91ea92d07a55bff3da367c6d,https://github.com/allenai/allennlp/commit/a2084fd3c7c808da91ea92d07a55bff3da367c6d,Remove last_dim_softmax as it's deprecated and scheduled for removal. (#2207),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1180,Joel Grus,joelgrus@gmail.com,2018-12-18 11:58:38-08:00,3fd224fc921e8e13ab89de1e6b8b3f16494d0435,https://github.com/allenai/allennlp/commit/3fd224fc921e8e13ab89de1e6b8b3f16494d0435,"fix lowercase-ization in bert indexer (#2205)

* fix lowercase-ization in bert indexer

* add never_lowercase feature for [UNK], etc

* add warnings when BERT model appears incongruent with do_lowercase",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed_tokens[] == [16, 2, 1, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [16, 2, 15, 10, 11, 6, 0, 17]', 'indexed_tokens[] == [16, 2, 15, 10, 11, 6, 1, 17]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1181,Nicola De Cao,nicola.decao@uva.nl,2018-12-18 22:17:38+00:00,6aaf76ae2592249187fa702a4a28fb0af404183f,https://github.com/allenai/allennlp/commit/6aaf76ae2592249187fa702a4a28fb0af404183f,"Adding DatasetReader for the bAbI tasks and Qangaroo (#2194)

* Adding DatasetReader for the bAbI tasks

* Adding DatasetReader for Qangaroo dataset

* Fixing issues for pull request of bAbI and Qangaroo dataset readers

* Added test for bAbI dataset reader and modified types

* Fixing test for bAbI dataset reader and modified types

* Adding test for Qangaroo dataset reader and fixing issues on bAbI reader

* Fixing test for Qangaroo dataset reader and fixing issues on Qangaroo/bAbI reader

* Fixing test for Qangaroo dataset reader and fixing typing bugs on Qangaroo/bAbI reader

* Fixing test for Qangaroo dataset reader and bAbI

* Fixing test for Qangaroo dataset reader and bAbI

* Fixing typing of bAbI reader

* Trying to fix mismatch of bAbI reader context

* Adding pylint: disable=arguments-differ to bAbI/Qangaroo readers

* Style correction, documentation and minor edits to bAbI/Qangaroo readers

* answer_idx -> answer_index in testing Qangaroo reader

* Added documentation of bAbI/Qangaroo readers",11,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,0,0,0,0,0,0,2,2,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 8', '[t.text for t in instances[0].fields[]', '[t.sequence_index for t in instances[0].fields[]] == [0, 1]', '[t.text for t in instances[0].fields[]', 'reader._keep_sentences', 'reader._token_indexers[', 'len(instances) == 2', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', 'instances[0].fields[].sequence_index == 4', 'reader._token_indexers[']",[],[],[],[],[],[],"['(, [(False, False), (False, True), (True, False), (True, True)])', '(, (True, False))']","['parametrize(, [(False, False), (False, True), (True, False), (True, True)])', 'parametrize(, (True, False))']","['mark.parametrize(, [(False, False), (False, True), (True, False), (True, True)])', 'mark.parametrize(, (True, False))']",[],[],"['import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
1182,Matt Gardner,mattg@allenai.org,2018-12-18 14:59:39-08:00,bb000a0115af30545eb2c8fde912be45a4bfd5c0,https://github.com/allenai/allennlp/commit/bb000a0115af30545eb2c8fde912be45a4bfd5c0,"Allow NLVR predictor to handle string inputs for the structured representation (#2209)

* Allow NLVR predictor to handle string inputs for the structured representation

* pylint",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 1  # Because there is one world in the input.', 'in result', 'in result', 'len(result[][0]) == 1  # Because there is one world in the input.']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1183,Michael Schmitz,michael@schmitztech.com,2018-12-18 15:04:08-08:00,050b76710a96d28209eba69d2d0ba69b0e0fbab9,https://github.com/allenai/allennlp/commit/050b76710a96d28209eba69d2d0ba69b0e0fbab9,Update predicting_paper_venues_pt2.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1184,Matt Gardner,mattg@allenai.org,2018-12-18 16:49:11-08:00,eff25a3085aa9976a7650d30d8961c3626ddc411,https://github.com/allenai/allennlp/commit/eff25a3085aa9976a7650d30d8961c3626ddc411,"Adding metadata and debug info for the NLVR demo (#2214)

* Adding metadata and debug info for the NLVR demo

* Fix tests, MML parser",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1185,Michael Schmitz,michael@schmitztech.com,2018-12-19 07:53:31-08:00,4cc4b6b62773df49c394180841f43b7e66dac14b,https://github.com/allenai/allennlp/commit/4cc4b6b62773df49c394180841f43b7e66dac14b,Remove constraint_type parameter from CRF Tagger (#2208),9,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model._f1_metric is not None', 'model._f1_metric._label_encoding == ', 'model.label_encoding == ', 'model.crf._constraint_mask.sum().item() != (model.num_tags + 2)**2']",[],[],[],[],[],[],[],[],[],[],[],[]
1186,Michael Schmitz,michael@schmitztech.com,2018-12-19 08:28:48-08:00,e142042c8dd05d7ae7416240ad86ac30975d46a6,https://github.com/allenai/allennlp/commit/e142042c8dd05d7ae7416240ad86ac30975d46a6,Update pretrained.py,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1187,Michael Schmitz,michael@schmitztech.com,2018-12-19 09:49:22-08:00,e2766bcee5ac802cc67db1e78f35f736123a89b8,https://github.com/allenai/allennlp/commit/e2766bcee5ac802cc67db1e78f35f736123a89b8,bump version number to v0.8.0,4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1188,Michael Schmitz,michael@schmitztech.com,2018-12-19 10:06:16-08:00,0889a0d53e142b9b6938bba7b113b8e1aaf760ad,https://github.com/allenai/allennlp/commit/0889a0d53e142b9b6938bba7b113b8e1aaf760ad,Bump version numbers to v0.8.1-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1189,Brendan Roof,brendanr@allenai.org,2018-12-20 16:07:08-08:00,ce060badd12d3047e3af81cf97d0b62805e397e5,https://github.com/allenai/allennlp/commit/ce060badd12d3047e3af81cf97d0b62805e397e5,"Bidirectional LM Embedder (#2138)

- A token embedder for transformer based bidirectional LMs.
- Includes demo model: constituency_parser_transformer_elmo.jsonnet
- New tests for training a transformer based bidirectional language model.",16,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(result) == {,', 'tuple(embeddings.shape) == (2, 8, 14)', 'set(result) == {,', 'tuple(embeddings.shape) == (2, 8, 32)', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(result) == {}', 'tuple(embeddings.shape) == (2, 6, 14)']",[],[],[],[],[],[],[],[],[],[],[],[]
1190,Vidur Joshi,vidurj@allenai.org,2018-12-20 18:40:41-08:00,e2f66c0de2600308044ec3ab7731dae9017378fa,https://github.com/allenai/allennlp/commit/e2f66c0de2600308044ec3ab7731dae9017378fa,"Simplifies Subsequent Mask  (#2224)

* works

* starting with torch.int32

* removed unused import

* formatting",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1191,Nicola De Cao,nicola.decao@uva.nl,2018-12-21 16:55:38+00:00,fe626580720986a28e966ea95c378c4eac47fafd,https://github.com/allenai/allennlp/commit/fe626580720986a28e966ea95c378c4eac47fafd,"Corrected documentation (#2229)

Some default values were wrong or not present in the documentation.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1192,Joel Grus,joelgrus@gmail.com,2018-12-22 08:13:47-08:00,1938a5af6d1ea3a2d8dccbb831f82990800fa3e1,https://github.com/allenai/allennlp/commit/1938a5af6d1ea3a2d8dccbb831f82990800fa3e1,"fix completely masked case in BooleanAccuracy (#2230)

* fix completely masked case in BooleanAccuracy

* fix dtypes

* really fix dtypes",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['accuracy.get_metric() == 2 / 3'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1193,jbkjr,33947792+jbkjr@users.noreply.github.com,2018-12-26 19:47:25-05:00,3f0953d19de3676ea82e642659fc96d90690e34d,https://github.com/allenai/allennlp/commit/3f0953d19de3676ea82e642659fc96d90690e34d,"change mislabeled variable in description (#2242)

the required parameter ""pretrained_model"" was mislabeled as ""pretrained_model_name"" in the documentation",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1194,Mohan Zhou,mhzero964@163.com,2018-12-28 07:32:11+08:00,e53b4f45c83c244d63da83e58cdd178da0b81224,https://github.com/allenai/allennlp/commit/e53b4f45c83c244d63da83e58cdd178da0b81224,"Allow loading model from path with ~ HOME (#2215)

Modify `allennlp/common/file_utils.py` to enable loading model
like this:

    from allennlp.predictors import Predictor
    predictor = Predictor.from_path(""~/<model_file>"")

It doesn't affect the origin process of loading model.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1195,WrRan,wrran@outlook.com,2018-12-28 14:27:25+08:00,b5b9b4019f8195bb6c13bad66b8eecc243651c83,https://github.com/allenai/allennlp/commit/b5b9b4019f8195bb6c13bad66b8eecc243651c83,"add some docstrings about parameter `force` (#2226)

There are some functions with their docstrings ignoring parameter `force` in `allennlp/commands/train.py`",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1196,Brendan Roof,brendanr@allenai.org,2018-12-28 12:28:12-08:00,42e0815e71007ab155e4e00dd2cedfcf7be5ef54,https://github.com/allenai/allennlp/commit/42e0815e71007ab155e4e00dd2cedfcf7be5ef54,"Fix circular dependency. (#2257)

- Fix for #2250",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1197,Tingkai Zhang,ztkevin2015@outlook.com,2018-12-28 16:05:29-05:00,2f56765b9c588992f44b37e0de0455761a8654de,https://github.com/allenai/allennlp/commit/2f56765b9c588992f44b37e0de0455761a8654de,"fix get_output_dim() for ElmoTokenEmbedder (#2234)

1. Fix get_output_dim() of ElmoTokenEmbedder with projection
2. Add test of get_output_dim() of ElmoTokenEmbedder with projection
 
#2227",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['embedding_layer.get_output_dim() == 20'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1198,Nelson Liu,nelson-liu@users.noreply.github.com,2018-12-31 06:42:35-05:00,cf67128018f0148498a27683601a17c49340db60,https://github.com/allenai/allennlp/commit/cf67128018f0148498a27683601a17c49340db60,"Remove EpochTrackingBucketIterator (#2249)

This was deprecated in (at least) version v0.6.0, so it's due to be deleted (even though the original deprecation warning didn't mention this...oops)",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1199,Nelson Liu,nelson-liu@users.noreply.github.com,2018-12-31 10:32:41-05:00,a98481c88bdf09e884bc1c3ee3366aa027088098,https://github.com/allenai/allennlp/commit/a98481c88bdf09e884bc1c3ee3366aa027088098,"Remove deprecated batch_average argument to sequence ce with logits (#2247)

* Remove deprecated batch_average argument to sequence ce with logits

* Fix test

* Fix lint",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1200,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-01 18:17:59-05:00,3cff7d35714aaaa6db5cd1d9a46a338b945fb092,https://github.com/allenai/allennlp/commit/3cff7d35714aaaa6db5cd1d9a46a338b945fb092,"Remove deprecated SpanPruner (#2248)

* Remove deprecated SpanPruner

* Remove mentions of spanpruner

* Update tutorial to replace num_spans_to_keep with num_items_to_keep",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1201,Nikhil Verma,nikhilweee@gmail.com,2019-01-02 22:22:34+05:18,fb587833084bf8f1a0cb172b5451e21d980f0d5f,https://github.com/allenai/allennlp/commit/fb587833084bf8f1a0cb172b5451e21d980f0d5f,"Check for existing vocabulary before creating a new one (#2240) (#2261)

* Check for existing vocabulary before creating a new one (#2240)

* 2261: Check for recover flag before using existing vocabulary.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1202,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-02 14:39:16-05:00,ee02ed0fbef746ec0dc2175c3c063cc72f0e5550,https://github.com/allenai/allennlp/commit/ee02ed0fbef746ec0dc2175c3c063cc72f0e5550,"Fix multiGPU peak gpu memory test (#2254)

This test was failing on a multigpu machine i use:

```
$ py.test -k ""trainer_test""
=============================================================================================== test session starts ================================================================================================
platform linux -- Python 3.6.5, pytest-3.6.2, py-1.5.3, pluggy-0.6.0
rootdir: /home/nfliu/Documents/Github/allennlp, inifile: pytest.ini
plugins: cov-2.5.1, flaky-3.4.0
collected 1161 items / 1140 deselected

allennlp/tests/training/trainer_test.py .............F.......                                                                                                                                                [100%]

===================================================================================================== FAILURES =====================================================================================================
__________________________________________________________________________________ TestTrainer.test_trainer_can_run_multiple_gpu ___________________________________________________________________________________

self = <allennlp.tests.training.trainer_test.TestTrainer testMethod=test_trainer_can_run_multiple_gpu>

    @pytest.mark.skipif(torch.cuda.device_count() < 2,
                        reason=""Need multiple GPUs."")
    def test_trainer_can_run_multiple_gpu(self):

        class MetaDataCheckWrapper(Model):
            """"""
                Checks that the metadata field has been correctly split across the batch dimension
                when running on multiple gpus.
                """"""
            def __init__(self, model):
                super().__init__(model.vocab)
                self.model = model

            def forward(self, **kwargs) -> Dict[str, torch.Tensor]:  # type: ignore # pylint: disable=arguments-differ
                assert 'metadata' in kwargs and 'tags' in kwargs, \
                    f'tokens and metadata must be provided. Got {kwargs.keys()} instead.'
                batch_size = kwargs['tokens']['tokens'].size()[0]
                assert len(kwargs['metadata']) == batch_size, \
                    f'metadata must be split appropriately. Expected {batch_size} elements, ' \
                    f""got {len(kwargs['metadata'])} elements.""
                return self.model.forward(**kwargs)

        multigpu_iterator = BasicIterator(batch_size=4)
        multigpu_iterator.index_with(self.vocab)
        trainer = Trainer(MetaDataCheckWrapper(self.model), self.optimizer,
                          multigpu_iterator, self.instances, num_epochs=2,
                          cuda_device=[0, 1])
        metrics = trainer.train()
        assert 'peak_cpu_memory_MB' in metrics
        assert isinstance(metrics['peak_cpu_memory_MB'], float)
        assert metrics['peak_cpu_memory_MB'] > 0
        assert 'peak_gpu_0_memory_MB' in metrics
>       assert isinstance(metrics['peak_gpu_0_memory_MB'], float)
E       AssertionError: assert False
E        +  where False = isinstance(549, float)

allennlp/tests/training/trainer_test.py:128: AssertionError
----------------------------------------------------------------------------------------------- Captured stderr call -----------------------------------------------------------------------------------------------
12/27/2018 09:34:40 - INFO - allennlp.common.checks -   Pytorch version: 0.4.1
0it [00:00, ?it/s]12/27/2018 09:34:40 - INFO - allennlp.data.dataset_readers.sequence_tagging -   Reading instances from lines in file at: /home/nfliu/Documents/Github/allennlp/allennlp/tests/fixtures/data/sequence_tagging.tsv
4it [00:00, 12409.18it/s]
12/27/2018 09:34:40 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.
100%|| 4/4 [00:00<00:00, 71392.41it/s]
12/27/2018 09:34:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.simple_tagger.SimpleTagger'> from params {'text_field_embedder': {'token_embedders': {'tokens': {'type': 'embedding', 'embedding_dim': 5}}}, 'encoder': {'type': 'lstm', 'input_size': 5, 'hidden_size': 7, 'num_layers': 2}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe36c0f5438>}
12/27/2018 09:34:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'tokens': {'type': 'embedding', 'embedding_dim': 5}}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe36c0f5438>}
12/27/2018 09:34:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'type': 'embedding', 'embedding_dim': 5} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe36c0f5438>}
12/27/2018 09:34:40 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'type': 'lstm', 'input_size': 5, 'hidden_size': 7, 'num_layers': 2} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe36c0f5438>}
12/27/2018 09:34:40 - WARNING - allennlp.training.trainer -   Multiple GPU support is experimental not recommended for use. In some cases it may lead to incorrect results or undefined behavior.
12/27/2018 09:34:40 - INFO - allennlp.training.trainer -   Beginning training.
12/27/2018 09:34:40 - INFO - allennlp.training.trainer -   Epoch 0/1
12/27/2018 09:34:40 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 2121.256
12/27/2018 09:34:40 - INFO - allennlp.training.trainer -   GPU 0 memory usage MB: 533
12/27/2018 09:34:40 - INFO - allennlp.training.trainer -   GPU 1 memory usage MB: 10
12/27/2018 09:34:40 - INFO - allennlp.training.trainer -   Training
  0%|          | 0/1 [00:00<?, ?it/s]12/27/2018 09:34:40 - DEBUG - allennlp.data.iterators.data_iterator -   Batch padding lengths: {'tokens': {'tokens_length': 4, 'num_tokens': 4}, 'tags': {'num_tokens': 4}}
12/27/2018 09:34:40 - DEBUG - allennlp.data.iterators.data_iterator -   Batch size: 4
loss: 0.7543 ||: 100%|| 1/1 [00:02<00:00,  2.04s/it]
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -                       Training |  Validation
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   loss            |     0.754  |       N/A
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   gpu_1_memory_MB |    10.000  |       N/A
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   gpu_0_memory_MB |   533.000  |       N/A
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   cpu_memory_MB   |  2121.256  |       N/A
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:02
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:00:02
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   Epoch 1/1
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 3892.764
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   GPU 0 memory usage MB: 549
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   GPU 1 memory usage MB: 549
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   Training
  0%|          | 0/1 [00:00<?, ?it/s]12/27/2018 09:34:42 - DEBUG - allennlp.data.iterators.data_iterator -   Batch padding lengths: {'tokens': {'tokens_length': 4, 'num_tokens': 4}, 'tags': {'num_tokens': 4}}
12/27/2018 09:34:42 - DEBUG - allennlp.data.iterators.data_iterator -   Batch size: 4
loss: 0.7522 ||: 100%|| 1/1 [00:00<00:00, 59.00it/s]
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -                       Training |  Validation
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   loss            |     0.752  |       N/A
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   gpu_1_memory_MB |   549.000  |       N/A
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   gpu_0_memory_MB |   549.000  |       N/A
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   cpu_memory_MB   |  3892.764  |       N/A
12/27/2018 09:34:42 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:00
------------------------------------------------------------------------------------------------ Captured log call -------------------------------------------------------------------------------------------------
09:34:40 - INFO - allennlp.common.checks - Pytorch version: 0.4.1
09:34:40 - INFO - allennlp.data.dataset_readers.sequence_tagging - Reading instances from lines in file at: /home/nfliu/Documents/Github/allennlp/allennlp/tests/fixtures/data/sequence_tagging.tsv
09:34:40 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
09:34:40 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.simple_tagger.SimpleTagger'> from params {'text_field_embedder': {'token_embedders': {'tokens': {'type': 'embedding', 'embedding_dim': 5}}}, 'encoder': {'type': 'lstm', 'input_size': 5, 'hidden_size': 7, 'num_layers': 2}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe36c0f5438>}
09:34:40 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'token_embedders': {'tokens': {'type': 'embedding', 'embedding_dim': 5}}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe36c0f5438>}
09:34:40 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'type': 'embedding', 'embedding_dim': 5} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe36c0f5438>}
09:34:40 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'type': 'lstm', 'input_size': 5, 'hidden_size': 7, 'num_layers': 2} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe36c0f5438>}
09:34:40 - WARNING - allennlp.training.trainer - Multiple GPU support is experimental not recommended for use. In some cases it may lead to incorrect results or undefined behavior.
09:34:40 - INFO - allennlp.training.trainer - Beginning training.
09:34:40 - INFO - allennlp.training.trainer - Epoch 0/1
09:34:40 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 2121.256
09:34:40 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 533
09:34:40 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 10
09:34:40 - INFO - allennlp.training.trainer - Training
09:34:40 - DEBUG - allennlp.data.iterators.data_iterator - Batch padding lengths: {'tokens': {'tokens_length': 4, 'num_tokens': 4}, 'tags': {'num_tokens': 4}}
09:34:40 - DEBUG - allennlp.data.iterators.data_iterator - Batch size: 4
09:34:42 - INFO - allennlp.training.trainer -                     Training |  Validation
09:34:42 - INFO - allennlp.training.trainer - loss            |     0.754  |       N/A
09:34:42 - INFO - allennlp.training.trainer - gpu_1_memory_MB |    10.000  |       N/A
09:34:42 - INFO - allennlp.training.trainer - gpu_0_memory_MB |   533.000  |       N/A
09:34:42 - INFO - allennlp.training.trainer - cpu_memory_MB   |  2121.256  |       N/A
09:34:42 - INFO - allennlp.training.trainer - Epoch duration: 00:00:02
09:34:42 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:00:02
09:34:42 - INFO - allennlp.training.trainer - Epoch 1/1
09:34:42 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 3892.764
09:34:42 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 549
09:34:42 - INFO - allennlp.training.trainer - GPU 1 memory usage MB: 549
09:34:42 - INFO - allennlp.training.trainer - Training
09:34:42 - DEBUG - allennlp.data.iterators.data_iterator - Batch padding lengths: {'tokens': {'tokens_length': 4, 'num_tokens': 4}, 'tags': {'num_tokens': 4}}
09:34:42 - DEBUG - allennlp.data.iterators.data_iterator - Batch size: 4
09:34:42 - INFO - allennlp.training.trainer -                     Training |  Validation
09:34:42 - INFO - allennlp.training.trainer - loss            |     0.752  |       N/A
09:34:42 - INFO - allennlp.training.trainer - gpu_1_memory_MB |   549.000  |       N/A
09:34:42 - INFO - allennlp.training.trainer - gpu_0_memory_MB |   549.000  |       N/A
09:34:42 - INFO - allennlp.training.trainer - cpu_memory_MB   |  3892.764  |       N/A
09:34:42 - INFO - allennlp.training.trainer - Epoch duration: 00:00:00
===Flaky Test Report===


===End Flaky Test Report===
================================================================================================= warnings summary =================================================================================================
allennlp/tests/training/trainer_test.py::TestTrainer::test_trainer_can_run_multiple_gpu
  /home/nfliu/Documents/Github/allennlp/allennlp/modules/encoder_base.py:116: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().
    module_output, final_states = module(packed_sequence_input, initial_states)
  /home/nfliu/Documents/Github/allennlp/allennlp/modules/encoder_base.py:116: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().
    module_output, final_states = module(packed_sequence_input, initial_states)

-- Docs: http://doc.pytest.org/en/latest/warnings.html
======================================================================== 1 failed, 20 passed, 1140 deselected, 2 warnings in 26.92 seconds =========================================================================
```

Pretty sure it should be checking for `int` instead of `float`, since `common.util.gpu_memory_mb()` returns `Dict[int, int]`. See https://github.com/allenai/allennlp/blob/3f0953d19de3676ea82e642659fc96d90690e34d/allennlp/common/util.py#L327",1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(metrics[], int)', 'isinstance(metrics[], int)']",[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(metrics[], float)', 'isinstance(metrics[], float)']",[],[],[],[],[],[],[],[],[],[],[],[]
1203,HT Liu,shomyliu@gmail.com,2019-01-03 06:44:03+08:00,07d193ee1086db74d88db77bbbb6653feca1ea73,https://github.com/allenai/allennlp/commit/07d193ee1086db74d88db77bbbb6653feca1ea73,"clarify the ""num_output_representations"" more clear (#2256)",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1204,Brendan Roof,brendanr@allenai.org,2019-01-02 17:16:24-08:00,0d54a7a3d5485af6ac0adf56fca988a5e5c647e8,https://github.com/allenai/allennlp/commit/0d54a7a3d5485af6ac0adf56fca988a5e5c647e8,"Add a quick README for training transformer ELMo. (#2231)

- Training instructions.
- Example of using the trained model as an embedder.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1205,Kathryn Chan,kathrync@allenai.org,2019-01-03 08:44:35-08:00,b5141b23ed14690bd09e89226f55ee621733a0ab,https://github.com/allenai/allennlp/commit/b5141b23ed14690bd09e89226f55ee621733a0ab,fix doc (#2213),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1206,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-03 13:33:39-05:00,511c846c9c779fdac0066dbae6765c1619037098,https://github.com/allenai/allennlp/commit/511c846c9c779fdac0066dbae6765c1619037098,Deprecate bidirectional-language-model for bidirectional_language_model (#2253),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1207,Qian,qianlxc@outlook.com,2019-01-05 01:37:19+08:00,cf6a7d7ddeb9e2ca7f34ebec3e2b9e361e25afa7,https://github.com/allenai/allennlp/commit/cf6a7d7ddeb9e2ca7f34ebec3e2b9e361e25afa7,Fix bug in uniform_unit_scaling #2239 (#2273),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1208,Pawe Mandera,pmandera@users.noreply.github.com,2019-01-04 19:29:17+01:00,e394b7a9e34a6261b32b65e89c071dbb3fb670ed,https://github.com/allenai/allennlp/commit/e394b7a9e34a6261b32b65e89c071dbb3fb670ed,Fix type annotation for .forward(...) in tutorial (#2122),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1209,Michael Schmitz,michael@schmitztech.com,2019-01-04 12:31:56-08:00,259ce3221b5ed35c94ba4eaae070e22947f23f7b,https://github.com/allenai/allennlp/commit/259ce3221b5ed35c94ba4eaae070e22947f23f7b,Add a Contributions section to README.md (#2277),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1210,Joel Grus,joelgrus@gmail.com,2019-01-04 16:54:54-08:00,e6b0f21300d33b33aa4d8db198ac9f968c37070a,https://github.com/allenai/allennlp/commit/e6b0f21300d33b33aa4d8db198ac9f968c37070a,"script for doing archive surgery (#2223)

* script for doing archive surgery

* simplify script",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1211,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-05 12:08:41-05:00,2f662cf48fc3543a507c9667133022c12d7032ac,https://github.com/allenai/allennlp/commit/2f662cf48fc3543a507c9667133022c12d7032ac,Fix spelling in tutorial README (#2283),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1212,WrRan,wrran@outlook.com,2019-01-06 07:58:49+08:00,e13aae416a5983bcfece80cf6acc7361e1269552,https://github.com/allenai/allennlp/commit/e13aae416a5983bcfece80cf6acc7361e1269552,fix #2285 (#2286),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tensor == [0, 0, 1, 1, 0]', 'set([type(item) for item in tensor]) == set([int])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1213,WrRan,wrran@outlook.com,2019-01-06 20:03:22+08:00,73f0e5b9193050fdc166aa8ea5a40cacb4124269,https://github.com/allenai/allennlp/commit/73f0e5b9193050fdc166aa8ea5a40cacb4124269,"Update the `find-lr` subcommand help text. (#2289)

* Update the elmo command help text.

* Update the find-lr subcommand help text.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1214,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-06 15:55:10-05:00,1bec3f96cf35ac68616fcbf4ef2cc18f55a9767a,https://github.com/allenai/allennlp/commit/1bec3f96cf35ac68616fcbf4ef2cc18f55a9767a,"Add __repr__ to Vocabulary (#2293)

As it currently stands, the following is logged during training:

```
2019-01-06 10:46:21,832 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.model
s.language_model.LanguageModel'> from params {'bidirectional': False, 'contextualizer': {'bidirectional':
 False, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 200, 'num_layers': 2, 'type': 'lstm'}, 'dropout
': 0.5, 'text_field_embedder': {'token_embedders': {'tokens': {'embedding_dim': 200, 'type': 'embedding'}
}}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7ff7811665f8>}
```

Note that the `Vocabulary` does not provide any useful information, since it doesn't have `__repr__` defined. This provides a fix.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1215,Michael Schmitz,michael@schmitztech.com,2019-01-07 13:04:41-08:00,01913fb48abc8511dfd222e6181504d4596b0128,https://github.com/allenai/allennlp/commit/01913fb48abc8511dfd222e6181504d4596b0128,Update the base image in the Dockerfiles. (#2298),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1216,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-07 16:25:12-05:00,b0191969fcd007803f87c48d7288d8480cebcb02,https://github.com/allenai/allennlp/commit/b0191969fcd007803f87c48d7288d8480cebcb02,Don't deprecate bidirectional-language-model name (#2297),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1217,Michael Schmitz,michaels@allenai.org,2019-01-07 23:40:15+00:00,87f977a5fd58568d44d68499521ab0d71f8a0012,https://github.com/allenai/allennlp/commit/87f977a5fd58568d44d68499521ab0d71f8a0012,bump version number to v0.8.1,4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1218,Michael Schmitz,michaels@allenai.org,2019-01-07 23:41:17+00:00,f76dc70b61cede54ca9fe07242d9d2b87f8dd543,https://github.com/allenai/allennlp/commit/f76dc70b61cede54ca9fe07242d9d2b87f8dd543,Bump version numbers to v0.8.2-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1219,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-07 16:42:14-08:00,088f0bb685231a17320bf916c091dfa8e60e3ce5,https://github.com/allenai/allennlp/commit/088f0bb685231a17320bf916c091dfa8e60e3ce5,"Turn BidirectionalLM into a more-general LanguageModel class (#2264)

Fixes https://github.com/allenai/allennlp/issues/2255

This PR replaces the `BidirectionalLM` class with a more-general `LanguageModel` that can be used in either the unidirectional/forward setting or the bidirectional setting.

It also accordingly replaces the `BidirectionalLanguageModelTokenEmbedder` with a `LanguageModelTokenEmbedder`.

Also fixes bug in the experiment_unsampled.jsonnet config that was preventing a test from actually being unsampled.

TODO:

- [x] test the unidirectional case
- [x] properly deprecate `BidirectionalLM` and `BidirectionalLanguageModelTokenEmbedder` 
- [x] check docs for accuracy
- [x] fix user-facing training configs",34,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,8,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,8,1,0,0,0,0,0,0,0,0,0,0,1,8,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],"['tuple(embeddings.shape) == self.expected_embedding_shape', 'set(result) == {,', 'tuple(embeddings.shape) == self.expected_embedding_shape', 'result[] is None', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['tuple(embeddings.shape) == (2, 8, 14)', 'set(result) == {,', 'tuple(embeddings.shape) == (2, 8, 32)', '(training_loss == validation_loss).all()', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}']",[],[],[],[],[],[],[],[],[],[],[],[]
1220,Matt Gardner,mattg@allenai.org,2019-01-08 10:46:28-08:00,a4670adb31d213277da084b850cf7a9aaf511fb9,https://github.com/allenai/allennlp/commit/a4670adb31d213277da084b850cf7a9aaf511fb9,"Grammar induction from a python executor (#2281)

* Got a simple LF executor working where all you need is to specify functions

* Grammar induction for simple cases now works

* Got logical_form_to_action_sequence working for simple cases

* Got action_sequence_to_logical_form working for simple cases

* Fix (most?) NLVR and WikiTables tests

* Renamed Executor to DomainLanguage

* Fix world test

* Add some documentation, fix pylint

* mypy

* Added docstrings, fixed docs

* Improve documentation, simplify some logic

* Removed the old type_declaration code entirely, better handled constants

* mypy

* PR feedback

* mypy...

* Actually fix mypy...",27,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,10,0,0,0,0,0,0,0,0,0,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(actual_right_sides) == set(expected_right_sides)', 'self.language.execute() == 5', 'self.language.execute() == 2', 'self.language.execute() == 20', 'self.language.execute() == 3', 'self.language.execute() == 3', 'self.language.execute() == 5', 'self.language.execute() == -1', 'self.language.execute() == 10', 'self.language.execute() == 2', 'self.language.execute() == 5', 'self.language.execute() == 5', 'self.language.execute() == 0', 'self.language.execute() == 4', 'self.language.execute() == 12', 'set(valid_actions.keys()) == {', 'action_sequence == [,', 'action_sequence == [,', 'action_sequence == [,', 'recovered_logical_form == logical_form', 'recovered_logical_form == logical_form', 'expression == [[]]', 'expression == []]]]']","['(ExecutionError, match=)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],"['expression == [[[]]]', 'expression == [[]]]]]']",[],[],[],[],[],[],[],[],[],[],[],[]
1221,Evan Pete Walsh,epwalsh10@gmail.com,2019-01-08 11:42:03-08:00,b0e2956677e3191ffd51eef25373f0bf4504c05b,https://github.com/allenai/allennlp/commit/b0e2956677e3191ffd51eef25373f0bf4504c05b,"Add CopyNet seq2seq model (#2237)

* add CopyNet seq2seq model

* add predictor

* fix for torch 1.0

* add version to deprecation warning

* Improve dataset reader docstring

* ensure tgt token indexers has SingleIdTokenIndexer

* make mypy happy

* fix serialized config

* get rid of warnings

* CopyMapField -> NamespaceSwappingField

* small code and doc improvements

* add copy token to vocab when model inits

* remove manual adding of copy token",28,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.vocab.get_vocab_size() > 5', 'len(self.instances) == 2', 'set(self.instances[0].fields.keys()) == set((,', '[t.text for t in fields[].tokens] == \\', 'fields[] == \\', '[t.text for t in fields[].tokens] == \\', 'fields[] == \\', 'list(source_token_ids) == [0,   # these', 'list(target_token_ids) == [9,   # @start@', 'tensor[1].item() != self.vocab.get_token_index(DEFAULT_OOV_TOKEN, )', 'vocab.get_vocab_size(self.model._target_namespace) == 8', 'not in vocab._token_to_index[self.model._target_namespace]', 'not in vocab._token_to_index[self.model._target_namespace]', ']', 'list(source_tokens[].size()) == [11]', 'list(target_tokens[].size()) == [10]', 'target_tokens[][0] == self.model._start_index', 'target_tokens[][4] == self.model._oov_index', 'target_tokens[][5] == self.model._oov_index', 'target_tokens[][-1] == self.model._end_index', 'list(input_choices.size()) == [3]', 'list(selective_weights.size()) == [3, 3]', 'target_vocab_size == 8', 'oov_index not in [5, 6]', 'list(final_probs.size()) == [2, target_vocab_size + 3]', 'tok_index not in [end_index, pad_index, oov_index]', 'len(predicted_tokens) == 2', 'len(predicted_tokens[0]) == 2', 'len(predicted_tokens[1]) == 2', 'predicted_tokens[0][0] == []', 'predicted_tokens[0][1] == []', 'len(predicted_tokens) == 2', 'predicted_tokens[0] == []', 'predicted_tokens[1] == []', 'predicted_tokens is not None', 'isinstance(predicted_tokens, list)', 'all(isinstance(x, str) for x in predicted_tokens)', 'len(output_dict[]) == model._beam_search.beam_size', 'len(output_dict[]) == model._beam_search.beam_size', 'all(isinstance(x, str) for x in predicted_tokens)', 'end_token not in predicted_tokens']",[],[],[],[],[],[],[],[],[],[],[],[],"['predicted_tokens is not None', 'isinstance(predicted_tokens, list)', 'all(isinstance(x, str) for x in predicted_tokens)']",[],[],[],[],[],[],[],[],[],[],[],[]
1222,Vidur Joshi,vidurj@allenai.org,2019-01-08 16:18:29-08:00,7d3b130eb01e7223ccc5cecd5a67456cf09f25ec,https://github.com/allenai/allennlp/commit/7d3b130eb01e7223ccc5cecd5a67456cf09f25ec,"Masked Flip (#2299)

Adds a `masked_flip` function that flips a tensor along the time dimension while respecting padding. This is useful for running an RNN in the backward direction along a padded batch. Eg: `masked_flip(lstm(masked_flip(batch, sequence_lengths))[0], sequence_lengths)`.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1223,WrRan,wrran@outlook.com,2019-01-09 11:01:40+08:00,8a7f808b342c3224ad419b2ca249e684df63b316,https://github.com/allenai/allennlp/commit/8a7f808b342c3224ad419b2ca249e684df63b316,"Check train/dev/test-file-path before process (#2308)

* check train/dev/test-file-path before process

* allow data_path to be a dir",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1224,Michael Schmitz,michael@schmitztech.com,2019-01-09 10:19:08-08:00,f1600591b6d1567dfbefd6fea4418449ff872090,https://github.com/allenai/allennlp/commit/f1600591b6d1567dfbefd6fea4418449ff872090,"Add raw prefix to avoid warnings from regex (#2310)

* Add raw prefix to avoid warnings from regex

* Update openai_transformer_byte_pair_indexer.py",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1225,Ratin_Kumar,ratin.kumar.2k@gmail.com,2019-01-10 02:22:18+05:18,36d7400654ba183c7c2c60f3350ccf667eea64c2,https://github.com/allenai/allennlp/commit/36d7400654ba183c7c2c60f3350ccf667eea64c2,"Added links for some tutorials and organized the How-to alphabetically. (#2315)

Added links for Tutorials  for the following:
    Creating a Configuration File.
    Using a Debugger.
    Training and Using a Transformer ELMo.

Fixes #2284",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1226,Evan Pete Walsh,epwalsh10@gmail.com,2019-01-09 13:47:59-08:00,5bce1d54bf15b10ae1400e3d387953169941d5e8,https://github.com/allenai/allennlp/commit/5bce1d54bf15b10ae1400e3d387953169941d5e8,"Display default values in help message for allennlp command (#2323)

* add custom arg parser

* add overrides decorator",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1227,Michael Schmitz,michael@schmitztech.com,2019-01-09 13:49:48-08:00,7ecf772d554474da24ae24e9ea3520334bc35dad,https://github.com/allenai/allennlp/commit/7ecf772d554474da24ae24e9ea3520334bc35dad,Fix backslash exceptions. (#2322),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1228,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-10 10:19:36-08:00,93250f05263eb5c468a09b7fbb19de90ef273aa6,https://github.com/allenai/allennlp/commit/93250f05263eb5c468a09b7fbb19de90ef273aa6,"Skip Custom Highway LSTM tests, since they're broken (#2307)

Skipping these tests, since they're pretty much useless in their current state.

Have we decided if we're going to fix the custom extensions, or remove the module? I think there was talk of the latter, at some point?",1,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],[],[],[],[],"['if(not torch.cuda.is_available(), reason=)']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)']","['mark.skipif(not torch.cuda.is_available(), reason=)']",[],[],[]
1229,Andrew Moore,andrew.p.moore94@gmail.com,2019-01-10 18:30:04+00:00,5f9fb419273f99c949ccdabab22fdc8e9b895c1c,https://github.com/allenai/allennlp/commit/5f9fb419273f99c949ccdabab22fdc8e9b895c1c,"Stacked Bi-Directional LSTM to be compatible with the Seq2Vec wrapper (#2318)

* Stacked Bi-directional LSTM works with Seq2Vec

* Doc String includes use_highway

* remove trailing spaces for pylint",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['encoder.get_input_dim() == 5', 'encoder.get_output_dim() == 18', 'output.detach().numpy().shape == (4, 18)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1230,Mark Neumann,markn@allenai.org,2019-01-10 11:44:22-08:00,059b0572387cfba46da1a4a51da0e7197de11bc5,https://github.com/allenai/allennlp/commit/059b0572387cfba46da1a4a51da0e7197de11bc5,"remove custom extensions (#2332)

fixes #2307 and fixes #1456",20,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],['import pytest']
1231,Joel Grus,joelgrus@gmail.com,2019-01-10 11:57:37-08:00,71ebcd8416b094b8f246fa06e7816c42a6fcf467,https://github.com/allenai/allennlp/commit/71ebcd8416b094b8f246fa06e7816c42a6fcf467,"add infer_and_cast (#2324)

* add infer_and_cast

* remove print statement + add comment

* address PR feedback

* pylint",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['infer_and_cast(lots_of_strings) == casted', 'params.as_dict() == lots_of_strings', 'params.as_dict(infer_type_and_cast=True) == casted', 'optimizer.defaults[] == 0.1']","['(ValueError, match=)', '(TypeError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1232,Brendan Roof,brendanr@allenai.org,2019-01-10 12:50:45-08:00,e6ad6e9a90b55f76dc921b35ec28578d82af8bbd,https://github.com/allenai/allennlp/commit/e6ad6e9a90b55f76dc921b35ec28578d82af8bbd,"Evaluate on a token-weighted basis. (#2183)

- Allow models to return a `""batch_weight""` key that will be used to weight each batch's loss.
  - Per @matt-peters' suggestion.
  - Performed in Calypso: https://github.com/allenai/calypso/blob/master/calypso/train.py#L699
- Remove unused ""loss_scale"". This was never set in the training config, so it should be fairly safe.",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('AlmostEqual', '(metrics[], 8.0)'), ('AlmostEqual', '(metrics[], (70 + 18 + 12)/13.5)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(result) == {,', 'set(result) == {,']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(result) == {,', 'set(result) == {,']",[],[],[],[],[],[],[],[],[],[],[],[]
1233,Michael Schmitz,michael@schmitztech.com,2019-01-10 14:49:10-08:00,236876017ada9eba060106ca02394c9d6c09605b,https://github.com/allenai/allennlp/commit/236876017ada9eba060106ca02394c9d6c09605b,Remove pylint ignores for backslashes. (#2331),4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1234,Kevin Lin,kl2806@columbia.edu,2019-01-11 10:57:01-08:00,43ea97cc10e351869bb7c532435688bce2705959,https://github.com/allenai/allennlp/commit/43ea97cc10e351869bb7c532435688bce2705959,"QuaRel Domain Language (#2321)

* init quarel language

* add other predicates

* add and and quaval

* types and tests

* move domain lang out of test file

* quarel domain lang

* add comments

* tests

* tests

* rename vars

* mypy, pylint

* rename file

* test mutiple, no answer correct

* add doc

* Address style issues

* Check for inconsistent and comparison

* add whitespace

* reduce nesting",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.language.execute((', 'self.language.execute((', 'self.language.execute((', 'self.language.execute((', 'self.language.logical_form_to_action_sequence((', 'self.language.execute((', 'self.language.execute((', 'self.language.logical_form_to_action_sequence((', 'recovered_logical_form == logical_form', 'self.language.execute(logical_form) == -1', 'set(valid_actions.keys()) == {']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1235,Oyvind Tafjord,OyvindTafjord@users.noreply.github.com,2019-01-11 15:23:49-08:00,4c5de5776478691da473bf69fd0acda054be28c6,https://github.com/allenai/allennlp/commit/4c5de5776478691da473bf69fd0acda054be28c6,adjust call to lisp_to_nested_expression (#2347),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1236,WrRan,wrran@outlook.com,2019-01-14 02:09:28+08:00,632b14ce29894e778db17201884ad332e09d9e13,https://github.com/allenai/allennlp/commit/632b14ce29894e778db17201884ad332e09d9e13,"Warn default value of min_padding_length (#2309)

* warn default-value of min_padding_length

* update warn type

* Update character_token_indexer_test.py

* add min_padding_length

* add min_padding_length

* add min_padding_length

* add min_padding_length",16,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1237,Matt Gardner,mattg@allenai.org,2019-01-14 19:49:35-08:00,0409371e7cd21777ac976296a891d3868f101f25,https://github.com/allenai/allennlp/commit/0409371e7cd21777ac976296a891d3868f101f25,"New NLVR language (#2319)

* Working on rewriting the NLVR language with DomainLanguage. Almost done...

* All execution tests pass; grammar induction probably isn't quite right yet

* Parsing tests now also pass

* Got higher-order functions working in Arithmetic

* negate_filter now works correctly in NlvrLanguage

* Working on converting NLVR code to use new API

* Mostly done, just need to fix processed data and saved models

* Fixed processed data

* Saving state

* Fix list/set bug

* Update fixtures

* Added partial list of sed commands for converting between old and new types

* Fix checklist info test

* Removed old code and all references to it, switched to new API

* Revert changes to train_fixtures.py

* pylint, mypy and docs

* Improving some docstrings

* Fix test

* Removed old TODO

* Fix problem introduced by rebase

* Update QuaRel test to use new function name",34,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,5,2,0,0,0,0,0,0,0,0,57,0,0,0,0,0,0,0,0,0,0,0,0,58,1,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],"[('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('RaisesRegex', '(ParsingError, ):'), ('RaisesRegex', '(ParsingError, ):'), ('RaisesRegex', '(ParsingError, ):')]","['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['set(agenda_strings) == set([,', 'isinstance(worlds[0], NlvrLanguage)', 'set(agenda_strings) == set([,', 'all([isinstance(world, NlvrLanguage) for world in worlds])', 'action_sequence == [,', 'self.language.execute() == 1', 'action_sequence == [,', 'recovered_logical_form == logical_form', 'executor.execute(logical_form_true) is True', 'executor.execute(logical_form_false) is False', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is True', 'self.custom_language.execute(', 'self.custom_language.execute(', 'self.custom_language.execute(logical_form) is True', 'self.custom_language.execute(logical_form) is True', 'self.custom_language.execute(', 'self.custom_language.execute(', 'self.custom_language.execute(', 'self.custom_language.execute(', 'self.custom_language.execute(', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'action_sequence == [,', 'action_sequence == [,', 'action_sequence == [,', 'set(agenda) == set([])', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'set(productions.keys()) == {']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(agenda_strings) == set([,', 'isinstance(worlds[0], NlvrWorld)', 'set(agenda_strings) == set([,', 'all([isinstance(world, NlvrWorld) for world in worlds])', 'action_sequence == [,', 'set(valid_actions.keys()) == {', 'executor.execute(logical_form_true) is True', 'executor.execute(logical_form_false) is False', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is True', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'self.custom_executor.execute(logical_form) is True', 'self.custom_executor.execute(logical_form) is True', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'self.custom_executor.execute(', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'action_sequence == [,', 'action_sequence == [,', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([])', 'set(agenda) == set([,', 'set(agenda) == set([])', 'set(agenda) == set([,', 'set(agenda) == set([,', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'parsed_logical_form == parsed_reconstructed_logical_form', 'nlvr_world.execute(logical_form) == nlvr_world.execute(reconstructed_logical_form)', 'parsed_logical_form == parsed_reconstructed_logical_form', 'nlvr_world.execute(logical_form) == nlvr_world.execute(reconstructed_logical_form)', 'parsed_logical_form == parsed_expected_logical_form']",['(ExecutionError)'],[],[],[],[],[],[],[],[],[],[],[]
1238,DNGros,dngros@live.com,2019-01-15 09:29:10-06:00,0f6796aaf3c7dffd08502e47845c9c5ca537f456,https://github.com/allenai/allennlp/commit/0f6796aaf3c7dffd08502e47845c9c5ca537f456,"Fix very minor docstring typo in elmo.py (#2361)

For the Elmo module the docstring labels the type of scalar_mix_parameters as List[int] but the type hint labels it as List[float]. This confused me slightly at first. I am pretty sure float was intended.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1239,Joel Grus,joelgrus@gmail.com,2019-01-15 07:32:50-08:00,6bd59751e994f18251f69ed432c5f045991c90ed,https://github.com/allenai/allennlp/commit/6bd59751e994f18251f69ed432c5f045991c90ed,"sanitize environment variables that can't be unicode encoded (#2357)

* sanitize environment variables that can't be unicode encoded

* fix mypy",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1240,Matthew Peters,matt-peters@users.noreply.github.com,2019-01-15 15:25:27-08:00,51ac81420def4629391a81b9caa2695ad4b7c085,https://github.com/allenai/allennlp/commit/51ac81420def4629391a81b9caa2695ad4b7c085,"Add optional additional tokens to ELMo character indexer (#2364)

* Add optional additional tokens to ELMo character indexer

* fix mypy",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['indices == expected_indices'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1241,Andrew Moore,andrew.p.moore94@gmail.com,2019-01-15 23:41:48+00:00,aa8ed3b794a8db45862b4839c77e94a70d9c8fd1,https://github.com/allenai/allennlp/commit/aa8ed3b794a8db45862b4839c77e94a70d9c8fd1,Added StackedBiDirectional to list of encoders (#2339),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1242,Sai,sai-prasanna@users.noreply.github.com,2019-01-16 05:15:26+05:18,083f49ea03d22b78ae32f6852f927bbb16c49911,https://github.com/allenai/allennlp/commit/083f49ea03d22b78ae32f6852f927bbb16c49911,Bump up pytorch-pretrained-bert to v0.4.0 (#2349),2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1243,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-15 17:09:36-08:00,abc10ed95aabd7b41ab0baa4957178aec359cd9f,https://github.com/allenai/allennlp/commit/abc10ed95aabd7b41ab0baa4957178aec359cd9f,"Update create_a_configuration.md howto by removing old allennlp configure (#2330)

@joelgrus is there any way to access the old functionality of `allennlp configure`? or was it completely removed?

I've updated the `create_a_configuration` tutorial for the latter case, but happy to just edit run commands if the functionality is still around.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1244,Brendan Roof,brendanr@allenai.org,2019-01-15 17:25:06-08:00,be57ecc3ba4ece1a311f7787b59c046e841b222b,https://github.com/allenai/allennlp/commit/be57ecc3ba4ece1a311f7787b59c046e841b222b,"Add snippet for using `LanguageModelTokenEmbedder`. (#2359)

- Improves documentation for using transformer ELMo.
- A user requested an example of how to use transformer ELMo directly.
- https://github.com/allenai/allennlp/issues/2351",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1245,Joel Grus,joelgrus@gmail.com,2019-01-15 17:27:48-08:00,e08ade81ff6684869883ce3da66941b9d3a37503,https://github.com/allenai/allennlp/commit/e08ade81ff6684869883ce3da66941b9d3a37503,"trainer refactor (#2304)

* refactor

* work

* work

* wip

* address PR / CI feedback + more factoring

* pylint

* add toy multi-task trainer

* merge conflict for real

* abstract out early stopping into MetricTracker

* more refactoring

* move more functionality into tensorboard writer

* checkpointer

* change checkpointer interface

* try for backward compatibility

* remove some factoring

* address pr feedback, add gan example / test

* pylint

* fix docs

* fix whitespace

* add checkpointing to multitask trainer

* address PR feedback

* use rescale_gradients()

* fixes

* add base class from params + test

* fix pylint",25,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,0,0,0,0,0,0,0,0,0,0,0,0,21,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(os.path.join(self.TEST_DIR, ))', 'tracker.is_best_so_far()', 'tracker._best_so_far is not None  # pylint: disable=protected-access', 'new_tracker.is_best_so_far()', 'not new_tracker.is_best_so_far()', 'new_tracker.is_best_so_far()', 'not new_tracker.is_best_so_far()', 'new_tracker.is_best_so_far()', 'not new_tracker.is_best_so_far()', 'new_tracker.is_best_so_far()', 'new_tracker.should_stop_early()', 'not new_tracker.should_stop_early()', 'tracker.should_stop_early', 'tracker.should_stop_early', 'new_tracker.should_stop_early()', 'not new_tracker.should_stop_early()', 'new_tracker.should_stop_early()', 'not tracker.should_stop_early()', 'not tracker.should_stop_early()', 'embedding.weight.grad.is_sparse  # pylint: disable=no-member']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(val_metrics_per_epoch) == 1', 'isinstance(val_metrics_per_epoch[0], float)', 'val_metrics_per_epoch[0] != 0.', 'new_trainer._is_best_so_far(1, [])  # pylint: disable=protected-access', 'not new_trainer._is_best_so_far(.3, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'new_trainer._is_best_so_far(13.00, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'not new_trainer._is_best_so_far(.0013, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'new_trainer._is_best_so_far(1, [])  # pylint: disable=protected-access', 'not new_trainer._is_best_so_far(.3, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'new_trainer._is_best_so_far(.013, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'not new_trainer._is_best_so_far(13.00, [.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'new_trainer._should_stop_early([.5, .3, .2, .1, .4, .4])  # pylint: disable=protected-access', 'not new_trainer._should_stop_early([.3, .3, .3, .2, .5, .1])  # pylint: disable=protected-access', 'Trainer(self.model, self.optimizer,  # pylint: disable=protected-access', 'Trainer(self.model, self.optimizer,  # pylint: disable=protected-access', 'new_trainer._should_stop_early([.02, .3, .2, .1, .4, .4])  # pylint: disable=protected-access', 'not new_trainer._should_stop_early([.3, .3, .2, .1, .4, .5])  # pylint: disable=protected-access', 'new_trainer._should_stop_early([.1, .3, .2, .1, .4, .5])  # pylint: disable=protected-access', 'not trainer._should_stop_early(decreasing_history)  # pylint: disable=protected-access', 'not trainer._should_stop_early(increasing_history)  # pylint: disable=protected-access', 'is_sparse(embedding.weight.grad)']",[],[],[],[],[],[],[],[],[],[],[],[]
1246,Jiyuan Zheng,jiyuanz95@gmail.com,2019-01-16 23:36:31+08:00,9649f3a21827b4ef4bc40a670744ff631cdf0e58,https://github.com/allenai/allennlp/commit/9649f3a21827b4ef4bc40a670744ff631cdf0e58,"fix a typo (#2367)

change ""experimenation"" to ""experimentation""",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1247,Matthew Peters,matt-peters@users.noreply.github.com,2019-01-16 08:39:57-08:00,e2af6b44eedcecd8c60f2341903d60cdb5d9005f,https://github.com/allenai/allennlp/commit/e2af6b44eedcecd8c60f2341903d60cdb5d9005f,"Install package in dockerfile (#2305)

* Install package in dockerfile

* pip install editable at Michael's request",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1248,Kevin Lin,kl2806@columbia.edu,2019-01-16 11:05:38-08:00,e75b19b837d60b3bb0388a9d0ec0ca656ae892fe,https://github.com/allenai/allennlp/commit/e75b19b837d60b3bb0388a9d0ec0ca656ae892fe,Use f-string (#2370),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1249,Suchin,github@suchin.io,2019-01-16 12:21:20-08:00,e9287d4d48d2d980226a4acf70d03eedda67c548,https://github.com/allenai/allennlp/commit/e9287d4d48d2d980226a4acf70d03eedda67c548,"Bag of words token embedder (#2365)

* added bow token embedder and tests",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['embedder_output.shape[1] == 50'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1250,Brendan Roof,brendanr@allenai.org,2019-01-16 14:27:55-08:00,7da19bc84824aad2808bcec149b66eecf4a5568f,https://github.com/allenai/allennlp/commit/7da19bc84824aad2808bcec149b66eecf4a5568f,"Disable requires_grad for Transformer ELMo parser. (#2336)

- Makes constituency_parser_transformer_elmo.jsonnet and constituency_parser_elmo.jsonnet comparable by default.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1251,Vidur Joshi,vidurj@allenai.org,2019-01-16 17:02:04-08:00,fc91f3e6afc807eac58667271b888cec721d5072,https://github.com/allenai/allennlp/commit/fc91f3e6afc807eac58667271b888cec721d5072,"Sparse Gradient Clipping (#2312)

* not clamping sparse tensors

* removed trailing white space

* supporting sparse gradient clipping

* removed trailing white space

* ignore protected-access warning

* removed trailing whitespace",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1252,Matt Gardner,mattg@allenai.org,2019-01-16 17:14:22-08:00,ae63a2ae2d564eb59af09e96cb550c475ae1af4c,https://github.com/allenai/allennlp/commit/ae63a2ae2d564eb59af09e96cb550c475ae1af4c,"New WikiTables language (#2350)

* Working on moving WikiTables language to new API

* Logical form execution passes all of the original tests

* Got WikiTablesLanguage passing all tests

* Remove old executor / type declaration / world

* pylint, mypy, and docs

* Switch executor tests back to returning lists

* Address PR feedback",16,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,24,2,0,0,0,0,0,0,0,0,77,18,0,0,0,0,0,0,0,0,0,0,1,77,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],"[('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Logs', '() as log:'), ('Equal', '(log.output,'), ('Logs', '() as log:'), ('Equal', '(log.output,'), ('Logs', '() as log:'), ('Equal', '(log.output,'), ('Logs', '() as log:'), ('Equal', '(log.output,'), ('Raises', '(ExecutionError):'), ('Raises', '(ExecutionError):'), ('Raises', '(ParsingError):')]","['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['set(cell_list) == {}', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_value_list == []', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'count_result == 0', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'cell_list == []', 'cell_list == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'sum_value == 13197', 'sum_value == 13197', 'avg_value == 6598.5', 'avg_value == 6598.5', 'avg_value == 1141', 'Date(2013, 12, 31) > Date(2013, 12, 30)', 'Date(2013, 12, 31) == Date(2013, 12, -1)', 'Date(2013, -1, -1) >= Date(2013, 12, 31)', '(Date(2013, 12, -1) > Date(2013, 12, 31)) == False', '(Date(2013, 12, 31) > 2013) == False', '(Date(2013, 12, 31) >= 2013) == False', 'Date(2013, 12, 31) != 2013', '(Date(2018, 1, 1) >= Date(-1, 2, 1)) == False', '(Date(2018, 1, 1) < Date(-1, 2, 1)) == False', 'Date(-1, 2, 1) < Date(-1, 2, 3)', '(Date(-1, -1, 1) < Date(-1, -1, 3)) == False', '(Date(-1, -1, 1) >= Date(-1, -1, 3)) == False', '(Date(2018, -1, 1) < Date(2018, -1, 3)) == False', '(Date(2018, -1, 1) >= Date(2018, -1, 3)) == False', 'result == []', 'self.language.evaluate_logical_form(logical_form, [,', 'not self.language.evaluate_logical_form(logical_form, [,', 'set(productions.keys()) == {', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'not in table_context.column_types.values()', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'self.language.logical_form_to_action_sequence(logical_form) == expected_sequence', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {}', 'agenda == {,', 'agenda == {,', 'agenda == {,', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}']","['(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],"['set(cell_list) == {}', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_value_list == []', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'count_result == 0', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'sum_value == 13197', 'sum_value == 13197', 'avg_value == 6598.5', 'avg_value == 6598.5', 'avg_value == 1141', 'Date(2013, 12, 31) > Date(2013, 12, 30)', 'Date(2013, 12, 31) == Date(2013, 12, -1)', 'Date(2013, -1, -1) >= Date(2013, 12, 31)', '(Date(2013, 12, -1) > Date(2013, 12, 31)) == False', '(Date(2013, 12, 31) > 2013) == False', '(Date(2013, 12, 31) >= 2013) == False', 'Date(2013, 12, 31) != 2013', '(Date(2018, 1, 1) >= Date(-1, 2, 1)) == False', '(Date(2018, 1, 1) < Date(-1, 2, 1)) == False', 'Date(-1, 2, 1) < Date(-1, 2, 3)', '(Date(-1, -1, 1) < Date(-1, -1, 3)) == False', '(Date(-1, -1, 1) >= Date(-1, -1, 3)) == False', '(Date(2018, -1, 1) < Date(2018, -1, 3)) == False', '(Date(2018, -1, 1) >= Date(2018, -1, 3)) == False', 'result == []', 'self.executor.evaluate_logical_form(logical_form, [,', 'not self.executor.evaluate_logical_form(logical_form, [,', 'set(actual_right_sides) == set(expected_right_sides)', 'set(valid_actions.keys()) == {', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'set([str(type_) for type_ in world.get_basic_types()]) == {,', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'set([str(type_) for type_ in world.get_basic_types()]) == {,', 'not in table_context.column_types.values()', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'set([str(type_) for type_ in world.get_basic_types()]) == {}', 'str(expression) == f', 'self.world_with_usl_a_league.get_action_sequence(expression) == expected_sequence', 'logical_form == reconstructed_logical_form', 'str(expression) == f', 'str(expression) == \\', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[]
1253,Joel Grus,joelgrus@gmail.com,2019-01-17 09:20:55-08:00,385e66e8a9621eb16ada1f4031d81aea7601470e,https://github.com/allenai/allennlp/commit/385e66e8a9621eb16ada1f4031d81aea7601470e,"pieces for multitask learning (#2369)

* pieces for multitask learning

* mypy

* add docs

* fix docs

* dashes to underscores",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['first_three_keys == {}', 'next_three_keys == {}', 'len(buckets) == 3', 'len(instance_types) == 1', 'observed_instance_type_counts == actual_instance_type_counts']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1254,Suchin,github@suchin.io,2019-01-17 11:00:43-08:00,122a21a53ab19704e58a5a041177faf8f357ac5b,https://github.com/allenai/allennlp/commit/122a21a53ab19704e58a5a041177faf8f357ac5b,changed log-to-console flags (#2381),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1255,Matt Gardner,mattg@allenai.org,2019-01-17 11:59:35-08:00,e9b0acacb34e8bc80d40638cb5be25939890da93,https://github.com/allenai/allennlp/commit/e9b0acacb34e8bc80d40638cb5be25939890da93,"Make DomainLanguage handle executing action sequences directly, with side arguments (#2375)

* Make DomainLanguage handle executing action sequences directly, with side arguments

* mypy

* Address PR feedback",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.language.execute_action_sequence(action_sequence) == 4', 'self.language.execute_action_sequence(action_sequence) == 12', 'self.language.execute_action_sequence(action_sequence) == 1', 'self.language.execute_action_sequence(action_sequence) == 2', 'language.execute_action_sequence(action_sequence, state) == 4', 'language.execute_action_sequence(action_sequence, state) == 11']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1256,Suchin,github@suchin.io,2019-01-17 14:00:32-08:00,8eb2d75cb31808deed946cab581cb292e056b825,https://github.com/allenai/allennlp/commit/8eb2d75cb31808deed946cab581cb292e056b825,"Text classification JSON dataset reader (#2366)

* add text classification JSON dataset reader with tests",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,0,0,0,0,0,0,3,3,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 3', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 3', 'text == instance1[]', 'fields[]', 'text == instance2[]', 'fields[]', 'text == instance3[]', 'fields[]']",[],[],[],[],[],[],"['(, (True, False))', '(, (True, False))', '(, (True, False))']","['parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))']","['mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1257,Joel Grus,joelgrus@gmail.com,2019-01-17 15:39:04-08:00,4fe8fa0d3a3af90419b2ce0d90726cdfe1598c90,https://github.com/allenai/allennlp/commit/4fe8fa0d3a3af90419b2ce0d90726cdfe1598c90,"move model to cuda in tests, add comment (#2384)",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1258,Brendan Roof,brendanr@allenai.org,2019-01-17 17:08:03-08:00,7cc8ba04d780b4dd2e5b72d4ded564f69ff84f6e,https://github.com/allenai/allennlp/commit/7cc8ba04d780b4dd2e5b72d4ded564f69ff84f6e,"Rollback PR #2308 ""Check train/dev/test-file-path"" (#2386)

- This breaks the `MultiprocessDatasetReader` which relies on globs.
- Test to prevent regressing.
- The motivation behind PR #2308 is good, but we need to be a bit more sophisticated in how we perform the check. Perhaps `DatasetReader` should provide an optional `check_path` method that users can override?",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1259,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-01-17 23:25:29-05:00,2d29736b6982dac2677ae6ebded3168d39d0960b,https://github.com/allenai/allennlp/commit/2d29736b6982dac2677ae6ebded3168d39d0960b,"Add support for extending Embeddings/Embedders with Extended Vocabulary. (#2374)

* Rough attempt for Embedder/Embedding extension.

* fix some mistakes.

* add tests for token-embedder and text-field-embedder extension.

* fix vocab_namespace usage in embedding.py

* update names and change some comments.

* update embedding tests.

* fix some typos.

* add more tests.

* update some comments.

* fix minor pylint issue.

* Implement extend_vocab for TokenCharactersEncoder.

* minor simplification.

* Update help text for --extend-vocab in fine-tune command.

* Shift location of model tests appropriately.

* Allow root Embedding in model to be extendable.

* Incorporate PR comments in embedding.py.

* Fix annotations.

* Add appropriate docstrings and minor cleanup.

* Resolve pylint complains.

* shift disable pytlint protected-access to top of tests.

* Add a test to increase coverage.

* minor update in TokenEmbedder docstrings.

* Remove a blank line.

* Add a blank line before Returns block in Embedding docstring.",13,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tuple(original_weight.shape) == (24, 300)', 'tuple(extended_weight.shape) == (25, 300)', 'torch.all(original_weight == extended_weight[:24, :])', 'tuple(original_weight.shape) == (24, 300)', 'tuple(extended_weight.shape) == (25, 300)', 'torch.all(original_weight == extended_weight[:24, :])', 'old_embedder._token_embedders.keys() == new_embedder._token_embedders.keys()', 'tuple(text_embedder.token_embedder_words1.weight.shape) == (6, 2)', 'tuple(text_embedder.token_embedder_words2.weight.shape) == (6, 5)', 'tuple(text_embedder.token_embedder_words3.weight.shape) == (6, 3)', 'tuple(text_embedder.token_embedder_words1.weight.shape) == (9, 2)', 'tuple(text_embedder.token_embedder_words2.weight.shape) == (9, 5)', 'tuple(text_embedder.token_embedder_words3.weight.shape) == (9, 3)', 'torch.all(text_embedder.token_embedder_words1.weight[:6, :]', 'torch.all(text_embedder.token_embedder_words2.weight[:6, :]', 'torch.all(text_embedder.token_embedder_words3.weight[:6, :]', 'original_weight.shape[0] == 4', 'extended_weight.shape[0] == 5', 'torch.all(extended_weight[:4, :] == original_weight[:4, :])', 'original_weight.shape[0] == 4', 'extended_weight.shape[0] == 5', 'torch.all(extended_weight[:4, :] == original_weight[:4, :])', 'original_weight.shape[0] == 4', 'extended_weight.shape[0] == 5', 'torch.all(extended_weight[:4, :] == original_weight[:4, :])', 'tuple(original_weight.shape) == (6, 2)', 'tuple(extended_weight.shape) == (7, 2)', 'torch.all(original_weight == extended_weight[:6, :])']",['(Exception)'],[],[],[],[],[],[],[],[],[],[],[],['old_embedder._token_embedders.keys() == new_embedder._token_embedders.keys() #pylint: disable=protected-access'],['(RuntimeError)'],[],[],[],[],[],[],[],[],[],[],[]
1260,Joel Grus,joelgrus@gmail.com,2019-01-18 11:21:50-08:00,174f53956f53acac475fc3180e9eb91978f958bb,https://github.com/allenai/allennlp/commit/174f53956f53acac475fc3180e9eb91978f958bb,"enable pickling for vocabulary (#2391)

* enable pickling for vocabulary

* pylint",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['dict(unpickled._index_to_token) == dict(vocab._index_to_token)', 'dict(unpickled._token_to_index) == dict(vocab._token_to_index)', 'unpickled._non_padded_namespaces == vocab._non_padded_namespaces', 'unpickled._oov_token == vocab._oov_token', 'unpickled._padding_token == vocab._padding_token', 'unpickled._retained_counter == vocab._retained_counter']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1261,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-01-18 14:36:44-05:00,9719b5c71207e642276fb1209ea1a4c8467e0792,https://github.com/allenai/allennlp/commit/9719b5c71207e642276fb1209ea1a4c8467e0792,"Allow embedding extension to load from pre-trained embeddings file. (#2387)

* Rough attempt for Embedder/Embedding extension.

* fix some mistakes.

* add tests for token-embedder and text-field-embedder extension.

* fix vocab_namespace usage in embedding.py

* update names and change some comments.

* update embedding tests.

* fix some typos.

* add more tests.

* update some comments.

* fix minor pylint issue.

* Implement extend_vocab for TokenCharactersEncoder.

* minor simplification.

* Update help text for --extend-vocab in fine-tune command.

* Shift location of model tests appropriately.

* Allow root Embedding in model to be extendable.

* Incorporate PR comments in embedding.py.

* Fix annotations.

* Add appropriate docstrings and minor cleanup.

* Resolve pylint complains.

* shift disable pytlint protected-access to top of tests.

* Add a test to increase coverage.

* minor update in TokenEmbedder docstrings.

* Allow to pass pretrained_file in embedding extension (with tests).

* Remove a blank line.

* Add a blank line before Returns block in Embedding docstring.

* Fix pylint complains.

* Allow pretrained file to be passed in token_characters_encoder also.

* Fix pylint complains and update some comments.

* Test to ensure trained embeddings do not get overriden.

* PR feedback: update comments, fix annotation.",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.all(embedder.weight[2:, :] == torch.Tensor([[2.0, 3.3, 0.0], [1.1, 1.4, -3.0]]))', 'tuple(original_weight.size()) == (4, 3)  # 4 because of padding and OOV', 'tuple(extended_weight.size()) == (5, 3)', 'torch.all(original_weight[:4, :] == extended_weight[:4, :])', 'torch.all(extended_weight[4, :] == torch.Tensor([0.5, 0.3, -6.0]))']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1262,Michael Schmitz,michael@schmitztech.com,2019-01-18 11:38:01-08:00,d0a5a40a1c626a1a88464eeed54fb0b047750b98,https://github.com/allenai/allennlp/commit/d0a5a40a1c626a1a88464eeed54fb0b047750b98,"Remove unnecessary line (#2385)

Fixes https://github.com/allenai/allennlp/issues/2306",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1263,Brendan Roof,brendanr@allenai.org,2019-01-18 15:18:29-08:00,7525c610e6b77247222099b59f21a227f1c3545c,https://github.com/allenai/allennlp/commit/7525c610e6b77247222099b59f21a227f1c3545c,"Remove scattering for multi-GPU training. (#2200)

- Instead just pull off a batch for each GPU.
- Enables increasing the effective batch size for `bidirectional_language_model.jsonnet` by 2x giving a 1.5x speedup.",11,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['if(torch.cuda.device_count()'],[],[],[],[],"['skipif(torch.cuda.device_count() < 2,']","['mark.skipif(torch.cuda.device_count() < 2,']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1264,Matt Gardner,mattg@allenai.org,2019-01-18 16:29:20-08:00,11d8327890bf3665fe687b1284f280a2a3974931,https://github.com/allenai/allennlp/commit/11d8327890bf3665fe687b1284f280a2a3974931,"Fix typing for python 3.7 (#2393)

* Fix typing for python 3.7

* Fix mypy, check sys.version_info instead of using try/catch

* Better way of checking version",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1265,Santiago Castro,bryant@montevideo.com.uy,2019-01-19 15:41:59-05:00,a9b34750be45e061abefd47c2d0003889831cf74,https://github.com/allenai/allennlp/commit/a9b34750be45e061abefd47c2d0003889831cf74,"Fix docstring for PretrainedBertIndexer's pretrained_model param (#2399)

`pretrained_model` is not an optional param, as stated in `PretrainedBertIndexer` docs, so I removed the ""optional"" part from it.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1266,Alasdair Tran,alasdair.tran@gmail.com,2019-01-22 00:07:36+08:00,012e42ddad21bf2971c8b528b6bfc62dcc283c5f,https://github.com/allenai/allennlp/commit/012e42ddad21bf2971c8b528b6bfc62dcc283c5f,Ensure vocab is popped off params (#2409),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1267,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-21 10:27:41-08:00,3baec620ab8dc0b4c40140475dc086fa6bc14146,https://github.com/allenai/allennlp/commit/3baec620ab8dc0b4c40140475dc086fa6bc14146,Remove outdated reference to custom extensions (#2401),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1268,Patrick Sodr,psodre@gmail.com,2019-01-21 17:18:02-05:00,d6e3140ffa6629c8e45a75c7920dcd6cf0186902,https://github.com/allenai/allennlp/commit/d6e3140ffa6629c8e45a75c7920dcd6cf0186902,"Replace scripts with entry_points.console_scripts (#2232)

* Replace scripts with entry_points.console_scripts

  The recommended approach to create launch scripts is to use entry_points
  and console_scripts.

  xref: https://packaging.python.org/guides/distributing-packages-using-setuptools/#scripts

* Remove bin directory from Dockerfile, it is not needed

* Update references to bin/allennlp to just allennlp.

* Update argv in test.",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1269,Joel Grus,joelgrus@gmail.com,2019-01-21 15:43:29-08:00,55b9bd089edb7f97b6dba7c16dd1e7f358acb416,https://github.com/allenai/allennlp/commit/55b9bd089edb7f97b6dba7c16dd1e7f358acb416,"serialization in the tutorial (#2412)

* serialization in the tutorial

* add serialization to tutorial

* address PR feedback

* add disclaimer about programmatic generation",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1270,Karen Hambardzumyan,mail@mahnerak.com,2019-01-22 20:55:28+04:00,c1aace7e3e07ecb6d4e7f806b2157f29a71cfab9,https://github.com/allenai/allennlp/commit/c1aace7e3e07ecb6d4e7f806b2157f29a71cfab9,"Get rid of hardcoded Vocabulary class name. (#2418)

In case of inheriting Vocabulary, the method `from_params` calls the
same method of the registered class if `type` is given. If
`from_params` is not overridden (even if it is), the default
implementation calls hardcoded `Vocabulary.from_instances` and
`Vocabulary.from_files` which makes overriding these methods in
subclass unreachable.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1271,Mark Neumann,markn@allenai.org,2019-01-22 14:18:10-08:00,9b01d4ca98908847bc6a746ff0e2dc537a72c505,https://github.com/allenai/allennlp/commit/9b01d4ca98908847bc6a746ff0e2dc537a72c505,fix params duplicate bug (#2421),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['new_params.loading_from_archive', 'new_params.files_to_archive == {}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1272,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-01-22 21:38:49-05:00,cb9651a4c77c10cbd2d76f79b85c6453386dc229,https://github.com/allenai/allennlp/commit/cb9651a4c77c10cbd2d76f79b85c6453386dc229,"Add AUC metric. (#2358)

* Add AUC metric.

* add masking.

* fix whitespace.

* fix docs.

* Incorporate PR feedback.",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1273,Nelson Liu,nelson-liu@users.noreply.github.com,2019-01-23 06:56:31-08:00,b7d56ae01708258821ffd1a98e3ee0610b6851e9,https://github.com/allenai/allennlp/commit/b7d56ae01708258821ffd1a98e3ee0610b6851e9,"Fix typo when loading train state (#2425)

* Fix typo when loading train state

* Fix comment",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1274,Ethan Perez,ethanperez18@gmail.com,2019-01-23 13:44:22-05:00,585c19e4d5846e6fcb212cde17be7aaf10389390,https://github.com/allenai/allennlp/commit/585c19e4d5846e6fcb212cde17be7aaf10389390,"Fixing BERT mask size (#2429)

* Fixing BERT mask size

Input tokens are truncated to <512 tokens long to fit into BERT. When this happens, the mask associated with that sample appears to not also be truncated. This edit is a fix for that issue, which can cause size mismatch errors downstream when the mask is used.

* update comment",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1275,Matt Gardner,mattg@allenai.org,2019-01-23 12:12:54-08:00,8b07c42ab70876580b5aeb3846775987b5e31b5f,https://github.com/allenai/allennlp/commit/8b07c42ab70876580b5aeb3846775987b5e31b5f,"Improve error message for ""undocumented modules"" (#2427)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1276,Brendan Roof,brendanr@allenai.org,2019-01-23 15:49:27-08:00,90f39f91b8cd6c8a8c390c895d9d4ce743c96c95,https://github.com/allenai/allennlp/commit/90f39f91b8cd6c8a8c390c895d9d4ce743c96c95,"Mark Atis Parser tests as flaky. Fix pylint. (#2430)

- Tests appear to pull down a DB file from S3.
- Spurious network failures are common, so mark as flaky to ameliorate the problem.
- Alternative: Bring DB file into fixtures directory. However, as we're trying to keep the size of the library down, this probably isn't advisable.
- Also disables some `pylint` warnings that hit with `numpy==1.16.0`.",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1277,Yizhong Wang,eastonwyz@gmail.com,2019-01-23 16:35:35-08:00,b6cc9d39651273e8ec2a7e334908ffa9de5c2026,https://github.com/allenai/allennlp/commit/b6cc9d39651273e8ec2a7e334908ffa9de5c2026,"Optimizing the memory usage in `multi_head_self_attention` and `masked_softmax` (#2405)

* Optimizing the memory usage in `multi_head_self_attention` and `masked_softmax`.

Fixes #2185

* Fixes pylint error

* Fixes typo and change the attention dropout back to its original version.",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1278,Yizhong Wang,eastonwyz@gmail.com,2019-01-24 14:01:09-08:00,4465a6e4127363c0aa62846d0b5f63c5426f6f16,https://github.com/allenai/allennlp/commit/4465a6e4127363c0aa62846d0b5f63c5426f6f16,"Support exponential moving average in the default trainer. (#2406)

* Support exponential moving average in the default trainer.

* Fixes pylint and type checker errors.

* Add doc string for the `ExponentialMovingAverage` module

* Add doc string for the `ExponentialMovingAverage` module

* add moving averages

* add docs

* Fixes pylint and doc.

* address pr feedback",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['w_value != shadow_value', 'model.w.item() == shadow_value', 'model.w.item() == w_value', 'epoch == 1', 'tracker.is_best_so_far()', 'tracker._best_so_far is not None  # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1279,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-01-25 15:29:51-05:00,00c877b9b8737d547f845bac5d5c69a86d6177e7,https://github.com/allenai/allennlp/commit/00c877b9b8737d547f845bac5d5c69a86d6177e7,"Fix edgecase of potentially missing best-val-metrics in metrics.json on training recovery (#2352)

* Save and load best val metrics from training state.

* update trainer test for updated _restore_checkpoint.

* fix pylint, and minor fix.

* add tests.

* fix mypy issues.

* update test.

* fix a typo.

* Updated changes.

* Cleanup metric_tracker to track best_epoch directly.

* Shift appropriate logic in _restore_checkpoint.

* Update tests.

* Resolve mypy complains.

* Fix a typo from original refactor. Add a test.

* shift disable=protected-access to top of trainer_test.py

* Shift best_epoch and best_epoch_metrics out of _restore_checkpoint.",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,21,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('AlmostEqual', '(grad._values().norm(2.0).item(), 1.5, places=5)')]",[],[],[],[],[],[],[],[],[],[],"[('AlmostEqual', '(grad._values().norm(2.0).item(), 1.5, places=5) # pylint: disable=protected-access')]",[],[],[],[],[],[],[],[],[],"['tracker._best_so_far is not None', 'restore_trainer._batch_num_total == 2', 'isinstance(best_validation_metrics_epoch_1, dict)', 'in best_validation_metrics_epoch_1', 'best_epoch_1 == 0 and best_epoch_2 == 1', 'best_validation_metrics_epoch_2 != best_validation_metrics_epoch_1', 'isinstance(best_validation_metrics_epoch_1, dict)', 'in best_validation_metrics_epoch_1', 'best_epoch_1 == best_epoch_2 == 0', 'best_validation_metrics_epoch_2 == best_validation_metrics_epoch_1', 'in restored_metrics', 'in restored_metrics', 'in restored_metrics', 'in restored_metrics', 'training_metrics[]', 'training_metrics[] == 0', 'training_metrics[]', 'next_epoch == 3', 'best_epoch == 1', 'trainer._metric_tracker._best_so_far == 0.1', 'trainer._metric_tracker._epochs_with_no_improvement == 1']",[],[],[],[],[],[],[],[],[],[],[],[],"['tracker._best_so_far is not None  # pylint: disable=protected-access', 'restore_trainer._batch_num_total == 2  # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[]
1280,Wang Ran (),wrran@outlook.com,2019-01-28 03:28:37+08:00,dc901a6aa67a32024ded159f01391bf1c8a29394,https://github.com/allenai/allennlp/commit/dc901a6aa67a32024ded159f01391bf1c8a29394,"rename test case (#2441)

Before, in `allennlp/tests/modules/seq2seq_encoders/pass_through_encoder_test.py`:
```python
class TestStackedSelfAttention(AllenNlpTestCase)
    # ...
```

after:
```python
class TestPassThroughEncoder(AllenNlpTestCase):
    # ...
```",1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1281,Wang Ran (),wrran@outlook.com,2019-01-28 10:04:34+08:00,508cb73025d0550d98adc0e9b6255f75a1d907ad,https://github.com/allenai/allennlp/commit/508cb73025d0550d98adc0e9b6255f75a1d907ad,"Instantiate the class `Activation` properly when testing FeedForward. (#2443)

* `RELU` -> `Activation.by_name('relu')()`

* add some comment",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1282,Evan Pete Walsh,epwalsh10@gmail.com,2019-01-28 13:41:39-08:00,5ff923c5c94d2300983303196adc85f9e7877df0,https://github.com/allenai/allennlp/commit/5ff923c5c94d2300983303196adc85f9e7877df0,"Generalize LR scheduler (#2345)

* start base scheduler

* fixes

* reorg

* add LearningRateScheduler base

* update custom LR schedulers

* fixes and update tests

* reorg tests

* fixes

* fix trainer

* fix docs

* fix trainer test

* make wrappers private

* improve docstring

* add momentum schedulers

* fix formatting for docs

* revert PyTorch LR scheduler behavior",22,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,3,4,0,0,0,0,0,0,0,0,0,4,2,0,0,0,0,0,0,0,0,44,0,0,0,0,0,0,0,0,0,0,0,0,27,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(TypeError):'), ('Raises', '(ConfigurationError) as context:'), ('Raises', '(TypeError):')]","['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],"[('Raises', '(ConfigurationError) as context:'), ('True', '('), ('Raises', '(TypeError):'), ('Raises', '(TypeError):')]","['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['sched.t_initial == 5', 'sched.last_epoch == -1', 'optim.param_groups[0][] == 1.0', 'lrs[it] == lr, f', 'lrs[it] == lr, f', 'in str(context.exception)', 'optimizer.param_groups[0][] == 1.0', 'optimizer.param_groups[0][] == 1.0', 'optimizer.param_groups[0][] == 0.5', 'optimizer.param_groups[0][] == 0.5 ** 2', 'scheduler.freezing_current', 'not is_hat_shaped([0.0] * 10)', 'not is_hat_shaped([float(k) for k in range(10)])', 'not is_hat_shaped([float(10 - k) for k in range(10)])', 'is_hat_shaped([float(k) for k in range(10)] +', 'not is_hat_shaped([float(k) for k in range(10)] +', 'sched.num_epochs == 5', 'sched.num_steps_per_epoch == 10', 'sched.gradual_unfreezing is True', 'sched.freezing_current is True', 'len(optim.param_groups) == 3', 'not optim.param_groups[-1][]', 'optim.param_groups[-2][] == 1.0 / sched.ratio', 'optim.param_groups[-3][] == 0.5 / sched.ratio', 'lr == lr_check, f', 'max(first_layer_lrs[:num_actual_steps_per_epoch]) < 1e-8', 'min(first_layer_lrs[:num_actual_steps_per_epoch]) > -1e-8', 'is_hat_shaped(first_layer_lrs[num_actual_steps_per_epoch:])', 'is_hat_shaped(second_layer_lrs[:num_actual_steps_per_epoch])', 'is_hat_shaped(second_layer_lrs[num_actual_steps_per_epoch:])', 'is_hat_shaped(first_layer_lrs)', 'is_hat_shaped(second_layer_lrs)', 'scheduler.cool_down == 10', 'scheduler.warm_up == 10', 'scheduler.ratio == 10', 'scheduler.last_epoch == -1', 'optimizer.param_groups[0][] == self.base_momentum', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],']",[],[],[],[],[],[],[],[],[],[],[],[],"['sched.t_initial == 5', 'sched._initialized is True', 'optim.param_groups[0][] == 1.0', 'lrs[it] == lr', 'lrs[it] == lr', 'scheduler.lr_scheduler.freezing_current', 'not is_hat_shaped([0.0] * 10)', 'not is_hat_shaped([float(k) for k in range(10)])', 'not is_hat_shaped([float(10 - k) for k in range(10)])', 'is_hat_shaped([float(k) for k in range(10)] +', 'not is_hat_shaped([float(k) for k in range(10)] +', 'sched.num_epochs == 5', 'sched.num_steps_per_epoch == 10', 'sched.gradual_unfreezing is True', 'sched.freezing_current is True', 'len(optim.param_groups) == 3', 'not optim.param_groups[-1][]', 'optim.param_groups[-2][] == 1.0 / sched.ratio', 'optim.param_groups[-3][] == 0.5 / sched.ratio', 'lr == lr_check, f', 'max(first_layer_lrs[:num_actual_steps_per_epoch]) < 1e-8', 'min(first_layer_lrs[:num_actual_steps_per_epoch]) > -1e-8', 'is_hat_shaped(first_layer_lrs[num_actual_steps_per_epoch:])', 'is_hat_shaped(second_layer_lrs[:num_actual_steps_per_epoch])', 'is_hat_shaped(second_layer_lrs[num_actual_steps_per_epoch:])', 'is_hat_shaped(first_layer_lrs)', 'is_hat_shaped(second_layer_lrs)']",[],[],[],[],[],[],[],[],[],[],[],[]
1283,Wang Ran (),wrran@outlook.com,2019-01-29 09:57:55+08:00,5560466e46266568ade2f86179fe0049cf31a981,https://github.com/allenai/allennlp/commit/5560466e46266568ade2f86179fe0049cf31a981,"[Feature Enhanced]Add FeedforwardEncoder for Sequences (#2444)

* add feedforward_encoder

* add mask & make mypy happy

* add doc

* mask on the output instead of the input",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['encoder.get_input_dim() == feedforward.get_input_dim()', 'encoder.get_output_dim() == feedforward.get_output_dim()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1284,Dan Kondratyuk,Hyperparticle@users.noreply.github.com,2019-01-29 23:15:22+01:00,dddcbf243e9931a5ab0241435b39613117e20acf,https://github.com/allenai/allennlp/commit/dddcbf243e9931a5ab0241435b39613117e20acf,Cleanup global logging after training (#2458),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1285,Wang Ran (),wrran@outlook.com,2019-01-31 03:51:05+08:00,35f7f169eb2c4c0e66997b76529ac02800c35c3d,https://github.com/allenai/allennlp/commit/35f7f169eb2c4c0e66997b76529ac02800c35c3d,"Update `Running AllenNLP` in README.md (#2447)

Add subcommands: `configure`, `find-lr`:
```bash
$ allennlp
Run AllenNLP

optional arguments:
  -h, --help    show this help message and exit
  --version     show program's version number and exit

Commands:
  
    configure   Run the configuration wizard.
    train       Train a model
    evaluate    Evaluate the specified model + dataset
    predict     Use a trained model to make predictions.
    make-vocab  Create a vocabulary
    elmo        Create word vectors using a pretrained ELMo model.
    fine-tune   Continue training a model on a new dataset
    dry-run     Create a vocabulary, compute dataset statistics and other
                training utilities.
    test-install
                Run the unit tests.
    find-lr     Find a learning rate range.
```",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1286,Matt Gardner,mattg@allenai.org,2019-01-30 17:10:35-08:00,2b52492e8002a534e647495ff55d592589a7d930,https://github.com/allenai/allennlp/commit/2b52492e8002a534e647495ff55d592589a7d930,Fix path issue for certain cases when using --include-package (#2464),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1287,Wang Ran (),wrran@outlook.com,2019-02-01 01:34:03+08:00,a8e0f15fafa7331b475df07d5a261312215860e3,https://github.com/allenai/allennlp/commit/a8e0f15fafa7331b475df07d5a261312215860e3,"Make `mask` in `PassThroughEncoder` work (#2448)

The current `PassThroughEncoder` simply returns the input without taking into account the role of the parameter `mask`. I don't think this is a good idea for two reasons:
1. We should try our best to ensure that the same parameters of similar modules play the same role instead of ignoring it;
2. Using the parameter `mask` is more flexible. If we don't want to mask out any part, just pass in `None` (default value).

This PR is for it. What do you think?",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1288,Wang Ran (),wrran@outlook.com,2019-02-01 04:01:43+08:00,84eb4d1acc03bad89e2282306eb4ede8f1badec5,https://github.com/allenai/allennlp/commit/84eb4d1acc03bad89e2282306eb4ede8f1badec5,"More help info for `archive_surgery.py` (#2327)

* Fix bug in uniform_unit_scaling #2239 (#2273)

* Fix type annotation for .forward(...) in tutorial (#2122)

* Add a Contributions section to README.md (#2277)

* script for doing archive surgery (#2223)

* script for doing archive surgery

* simplify script

* Fix spelling in tutorial README (#2283)

* fix #2285 (#2286)

* Update the `find-lr` subcommand help text. (#2289)

* Update the elmo command help text.

* Update the find-lr subcommand help text.

* Add __repr__ to Vocabulary (#2293)

As it currently stands, the following is logged during training:

```
2019-01-06 10:46:21,832 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.model
s.language_model.LanguageModel'> from params {'bidirectional': False, 'contextualizer': {'bidirectional':
 False, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 200, 'num_layers': 2, 'type': 'lstm'}, 'dropout
': 0.5, 'text_field_embedder': {'token_embedders': {'tokens': {'embedding_dim': 200, 'type': 'embedding'}
}}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7ff7811665f8>}
```

Note that the `Vocabulary` does not provide any useful information, since it doesn't have `__repr__` defined. This provides a fix.

* Update the base image in the Dockerfiles. (#2298)

* Don't deprecate bidirectional-language-model name (#2297)

* bump version number to v0.8.1

* Bump version numbers to v0.8.2-unreleased

* Turn BidirectionalLM into a more-general LanguageModel class (#2264)

Fixes https://github.com/allenai/allennlp/issues/2255

This PR replaces the `BidirectionalLM` class with a more-general `LanguageModel` that can be used in either the unidirectional/forward setting or the bidirectional setting.

It also accordingly replaces the `BidirectionalLanguageModelTokenEmbedder` with a `LanguageModelTokenEmbedder`.

Also fixes bug in the experiment_unsampled.jsonnet config that was preventing a test from actually being unsampled.

TODO:

- [x] test the unidirectional case
- [x] properly deprecate `BidirectionalLM` and `BidirectionalLanguageModelTokenEmbedder` 
- [x] check docs for accuracy
- [x] fix user-facing training configs

* more help info

* typo fix

* add option '--inplace', '--force'

* clearer help text",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1289,Mei Jie,535370561@qq.com,2019-02-01 05:29:52+08:00,9a5ea1a280c78c0ce18480f2651ae36690bc57b8,https://github.com/allenai/allennlp/commit/9a5ea1a280c78c0ce18480f2651ae36690bc57b8,"Ten times faster than before in GPU get_best_span of bidaf (#2465)

* faster(GPU) get_best_span in bidaf

* reanme

* chang the way of mask: from multipilcation to addition

* Improve names and comments",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1290,Santiago Castro,bryant@montevideo.com.uy,2019-01-31 17:16:36-05:00,9a2f1982fc306ba132b900f12b78f50986fcc8f5,https://github.com/allenai/allennlp/commit/9a2f1982fc306ba132b900f12b78f50986fcc8f5,"Add support to kwargs in TimeDistributed (#2439)

* Add support to kwargs in TimeDistributed

* Add a TODO in the named arg and kwarg TD test

* Fix PR comments

* Remove unused import

* Fix a PR comment: Iterable -> List

* Add missing @overrides

* Add tests

* Add missing forward methods pylint warning suppression",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1291,Yizhong Wang,eastonwyz@gmail.com,2019-01-31 16:36:18-08:00,e4174868530ecaa7572aab3ced7008e4619c2247,https://github.com/allenai/allennlp/commit/e4174868530ecaa7572aab3ced7008e4619c2247,Fixes unnecessary parameter clone in moving average. (#2468),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1292,Yizhong Wang,eastonwyz@gmail.com,2019-01-31 22:05:11-08:00,08a8c5e56d8728c17eb96de3ae603ce6799a5b2f,https://github.com/allenai/allennlp/commit/08a8c5e56d8728c17eb96de3ae603ce6799a5b2f,"Add QaNet model (#2446)

* Add max length limit for passage and question in SQuAD reader.

* Add QaNet model.

* fixes the squad reader and adds doc.

* Move `get_best_span()` function out of bidaf.

* Update the docstring of QANet and BiDAF

* Move `ResidualWithLayerDropout` to a separate module file.

* Update the docstring and test cases for the length limits in squad reader.

* Keep the old `get_best_span` function in `bidaf.py`.

* Add docstring for `get_best_span` function.

* Separate test case for the `get_best_span` function.

* Fixes docs.

* Update the training configuration file.

* ignores pylint error.

* add docs for layer dropout.

* fixes docs.

* Remove the unsqueeze()",22,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances[0].fields[].tokens) == 10', 'len(instances[0].fields[].tokens) == 30', 'len(instances) == 3', 'len(instances[0].fields[].tokens) == 10', 'len(instances[0].fields[].tokens) == 30', 'len(instances) == 5', 'set(instance_x.fields[]) \\', 'metrics[] > 0', 'span_start >= 0', 'span_start <= span_end', 'span_end < self.instances[0].fields[].sequence_length()', 'isinstance(output_dict[][0], str)', 'result.shape == (2, 2)', 'result.shape == (2, 2)', 'result.shape == (2, 2)', 'result.shape == (2, 2)', 'isinstance(encoder, QaNetEncoder)', 'encoder.get_input_dim() == 16', 'encoder.get_output_dim() == 16', 'list(encoder(inputs).size()) == [2, 12, 16]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1293,Nelson Liu,nelson-liu@users.noreply.github.com,2019-02-02 17:02:53-08:00,6f5f56578364d1231b457253a42dcf709ee2e619,https://github.com/allenai/allennlp/commit/6f5f56578364d1231b457253a42dcf709ee2e619,Fix CORS error for react in config explorer (#2476),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1294,Wang Ran (),wrran@outlook.com,2019-02-05 03:00:00+08:00,e5a74abccb969efe33001e20b8c749780d8f657e,https://github.com/allenai/allennlp/commit/e5a74abccb969efe33001e20b8c749780d8f657e,"[Feature Enhanced] Support sentence pair in BERT (#2279)

* support sentence pair in BERT

* support sentence pair in BERT

* fix bug: `get_keys` in WordpieceIndexer

* make pylint happy

* add doc & more efficient implementation

* make pylint and mypy happy",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', 'indexed_tokens[] == [0,    0, 0,  0,  0,  0, 0,  1, 1,  1,  1,  1, 1]  #pylint: disable=bad-whitespace']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1295,Suchin,github@suchin.io,2019-02-04 19:23:38-05:00,234fb18fc253d8118308da31c9d3bfaa9e346861,https://github.com/allenai/allennlp/commit/234fb18fc253d8118308da31c9d3bfaa9e346861,"make bag_of_word_counts token embedder ignore padding and UNK tokens (#2432)

* added patch to ignore padding and UNK tokens",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ConfigurationError,')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1296,Michael Schmitz,michael@schmitztech.com,2019-02-05 10:49:42-08:00,dbd708519411a16715757ee8887dd54adb003b96,https://github.com/allenai/allennlp/commit/dbd708519411a16715757ee8887dd54adb003b96,WIP: Make warnings errors and filter library warnings from pytest (#2479),13,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ValueError, message=)']",[],[],[],[],[],[],[],[],[],[],[]
1297,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-02-05 15:42:04-05:00,23ea5908117c379b44ef04e94695d5f4371c26bd,https://github.com/allenai/allennlp/commit/23ea5908117c379b44ef04e94695d5f4371c26bd,"Add support for pretrained embedding extension in fine-tuning. (#2395)

* First attempt to allow pretrained embedding extension in fine-tune.

* Fix some typos, fix mypy and pylint.

* Revert changes in Train and Archival.

* Allow mapping to be explicitly passed in fine-tune, instead of getting it from  archive.

* Use model_path to pretrained-file path mapping.

* Remove unnessary code.

* Remove tests for unnecessary code.

* Correct typos.

* Fix minor mistakes.

* Fix pylint issues.

* Change error to warning in embedding extension.

* Add test to check mapping works.

* Remove test for the remove code.

* Fix mypy and pylint complains.

* Add more tests.

* Fix a typo.

* Make sure embedding extension is no-op when required.

* Use fixture in test.

* Update docstring and helper message.

* Fix file availability bug and cleanup.

* Update docstring.

* Minor cleanup.

* Add missing fixture file.

* Fix pylint issues.

* Incorporate PR feedback.

* Fix argument call.

* Update test.

* flatten logic

* fix none + check for 'extend_vocab' attribute

* remove unused import

* Fix condition typo.",14,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,0,0,0,0,0,0,0,0,0,0,12,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['original_weight.shape[0] + 1 == extended_weight.shape[0] == 25', 'torch.all(original_weight == extended_weight[:24, :])', 'torch.all(extended_weight[24, :] == extra_token_vector)', 'torch.all(extended_weight[24, :] != extra_token_vector)']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],"['tuple(text_embedder.token_embedder_words1.weight.shape) == (6, 2)', 'tuple(text_embedder.token_embedder_words2.weight.shape) == (6, 5)', 'tuple(text_embedder.token_embedder_words3.weight.shape) == (6, 3)', 'tuple(text_embedder.token_embedder_words1.weight.shape) == (9, 2)', 'tuple(text_embedder.token_embedder_words2.weight.shape) == (9, 5)', 'tuple(text_embedder.token_embedder_words3.weight.shape) == (9, 3)', 'torch.all(text_embedder.token_embedder_words1.weight[:6, :]', 'torch.all(text_embedder.token_embedder_words2.weight[:6, :]', 'torch.all(text_embedder.token_embedder_words3.weight[:6, :]', 'tuple(original_weight.shape) == (6, 2)', 'tuple(extended_weight.shape) == (7, 2)', 'torch.all(original_weight == extended_weight[:6, :])']",['(Exception)'],[],[],[],[],[],[],[],[],[],[],[]
1298,Matt Gardner,mattg@allenai.org,2019-02-05 18:04:22-08:00,2e7acb0592571798bd7a812062e4d14aa29bccb5,https://github.com/allenai/allennlp/commit/2e7acb0592571798bd7a812062e4d14aa29bccb5,"Mark QaNet test as flaky (#2481)

* Mark QaNet test as flaky

* Import the decorator :facepalm:",1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1299,Andrew Moore,andrew.p.moore94@gmail.com,2019-02-06 17:30:32+00:00,ce83cb41bfec1f9c8398f6c77db78bf5a5b3adb5,https://github.com/allenai/allennlp/commit/ce83cb41bfec1f9c8398f6c77db78bf5a5b3adb5,"Variational dropout in Augmented LSTM (#2344)

This pull requests fixes #2320 I have done point 2 on the list within the issue. Apart from the points made in the issue I have also added more detail to the doc strings in the [Stacked Bi-Directional LSTM](https://github.com/allenai/allennlp/blob/master/allennlp/modules/stacked_bidirectional_lstm.py) such as the corrected shape of the `final_states` returned form the forward pass and the correct shape required for the `initial_state` argument for the forward pass. I have also included the returned Type of the forward pass for the [Stacked Bi-Directional LSTM](https://github.com/allenai/allennlp/blob/master/allennlp/modules/stacked_bidirectional_lstm.py).

Screen shot of the changed doc strings for the augmented LSTM is below: Only change is the wording of the `recurrent_dropout_probability` argument within the constructor:
![augmented doc string](https://user-images.githubusercontent.com/13574854/51051958-34cf7180-15cd-11e9-9a48-7bbb039ae504.png)

Screen shots of the changed doc strings for the Stacked Bi-Directional LSTM are below: Changes are those stated above with regards to the forward pass and the wording of the `recurrent_dropout_probability` and `layer_dropout_probability` within the constructor as well as the text of the constructor:
![stacked constructor doc string](https://user-images.githubusercontent.com/13574854/51051945-2719ec00-15cd-11e9-9809-4a603a8e1a66.png)
![stacked forward doc string](https://user-images.githubusercontent.com/13574854/51051952-2d0fcd00-15cd-11e9-906b-7a1cf3ab7b25.png)",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,6,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not num_hidden_dims_zero_across_timesteps', 'not num_hidden_dims_zero_across_timesteps']","['(AssertionError)', '(AssertionError)', '(AssertionError)', '(AssertionError)', '(AssertionError)', '(AssertionError)']",[],[],[],[],[],[''],"['parametrize(,']","['mark.parametrize(,']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1300,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-02-07 12:18:17-05:00,19d0f592fa075f32e5eeb2c46e5d2a6571fc3d7b,https://github.com/allenai/allennlp/commit/19d0f592fa075f32e5eeb2c46e5d2a6571fc3d7b,"Add support to transfer submodules, and in different modes. (#2471)

* Add method to find module path from module in model.

* Add method to add prevent_regexes in initializer.

* Add TransferModule helper.

* Add examples and tests to use TransferModules class.

* Revert previous changes.

* Add from_pretrained_params and tests.

* Use from_pretrained_params for modules in which from_params was overrided.

* Fix typos, pylint and mypy issues.

* Fix some more typos.

* Handle some edge cases.

* Add docstring to from_pretrained_params.

* Fix docstring syntax.

* Add return type annotation to from_pretrained_params.

* Correct typos in docstring.

* Fix mistake.

* Add test to assure type consistency of loaded module.

* Shift back from_pretrained_params to FromParams and fix mypy.

* Revert unnecessary code changes.

* Revert more unnecessary changes.

* Simpify implementation according to pr feedback.

* Fix edgecase in the condition; add comment.

* Shift comment above the condition.

* Shift load module to archival.

* Remove comment.

* Change module_path argument to path.

* Fix mypy.

* Fix docstring.",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.all(trained_parameter == transfer_parameter)', 'torch.all(trained_parameter == transfer_parameter)', 'torch.all(trained_parameter != transfer_parameter)', 'not parameter.requires_grad', 'parameter.requires_grad']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1301,Evan Pete Walsh,epwalsh10@gmail.com,2019-02-11 08:12:33-08:00,b9a40036251f338d0cea1bf59a51155519e43807,https://github.com/allenai/allennlp/commit/b9a40036251f338d0cea1bf59a51155519e43807,"Add momentum schedulers to trainer (#2469)

* add momentum scheduler to trainer

* add test for momentum scheduler in trainer",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['epoch == 4', 'new_trainer._momentum_scheduler.last_epoch == 3']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1302,Joel Grus,joelgrus@gmail.com,2019-02-11 08:29:37-08:00,43dc4cb468a28a22dc6659fd49b37d5867f2b56f,https://github.com/allenai/allennlp/commit/43dc4cb468a28a22dc6659fd49b37d5867f2b56f,upgrade pytorch-pretrained-bert (#2495),2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1303,Matthew Peters,matt-peters@users.noreply.github.com,2019-02-11 11:33:59-08:00,89056f1e5063a3b10ab9230d8d6d0a43f5657fd0,https://github.com/allenai/allennlp/commit/89056f1e5063a3b10ab9230d8d6d0a43f5657fd0,"Less restrictive token characters indexer (#2494)

* Less restrictive token characters indexer

* fix tests

* add clarifying comment

* mypy

* add tests

* pylint",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(indexer._character_tokenizer, WordTokenizer) # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1304,Matt Gardner,mattg@allenai.org,2019-02-11 13:06:48-08:00,56c11e5343b672c029deb6f648258ced4fb60efd,https://github.com/allenai/allennlp/commit/56c11e5343b672c029deb6f648258ced4fb60efd,"Revert ""Less restrictive token characters indexer (#2494)"" (#2497)

This reverts commit 89056f1e5063a3b10ab9230d8d6d0a43f5657fd0.",2,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(indexer._character_tokenizer, WordTokenizer) # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[]
1305,Mark Neumann,markn@allenai.org,2019-02-11 14:33:51-08:00,47feb35e4db8a3022f93eff3810a85711d033a54,https://github.com/allenai/allennlp/commit/47feb35e4db8a3022f93eff3810a85711d033a54,remove notebooks and juptyer dependency (#2499),8,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,3,0,0,0,0,3,3,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.execute_notebook()', 'self.execute_notebook()', 'self.execute_notebook()']",[],[],"['(reason=)', '(reason=)', '(reason=)']",[],[],[],[],"['skip(reason=)', 'skip(reason=)', 'skip(reason=)']","['mark.skip(reason=)', 'mark.skip(reason=)', 'mark.skip(reason=)']",[],[],['import pytest']
1306,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-02-11 22:23:09-05:00,39413f220f2e682001299f8975a38f2221fac840,https://github.com/allenai/allennlp/commit/39413f220f2e682001299f8975a38f2221fac840,"Add necessary implicit embedding extension for transfer-modules api and vocab extension (#2431)

* Fix loading of fine-tuned + extended model.

* Refactor comments and remove unnecessary line.

* Assure transferred embedding modules are extended when required.

* Make embedding extension be no-op when extension isn't required.

* Don't allow embedding extension to assume ""tokens"" namespace.

* Test embedding extension to be no-op when appropriate.

* Add more tests.

* Fix a typo.

* update comments.

* Fix typos in test and add some comments.

* Remove duplicate condition.

* Change no namespace warning to info log level.

* Change no-op condition for extend_vocab call.

* Raise error if vocab or namespace is surely incorrect.

* Fix pylint.

* Update tests.

* Prevent incorrect vocab namespace assignment.

* Working tweaks in messages.

* Wording tweak in comment.",10,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['original_vocab.get_vocab_size() == 24', 'transferred_model.vocab.get_vocab_size() == 25', 'original_weight.shape[0] + 1 == extended_weight.shape[0] == 25', 'torch.all(original_weight == extended_weight[:24, :])', 'torch.all(embedder.weight == original_weight)', 'embedder.weight.shape[0] == 1', 'embedder.weight.shape[0] == 1']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1307,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-02-12 17:28:01-05:00,cf6eff221858518e777c1a7d069c9e832e92251a,https://github.com/allenai/allennlp/commit/cf6eff221858518e777c1a7d069c9e832e92251a,"Allow vocab+embedding extension in evaluate command. (#2501)

* Allow vocab+embedding extension in evaluate.

* Fix typo.

* make extend_embedder_vocab call conditional.

* Add test.

* Update evaluate command help.",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics_1 != metrics_2', 'metrics_2 != metrics_3']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1308,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-02-12 19:29:04-05:00,751d2e1ef7f017541fb74c8da730fb3d0e7537f0,https://github.com/allenai/allennlp/commit/751d2e1ef7f017541fb74c8da730fb3d0e7537f0,"Remove extended_vocab argument from extend_embedder_vocab API. (#2505)

* Remove extended_vocab argument from extend_embedder_vocab api.

* Fix test call.",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1309,Wang Ran (),wrran@outlook.com,2019-02-13 23:18:38+08:00,9f87aa56177ef3dc1b0c58ebb49d15584c500e29,https://github.com/allenai/allennlp/commit/9f87aa56177ef3dc1b0c58ebb49d15584c500e29,fix typo (#2508),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1310,saujasv,saujas1999@gmail.com,2019-02-18 09:12:41+05:18,2f2b481cff7bebd2f908f278cac7e2c7fba31df8,https://github.com/allenai/allennlp/commit/2f2b481cff7bebd2f908f278cac7e2c7fba31df8,Adding bag_of_embeddings as an alternate name for the boe encoder (Issue #2268) (#2521),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1311,Joel Grus,joelgrus@gmail.com,2019-02-18 08:39:34-08:00,3a5373fd56b9f373f54847f198c9c87efaef9470,https://github.com/allenai/allennlp/commit/3a5373fd56b9f373f54847f198c9c87efaef9470,upgrade huggingface pretrained bert (#2524),2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1312,Michael Schmitz,michael@schmitztech.com,2019-02-19 07:41:08-08:00,4bac9b55c8b947678ce32833cf36c3c3133b596c,https://github.com/allenai/allennlp/commit/4bac9b55c8b947678ce32833cf36c3c3133b596c,bump version number to v0.8.2,3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1313,Michael Schmitz,michael@schmitztech.com,2019-02-19 08:14:55-08:00,0205c26f3db7ef44d7ee70fa9ebdf5a7f6b43baf,https://github.com/allenai/allennlp/commit/0205c26f3db7ef44d7ee70fa9ebdf5a7f6b43baf,Bump version numbers to v0.8.3-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1314,Matt Gardner,mattg@allenai.org,2019-02-20 11:35:09-08:00,fefc439035df87e3d2484eb2f53ca921c4c2e2fe,https://github.com/allenai/allennlp/commit/fefc439035df87e3d2484eb2f53ca921c4c2e2fe,"Restore tensorboard epoch metrics to pre-refactoring behavior (#2532)

* Make ""epoch_metrics"" prefix consistent

* Restore pre-refactor metric behavior",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1315,Mark Neumann,markn@allenai.org,2019-02-21 15:18:18-08:00,6d8da97312bfbde05a41558668ff63d92a9928e9,https://github.com/allenai/allennlp/commit/6d8da97312bfbde05a41558668ff63d92a9928e9,make archival take an optional output path (#2510),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['archive'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1316,Brendan Roof,brendanr@allenai.org,2019-02-25 17:43:15-08:00,540ebac72c430aebcc595bd9909306de0181556e,https://github.com/allenai/allennlp/commit/540ebac72c430aebcc595bd9909306de0181556e,"Propose a deprecation policy. (#2424)

- Examples of when backward compatibility is likely to be an issue.
- Suggestions for ensuring compatibility.
- Mechanics for deprecating.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1317,Brendan Roof,brendanr@allenai.org,2019-02-26 11:53:31-08:00,321cf9150774c71fe14531f32c11b6d4dcf7a2bd,https://github.com/allenai/allennlp/commit/321cf9150774c71fe14531f32c11b6d4dcf7a2bd,"Clarify `data_parallel` implementation. (#2488)

- It appears we're unnecessarily replicating the model to the source device, but this is not the case.
- Silence some deprecation warnings that were missed previously.",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1318,Matt Gardner,mattg@allenai.org,2019-02-27 17:34:59-08:00,64a8e130bb5c497b8eba1b35fb65286e60777267,https://github.com/allenai/allennlp/commit/64a8e130bb5c497b8eba1b35fb65286e60777267,Scope DeprecationWarning errors to just allennlp-internal stuff (#2549),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1319,Kyle Lo,kylel@allenai.org,2019-02-28 15:35:02-08:00,3d5560fa79858ea1ff0cb62d28d63c6f886f32c7,https://github.com/allenai/allennlp/commit/3d5560fa79858ea1ff0cb62d28d63c6f886f32c7,missing `=overrides` argument when instantiate Params despite a second time (#2553),1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1320,Matt Gardner,mattg@allenai.org,2019-03-01 14:33:26-08:00,4d5eadee16aab2c972e022cdcf3aa7cc13d119c3,https://github.com/allenai/allennlp/commit/4d5eadee16aab2c972e022cdcf3aa7cc13d119c3,"Add official DROP evaluation script (#2559)

* Added (initial version of) the DROP evaluation script

* Updated eval script

* Docs

* pylint, mypy",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['_normalize_answer()', '_normalize_answer()', '_normalize_answer()', '_normalize_answer()', '_normalize_answer(', '_normalize_answer(', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (0.0, 1.0)', 'get_metrics([]) == (0.0, 1.0)', 'get_metrics([]) == (0.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (0.0, 0.67)', 'get_metrics([]) == (0.0, 0.67)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (0.0, 0.0)', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics([]) == (0.0, 0.0)', 'get_metrics([]) == (0.0, 0.0)', 'get_metrics([]) == (0.0, 0.0)', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics([],', 'get_metrics([],', 'get_metrics([],', 'get_metrics([],']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1321,Matt Gardner,mattg@allenai.org,2019-03-01 17:14:09-08:00,bbb67e9f5f2e804dc5f093f1f6e30ef3bbd96030,https://github.com/allenai/allennlp/commit/bbb67e9f5f2e804dc5f093f1f6e30ef3bbd96030,"Add dataset reader for DROP (#2556)

* Add dataset reader for DROP

* Add missing dependency

* Fix pylint, mypy and docs

* Add some more tests

* Address PR feedback

* mypy again",8,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 19', 'set(instance.fields.keys()) == {', '[t.text for t in instance[]', '[t.text for t in instance[]', '[t.text for t in instance[]', '[f.sequence_index for f in instance[]] == [', '[t.text for t in instance[]] == [', 'len(instance[]) == 1', 'instance[][0] == (46, 47)', 'len(instance[]) == 1', 'instance[][0] == (5, 6)', 'len(instance[]) == 1', 'instance[][0].labels == [0,] * 22', 'len(instance[]) == 1', 'instance[][0].label == -1', 'set(instance[].metadata.keys()) == {', 'len(instances) == 19', 'set(instance.fields.keys()) == {', '[t.text for t in instance[]', '[t.text for t in instance[]', '[t.text for t in instance[]', 'len(instance[]) == question_length + passage_length + 1', 'len(instance[]) == 1', 'instance[][0] == (question_length + 1 + 46,', 'set(instance[].metadata.keys()) == {', 'len(instances) == 19', 'set(instance.fields.keys()) == {', '[t.text for t in instance[]', '[t.text for t in instance[]', '[t.text for t in instance[]', 'instance[] == 46', 'instance[] == 47', 'set(instance[].metadata.keys()) == {', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1322,Evan Pete Walsh,epwalsh10@gmail.com,2019-03-01 20:30:34-08:00,97f3578b58686f7af0194558e72f826193708a86,https://github.com/allenai/allennlp/commit/97f3578b58686f7af0194558e72f826193708a86,add initializer to copynet (#2558),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1323,Matt Gardner,mattg@allenai.org,2019-03-02 12:45:45-08:00,c54fcc62936392cff23a7174a0309165c749df90,https://github.com/allenai/allennlp/commit/c54fcc62936392cff23a7174a0309165c749df90,"Add NAQANet model for DROP (#2560)

* Added NAQANet

* Docs

* Fix imports

* mypy, minor cleanup

* mypy and pylint

* Added docs

* More doc fixes

* Minor cleanup

* pylint...

* Address PR comments

* More pylint...

* Mark NAQANet test as flaky",10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['[t.text for t in instance[]] == ['],[],[],[],[],[],[],[],[],[],[],[],[]
1324,Matt Gardner,mattg@allenai.org,2019-03-02 14:16:31-08:00,31af01e0db7ac401b6c4923d5badd7de2691d6a2,https://github.com/allenai/allennlp/commit/31af01e0db7ac401b6c4923d5badd7de2691d6a2,Add missing requirement to setup.py (#2564),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1325,Brendan Roof,brendanr@allenai.org,2019-03-04 12:07:25-08:00,d0f7170b45fc670f715155235fd1f7d9f21ec69b,https://github.com/allenai/allennlp/commit/d0f7170b45fc670f715155235fd1f7d9f21ec69b,"Make `load_archive` operate on serialization directories. (#2554)

- Fixes https://github.com/allenai/allennlp/issues/1052.
- Files like ELMo weight files aren't added to the serialization dir, but are added to the archive with `add_file_to_archive`.
- This results in misleading errors when using `load_archive` as it will attempt to load a serialization dir.
- Solution: Retain original paths when we're loading from a directory.
- Drive by fix for overrides not overriding.",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['keys == keys2', 'torch.equal(model.state_dict()[key], model2.state_dict()[key])', 'vocab._token_to_index == vocab2._token_to_index  # pylint: disable=protected-access', 'vocab._index_to_token == vocab2._index_to_token  # pylint: disable=protected-access', 'params2.as_dict() == params_copy', 'params.get() == original_train_data_path']",[],[],[],[],[],[],[],[],[],[],[],[],"['keys == keys2', 'torch.equal(model.state_dict()[key], model2.state_dict()[key])', 'vocab._token_to_index == vocab2._token_to_index  # pylint: disable=protected-access', 'vocab._index_to_token == vocab2._index_to_token  # pylint: disable=protected-access']",[],[],[],[],[],[],[],[],[],[],[],[]
1326,Matt Gardner,mattg@allenai.org,2019-03-07 09:36:14-08:00,cdbac6dbe473365656dd5db05839235eec518dd2,https://github.com/allenai/allennlp/commit/cdbac6dbe473365656dd5db05839235eec518dd2,"Fix min padding length in pretrained NER predictors (#2541)

* Fix min padding length in NER predictors

* Fix dumb mistake",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1327,razor-mu,47815172+razor-mu@users.noreply.github.com,2019-03-08 04:54:33+08:00,32defc3b60e97ae171d779482cc4023fecd01bfa,https://github.com/allenai/allennlp/commit/32defc3b60e97ae171d779482cc4023fecd01bfa,"fix a bug in augmented_lstm.py (#2534)

 fix the bug of tensor.data in argumented_lstm.py
Fixes #2530",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1328,Brendan Roof,brendanr@allenai.org,2019-03-07 13:24:50-08:00,41174daa5580f9ab4582222fac14f0b3963d33ae,https://github.com/allenai/allennlp/commit/41174daa5580f9ab4582222fac14f0b3963d33ae,"Fix unit test to work with GPUs. (#2574)

- The error the test matches against is different depending on whether you have GPUs available.
- Simply make the match more general.",1,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError, match=)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1329,Brendan Roof,brendanr@allenai.org,2019-03-08 02:14:15-08:00,b0ea7ab6be2787495fa52efd0f603659197c7d76,https://github.com/allenai/allennlp/commit/b0ea7ab6be2787495fa52efd0f603659197c7d76,"Make tutorial use GPU if available. (#2570)

- For https://github.com/allenai/allennlp/issues/2555.
- Add a test for the tutorial.",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1330,mikerossgithub,mikenon@gmail.com,2019-03-08 13:44:56-08:00,6ea273efb80b2b1703a2dad1f00ab6d39adcc84d,https://github.com/allenai/allennlp/commit/6ea273efb80b2b1703a2dad1f00ab6d39adcc84d,"Allow checkpointer to be initialized from params (#2491)

* Allow passing checkpointer as argument to trainer. Also adds some checkpointer unittests

Added unit test for registration

Added unit test comments

Added checkpointer unit test for configuration error

* Added checkpointer unit test comments",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['models == training == target', 'models == training == target', 'sub_inst.__class__ == CheckpointerSubclass', 'sub_inst.x == 1 and sub_inst.y == 3']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1331,Joel Grus,joelgrus@gmail.com,2019-03-08 14:59:03-08:00,9437b614dbc518b3b532bbaa201446dc454fc6e2,https://github.com/allenai/allennlp/commit/9437b614dbc518b3b532bbaa201446dc454fc6e2,disable tutorial test (#2580),1,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['()'],[],[],[],[],['skip()'],['mark.skip()'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1332,Valthor Halldorsson,vlthrh@gmail.com,2019-03-12 00:29:58+01:00,0f7bcf5261b7bb1e7231e172f88cb18210ea51fd,https://github.com/allenai/allennlp/commit/0f7bcf5261b7bb1e7231e172f88cb18210ea51fd,"Add support for overriding list elements (#2585)

* add support for overriding list elements

* fix formatting issues",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['params[', 'params.files_to_archive == {']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1333,Joel Grus,joelgrus@gmail.com,2019-03-12 14:55:48-07:00,1adb3e8aae1b1d6c90de27ff1bf7e0c1e9e621ee,https://github.com/allenai/allennlp/commit/1adb3e8aae1b1d6c90de27ff1bf7e0c1e9e621ee,"Interactive beam search (#2513)

* add interactive beam search to wikitables predictor

* clean up test

* move interactive beam search into predictor

* mypy + pylint + sphinx

* wip

* final cleanup

* revert

* fix mypy

* address pr feedback

* address pr feedback

* pylint

* fix coments

* model must have parameters

* address pr feedback",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['best_action_sequence', 'best_action_sequence[:2] != initial_tokens', 'best_action_sequence[:2] == initial_tokens', 'any(token == initial_token for _, token in choices)', 'len(beam_snapshots) == 1', '0 in beam_snapshots', 'all(len(sequence) == idx + 1 for _, sequence in beam)', 'any(sequence[-1] == action for _, sequence in beam)', 'len(best_states) == 1', 'best_states[0][0].action_history[0] == [-2, -1, 0, 1, 3, 4]', 'best_states[0][1].action_history[0] == [-2, -1, 0, 1, 2, 4]', 'best_states[0][2].action_history[0] == [-2, -1, 0, 1, 3, 5, 7]', 'len(best_states) == 1', 'len(best_states[0]) == 3', 'best_states[0][0].action_history[0] == [-2, -1, 0, 1, 3, 4]', 'best_states[0][1].action_history[0] == [-2, -1, 0, 1, 2, 4]', 'best_states[0][2].action_history[0] == [-2, -1, 0, 1, 2, 3, 4]', 'len(beam_snapshots) == 1', 'beam_snapshots0 is not None', 'all(len(sequence) == i + 1 for _, sequence in beam)', 'any(sequence[-1] == best_action_sequence[i] for _, sequence in beam)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1334,Andreas Madsack,andreas@madflex.de,2019-03-13 15:44:13+01:00,18312a0c44461ace561f1dab7cb2e3e6b822849f,https://github.com/allenai/allennlp/commit/18312a0c44461ace561f1dab7cb2e3e6b822849f,"Seq2seq dataset reader improvements (#2599)

* use Python core csv module.

* add delimiter parameter to seq2seq datareader

* add test for ConfigurationError in Seq2SeqDatasetReader

* add test that ensures quoting with/without '""' works the same

* some changes to satisfy pylint",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,1,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', 'len(instances) == 1', '[t.text for t in fields[]', '[t.text for t in fields[]']",['(ConfigurationError)'],[],[],[],[],[],"['', '']","['parametrize(, (', 'parametrize(, (']","['mark.parametrize(, (', 'mark.parametrize(, (']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1335,Michael Schmitz,michael@schmitztech.com,2019-03-13 12:42:51-07:00,3e0fcf0b5ac2160ae3ac999d4df38dfc4faeb32b,https://github.com/allenai/allennlp/commit/3e0fcf0b5ac2160ae3ac999d4df38dfc4faeb32b,Update README.md (#2601),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1336,Joel Grus,joelgrus@gmail.com,2019-03-13 13:48:48-07:00,b61d511d78552d7854bba1317eaeb2a74ec685ec,https://github.com/allenai/allennlp/commit/b61d511d78552d7854bba1317eaeb2a74ec685ec,"context manager that allows predictor to capture model internals (#2581)

* model internals

* undo formatting change

* more undo formatting

* work

* mypy + docs",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['internals is not None', 'len(internals) == 25', ']', 'len(linear_50_1[]) == 17', 'all(len(a) == 1 for a in linear_50_1[])', 'not module._forward_hooks']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1337,Marcin Flis,marcin.flis@protonmail.com,2019-03-14 17:36:06+01:00,c163b638d30ec6924067a4735718d4f61da03d99,https://github.com/allenai/allennlp/commit/c163b638d30ec6924067a4735718d4f61da03d99,"Fixed memory error in `make_vocab` on big dataset. (#2606)

Used generator instead of reading all instances to memory before
passing to Vocabulary class(as in train loop).",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1338,Haonan Li,haonanl5@student.unimelb.edu.au,2019-03-15 04:02:30+11:00,55458f51e63a4e7d9e18db2710bbef3789586672,https://github.com/allenai/allennlp/commit/55458f51e63a4e7d9e18db2710bbef3789586672,fix bugs in naqanet (#2604),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1339,Michael Schmitz,michael@schmitztech.com,2019-03-14 11:16:22-07:00,79936e5e0319275f5cd7598fc58d6b3768823817,https://github.com/allenai/allennlp/commit/79936e5e0319275f5cd7598fc58d6b3768823817,"Re-use .allennlp when running Docker commands (#2593)

* Add cache to Docker command in README.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1340,Evan Pete Walsh,epwalsh10@gmail.com,2019-03-14 12:40:40-07:00,720d306bbb562f754e4f4fe89ff1521cb1d17d32,https://github.com/allenai/allennlp/commit/720d306bbb562f754e4f4fe89ff1521cb1d17d32,"Handle edge cases in beam search (#2557)

Addresses the edge case brought up in #2486 (fixes #2486) as well as another. This actually turned out to be a little more nuanced...

I first thought the issue brought up was caused by `start_predictions` being the `end_index`, but it actually occurs in general with a beam size of 1 when the first predictions that the step function produces are the `end_index`, regardless of what `start_predictions` are, i.e. at this line: 

`start_class_log_probabilities, state = step(start_predictions, start_state)`

The other edge case is similar, and occurs when the beam size is smaller than the number of valid (non-zero probability) transitions that the step function produces. For example, this could happen in a semantic parsing task where a masked log softmax is used to create predicted log probs for valid next actions. Though this doesn't cause the beam search to crash per se, I thought it would still be good to warn the user in these cases since some of the predicted sequences may be improbable.",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(predictions.size()) == [2, 1, 1]', 'list(log_probs.size()) == [2, 1]', '(predictions == self.end_index).all()', '(log_probs == 0).all()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1341,Matt Gardner,mattg@allenai.org,2019-03-14 16:54:33-07:00,9e3f4052bc5f25bdc39008fc606e55612df87481,https://github.com/allenai/allennlp/commit/9e3f4052bc5f25bdc39008fc606e55612df87481,"Only log the keys in the ""extras"" dictionary when instantiating objects from_params (#2608)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1342,Joel Grus,joelgrus@gmail.com,2019-03-14 17:42:53-07:00,0542c5a6be82461e8be569125ab6f43c65f55c39,https://github.com/allenai/allennlp/commit/0542c5a6be82461e8be569125ab6f43c65f55c39,"make spacy word splitter return allennlp Tokens (now NamedTuples) by default (#2607)

* unspacify

* add underscores

* fix tag_indexer tests

* change sanitize logic",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens', 'all(isinstance(token, Token) for token in tokens)', 'tokens', 'all(isinstance(token, spacy.tokens.Token) for token in tokens)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1343,phiradet,phiradet@gmail.com,2019-03-16 00:35:30+09:00,0fffb9b017f04dfbd3849c479987ad7f2addbbdd,https://github.com/allenai/allennlp/commit/0fffb9b017f04dfbd3849c479987ad7f2addbbdd,Allow the transition from M to M in the BMES constraint type (#2611),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1344,Joel Grus,joelgrus@gmail.com,2019-03-15 11:16:26-07:00,ff9084568c388a4290ccb66aefddda9fda78cbe4,https://github.com/allenai/allennlp/commit/ff9084568c388a4290ccb66aefddda9fda78cbe4,"change pins to bounds (#2490)

* change pins to bounds

* Update requirements.txt

* Update setup.py

* Update requirements.txt

* improve type annotation

* pylint is an eternal mystery",3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1345,Robert L. Logan IV,rloganiv@gmail.com,2019-03-18 08:32:17-07:00,ca998b267311c4897617853d83345143f6e27dad,https://github.com/allenai/allennlp/commit/ca998b267311c4897617853d83345143f6e27dad,"Feature Request: Add a `dtype` parameter to `ArrayField` (#2609)

* Allow dtype to be specified for ArrayField

* ArrayField now has an additional (optional) parameter: dtype

* To maintain backwards compatibility, the default remains: float32

* Changed argument order for backwards compatibility",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['returned_tensor1.dtype == torch.int64', 'returned_tensor2.dtype == torch.uint8', 'padded_tensor.dtype == torch.uint8', 'empty_field.dtype == array_field2.dtype']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1346,Robert L. Logan IV,rloganiv@gmail.com,2019-03-18 09:06:04-07:00,3cdb7e21c42aa5b3938cbd405cdc0f34f3178e9f,https://github.com/allenai/allennlp/commit/3cdb7e21c42aa5b3938cbd405cdc0f34f3178e9f,"Ensure contiguous initial state tensors in `_EncoderBase(stateful=True)` (#2451)

This PR fixes the following bug:

**Describe the bug** If subsequent batches of inputs containing a zero-length sequence are passed to a stateful encoder (e.g. a child of `_EncoderBase` with the `stateful` parameter set to `True`) then the following error is raised:
```
RuntimeError: rnn: hx is not contiguous
```

**To Reproduce**
```python
import torch

from allennlp.modules.seq2seq_encoders import PytorchSeq2SeqWrapper


lstm = torch.nn.LSTM(input_size=2,
                     hidden_size=2,
                     num_layers=3,
                     dropout=0.1,
                     batch_first=True)
encoder = PytorchSeq2SeqWrapper(lstm, stateful=True)
encoder = encoder.cuda(0)

inputs = torch.randn(4, 4, 2).cuda(0)
mask = torch.ones(4, 4).cuda(0)
mask[2, :] = 0

encoder(inputs, mask)
encoder(inputs, mask)
```",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not initial_states[0].is_contiguous() and not initial_states[1].is_contiguous()', 'initial_states[0].size() == torch.Size([6, 5, 7])', 'initial_states[1].size() == torch.Size([6, 5, 7])']",[],[],"['if(not torch.cuda.is_available(), reason=)']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)']","['mark.skipif(not torch.cuda.is_available(), reason=)']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1347,David Wadden,dwadden@cs.washington.edu,2019-03-18 09:34:06-07:00,f19c0ee2a57b731442c14c5014099ab1e5f8f401,https://github.com/allenai/allennlp/commit/f19c0ee2a57b731442c14c5014099ab1e5f8f401,"Enable Pruner class to keep different number of items for different entries in minibatch. (#2511)

This is a somewhat special case. There are occasionally situations where entries in a minibatch need to be, e.g., ordered sentences from the same document. Coreference resolution is an example. In AllenNLP, an entire document is considered as a single entry, but for very long documents (or on low-memory machines) it might be necessary to split up the document into minibatches during training.
In this situation, smart batching can't be used, and entries in the same minibatch may have widely varying lengths. Keeping the same number of span candidates for each entry may not be desirable.
This PR does the same thing as before if an integer is passed to `num_items_to_keep`. If a tensor is passed instead, it keeps the desired number of items for each minibatch entry.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1348,Santiago Castro,bryant@montevideo.com.uy,2019-03-18 12:48:28-04:00,fe80f9fb25b60c1296505b9189febf6e593afd8d,https://github.com/allenai/allennlp/commit/fe80f9fb25b60c1296505b9189febf6e593afd8d,"Fix 'cuda_device' docstring in Trainer.__init__ (#2613)

* Fix 'cuda_device' docstring in Trainer.__init__

* Fix a PR comment",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1349,Wang Ran (),wrran@outlook.com,2019-03-19 01:00:24+08:00,43b384d4d1c296f85cf3a99a382691fc21f08289,https://github.com/allenai/allennlp/commit/43b384d4d1c296f85cf3a99a382691fc21f08289,"Move some scripts to `allennlp/allennlp/tools` (#2584)

* Fix bug in uniform_unit_scaling #2239 (#2273)

* Fix type annotation for .forward(...) in tutorial (#2122)

* Add a Contributions section to README.md (#2277)

* script for doing archive surgery (#2223)

* script for doing archive surgery

* simplify script

* Fix spelling in tutorial README (#2283)

* fix #2285 (#2286)

* Update the `find-lr` subcommand help text. (#2289)

* Update the elmo command help text.

* Update the find-lr subcommand help text.

* Add __repr__ to Vocabulary (#2293)

As it currently stands, the following is logged during training:

```
2019-01-06 10:46:21,832 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.model
s.language_model.LanguageModel'> from params {'bidirectional': False, 'contextualizer': {'bidirectional':
 False, 'dropout': 0.5, 'hidden_size': 200, 'input_size': 200, 'num_layers': 2, 'type': 'lstm'}, 'dropout
': 0.5, 'text_field_embedder': {'token_embedders': {'tokens': {'embedding_dim': 200, 'type': 'embedding'}
}}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7ff7811665f8>}
```

Note that the `Vocabulary` does not provide any useful information, since it doesn't have `__repr__` defined. This provides a fix.

* Update the base image in the Dockerfiles. (#2298)

* Don't deprecate bidirectional-language-model name (#2297)

* bump version number to v0.8.1

* Bump version numbers to v0.8.2-unreleased

* Turn BidirectionalLM into a more-general LanguageModel class (#2264)

Fixes https://github.com/allenai/allennlp/issues/2255

This PR replaces the `BidirectionalLM` class with a more-general `LanguageModel` that can be used in either the unidirectional/forward setting or the bidirectional setting.

It also accordingly replaces the `BidirectionalLanguageModelTokenEmbedder` with a `LanguageModelTokenEmbedder`.

Also fixes bug in the experiment_unsampled.jsonnet config that was preventing a test from actually being unsampled.

TODO:

- [x] test the unidirectional case
- [x] properly deprecate `BidirectionalLM` and `BidirectionalLanguageModelTokenEmbedder` 
- [x] check docs for accuracy
- [x] fix user-facing training configs

* move some utilities from allennlp/scripts to allennlp/allennlp/tools

* make pylint happy

* add modules to API doc",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1350,Suchin,github@suchin.io,2019-03-18 12:26:25-07:00,01065364502450cb12ee9da844b73ae05deeb5a9,https://github.com/allenai/allennlp/commit/01065364502450cb12ee9da844b73ae05deeb5a9,"Add text classification model (#2591)

* added basic text classification model",9,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1351,Nelson Liu,nelson-liu@users.noreply.github.com,2019-03-18 12:50:10-07:00,9e72ee03041e1c690ba289612308f12357b2fee8,https://github.com/allenai/allennlp/commit/9e72ee03041e1c690ba289612308f12357b2fee8,"Fix TextClassificationJsonReader handling of unlabeled instances (#2621)

* Fix docstring to accurately reflect input expectations

* Fix TextClassificationJson reader handling of unlabeled data",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1352,Brendan Roof,brendanr@allenai.org,2019-03-18 14:24:43-07:00,f8b10a94d74d32f2ba0ff792f75a7335ab0c2651,https://github.com/allenai/allennlp/commit/f8b10a94d74d32f2ba0ff792f75a7335ab0c2651,"Add a no-op trainer. (#2610)

- Simply loads a model, creates the vocab and serializes without any training.
- Intended to be used principally for untrained baselines like majority class.",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model.forward(torch.tensor([1, 2, 3]))[] == torch.tensor(98) # pylint: disable=not-callable', 'model.vocab.get_vocab_size() == 9', 'metrics == {}', 'os.path.exists(serialization_dir / )', 'os.path.exists(serialization_dir / )']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1353,Dheeru Dua,dheeru_dua@hotmail.com,2019-03-18 16:09:11-07:00,e3038a3f55eef218b936a22cc16ce412bf929f09,https://github.com/allenai/allennlp/commit/e3038a3f55eef218b936a22cc16ce412bf929f09,"bug fixes in drop evaluation and more test cases (#2594)

* bug fixes in drop evaluation and adding more tests

* fixing comment

* resolved review comments and added failure test for answer

* fixing the style error",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['evaluate_json(annotation, prediction) == (1.0, 1.0)', 'evaluate_json(annotation, prediction) == (1.0, 1.0)', 'evaluate_json(annotation, prediction) == (1.0, 1.0)', 'evaluate_json(annotation, prediction) == (1.0, 1.0)', 'evaluate_json(annotation, prediction) == (0.0, 0.5)', 'evaluate_json(annotation, prediction) == (0.0, 0.0)', 'evaluate_json(annotation, prediction) == (0.0, 0.0)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1354,Sai,sai-prasanna@users.noreply.github.com,2019-03-19 23:01:49+05:18,1b07b481007a52c76531fb4295120448493e6a41,https://github.com/allenai/allennlp/commit/1b07b481007a52c76531fb4295120448493e6a41,"Bump up spacy version pin to 2.1 (#2626)

* Bump up spacy version pin to 2.1

* Fix failing tests after spacy 2.1 upgrade

* Update expected tree result in sniff test.

* Update comment for spacy sentence boundary detection.",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['result['],[],[],[],[],[],[],[],[],[],[],[],[],['result['],[],[],[],[],[],[],[],[],[],[],[],[]
1355,Matt Gardner,mattg@allenai.org,2019-03-19 16:12:48-07:00,0bbd359f0840637675a4e6cb9f593871390bb87b,https://github.com/allenai/allennlp/commit/0bbd359f0840637675a4e6cb9f593871390bb87b,"Add workaround for missing linking in spacy 2.1, remove install_requirements.sh (#2632)

* Trying to fix requirements

* Fix spacy 2.1 linking bug

* Add reference to github in comment",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1356,Matt Gardner,mattg@allenai.org,2019-03-20 16:06:27-07:00,1357c7e8ee36cd9e81fcb0ae44d65e1fc5b0ffe7,https://github.com/allenai/allennlp/commit/1357c7e8ee36cd9e81fcb0ae44d65e1fc5b0ffe7,"Remove reference to install_requirements.sh from the README (#2633)

* Remove reference to install_requirements.sh from the README

* Simplify instructions for installing from source",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1357,Andreas Madsack,andreas@madflex.de,2019-03-22 04:50:13+01:00,c06e904588503768331a580d8766bf4a47f83574,https://github.com/allenai/allennlp/commit/c06e904588503768331a580d8766bf4a47f83574,"add option ""-k"" to limit tests in test-install command (#2635)

* add option ""-k"" to limit tests in test-install command

* remove ""not notebooks_test"" argument

* explicit is better than a comment

* Remove last reference to notebook tests

* Simplify nesting",1,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1358,Joel Grus,joelgrus@gmail.com,2019-03-22 15:47:58-07:00,12626ac4ad8b290d1826d2f194b7e80e582a2d82,https://github.com/allenai/allennlp/commit/12626ac4ad8b290d1826d2f194b7e80e582a2d82,fix sampled softmax tests (#2061),1,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['eval_loss > train_loss', '(num_words, num_samples) == (10000, 10)', 'abs(pct_error) < 0.001']",[],[],[],[],[],[],[],[],[],[],[],[],['abs(pct_error) < 0.02'],[],[],['()'],[],[],[],[],['skip()'],['mark.skip()'],[],[],['import pytest']
1359,Maksym Del,max.del.edu@gmail.com,2019-03-25 04:18:43+02:00,3c889cae12095c979b7085195201b24dba63c4bc,https://github.com/allenai/allennlp/commit/3c889cae12095c979b7085195201b24dba63c4bc,Update outdated doc (#2641),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1360,Dan Kondratyuk,Hyperparticle@users.noreply.github.com,2019-03-26 00:31:01+01:00,a4a43066a1752c866f039506068fdb7e59477f41,https://github.com/allenai/allennlp/commit/a4a43066a1752c866f039506068fdb7e59477f41,"Checkpointer should check in case user deleted a serialized model (#2531)

If the user deletes an old checkpoint file, the checkpointer will crash when it also tries to delete it. This fix should prevent that.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1361,Vidur Joshi,vidurj@allenai.org,2019-03-25 18:50:23-07:00,305bd35cf2c15fe537ca42cf2321a7280e48d68c,https://github.com/allenai/allennlp/commit/305bd35cf2c15fe537ca42cf2321a7280e48d68c,"final_state_tuple is a Tuple (#2645)

Fixes #2503. The `final_state_tuple` in the `StackedAlternatingLstm` was a generator instead of a tuple.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tuple(output.size()) == (2, 5)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1362,Mark Neumann,markn@allenai.org,2019-03-26 09:15:02-07:00,e79b713d46f56c308b017101de99880cfbfdbcb9,https://github.com/allenai/allennlp/commit/e79b713d46f56c308b017101de99880cfbfdbcb9,"add dependency parser config (#2639)

fixes #2445",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1363,Joel Grus,joelgrus@gmail.com,2019-03-26 14:05:57-07:00,37a078afd6615cf63e6af2ece97038628aaafba4,https://github.com/allenai/allennlp/commit/37a078afd6615cf63e6af2ece97038628aaafba4,"make things backward compatible with spacy 2.0 (#2644)

* make things backward compatible with spacy 2.0

* disable more tests",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,3,3,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['if(spacy.__version__ < )', 'if(spacy.__version__ < )', 'if(spacy.__version__ < )']",[],[],[],[],"['skipif(spacy.__version__ < )', 'skipif(spacy.__version__ < )', 'skipif(spacy.__version__ < )']","['mark.skipif(spacy.__version__ < )', 'mark.skipif(spacy.__version__ < )', 'mark.skipif(spacy.__version__ < )']",[],[],"['import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
1364,Matt Gardner,mattg@allenai.org,2019-03-26 16:43:22-07:00,fab4b15eafe125b5be843107938386de9ad9e498,https://github.com/allenai/allennlp/commit/fab4b15eafe125b5be843107938386de9ad9e498,"Fix quarel explanations (#2648)

* Fix a bug due to a change in the behavior of lisp_to_nested_expression

* Add regression test that fails on master",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['len(explanation) == 4'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1365,Michael Schmitz,michael@schmitztech.com,2019-03-27 09:00:24-07:00,263d3401a3986b0bebb51033c55d6132b5d321d2,https://github.com/allenai/allennlp/commit/263d3401a3986b0bebb51033c55d6132b5d321d2,Upgrade Dockerfile to stretch. (#2647),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1366,Ben Shaver,benpshaver@gmail.com,2019-03-27 21:09:33-04:00,6e1ee2e1b7d958a93e2444b2a5293ae094fe6d41,https://github.com/allenai/allennlp/commit/6e1ee2e1b7d958a93e2444b2a5293ae094fe6d41,"config_allennlp.py uses open(file_path) where file_path is a URL (#2654)

Running the tutorial from the command line will cause a `FileNotFoundError`, so I added `cached_path`.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1367,Vidur Joshi,vidurj@allenai.org,2019-03-28 10:41:26-07:00,e138d6cb81cbc6d4c7fa82dcf973d4f46f030fab,https://github.com/allenai/allennlp/commit/e138d6cb81cbc6d4c7fa82dcf973d4f46f030fab,"TextCat Reader skip_label_indexing Fix (#2653)

Fixes #2651.",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,1,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'str(exec_info.value) == ']",['(ValueError)'],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1368,Nuno-Mota,nunonetomota@gmail.com,2019-03-28 21:08:55+01:00,2bf0779f5bca2dba1dc8e11376033739f3dcdf52,https://github.com/allenai/allennlp/commit/2bf0779f5bca2dba1dc8e11376033739f3dcdf52,"Fixed ELMO command's lack of encoding specification when reading from (#2614)

Fixes #2518 
Running the ""allennlp elmo"" command might produce sequences of length different than the original intended one. The issue lies without not being able to specify an encoding type with which to read the input file, which will have the argparse.FileType('r') reader interpret some unicode characters as 0 length white spaces.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1369,Matt Gardner,mattg@allenai.org,2019-03-28 14:22:39-07:00,e1d70bb7b2e6ca1c8961a1789f99a46ebf039187,https://github.com/allenai/allennlp/commit/e1d70bb7b2e6ca1c8961a1789f99a46ebf039187,Add missing paren (#2661),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1370,Brendan Roof,brendanr@allenai.org,2019-03-28 16:31:29-07:00,a80aac7ec4352cf4dce5b3785cb6b9ba41193a98,https://github.com/allenai/allennlp/commit/a80aac7ec4352cf4dce5b3785cb6b9ba41193a98,"Move register to typical location. (#2662)

- Fixes https://github.com/allenai/allennlp/issues/2462.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1371,Santiago Castro,bryant@montevideo.com.uy,2019-03-29 13:59:47-04:00,0abefe2566c843af063dd0e4608002321cc4aa28,https://github.com/allenai/allennlp/commit/0abefe2566c843af063dd0e4608002321cc4aa28,"Fix docstrings after inspection (#2655)

* Fix docstrings after inspection

* Fix PR comments",24,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1372,Brendan Roof,brendanr@allenai.org,2019-03-29 13:31:40-07:00,baef95371052bebc871b67781ba0e8fda88e04be,https://github.com/allenai/allennlp/commit/baef95371052bebc871b67781ba0e8fda88e04be,bump version number to v0.8.3,3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1373,Brendan Roof,brendanr@allenai.org,2019-03-29 13:47:25-07:00,72de856ad74668f28322a4c6b8194ed0e9289eac,https://github.com/allenai/allennlp/commit/72de856ad74668f28322a4c6b8194ed0e9289eac,Bump version numbers to v0.8.4-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1374,Mark Neumann,markn@allenai.org,2019-03-29 16:20:31-07:00,efdc9f3c0e758e6905a119f4c5ea48c9668e7423,https://github.com/allenai/allennlp/commit/efdc9f3c0e758e6905a119f4c5ea48c9668e7423,"unpin msgpack, pin spacy to > 2.0.18 (#2671)

fixes #2516",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1375,Brendan Roof,brendanr@allenai.org,2019-03-29 17:10:34-07:00,0f4175034f5d79f9415e47d915603cbba6af01a6,https://github.com/allenai/allennlp/commit/0f4175034f5d79f9415e47d915603cbba6af01a6,Catch some references to old library versions. (#2672),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1376,Harsh Rangwani,harsh.rangwani.cse15@itbhu.ac.in,2019-04-02 12:17:22+05:18,1bca7f60a701c8cf37fc9724143f5648cb2c438b,https://github.com/allenai/allennlp/commit/1bca7f60a701c8cf37fc9724143f5648cb2c438b,Correct The Pearson Correlation Formula In Docs (#2683),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1377,Joel Grus,joelgrus@gmail.com,2019-04-02 11:33:43-07:00,53a46ab7227a7f4293030c06a1ad18d010e87d74,https://github.com/allenai/allennlp/commit/53a46ab7227a7f4293030c06a1ad18d010e87d74,"call parse_cuda_device inside check_for_gpu (#2646)

* move things around to avoid circular imports

* move log_pytorch_version back to checks

* cleanup",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1378,Nelson Liu,nelson-liu@users.noreply.github.com,2019-04-04 15:58:06-07:00,e5adfd734ba6ce5e18d4fab6d2432b77e71c3fea,https://github.com/allenai/allennlp/commit/e5adfd734ba6ce5e18d4fab6d2432b77e71c3fea,"Ignore 2 root node types in PTB parsing reader (#2675)

Some variants of the PTB dataset use `TOP` as the root node, rather than `VROOT`. This lets the dataset reader handle both.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1379,Dheeru Dua,dheeru_dua@hotmail.com,2019-04-05 20:56:28-07:00,73bc049b01545c48043791e96fbb450648bd7543,https://github.com/allenai/allennlp/commit/73bc049b01545c48043791e96fbb450648bd7543,"Adding NAQANET training config and fixing test format in evaluation (#2695)

* bug fixes in drop evaluation and adding more tests

* fixing comment

* resolved review comments and added failure test for answer

* fixing the style error

* adding naqanet config and fixing drop test format

* fixing config failure",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1380,Santiago Castro,bryant@montevideo.com.uy,2019-04-08 12:54:56-04:00,a9d957b7e81a1aefb66187642d2dcd9a122cba21,https://github.com/allenai/allennlp/commit/a9d957b7e81a1aefb66187642d2dcd9a122cba21,"Update pylint to 1.9.4 (#2698)

* Fix ignored linted messages in domain_language.py

* Simplify scripts/verify.py

* Update pylint to 1.9.4

* Move a supression up",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1381,Kevin Lin,kl2806@columbia.edu,2019-04-08 10:37:10-07:00,482948317a9228f6136e7d591e10334ae91ebcf1,https://github.com/allenai/allennlp/commit/482948317a9228f6136e7d591e10334ae91ebcf1,Fix tagger tutorial (#2705),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1382,Santiago Castro,bryant@montevideo.com.uy,2019-04-08 15:59:40-04:00,79e2cf7b677f84daefaf63acc2a8e3833782de23,https://github.com/allenai/allennlp/commit/79e2cf7b677f84daefaf63acc2a8e3833782de23,Fix ArrayField.to_tensor's dtype when it's a scalar (#2676),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['returned_tensor.dtype == torch.float32'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1383,Santiago Castro,bryant@montevideo.com.uy,2019-04-11 11:54:52-04:00,08d66bf2d3cdfd0f1aa7df8b0e9a8f7f6c52eb9c,https://github.com/allenai/allennlp/commit/08d66bf2d3cdfd0f1aa7df8b0e9a8f7f6c52eb9c,Fix typo in output parameter name in docstring (#2708),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1384,Santiago Castro,bryant@montevideo.com.uy,2019-04-12 11:37:46-04:00,74634e34145cb6b54ec16c4cc404eba5deed63d5,https://github.com/allenai/allennlp/commit/74634e34145cb6b54ec16c4cc404eba5deed63d5,Add missing docstring for Embedding.pretrained_file (#2710),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1385,Seth Hendrickson,sethah@users.noreply.github.com,2019-04-14 21:38:44-07:00,58f386c5a95ea7a771776cad702c3931d7df0acc,https://github.com/allenai/allennlp/commit/58f386c5a95ea7a771776cad702c3931d7df0acc,clarify that seq2vecencoder is required for basic classifier (#2712),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1386,ananda seelan,ananda.seelan@gmail.com,2019-04-16 18:20:49+00:00,7d34ca3b8f723eca603b3a012e9c17da809dc6d2,https://github.com/allenai/allennlp/commit/7d34ca3b8f723eca603b3a012e9c17da809dc6d2,"Fix to include day count in training duration for metrics.json  (#2718)

* Added default predictor for bimpm model

* Fix #2717: Add day count in training duration

This fixes Issue [@2717](https://github.com/allenai/allennlp/issues/2717) to include day count in `training_duration` key in metrics.

* Modify elapsed time format to use `timedelta`

`time.strftime` does not account for number of days more than
31. Changing it to `datetime.timedelta` and using its `str`
representation for printing epoch duration as well as training
duration.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1387,Franklin Bradfield,fbradfield1@gmail.com,2019-04-20 10:13:21-04:00,deae1db203efa9400b1d8b479b4faca3876a907a,https://github.com/allenai/allennlp/commit/deae1db203efa9400b1d8b479b4faca3876a907a,"Add coref_resolved method to CorefPredictor (#2296)

* Add coref_resolved method to CorefPredictor

  * Resolves coreferences by producing a document that has had
    its coreferences substituted with their main mentions

  * Ex:
      Personal
      ========
      ""Charlie wants to buy a game, so he can play it with friends.""
        -->
      ""Charlie wants to buy a game, so Charlie can play a game
       with friends.""

      Possessive
      ==========
      ""Stocks also got a boost after China took steps to encourage
       bank lending and stimulate the country's flagging economy.""
       -->
      ""Stocks also got a boost after China took steps to encourage
       bank lending and stimulate China's flagging economy.""

* Remove redudant Doc import",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(result, str)', 'text == inputs[i]', 'output == expected_outputs[i]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1388,Santiago Castro,bryant@montevideo.com.uy,2019-04-21 23:40:48-04:00,4c98095ba8940d24f9cf915e9db9eef530ac36a6,https://github.com/allenai/allennlp/commit/4c98095ba8940d24f9cf915e9db9eef530ac36a6,Fix example in RegularizerApplicator.from_params docstring (#2733),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1389,Kevin Lin,kl2806@columbia.edu,2019-04-22 15:33:43-07:00,4422d53d68374de5c0129f679fa1d43f18b8f42d,https://github.com/allenai/allennlp/commit/4422d53d68374de5c0129f679fa1d43f18b8f42d,"QaNetEncoder Multi-GPU (#2692)

* Replace List with ModuleList

* Remove List import

* Rebase

* Remove List import

* Add test

* Pylint",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['if(torch.cuda.device_count()'],[],[],[],[],"['skipif(torch.cuda.device_count() < 2,']","['mark.skipif(torch.cuda.device_count() < 2,']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1390,Sam Gehman,sam.gehman@gmail.com,2019-04-22 17:59:18-07:00,e2d153f89c40e331a2bb072866f12f6d482ecf72,https://github.com/allenai/allennlp/commit/e2d153f89c40e331a2bb072866f12f6d482ecf72,"Add perplexity metric to LanguageModel (#2548)

- Add Perplexity metric
- Call Perplexity metric with `average_loss` from `LanguageModel`
- Add Perplexity docs",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1391,Wang Ran (),wrran@outlook.com,2019-04-23 09:23:08+08:00,9dec020281ee9521e7f1ffd696bcbb102c399703,https://github.com/allenai/allennlp/commit/9dec020281ee9521e7f1ffd696bcbb102c399703,"[Feature Enhanced] Generalize F1-measure to FBeta-measure (#2275)

Inspired by [`precision_recall_fscore_support`](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/classification.py#L1095) in `sklearn`, I generalize F1-measure to FBeta-measure.",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ConfigurationError, FBetaMeasure,'), ('Raises', '(ConfigurationError, FBetaMeasure,'), ('Raises', '(RuntimeError, fbeta.get_metric)')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['f1_measure._true_negatives == 3.0', 'isinstance(precision, float)', 'isinstance(recall, float)', 'isinstance(f1, float)', 'isinstance(precisions, List)', 'isinstance(recalls, List)', 'isinstance(fscores, List)', 'isinstance(precisions, float)', 'isinstance(recalls, float)', 'isinstance(fscores, float)']",[],[],[],[],[],[],[],[],[],[],[],[],['f1_measure._true_negatives == 3.'],[],[],[],[],[],[],[],[],[],[],[],[]
1392,Matt Gardner,mattg@allenai.org,2019-04-23 10:26:36-07:00,00e95b8b00b3edcb3df6f8338dd4440f3c39c698,https://github.com/allenai/allennlp/commit/00e95b8b00b3edcb3df6f8338dd4440f3c39c698,"Added NAQANet to pretrained.py and DEFAULT_PREDICTORS (#2731)

* Added NAQANet to pretrained.py and DEFAULT_PREDICTORS

* Trivial change to trigger CI",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1393,Nelson Liu,nelson-liu@users.noreply.github.com,2019-04-23 11:17:11-07:00,57956e789b8568bbb618436d2d52f9bbfac65a36,https://github.com/allenai/allennlp/commit/57956e789b8568bbb618436d2d52f9bbfac65a36,"Enable span-level F1 metric in SimpleTagger (#2735)

* Enable span-level F1 metric in SimpleTagger

* Fix missing import

* Don't track self.calculate_span_f1

* Add comment to explain redundant calculate_span_f1 argument

* Fix case where span f1 is not calculated

* Clean up span f1 logic",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1394,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2019-04-23 14:44:32-04:00,016ea34e9a27348372c208c44a967df4d912a799,https://github.com/allenai/allennlp/commit/016ea34e9a27348372c208c44a967df4d912a799,Fixing typo in ElmoTokenEmbedder documentation (#2741),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1395,Matt Gardner,mattg@allenai.org,2019-04-23 13:14:44-07:00,7e2e592df5e3928924bde38af1bcba32df97554e,https://github.com/allenai/allennlp/commit/7e2e592df5e3928924bde38af1bcba32df97554e,"Allow FromParams to construct Union types (#2734)

* Allow FromParams to construct Union types

* Add test for Joel's failure case, make it pass

* Clean up comment

* pylint (again, hopefully correctly this time...)",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['a.a == 3', 'a.a == [3, 4, 5]', 'isinstance(b.b, A)', 'b.b.a == 3', 'isinstance(b.b, list)', 'b.b[0].a == 3', 'b.b[1].a == [4, 5]', 'isinstance(c.c, dict)', 'c.c[].a == 3', 'c.c[].a == [4, 5]', 'len(feedforward._activations) == 2', '[isinstance(a, torch.nn.ReLU) for a in feedforward._activations]', 'len(feedforward._linear_layers) == 2', '[l.weight.size(-1) == 3 for l in feedforward._linear_layers]', 'len(feedforward._activations) == 3', 'isinstance(feedforward._activations[0], torch.nn.ReLU)', 'isinstance(feedforward._activations[1], torch.nn.ReLU)', 'not isinstance(feedforward._activations[2], torch.nn.ReLU)', 'len(feedforward._linear_layers) == 3', 'feedforward._linear_layers[0].weight.size(0) == 3', 'feedforward._linear_layers[1].weight.size(0) == 4', 'feedforward._linear_layers[2].weight.size(0) == 5', 'len(feedforward._dropout) == 3', '[d.p == 0.2 for d in feedforward._dropout]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1396,Nelson Liu,nelson-liu@users.noreply.github.com,2019-04-23 13:58:45-07:00,75f7992cc870e999ceefccb6449e97b42228567a,https://github.com/allenai/allennlp/commit/75f7992cc870e999ceefccb6449e97b42228567a,Document interaction between UNK token and max_vocab_size (#2740),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1397,Matt Gardner,mattg@allenai.org,2019-04-23 18:54:59-07:00,b90722188a1ff670f5b1cb8a8f2bdb57c42efe1b,https://github.com/allenai/allennlp/commit/b90722188a1ff670f5b1cb8a8f2bdb57c42efe1b,"Add caching functionality to the base DatasetReader class (#2726)

* Add caching functionality to the base DatasetReader class

* Switched to using commandline arguments

* pylint and mypy

* pylint, mypy, cleanup

* more mypy

* Saving the parameter file in the cache directory

* Simplify code using Joel's suggestions

* Fix failing tests

* mypy, pylint

* Clean up cache setup, use pathlib

* get rid of slashes

* Use os.makedirs instead of Path.mkdir",19,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],"['def tearDown(self):', 'def tearDown(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not os.path.exists(cache_file)', 'os.path.exists(cache_file)', 'len(instances) == len(cached_instances)', 'instance.fields == cached_instance.fields', 'os.path.exists(cache_file)', 'cache_contents == final_cache_contents', 'isinstance(instances, _LazyInstances)', 'not os.path.exists(cache_file)', 'os.path.exists(cache_file)', 'len(first_pass_instances) == len(second_pass_instances)', 'instance.fields == cached_instance.fields', 'len(first_pass_instances) == len(cached_instances)', 'instance.fields == cached_instance.fields', 'os.path.exists(expected_cache_file)', 'os.path.exists(expected_param_file)', 'saved_params == self.params.pop().as_dict(quiet=True)', 'os.path.exists(expected_cache_file)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1398,Pradeep Dasigi,pradeep.dasigi@gmail.com,2019-04-24 10:33:03-07:00,f8d2ec5b8fa22ff051ad83623327c1bccae653b9,https://github.com/allenai/allennlp/commit/f8d2ec5b8fa22ff051ad83623327c1bccae653b9,"Moving WTQ language updates from iterative-search-semparse (#2637)

* passing domain language tests

* str -> List[str]

* fixed context tests

* fixed mypy issues

* addressed PR comments",8,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,6,0,0,0,0,0,0,0,0,0,0,1,61,8,0,0,0,0,0,0,0,0,0,0,0,[],"[('Logs', '() as log:'), ('Equal', '(log.output,'), ('Logs', '() as log:'), ('Equal', '(log.output,')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['table_question_context.table_data == [{: Date(2001, -1, -1),', 'entities == [(]),', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'string_entities == [(]),', 'sorted(entities) == [,', 'neighbors_with_sets == {},', 'set(neighbors.keys()) == {,', 'neighbors[]', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[]', 'neighbors[]', 'neighbors[] == []', 'set(neighbors[,', 'Date(2013, 12, 31) > Date(2013, 12, 30)', 'Date(2013, 12, 31) == Date(2013, 12, -1)', 'Date(2013, -1, -1) >= Date(2013, 12, 31)', '(Date(2013, 12, -1) > Date(2013, 12, 31)) == False', '(Date(2013, 12, 31) > 2013) == False', '(Date(2013, 12, 31) >= 2013) == False', 'Date(2013, 12, 31) != 2013', '(Date(2018, 1, 1) >= Date(-1, 2, 1)) == False', '(Date(2018, 1, 1) < Date(-1, 2, 1)) == False', 'Date(-1, 2, 1) < Date(-1, 2, 3)', '(Date(-1, -1, 1) < Date(-1, -1, 3)) == False', '(Date(-1, -1, 1) >= Date(-1, -1, 3)) == False', '(Date(2018, -1, 1) < Date(2018, -1, 3)) == False', '(Date(2018, -1, 1) >= Date(2018, -1, 3)) == False', 'selected_number == 2.0', 'cell_list == Date(2005, 3, -1)', 'row_list == self.language.execute()', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'str(cell_list) == ', 'str(cell_list) == ', 'cell_list == 2.0', 'cell_list == []', 'str(cell_list) == ', 'result == Date(-1, 11, 10)', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {}', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}']","['(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],"['table_question_context.table_data == [{,', 'entities == [(),', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'predicted_types[', 'string_entities == [()]', 'sorted(entities) == [,', 'neighbors == {],', 'set(neighbors.keys()) == {,', 'set(neighbors[,', 'cell_list == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'self.language.execute(logical_form) == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'Date(2013, 12, 31) > Date(2013, 12, 30)', 'Date(2013, 12, 31) == Date(2013, 12, -1)', 'Date(2013, -1, -1) >= Date(2013, 12, 31)', '(Date(2013, 12, -1) > Date(2013, 12, 31)) == False', '(Date(2013, 12, 31) > 2013) == False', '(Date(2013, 12, 31) >= 2013) == False', 'Date(2013, 12, 31) != 2013', '(Date(2018, 1, 1) >= Date(-1, 2, 1)) == False', '(Date(2018, 1, 1) < Date(-1, 2, 1)) == False', 'Date(-1, 2, 1) < Date(-1, 2, 3)', '(Date(-1, -1, 1) < Date(-1, -1, 3)) == False', '(Date(-1, -1, 1) >= Date(-1, -1, 3)) == False', '(Date(2018, -1, 1) < Date(2018, -1, 3)) == False', '(Date(2018, -1, 1) >= Date(2018, -1, 3)) == False', 'result == []', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'not in table_context.column_types.values()', 'not in table_context.column_types.values()', 'set(actions.keys()) == {', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {}', 'agenda == {,', 'agenda == {,', 'agenda == {,', 'set(world.get_agenda()) == {}', 'set(world.get_agenda()) == {}']","['(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)']",[],[],[],[],[],[],[],[],[],[],[]
1399,Mark Neumann,markn@allenai.org,2019-04-24 14:08:43-07:00,12cee9222cd9df4d284a21d9e4d778acc24cdaa0,https://github.com/allenai/allennlp/commit/12cee9222cd9df4d284a21d9e4d778acc24cdaa0,"lowercase stopword set in word filter (#2749)

* lowercase stopword set in word filter

* indentation",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['filter_.stopwords == {}'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1400,Riddhiman Dasgupta,subhoman_sp07@yahoo.co.in,2019-04-25 03:43:32+05:18,53b3d37b2987d9935c0ca57e9d7663d45f924839,https://github.com/allenai/allennlp/commit/53b3d37b2987d9935c0ca57e9d7663d45f924839,"Text Classification Predictor (#2745)

* Text Classification Predictor

* Linting fixes

* Linting fixes

* Addressing comments

* Adding doc

* Adding test for text_classifier predictor along with serialization dir",15,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in output_dict.keys()', 'logits is not None', 'isinstance(logits, list)', 'len(logits) == 2', 'all(isinstance(x, float) for x in logits)', 'probs is not None', 'isinstance(probs, list)', 'len(probs) == 2', 'all(isinstance(x, float) for x in probs)', 'all(x >= 0 for x in probs)', 'sum(probs) == approx(1.0)', 'label is not None', 'label in predictor._model.vocab.get_token_to_index_vocabulary(namespace=)', 'e / sum_exps == approx(p)', 'len(results) == 2', 'logits is not None', 'isinstance(logits, list)', 'len(logits) == 2', 'all(isinstance(x, float) for x in logits)', 'probs is not None', 'isinstance(probs, list)', 'len(probs) == 2', 'all(isinstance(x, float) for x in probs)', 'all(x >= 0 for x in probs)', 'sum(probs) == approx(1.0)', 'label is not None', 'label in predictor._model.vocab.get_token_to_index_vocabulary(namespace=)', 'e / sum_exps == approx(p)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1401,Brendan Roof,brendanr@allenai.org,2019-04-24 18:33:24-07:00,20772152f930f9e34126083dc966911ef03d6414,https://github.com/allenai/allennlp/commit/20772152f930f9e34126083dc966911ef03d6414,"Use numpy's shuffle for reproducibility. (#2729)

- Fixes https://github.com/allenai/allennlp/issues/2620.
- Python resets the `random` library's seeds whenever a new process is spawned.
- Use numpy to avoid this.",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(actual_fingerprints) == 100', 'actual_fingerprints == expected_fingerprints']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1402,Nelson Liu,nelson-liu@users.noreply.github.com,2019-04-24 22:49:16-07:00,b6453dc1427fcad71616d10e9394c7d6ccb91566,https://github.com/allenai/allennlp/commit/b6453dc1427fcad71616d10e9394c7d6ccb91566,Directly capture output in EVALB metric (#2755),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1403,Brendan Roof,brendanr@allenai.org,2019-04-24 23:20:48-07:00,90839d0bab57524dde7f0d71a3626b319cd1ab47,https://github.com/allenai/allennlp/commit/90839d0bab57524dde7f0d71a3626b319cd1ab47,Dummy commit to test Google Cloud Build removal.,0,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1404,Mark Neumann,markn@allenai.org,2019-04-25 10:13:37-07:00,282f12aeef84771c046a34d039e1567cc137f01a,https://github.com/allenai/allennlp/commit/282f12aeef84771c046a34d039e1567cc137f01a,fix abstract type hint (#2753),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1405,Mark Neumann,markn@allenai.org,2019-04-25 11:56:13-07:00,979817dd2b76ca4c6a8958915aa7e5f12c087516,https://github.com/allenai/allennlp/commit/979817dd2b76ca4c6a8958915aa7e5f12c087516,"add print-results command (#2744)

* add print-results command

* add docs

* correct name

* fix sphinx?",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['lines[0] == ', 'results == expected_results', 'lines[0] == ', 'results == expected_results']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1406,Bai Li,luckytoilet@users.noreply.github.com,2019-04-26 13:13:28-04:00,c6ddb9d313e8c459464c3b7aa2a9f1d2bc2bf285,https://github.com/allenai/allennlp/commit/c6ddb9d313e8c459464c3b7aa2a9f1d2bc2bf285,Update comment on ELMo NER model to match current configuration (#2761),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1407,Barun Patra,codedecde@users.noreply.github.com,2019-04-27 09:07:36-07:00,3c226042ae3982d50c91886982043c25892bc416,https://github.com/allenai/allennlp/commit/3c226042ae3982d50c91886982043c25892bc416,"Extras checks (#2754)

* todo: testing

* ready to merge

* fixed issue to check against from_params_method

* removed hard coded extras

* better inspection and mypy issues fixed

* fixing pylint errors

* fixed pylint issues of simplified if-else statement, and mypy issues in testing

* minor fix

* fixed pylint issues

* fixing pylint and mypy errors for the tests

* fixed test

* typo in comments",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(d.arg1) == len(vals)', 'isinstance(d.arg1, list)', 'isinstance(d.arg1[0], A)', 'all([x.b == y for x, y in zip(d.arg1, vals)])', 'all([x.a == tval1 for x in d.arg1])', 'isinstance(d.arg2, tuple)', 'isinstance(d.arg2[0], A)', 'isinstance(d.arg2[1], B)', 'd.arg2[0].a == tval1', 'd.arg2[1].c == tval2', 'd.arg2[0].b == d.arg2[1].b == vals[0]', 'isinstance(d.arg3, dict)', 'isinstance(d.arg3[], A)', 'd.arg3[].a == tval1', 'd.arg3[].b == vals[0]', 'd.arg3[].b == vals[1]', 'isinstance(d.arg4, set)', 'len(d.arg4) == 2', 'any(x.val ==  for x in d.arg4)', 'any(x.val ==  for x in d.arg4)', 'isinstance(d.arg5, list)', 'isinstance(d.arg5[0], E)', 'd.arg5[0].m == 9', 'd.arg5[0].n == 10']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1408,Santiago Castro,sacastro@umich.edu,2019-04-27 14:00:54-04:00,c059b1513404be35c15d302c02ecbacea47267e8,https://github.com/allenai/allennlp/commit/c059b1513404be35c15d302c02ecbacea47267e8,Remove misleading dropout from bidaf.jsonnet (#2767),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1409,Santiago Castro,sacastro@umich.edu,2019-04-27 15:43:19-04:00,95b439da692eff28532179aaa1dbedc64ebf658a,https://github.com/allenai/allennlp/commit/95b439da692eff28532179aaa1dbedc64ebf658a,Remove misleading dropout from training configs where RNN has only one layer (#2768),4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1410,Matt Gardner,mattg@allenai.org,2019-04-29 13:57:38-07:00,7c0d5d538d836e98cdb1186f59e2e5318b5a80d9,https://github.com/allenai/allennlp/commit/7c0d5d538d836e98cdb1186f59e2e5318b5a80d9,"Fix bug in QaNetEncoder, update pretrained model (#2773)

* Fix bug in QaNetEncoder, update pretrained model

* pylint",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1411,Matt Gardner,mattg@allenai.org,2019-04-29 13:58:25-07:00,b97bca026b82bf413249151ecc041c318d9a280f,https://github.com/allenai/allennlp/commit/b97bca026b82bf413249151ecc041c318d9a280f,"Make _replace_none properly handle ""None"" in parameter lists (#2774)",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['params[] is None', 'params[][1] is None', 'params[] is None']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1412,Brendan Roof,brendanr@allenai.org,2019-04-29 18:00:10-07:00,3170f6f3e089062b522986ed906ef1ef1b68bf90,https://github.com/allenai/allennlp/commit/3170f6f3e089062b522986ed906ef1ef1b68bf90,"Make FBetaMeasure work with batch size of 1. (#2777)

- A stray squeeze caused batches of size one to be zero dimensional. Indexing into them was thus invalid and crashed.
- See https://github.com/allenai/allennlp/pull/2275#issuecomment-487486905",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1413,Brendan Roof,brendanr@allenai.org,2019-04-29 18:29:30-07:00,648a36f77db7e45784c047176074f98534c76636,https://github.com/allenai/allennlp/commit/648a36f77db7e45784c047176074f98534c76636,"Increase max_runs for NumericallyAugmentedQaNetTest. (#2778)

- This test has caused a couple failures of the ""GPU Unit Tests"" over the past few days due to flakiness.
- Examples:
http://build.allennlp.org/viewLog.html?buildId=14497&buildTypeId=AllenNLP_GpuUnitTests&tab=buildLog&_focus=2658
http://build.allennlp.org/viewLog.html?buildId=14313&buildTypeId=AllenNLP_GpuUnitTests&tab=buildLog&_focus=2600",1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1414,Brendan Roof,brendanr@allenai.org,2019-05-01 18:48:37-07:00,6acfc6ca7f34c50fc0c1d9de22a7f351e09b2760,https://github.com/allenai/allennlp/commit/6acfc6ca7f34c50fc0c1d9de22a7f351e09b2760,"Repro for #2776 and backwards compatible fix. (#2784)

- Fixes #2776.
- Just access the modules that we added.",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(encoder_output.size()) == [3, 5, 12]']",[],[],['if(torch.cuda.device_count()'],[],[],[],[],"['skipif(torch.cuda.device_count() < 2,']","['mark.skipif(torch.cuda.device_count() < 2,']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1415,Clara Meister,cmeister7.47@gmail.com,2019-05-02 15:27:03+02:00,d9baa6f7e07a1a2beb749317049c7b455a00d37b,https://github.com/allenai/allennlp/commit/d9baa6f7e07a1a2beb749317049c7b455a00d37b,Changing model name in config file to match registered name (#2794),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1416,Dheeru Dua,dheeru_dua@hotmail.com,2019-05-02 12:51:54-07:00,42ada05d099017b138909ef50efb4d369532cf24,https://github.com/allenai/allennlp/commit/42ada05d099017b138909ef50efb4d369532cf24,"fixing regression in drop script and adding a test case for the same (#2796)

* bug fixes in drop evaluation and adding more tests

* fixing comment

* resolved review comments and added failure test for answer

* fixing the style error

* adding naqanet config and fixing drop test format

* fixing config failure

* fixing bug in drop and adding regression test for it",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['evaluate_json(annotation, prediction) == (0.5, 0.5)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1417,Nelson Liu,nelson-liu@users.noreply.github.com,2019-05-02 16:49:55-07:00,9fc6f9ebc27dd4172b91505192c0c6d51cbb769a,https://github.com/allenai/allennlp/commit/9fc6f9ebc27dd4172b91505192c0c6d51cbb769a,"Add SrlEvalMetric (#2743)

* Test SRL reader metadata

* Return gold SRL tags as metadata

* Fix lint

* Add initial SrlEvalScorer

* Fix mypy

* Add function for writing conll-formatted SRL tags to disk

* Decouple SrlEvalScorer from BIO tagging paradigm

* Directly capture stdout

* Fix lint

* Replace write_to_conll_eval_file with write_bio_formatted_tags_to_file

* Mark arg as optional

* Add perl version and disk usage info

* Fix SrlEval.__call__ docstring types

* Assert that 'overall' is not a tag type

* Add information about BIO (IOB2) and CoNLL formats

* Explicitly check keys in SrlEvalScorer test

* Add a more-realistic test",10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['fields[] == tokens', 'fields[] == tokens[3]', 'fields[].labels', 'fields[] == tokens', 'fields[] == tokens[8]', 'fields[].labels', 'fields[] == tokens', 'fields[] == tokens[2]', 'fields[].labels', 'fields[] == tokens', 'fields[] == tokens[11]', 'fields[].labels', 'fields[] == tokens', 'fields[] is None', 'fields[].labels', 'len(metrics) == 18', 'len(metrics) == 12']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1418,Waleed Ammar,waleeda@allenai.org,2019-05-02 20:15:57-07:00,a701a0ae62b967ea4297f920bd4bf14fcf13b422,https://github.com/allenai/allennlp/commit/a701a0ae62b967ea4297f920bd4bf14fcf13b422,Fix out-of-bound checking in BidirectionalEndpointSpanExtractor for empty sequences. (#2763),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1419,ValentinaPy,ValentinaPy@users.noreply.github.com,2019-05-06 06:44:48+03:00,24f90a82928e0ff6e8f2d187148b6f5156f7083b,https://github.com/allenai/allennlp/commit/24f90a82928e0ff6e8f2d187148b6f5156f7083b,"Adding NamedTuple case for Tensors to be moved to GPU. (#2799)

* Adding NamedTuple case for Tensors to be moved to GPU.

* Imported NamedTuple type

* Changed to a different check for NamedTuple as the previous one does not work and added a test.

* Changed to a different check for NamedTuple as the previous one does not work and added a test.

* Import NamedTuple

* Minor cleanup

* pylint

* More pylint",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['moved_obj[][0].a == 1', 'moved_obj[][0].b._device == new_device', 'moved_obj[][1].b._device == new_device', 'moved_obj[]._device == new_device', 'moved_obj[][0] == 1', 'moved_obj[][1]._device == new_device']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1420,Santiago Castro,bryant@montevideo.com.uy,2019-05-06 10:38:22-04:00,16c40ec5ff5a9ab9d4ce1e3a4d439068c7f7799f,https://github.com/allenai/allennlp/commit/16c40ec5ff5a9ab9d4ce1e3a4d439068c7f7799f,"Delete .DS_Store (#2803)

* Delete .DS_Store

* Update .gitignore",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1421,David Wadden,dwadden@cs.washington.edu,2019-05-06 07:43:17-07:00,30460e614fca5eb88377b04008ee9925b191b8c7,https://github.com/allenai/allennlp/commit/30460e614fca5eb88377b04008ee9925b191b8c7,"Use a hash function that is constant across program invocations. (#2802)

The builtin Pythong `hash` is not, which means data set configs will not be
hashed conistently across training runs.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1422,Brendan Roof,brendanr@allenai.org,2019-05-06 12:27:20-07:00,63be47a208e03d4237adba7bd403f237c8c5154b,https://github.com/allenai/allennlp/commit/63be47a208e03d4237adba7bd403f237c8c5154b,"Improve handling of empty ListFields. (#2697)

- There appears to be an edge case in our handling of empty ListFields such that we fail to tensorize a batch of entirely empty ones. 
- Proposed solution: Make `TextField` always return a minimum padding size of 1.
- Fixes https://github.com/allenai/allennlp/issues/2660",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1423,Joel Grus,joelgrus@gmail.com,2019-05-06 15:24:31-05:00,aeafe1c58b6041e654c7fb645d6aa98f2fac9b9a,https://github.com/allenai/allennlp/commit/aeafe1c58b6041e654c7fb645d6aa98f2fac9b9a,"Bert for classification (#2787)

* bert for classification

* add docs

* update comment

* address PR feedback

* add test for caching

* make things cleaner + better documented

* replace None dropout with p=0 dropout",11,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in decoded', 'model1 is model2', 'model3 is not model4', 'model5 is not model6']",[],[],[],[],[],[],[],[],[],"['setattr(BertModel, , lambda _: BertModel(config))']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1424,Michael Schmitz,michael@schmitztech.com,2019-05-07 10:06:16-07:00,48f46ea9b7390658c200a9f74e6dcaca93feb4ab,https://github.com/allenai/allennlp/commit/48f46ea9b7390658c200a9f74e6dcaca93feb4ab,Number predictions. (#2709),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1425,Brendan Roof,brendanr@allenai.org,2019-05-08 17:51:24-07:00,e70eb7bb903b3387d4f872d0727c7180c9c66043,https://github.com/allenai/allennlp/commit/e70eb7bb903b3387d4f872d0727c7180c9c66043,"Link pretrained model in tutorial. (#2814)

- Fixes https://github.com/allenai/allennlp/issues/2812",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1426,Wang Ran (),wrran@outlook.com,2019-05-09 22:53:10+08:00,425f2af310e1000453ba94d4206166cbca1a971b,https://github.com/allenai/allennlp/commit/425f2af310e1000453ba94d4206166cbca1a971b,"add `token_min_padding_length` to `TokenIndexer` (#2615)

* add token_min_padding_length to TokenIndexer

* add tests; pass pytest

* make mypy happy

* minor update: un-rename

* make pylint & sphinx happy

* are u happy? sphinx",12,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['padding_lengths == {', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == [0] * 8']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1427,JianLiu91,jianliu.cc@gmail.com,2019-05-10 09:55:27+08:00,2452492f35e5122b675e77108385d9853411900c,https://github.com/allenai/allennlp/commit/2452492f35e5122b675e77108385d9853411900c,"fix batched_index_select (#2765)

* fix batched_index_select

* fix batched_index_select

* add unit test",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1428,Victor Quach,victor.quach@polytechnique.edu,2019-05-10 15:17:23-04:00,7c4311b11de7bcd7b32b8133f8684441ae98a456,https://github.com/allenai/allennlp/commit/7c4311b11de7bcd7b32b8133f8684441ae98a456,Unwrap masks to tensors as well in AUC metric (#2813),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1429,Santiago Castro,sacastro@umich.edu,2019-05-10 16:07:11-04:00,aa1524ee20e6d23a5045da52df6122ee2bbeaf95,https://github.com/allenai/allennlp/commit/aa1524ee20e6d23a5045da52df6122ee2bbeaf95,Fix typo in a comment (#2826),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1430,Santiago Castro,sacastro@umich.edu,2019-05-13 13:37:13-04:00,e3febb99bd2f56bb31a38de2f62ea2b391d84caa,https://github.com/allenai/allennlp/commit/e3febb99bd2f56bb31a38de2f62ea2b391d84caa,Fix test evaluation after training in the general case (#2835),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1431,Santiago Castro,sacastro@umich.edu,2019-05-13 16:40:01-04:00,8e0953ab52388b132b3a73e56a43d265fb9ef8a1,https://github.com/allenai/allennlp/commit/8e0953ab52388b132b3a73e56a43d265fb9ef8a1,Fix typo in tagger README file (#2836),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1432,Brendan Roof,brendanr@allenai.org,2019-05-13 14:47:00-07:00,7bdd575c64359a7e18b20caa7930a0f00f5e406c,https://github.com/allenai/allennlp/commit/7bdd575c64359a7e18b20caa7930a0f00f5e406c,"Remove multiple GPU warning (#2837)

- This code is relatively stable.
- However, our support isn't ideal as it's based on `torch.nn.DataParallel`.
- We should really investigate using `torch.nn.parallel.DistributedDataParallel`.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1433,Guo Quan,guoquanscu@gmail.com,2019-05-16 11:39:53-05:00,c59a3a8b645e77cf134cee33f4f08841585bf046,https://github.com/allenai/allennlp/commit/c59a3a8b645e77cf134cee33f4f08841585bf046,"Update auc.py (#2775)

* Update auc.py

To allow, in some case, there is no positive or negative sample in a batch.

* Update auc.py

* Update auc.py

Not sure should it be more efficient leaving `torch.unique` at line #50 there or not.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1434,Kenton Lee,kentonl@google.com,2019-05-16 12:07:16-07:00,b20c12ba4a68f5e155fc0cf320dab73fdb077264,https://github.com/allenai/allennlp/commit/b20c12ba4a68f5e155fc0cf320dab73fdb077264,"Use optimal matching for the drop eval and add appropriate tests. (#2853)

* Use optimal matching for the drop eval and add appropriate tests.

* Variable names for pylint

* more pylint",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['get_metrics([]) == (0, 0.5)', 'get_metrics([]) == (0, 0.5)', 'get_metrics([]) == (0, 0.5)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1435,Brendan Roof,brendanr@allenai.org,2019-05-17 12:07:09-07:00,b6693107633feb261ed79f4aac7c5f4cda4fbe5f,https://github.com/allenai/allennlp/commit/b6693107633feb261ed79f4aac7c5f4cda4fbe5f,"Log random seeds to disk. (#2859)

- Seeds are already logged, but before we're writing to `stdout.log`.
- `create_serialization_dir` and `prepare_global_logging` don't appear to rely on random seeds, so this should be safe.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1436,Gabriel Stanovsky,gabriel.satanovsky@gmail.com,2019-05-19 18:21:16-07:00,93e86a961c31467885905280b7f9b2a444e371b4,https://github.com/allenai/allennlp/commit/93e86a961c31467885905280b7f9b2a444e371b4,"Add output path to drop eval (#2860)

* adding output path to drop eval

* checking codecov issue

* checking codecov issue

* checking codecov issue

* pylint

* removing dev null

* removing dev null

* pylint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1437,Sundeep Pidugu,49222318+SundeepPidugu@users.noreply.github.com,2019-05-20 19:07:40+05:18,093847a756746ed50cd95a74753261a71d50f345,https://github.com/allenai/allennlp/commit/093847a756746ed50cd95a74753261a71d50f345,"updated fine-grained-ner-model-elmo URL (#2868)

Updated the model with the new one : fine-grained-ner-model-elmo-2018.08.31.tar.gz ->  fine-grained-ner-model-elmo-2018.12.21.tar.gz",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1438,Dan Kondratyuk,Hyperparticle@users.noreply.github.com,2019-05-20 18:31:59-06:00,20844259485f2e24c973e138225b5daab3298095,https://github.com/allenai/allennlp/commit/20844259485f2e24c973e138225b5daab3298095,"Add ability to generate BERT embeddings using a sliding window (#2493) (#2537)

* Add ability to generate BERT embeddings using a sliding window (#2493)

* Fix truncating offsets, formatting

* Use maximal context embeddings

* Fix stride calculation

* test token-type-ids

* correct token_type_id computation

* make test more informative

* rename start_tokens -> num-start_tokens

* pylint

* pylint + fix comment

* add broken test

* fix edge case

* Fix lint (unused import)",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed_tokens[] == [16,   2,  3,    4,  3,    5,    17,   8,     9,   17,', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9, 10, 11]', 'indexed_tokens[] == [0,    0,  0,    0,  0,    0,    0,    1,     1,   1,', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8]', 'tokens[].tolist() == [[16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 14, 12, 17, 0],', 'tokens[].tolist() == [[1, 3, 4, 5, 6, 7, 8, 9, 10, 11],', 'tokens[].tolist() == [[16, 2, 3, 5, 6, 8, 9, 2, 14, 12, 17]]', 'tokens[].tolist() == [[1, 2, 3, 4, 5, 6, 7, 8, 9]]', 'tokens[].tolist() == [[16, 2, 3, 4, 3, 5, 6, 17,', 'tokens[].tolist() == [[1, 3, 4, 5, 6, 7, 8, 9, 10, 11]]', 'list(bert_vectors.shape) == [1, 13, 12]', 'list(bert_vectors.shape) == [1, 10, 12]', 'bert_vectors is not None']",[],[],[],[],[],[],[],[],[],[],[],[],"['tokens[].tolist() == [', 'tokens[].tolist() == [', 'tokens[].tolist() == [', 'tokens[].tolist() == [']",[],[],[],[],[],[],[],[],[],[],[],[]
1439,Sundeep,pidugusundeep5@gmail.com,2019-05-21 18:38:36+05:18,c2609453d5c5f9ed261052acc72e4e3b0a12c497,https://github.com/allenai/allennlp/commit/c2609453d5c5f9ed261052acc72e4e3b0a12c497,updated links for pretrained NER models (#2872),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1440,Joel Grus,joelgrus@gmail.com,2019-05-21 08:35:36-07:00,d800e823833dc5b30fa170b554d0a842b53de377,https://github.com/allenai/allennlp/commit/d800e823833dc5b30fa170b554d0a842b53de377,truncate type ids (#2875),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1441,Nelson Liu,nelson-liu@users.noreply.github.com,2019-05-23 13:45:24-07:00,d6bb6c87581bc3a37ec7cccbb1778364344b1a7f,https://github.com/allenai/allennlp/commit/d6bb6c87581bc3a37ec7cccbb1778364344b1a7f,"Make DROP EM and F1 calculation length aware (#2866)

* Make DROP EM calculation length-aware

* Test that EM calculation is length-aware

* Properly penalize DROP F1 when overpredicting",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['get_metrics(predicted=[]) == (0.0, 0.5)', 'get_metrics(]) == (0.0, 0.5)', 'get_metrics(predicted=[]) == (0.0, 0.5)', 'get_metrics(predicted=[) == (0.0, 0.5)', 'get_metrics(predicted=[],', 'get_metrics(predicted=[],', 'get_metrics(predicted=[],']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1442,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-05-28 13:31:48-07:00,69c1c9fc0588da1f88c9510e014ff23ba7093fde,https://github.com/allenai/allennlp/commit/69c1c9fc0588da1f88c9510e014ff23ba7093fde,"Shift extra_weight for embedding extension to right device (#2896)

Make sure the `extra_weight` is shifted to the right device before trying to extend the embedding.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1443,Joel Grus,joelgrus@gmail.com,2019-05-29 11:22:12-07:00,26ac34991cb9139d3b99bd051e89f657e5c27ce4,https://github.com/allenai/allennlp/commit/26ac34991cb9139d3b99bd051e89f657e5c27ce4,"fix dependency conflicts (by removing moto + disabled tests that use it) (#2902)

* reinstate + fix moto tests

* remove moto and its tests",3,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,3,0,4,0,0,0,0,4,4,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(buckets) == 1', 'buckets[0][', 'get_file_info(', 'isinstance(etag, str)', 'etag.startswith()', 'os.stat(temp_file.name).st_size != 0']","['(FileNotFoundError)', '(FileNotFoundError)', '(FileNotFoundError)']",[],"['(reason=)', '(reason=)', '(reason=)', '(reason=)']",[],[],[],[],"['skip(reason=)', 'skip(reason=)', 'skip(reason=)', 'skip(reason=)']","['mark.skip(reason=)', 'mark.skip(reason=)', 'mark.skip(reason=)', 'mark.skip(reason=)']",[],[],[]
1444,Santiago Castro,sacastro@umich.edu,2019-05-30 12:25:27-04:00,fbc28cefe03b1ea3ff65300d475d34f5f9629a5c,https://github.com/allenai/allennlp/commit/fbc28cefe03b1ea3ff65300d475d34f5f9629a5c,Fix typo in Model.extend_embedder_vocab docstring (#2806),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1445,Michael Schmitz,michael@schmitztech.com,2019-05-30 12:52:43-07:00,030ef755aeeee7d05d119dcfe367f81bb26aed53,https://github.com/allenai/allennlp/commit/030ef755aeeee7d05d119dcfe367f81bb26aed53,bump version number to v0.8.4,4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1446,Michael Schmitz,michael@schmitztech.com,2019-05-30 13:45:12-07:00,954a02f967863f4b1e8e6e8b11e323bad2569aec,https://github.com/allenai/allennlp/commit/954a02f967863f4b1e8e6e8b11e323bad2569aec,Bump version numbers to v0.8.5-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1447,Santiago Castro,sacastro@umich.edu,2019-05-30 18:03:11-04:00,6afba9a29b78c319d2146dcbbaa52bc1b40a3a07,https://github.com/allenai/allennlp/commit/6afba9a29b78c319d2146dcbbaa52bc1b40a3a07,"Fix TextField padding when there are no tokens (#2843)

* Add test for getting the tensor of empty text field with token indexer

* Fix TextField padding when there are no tokens",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1448,Pradeep Dasigi,pradeepd@allenai.org,2019-05-31 18:23:27-04:00,53938826271300c3d9d2d9b8e9f40666d613430d,https://github.com/allenai/allennlp/commit/53938826271300c3d9d2d9b8e9f40666d613430d,"Change blueprint to image in run_with_beaker (#2903)

* blueprint -> image

* separate docker image from beaker image",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1449,Kevin Lin,kl2806@columbia.edu,2019-06-03 09:56:54-07:00,89700de2cab9bb1f71559eae9cd098d88c015dc7,https://github.com/allenai/allennlp/commit/89700de2cab9bb1f71559eae9cd098d88c015dc7,Change image to docker_image (#2918),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1450,Evan Pete Walsh,epwalsh10@gmail.com,2019-06-06 12:16:02-07:00,c629093b6fbef2dea99765cd9044bb9cff5f0984,https://github.com/allenai/allennlp/commit/c629093b6fbef2dea99765cd9044bb9cff5f0984,"CopyNet: replace in-place tensor operation with out-of-place equivalent (#2925)

* remove in-place operation

* oops, fixed",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1451,Sumithra Bhakthavatsalam,sumithra.b@gmail.com,2019-06-07 09:58:37-07:00,5b2066bd15e614ef71895743752cad1cc28d3cfc,https://github.com/allenai/allennlp/commit/5b2066bd15e614ef71895743752cad1cc28d3cfc,"Fix Invalid Index Reference for labels in Vocabulary (#2926)

* Fix bug with invalid reference to index when labels dict is empty

* Simplify if-then to get() and make same change in basic_classifier

* Changes per PR comments

* Update bert_for_classification.py

* Update basic_classifier.py",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1452,Mark Neumann,markn@allenai.org,2019-06-07 10:48:00-07:00,5f377834e3230a712b33d4e6c5c3219e7fd339ac,https://github.com/allenai/allennlp/commit/5f377834e3230a712b33d4e6c5c3219e7fd339ac,"Bert srl (#2854)

* initial working dataset reader for bert srl

* tests for everything, all good

* pylint, mypy

* clean up after monkeypatch

* docs, rename model

* import

* get names the right way around

* shift everything over to the srl reader

* docstring, update model to not take bert_dim param

* I love to lint

* sneaky configuration test

* joel's comments",10,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,2,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,6,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],"['def tearDown(self):', 'def tearDown(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(items) == 4', 'in items', 'domain_identifier.annotation == str', 'domain_identifier.default_value is None', 'converted == wordpiece_tags', 'converted == [,', 'converted == []', 'converted == []', 'tokens == [,', 'fields[].labels[4] == 1', 'fields[,', 'tokens == [,', 'fields[].labels[10] == 1', 'fields[,', 'tokens == [,', 'fields[].labels[3] == 1', 'fields[,', 'tokens == [,', 'fields[].labels[12] == 1', 'fields[,', 'tokens == []', 'fields[].labels == [0, 0, 0, 0, 0, 0, 0]', 'fields[]', 'len(prediction) == length']",[],[],[],[],[],[],[],[],[],"['setattr(BertModel, , lambda _: BertModel(config))', 'undo()', 'setattr(BertModel, , lambda _: BertModel(config))', 'setattr(BertTokenizer, , lambda _: BertTokenizer(vocab_path))', 'undo()', 'undo()']",[],[],['len(items) == 3'],[],[],[],[],[],[],[],[],[],"['setattr(BertModel, , lambda _: BertModel(config))']",[],[]
1453,David Fidalgo,david@recogn.ai,2019-06-08 01:03:03+02:00,9a0e01fae76fd40211c3499a791d334a8f48da9c,https://github.com/allenai/allennlp/commit/9a0e01fae76fd40211c3499a791d334a8f48da9c,fix trainable and requires_grad kwargs (#2932),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1454,Daniel Darabos,darabos.daniel@gmail.com,2019-06-10 17:35:38+02:00,8e180cb90a674546cb1b4e874be12e0e6f68ce60,https://github.com/allenai/allennlp/commit/8e180cb90a674546cb1b4e874be12e0e6f68ce60,"Pad coreference model input to 5 (#2933)

* Pad coreference model input to 5.

It has a 5-wide Conv1D layer.

* mypy",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1455,Abhishek Sharma,abhisheksharma0318@gmail.com,2019-06-10 23:57:09+05:18,c0f44f74ab5b7505bc6a8ca18ce05e9afaf67699,https://github.com/allenai/allennlp/commit/c0f44f74ab5b7505bc6a8ca18ce05e9afaf67699,"Fixed minor error while calculating span accuracy (#2923)

* Fixed minor error while calculating span accuracy

* Added checks for input shape in BooleanAccuracy

* Fixed label shape in QaNet

* Use f-string",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ValueError)', '(ValueError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1456,Evan Pete Walsh,epwalsh10@gmail.com,2019-06-10 15:38:22-07:00,44ba490010e735e3165413fcbcfad0d6123ce067,https://github.com/allenai/allennlp/commit/44ba490010e735e3165413fcbcfad0d6123ce067,"Use unsigned s3 requests when missing credentials (#2939)

* use unsigned s3 requests when missing credentials

* revert to using resource",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1457,Ana Marasovic,anam@allenai.org,2019-06-11 15:39:17-07:00,5e3c4cdda9ed5fd7206c5cc3d417101f4deff242,https://github.com/allenai/allennlp/commit/5e3c4cdda9ed5fd7206c5cc3d417101f4deff242,token_type_ids fix for window reshaping (#2942),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(bert_vectors.shape) == [1, 10, 12]', 'bert_vectors is not None']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1458,Nilesh Chakraborty,nilesh@nileshc.com,2019-06-12 17:01:30+02:00,92ee4215a33e0d9592af115d1a05e0315f54e22f,https://github.com/allenai/allennlp/commit/92ee4215a33e0d9592af115d1a05e0315f54e22f,"Fix for cyclic import problems (issue #2935) (#2938)

* Move domain_languages.common to semparse.common

* Move exception classes from domain_langauge.py to semparse/common/errors.py

* Undo over-specific semparse.common.error import changes

* Fix formatting issues

* Copy over common docs to .semparse.common.rst

* Fix (at least part of) the docs

* Fixing docs again

* Moving tests to the right place",20,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1459,TalSchuster,talschuster@gmail.com,2019-06-12 11:06:03-04:00,da16ad13f891a9a91a55a1a5eefd404fbc7d1b70,https://github.com/allenai/allennlp/commit/da16ad13f891a9a91a55a1a5eefd404fbc7d1b70,"Multilingual parser and Cross-lingual ELMo (#2628)

* Multilingual version of biaffine dependency parser with elmo alignment

* alignment addition to elmo embedder

* dataset reader for multiple sources

* iterator that groups samples from the same language

* Clean multilang biaffine

* Inherit unmodified functions from the biaffine parser.

* Also using defaultdict for same_lang_iterator.

* Multi-lang dep config example

* Jsonnet format

* Larger softmax value

The previous one caused overflow sometimes. e-10 is good enough

* formating

* reorganize multilang dataset reader to work with a pathname

* factoring biaffine parser to prevent duplicating code

* multilangTokenEmbedder interface

* fix parser factorization and pylint staff

* more pylint

* inspect embedder and fix params_test

* make mypy happy

* cr comments and doc

* doc

* fix doc

* Multilingual tests (#4)

* Added dependencies data for es, fr and it + json configuration for tests

* Tests for multilingual UD reader and same-language iterator

* Tests for multilingual dependency parser

* fixed some of the tests - not final

* use not lazy option in the parser test

* better doc

* test basic text field emb

* pylint

* multilingual embedder test

* cr comments

* new link",41,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['fields1[]', 'fields1[', '[t.text for t in fields1[,', 'fields1[,', 'fields1[,', 'fields1[].labels == [2, 4, 4, 0, 6, 4, 6, 9, 6, 4]', 'fields2[', '[t.text for t in fields2[,', 'fields2[,', 'fields2[,', 'fields2[].labels == [2, 6, 2, 6, 6, 0, 6, 7, 6]', '[t.text for t in fields1[,', 'fields1[,', 'fields1[,', 'fields1[].labels == [0, 1, 5, 5, 2, 9, 6, 6, 1, 12, 12, 9, 1]', '[t.text for t in fields2[,', 'fields2[,', 'fields2[,', 'fields2[].labels == [0, 3, 1, 3, 4, 5, 8, 9, 1, 11, 9, 1]', 'fields1[', '[t.text for t in fields1[,', 'fields1[]', 'fields1[]', 'fields1[].labels == [2, 0, 2, 5, 3, 2]', 'fields2[', '[t.text for t in fields2[,', 'fields2[,', 'fields2[,', 'fields2[].labels == [2, 4, 4, 0, 4, 5, 4, 9, 7, 4]', 'len(instances) == 6', 'in processed_langs', '(counter_es > 20 or counter_fr > 20 or counter_it > 20)', 'len(batches) == 3', 'lang == batch_lang', 'os.path.exists(fta_file)', 'files_to_archive == {', 'filecmp.cmp(original_filename, new_filename)', 'np.count_nonzero(embedded_en) == 0', 'np.count_nonzero(embedded_fr) > 0', 'np.count_nonzero(embedded_en) == 0', 'np.count_nonzero(embedded_fr) > 0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1460,Mark Neumann,markn@allenai.org,2019-06-12 12:43:53-07:00,eaebe02f2334a51ebfe82df9760f8b614a2ce281,https://github.com/allenai/allennlp/commit/eaebe02f2334a51ebfe82df9760f8b614a2ce281,Update issue templates to request full stacktrace (#2876),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1461,Michael Schmitz,michael@schmitztech.com,2019-06-13 09:11:19-07:00,01602c86e3dfa89ed13e604c6906d32683d11157,https://github.com/allenai/allennlp/commit/01602c86e3dfa89ed13e604c6906d32683d11157,Link to Wikitables and ATIS data. (#2947),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1462,Sundeep,pidugusundeep5@gmail.com,2019-06-14 19:11:58+05:18,e7b0013002d3f3272dcd470b34cd686e6ef1c52b,https://github.com/allenai/allennlp/commit/e7b0013002d3f3272dcd470b34cd686e6ef1c52b,"Linear assignment depricated fix (#2950)

* linear assignment deprecated fix to linear_sum_assignment",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1463,Santiago Castro,sacastro@umich.edu,2019-06-14 11:20:38-04:00,ac72c88838a3ba2663d76f6bead3c2f318508d32,https://github.com/allenai/allennlp/commit/ac72c88838a3ba2663d76f6bead3c2f318508d32,Fix Model.load fail if model_params is str (#2805),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1464,Sundeep,pidugusundeep5@gmail.com,2019-06-14 20:46:03+05:18,acfbb8c07caf8038a053a051acbc1996c6d016db,https://github.com/allenai/allennlp/commit/acfbb8c07caf8038a053a051acbc1996c6d016db,"Replace s3 path style to virtual host style (#2873)

* updated links for pretrained NER models

* replace path-style s3 links with virtual-host-style s3 links",44,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1465,Barun Patra,codedecde@users.noreply.github.com,2019-06-14 08:31:32-07:00,6a3d3a8d39f71398d12f0fddb0c1c3997ff1bc14,https://github.com/allenai/allennlp/commit/6a3d3a8d39f71398d12f0fddb0c1c3997ff1bc14,ensure regularizers are only computed for parameters requiring gradients (#2887),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['value.data.numpy() == 55'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1466,davatk,davatk@gmail.com,2019-06-14 09:37:50-06:00,c9eb2d0ee760244e827d824aaa316a309f524b22,https://github.com/allenai/allennlp/commit/c9eb2d0ee760244e827d824aaa316a309f524b22,Replace current default stopword list with spaCy's. (#2940),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1467,Matt Gardner,mattg@allenai.org,2019-06-14 13:22:46-07:00,1b656dd759427b44c82fe180aef8da52659ce87c,https://github.com/allenai/allennlp/commit/1b656dd759427b44c82fe180aef8da52659ce87c,"Allowing for bulk adding of tokens to vocab (#2948)

* Allowing for bulk adding of tokens to vocab

* Fix small bug in test",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1468,Joel Grus,joelgrus@gmail.com,2019-06-17 10:24:48-07:00,9e6e0af620ecb44f78488fae7102b50e4ce52750,https://github.com/allenai/allennlp/commit/9e6e0af620ecb44f78488fae7102b50e4ce52750,"callback based trainer (#2817)

* wip event based trainer

* wip

* test passing

* progress

* callbacks everywhere

* fix registered names

* revert

* clean things up

* no default callbacks

* add momentum scheduler callback

* move movingaverage into callback

* progress

* remove metrics

* clean up

* move training into a callback

* cleanup

* address PR feedback

* address final PR feedback

* remove deprecated test",30,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,90,2,0,3,0,0,0,0,3,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'len(responses.calls) == 1', 'responses.calls[0].response.request.body == b', 'in kwargs, \\', 'len(kwargs[]) == batch_size, \\', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], int)', 'new_trainer.epoch_number == 1', 'tracker is not None', 'tracker.is_best_so_far()', 'tracker._best_so_far is not None', 'new_trainer.epoch_number == 1', 'tracker.is_best_so_far()', 'tracker._best_so_far is not None  # pylint: disable=protected-access', 'new_tracker.is_best_so_far()', 'not new_tracker.is_best_so_far()', 'new_tracker.is_best_so_far()', 'not new_tracker.is_best_so_far()', 'new_tracker.is_best_so_far()', 'not new_tracker.is_best_so_far()', 'new_tracker.is_best_so_far()', 'new_tracker.should_stop_early()', 'not new_tracker.should_stop_early()', 'new_tracker.should_stop_early()', 'not new_tracker.should_stop_early()', 'new_tracker.should_stop_early()', 'not tracker.should_stop_early()', 'not tracker.should_stop_early()', 'new_trainer.epoch_number == 4', 'new_scheduler.last_epoch == 3', 'new_trainer.epoch_number == 2', 'new_lr_scheduler.lr_scheduler.last_epoch == 1', 'sorted(epochs) == [2, 3, 4]', 'epoch_file.exists()', 'in metrics', 'in metrics', 'metrics.get() == epoch', 'sorted(epochs) == [1, 3, 4, 5]', 'len(epochs) == 4', 'epochs[3] == ', 'in epochs[0]', 'restore_trainer.epoch_number == 2', 'restore_trainer.batch_num_total == 2', 'isinstance(best_validation_metrics_epoch_1, dict)', 'in best_validation_metrics_epoch_1', 'best_epoch_1 == 0 and best_epoch_2 == 1', 'best_validation_metrics_epoch_2 != best_validation_metrics_epoch_1', 'isinstance(best_validation_metrics_epoch_1, dict)', 'in best_validation_metrics_epoch_1', 'best_epoch_1 == best_epoch_2 == 0', 'best_validation_metrics_epoch_2 == best_validation_metrics_epoch_1', 'in restored_metrics', 'in restored_metrics', 'in restored_metrics', 'in restored_metrics', 'training_metrics[]', 'training_metrics[] == 0', 'training_metrics[]']","['(ConfigurationError)', '(RuntimeError)']",[],"['if(not torch.cuda.is_available(), reason=)', 'if(torch.cuda.device_count()', 'if(torch.cuda.device_count()']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)', 'skipif(torch.cuda.device_count() < 2,', 'skipif(torch.cuda.device_count() < 2,']","['mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.skipif(torch.cuda.device_count() < 2,', 'mark.skipif(torch.cuda.device_count() < 2,']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1469,Santiago Castro,bryant@montevideo.com.uy,2019-06-17 14:36:19-04:00,3dc99a774b43624bd52e879e981d190f3aaf9b97,https://github.com/allenai/allennlp/commit/3dc99a774b43624bd52e879e981d190f3aaf9b97,"Add missing param in CallbackTrainer.__init__ docstring (#2960)

* Add missing param in CallbackTrainer.__init__ docstring

* Update callback_trainer.py",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1470,Mark Neumann,markn@allenai.org,2019-06-17 15:21:26-07:00,165b282b26c08084b98ef59397760b1509a9b7e2,https://github.com/allenai/allennlp/commit/165b282b26c08084b98ef59397760b1509a9b7e2,"Bert srl model (#2961)

* update write to conll script, training config

* update default predictor, add pretrained model with url

* use same env var for data name",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1471,Joel Grus,joelgrus@gmail.com,2019-06-17 15:26:31-07:00,2a8845019802df8dd354fc5197fb81e597e2eee9,https://github.com/allenai/allennlp/commit/2a8845019802df8dd354fc5197fb81e597e2eee9,update sphinx version (#2959),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1472,Evan Pete Walsh,epwalsh10@gmail.com,2019-06-18 11:27:26-07:00,2a59be3a0ff589014d15e5ff1a3c8db469f7c335,https://github.com/allenai/allennlp/commit/2a59be3a0ff589014d15e5ff1a3c8db469f7c335,"Change registered names of scheduler callbacks (#2964)

* change registered names of scheduler callbacks

* change file names

* change class names

* fix docs",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1473,Joel Grus,joelgrus@gmail.com,2019-06-18 14:43:51-07:00,a655ad521e8fb8a7a2803809cf3fad1ce584e886,https://github.com/allenai/allennlp/commit/a655ad521e8fb8a7a2803809cf3fad1ce584e886,"experimental: add backoff (#2968)

* add backoff

* use for etag

* use backoff everywhere

* pylint",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1474,Sundeep,pidugusundeep5@gmail.com,2019-06-19 03:32:27+05:18,0f1bc3b94a8098a383b8136690b6d711b267b2f7,https://github.com/allenai/allennlp/commit/0f1bc3b94a8098a383b8136690b6d711b267b2f7,"DeprecationWarning removed for op-level token_embedders (#2955)

* DeprecationWarning removed for op-level token_embedders

* removed test for DeprecationWarning

* removed old_embedder in test

* removed unused warning import

* added old_embedded to test

* Update basic_text_field_embedder_test.py

* Update basic_text_field_embedder_test.py",2,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1475,Joel Grus,joelgrus@gmail.com,2019-06-18 16:24:03-07:00,459633c9474de1dfca0976629f16beeb92e83d30,https://github.com/allenai/allennlp/commit/459633c9474de1dfca0976629f16beeb92e83d30,rename callbacks (#2966),5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1476,Brendan Roof,brendanr@allenai.org,2019-06-19 13:50:26-07:00,bcd1070094b5cbd5a241fcccb67284646fdef76b,https://github.com/allenai/allennlp/commit/bcd1070094b5cbd5a241fcccb67284646fdef76b,"Add cuda_device to Predictor.from_path (#2974)

- Fixes https://github.com/allenai/allennlp/issues/1573",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1477,Mark Neumann,markn@allenai.org,2019-06-19 17:39:56-07:00,51b74b1ace4ded076d665db55792f8d0f15966b0,https://github.com/allenai/allennlp/commit/51b74b1ace4ded076d665db55792f8d0f15966b0,"use starting offsets in the srl model so output is wellformed (#2972)

* use starting offsets in the srl model so output is wellformed

* fix bug in viterbi_decode for constrained start and end sequences

* add failing tests for srl models without viterbi constraint

* fix srl models to use start transitions for bio tagging

* lint

* fix random bug surfaced in openie predictor

* fix more openie tests

* clarify comments, PR feedback",10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['wordpieces == [,', '[wordpieces[i] for i in offsets] == []', '[wordpieces[i] for i in start_offsets] == []', 'indices[0] == 8', 'indices[-1] == 0', 'sanitize_label(']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1478,Mark Neumann,markn@allenai.org,2019-06-20 11:19:12-07:00,03aa838e078f23e985858bb01b9616ae4fc842a9,https://github.com/allenai/allennlp/commit/03aa838e078f23e985858bb01b9616ae4fc842a9,fix incorrect logging in viterbi decode (#2982),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1479,Maksym Bevza,maksym.bevza@grammarly.com,2019-06-20 21:51:14+03:00,7e08298e7d17e8037b2b325bec21733ce1e2fd20,https://github.com/allenai/allennlp/commit/7e08298e7d17e8037b2b325bec21733ce1e2fd20,"Fix wordpiece indexer truncation (#2931)

* Fix wordpiece indexer

* Add comments for test and count pieces accumulated",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8, 9]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 3, 4, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8, 9, 10]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 3, 4, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9, 11]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1480,Pradeep Dasigi,pradeepd@allenai.org,2019-06-20 14:20:52-05:00,0fbd1ca8982cb3b0cdbf94f7c03b0420687adc3d,https://github.com/allenai/allennlp/commit/0fbd1ca8982cb3b0cdbf94f7c03b0420687adc3d,"WTQ dataset reader and models moved from iterative-search-semparse (#2764)

* added dataset reader

* moved dataset reader

* moved models

* removed unnecessary except

* fixed the name of the model in docs

* change trainer_test

* minor fixes

* removed unnecessary modules

* removed unnecessary tests

* removed table knowledge graph

* removed table knowledge graph

* updated knowledge graph field test with new context

* fixed docs after removing table knowledge graph

* got the predictor tests passing

* fixed a bug in checking if data is tagged

* minor fixes

* addressed PR comments and added a test for reading untagged tables

* fixed a silly doc issue

* removed jdk dependency

* more language changes

* undid changes made for backwards compatibility

* pylint and mypy fixes

* better error raising",51,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,1,4,0,4,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,132,1,0,1,0,0,0,0,4,4,0,0,4,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],"[('RaisesRegex', '(ParsingError, ):')]","['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],"['def tearDown(self):', 'def tearDown(self):', 'def tearDown(self):', 'def tearDown(self):']",[],[],[],[],[],[],"['isinstance(instance.fields[].as_tensor({}), WikiTablesLanguage)', 'actions == [,', 'self.field.get_padding_lengths() == {: 3,', 'self.field.get_padding_lengths() == {: 3,', 'in decode_output', 'table_question_context.table_data == [{: 2001.0,', 'cell_list == 2.0', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'set(world.get_agenda()) == {,']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(entities) == 59', 'sorted(entities) == [', 'isinstance(instance.fields[].as_tensor({}), WikiTablesWorld)', 'actions == [', 'action_strings == [', 'example_info == {,', 'self.field.get_padding_lengths() == {: 3,', 'self.field.get_padding_lengths() == {: 3,', 'graph.entities == [,', 'neighbors == {}', 'neighbors == {}', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.entity_text[', 'graph.entity_text[', 'graph.entity_text[', 'graph.entities == [,', 'graph.entity_text[', 'graph.entities == [,', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.neighbors[] == []', 'graph.entity_text[', 'graph.entity_text[', 'TableQuestionKnowledgeGraph._get_cell_parts()]', 'TableQuestionKnowledgeGraph._get_cell_parts()]', 'TableQuestionKnowledgeGraph._get_cell_parts(,', 'set(parts) == {(),', 'set(parts) == {(),', 'set(parts) == {(),', 'TableQuestionKnowledgeGraph._should_split_column_cells([]) is False', 'TableQuestionKnowledgeGraph._should_split_column_cells([]) is True', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {', 'neighbors == {,', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {,', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'neighbors == {}', 'graph.entities == [,', 'numbers == [()]', 'numbers == [()]', 'numbers == [()]', 'numbers == [()]', 'numbers == [()]', 'graph.get_linked_agenda_items() == []', 'graph._get_longest_span_matching_entities() == []', 'set(world.get_agenda()) == {}', 'executor.evaluate_logical_form(logical_form, example_string) is True', 'executor.evaluate_logical_form(None, example_string) is False', 'executor.evaluate_logical_form(, example_string) is False', 'executor.evaluate_logical_form(logical_form, example_string) is False', 'valid_actions[,', 'REVERSE_TYPE.resolve(CELL_TYPE) is None', 'resolution == ReverseType(ComplexType(ROW_TYPE, CELL_TYPE), ComplexType(CELL_TYPE, ROW_TYPE))', 'resolution == ReverseType(ComplexType(ROW_TYPE, CELL_TYPE), ComplexType(CELL_TYPE, ROW_TYPE))', 'resolution == ReverseType(ComplexType(ROW_TYPE, ANY_TYPE), ComplexType(ANY_TYPE, ROW_TYPE))', 'resolution is None', ']', 'COUNT_TYPE.resolve(CELL_TYPE) is None', 'COUNT_TYPE.resolve(ComplexType(CELL_TYPE, ROW_TYPE)) is None', 'COUNT_TYPE.resolve(ComplexType(CELL_TYPE, ANY_TYPE)) == CountType(CELL_TYPE)', 'COUNT_TYPE.resolve(ComplexType(ANY_TYPE, ANY_TYPE)) == CountType(ANY_TYPE)', 'ARG_EXTREME_TYPE.resolve(ROW_TYPE) is None', 'ARG_EXTREME_TYPE.resolve(ComplexType(CELL_TYPE, ROW_TYPE)) is None', 'resolution == ArgExtremeType(CELL_TYPE)', 'set(actual_right_sides) == set(expected_right_sides)', 'set(valid_actions.keys()) == {', 'str(expression) == f', 'str(expression) == \\', 'str(expression) == f', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', ']', 'actions == target_action_sequence', 'actions == target_action_sequence', 'in actions_with_var', 'in actions_with_var', 'not in actions_without_var', 'in actions_without_var', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'in action_sequence', 'not in action_sequence_without_var', 'in action_sequence_with_var', 'parsed_logical_form == parsed_reconstructed_logical_form', 'parsed_logical_form == parsed_reconstructed_logical_form', 'logical_form == expected_logical_form', 'parsed_logical_form == parsed_reconstructed_logical_form', 'in logical_form', 'parsed_logical_form == parsed_expected_logical_form']",['(ParsingError)'],[],['(reason=)'],[],[],[],[],"['java', 'java', 'java', 'skip(reason=)']","['mark.java', 'mark.java', 'mark.java', 'mark.skip(reason=)']",[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest']"
1481,Harsh Trivedi,harshjtrivedi94@gmail.com,2019-06-20 13:15:26-07:00,cf247c6ac8d38708dd9771ee61ec6eef82ad2d13,https://github.com/allenai/allennlp/commit/cf247c6ac8d38708dd9771ee61ec6eef82ad2d13,"Add model parameters / modules inspection helper. (#2466)

* Adds inspection method on models to view parameters and modules.

* Add a test.

* Fix a typo.

* Fix another typo.

* Fix mypy and docs.

* Revert changes on model.

* Add inspect_model_parameters and tests.

* Avert circular import (for now).

* Remove extra blank lines.

* Allow modules instead of restricting to only model.

* Add a blank line.

* Allow too many lines in util_test.py

* update inspection util.

* pylint and mypy.

* Update docstring.",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['parameters_inspection_dict == util.inspect_parameters(model)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1482,wlhgtc,hgtcwl@foxmail.com,2019-06-22 01:02:46+08:00,b6a2abbfe2d4264db4e88ebb2399a8d3e031e76d,https://github.com/allenai/allennlp/commit/b6a2abbfe2d4264db4e88ebb2399a8d3e031e76d,"correct the wrong parameter note(target_namespace) (#2987)

Should be ""tokens"" rather than ""target tokens""",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1483,Tingkai Zhang,tingkai.zhang@outlook.com,2019-06-22 04:14:56+08:00,fb878721115aa8a6ab836acdb72c48eb5345c15e,https://github.com/allenai/allennlp/commit/fb878721115aa8a6ab836acdb72c48eb5345c15e,"Add never_split signature (#2463)

* fix output dimension

* add test of get_output_dim() 

add test of get_output_dim() in test_forward_works_with_projection_layer()

* add test of get_output_dim()

* add output_dim attribute 

add output_dim attribute in `ElmoTokenEmbedder`

* formatting

* Try to appease pylint

* Add never_split signature

Add ``never_split`` signature to the initialization of ``BertBasicWordSplitter``

* Update word_splitter.py

pass the parameter

* Update word_splitter.py

fix never_split

* Update word_splitter.py

fix never split

* Add never_split signature

Add never_split signature  in  `BertBasicWordSplitter`

* Add BertBasicWordSplitter test

* change the signature typing from Tuple to List

* change defaults",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == expected_tokens', 'tokens == expected_tokens']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1484,Brendan Roof,brendanr@allenai.org,2019-06-21 15:34:43-07:00,7b465c6989ddbbf9a269544e6df5f5fdbfb1afcf,https://github.com/allenai/allennlp/commit/7b465c6989ddbbf9a269544e6df5f5fdbfb1afcf,"Clarify docs for CosineWithRestarts (#2953)

- Fixes https://github.com/allenai/allennlp/issues/2388",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1485,Abhishek Sharma,abhisheksharma0318@gmail.com,2019-06-22 11:24:52+05:18,30ffaa54b66dfe85c6f6e9fa495745332466cccc,https://github.com/allenai/allennlp/commit/30ffaa54b66dfe85c6f6e9fa495745332466cccc,Removed target_token_indexers documentation (#2990),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1486,Joel Grus,joelgrus@gmail.com,2019-06-24 10:45:00-07:00,9a13ab570025a0c1659986009d2abddb2e652020,https://github.com/allenai/allennlp/commit/9a13ab570025a0c1659986009d2abddb2e652020,do not evaluate after training if non-default trainer (#2997),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1487,Pradeep Dasigi,pradeepd@allenai.org,2019-06-25 18:22:01-05:00,0a2673971ea54a77d374f797762a1012d0c05abf,https://github.com/allenai/allennlp/commit/0a2673971ea54a77d374f797762a1012d0c05abf,"Modified ActionSpaceWalker to use DomainLanguage (#3006)

* moved action space walker and lf search script from iterative search

* action space walker uses DomainLanguage

* modified script for searching nlvr logical forms

* addressed PR comments

* mypy fix",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Logs', '() as log:'), ('Equal', '(log.output,')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(black_logical_forms) == 25', 'shortest_logical_form == ', 'set(black_triangle_touch_forms[:6]) == set([', 'set(black_triangle_touch_forms[6:12]) == set([', 'set(black_triangle_touch_forms[30:33]) == set([', 'set(first_four_logical_forms) == {,', 'empty_set == []']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1488,Vikash,master.bvik@gmail.com,2019-06-26 14:16:58-04:00,9b929b289bb5220f0a8c8f21bd0c1ffc0bbca9e9,https://github.com/allenai/allennlp/commit/9b929b289bb5220f0a8c8f21bd0c1ffc0bbca9e9,"Fixes inconsistent resetting of metrics with Validate and TrackMetrics callbacks  (issue #3001) (#3002)

* Fixes inconsistent resetting of metrics with Validate and TrackMetrics callbacks: (issue #3001)

* minor PR cleanup

* pylint

* I hate you pylint and/or github editor",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics1.keys() == metrics2.keys()', 'metrics1.keys() == metrics2.keys()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1489,Sergiusz Bleja,sergiuszbleja@gmail.com,2019-06-26 23:53:11+01:00,7943b2fb231264db569cfba21e813344beff9a6a,https://github.com/allenai/allennlp/commit/7943b2fb231264db569cfba21e813344beff9a6a,Expose the spacy language model for the word splitter in the se (#3008),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1490,Joel Grus,joelgrus@gmail.com,2019-06-27 11:34:55-07:00,2cce412e7707aee5770a4a36a6835d66ef45832a,https://github.com/allenai/allennlp/commit/2cce412e7707aee5770a4a36a6835d66ef45832a,fix type in vocab config (#2977),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1491,Joel Grus,joelgrus@gmail.com,2019-06-27 15:02:26-07:00,c85dcfcf35c183d494af2af9863450d7adbc96fb,https://github.com/allenai/allennlp/commit/c85dcfcf35c183d494af2af9863450d7adbc96fb,"fix behavior when num_serialized_models_to_keep is 0 (#2880)

* fix behavior when num_serialized_models_to_keep is 0

* pylint",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not in files', 'not in files']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1492,Tom Sherborne,tr.sherborne@gmail.com,2019-06-28 14:10:11+01:00,70fa4aac3762c2de48e1123938ead2c50c0bb99c,https://github.com/allenai/allennlp/commit/70fa4aac3762c2de48e1123938ead2c50c0bb99c,Typo in initializers.py (#3016),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1493,Robert L. Logan IV,rloganiv@gmail.com,2019-06-28 14:48:18-07:00,15a9cbe57bd986ccf0845be372fa3860a33fc517,https://github.com/allenai/allennlp/commit/15a9cbe57bd986ccf0845be372fa3860a33fc517,"PassThroughIterator (#3015)

* Added PassThroughIterator

* Added test for PassThroughIterator

* Add @overrides and appease mypy.

* Appease pylint and mypy.

* Added new iterator to docs (I think...)

* Opted for simplified implementation

* Appease pylint

* Typo

* Added back in overrides decorator",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Equal', '(PassThroughIterator().get_num_batches(self.instances),'), ('Logs', '(logger, level=) as context_manager:'), ('In', '(, context_manager.output[0])'), ('Equal', '(tensor_dict[].size(), (4,))')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1494,Robert L. Logan IV,rloganiv@gmail.com,2019-06-28 15:21:26-07:00,e71618de705c7e54da325f5494c4718d50f61f58,https://github.com/allenai/allennlp/commit/e71618de705c7e54da325f5494c4718d50f61f58,"Allow option to only reset some states in _EncoderBase (#2967)

This PR adds the ability for only some states to be reset when `_EncoderBase.reset_states()` is called, which can be useful when not all sequences in a batch terminate. Closes #2828.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ValueError):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.encoder_base._states is None', 'self.encoder_base._states is None']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1495,Yn.PnG,yannzhao.ed@gmail.com,2019-07-01 18:37:10+02:00,57870f5ab29888b20882b9c9a94c7c1c1a531558,https://github.com/allenai/allennlp/commit/57870f5ab29888b20882b9c9a94c7c1c1a531558,removing unnecessary data iteration (#3027),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1496,Brendan Roof,brendanr@allenai.org,2019-07-01 11:32:44-07:00,ae72049ff170850c64df57696a73c9bb369d1652,https://github.com/allenai/allennlp/commit/ae72049ff170850c64df57696a73c9bb369d1652,"Make per-batch logging quieter. (#3020)

- Fixes https://github.com/allenai/allennlp/issues/2998",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1497,konstin,github@schuetze.link,2019-07-01 23:42:51+02:00,c2c4b64db32fcde1b88c97fc396d417ff9bd2667,https://github.com/allenai/allennlp/commit/c2c4b64db32fcde1b88c97fc396d417ff9bd2667,"Remove awscli from dependencies (#3024)

awscli is only used by a tutorial",3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1498,Pradeep Dasigi,pradeepd@allenai.org,2019-07-03 13:34:08-05:00,9e52e0f68816a2cf3ead375e3233e72fe74db6d3,https://github.com/allenai/allennlp/commit/9e52e0f68816a2cf3ead375e3233e72fe74db6d3,"Remove separate start type prediction in state machines (#3030)

* language change and no separate first action prediction

* no separate start state prediction for erm

* added metadata back

* remove separate start type prediction

* update remaining semantic parsers

* retrain fixtures and update predictor tests",22,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['instance.fields[] == question_tokens'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1499,Abhishek Sharma,abhisheksharma0318@gmail.com,2019-07-08 19:44:26+05:18,715422c7423a07dd75e7c09eb085a15db3a7ff6a,https://github.com/allenai/allennlp/commit/715422c7423a07dd75e7c09eb085a15db3a7ff6a,"Fix error in BooleanAccuracy when total count is 0 (#2991)

* Fix error when count is 0

* Update boolean_accuracy.py",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('AlmostEqual', '(accuracy.get_metric(), 0.0)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1500,Michael Schmitz,MichaelS@allenai.org,2019-07-08 13:23:51-07:00,38a10735af2f6b5a06d2114e31ce998b10988a40,https://github.com/allenai/allennlp/commit/38a10735af2f6b5a06d2114e31ce998b10988a40,Update README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1501,Michael Schmitz,MichaelS@allenai.org,2019-07-09 08:23:25-07:00,427996d44b663d120eefc598d1c3b9890c31c689,https://github.com/allenai/allennlp/commit/427996d44b663d120eefc598d1c3b9890c31c689,Fix forward in EndpointSpanExtractor (#3042),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1502,Guo Quan,guoquanscu@gmail.com,2019-07-09 10:31:49-05:00,354a19b4e62e6f51a78b06de9ccb4027ffe7401c,https://github.com/allenai/allennlp/commit/354a19b4e62e6f51a78b06de9ccb4027ffe7401c,"Update documents to sentence_splitter.py (#3023)

* Update sentence_splitter.py

Update some legacy documents that look like copied from `WordSplitter`.

* Update sentence_splitter.py",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1503,zoS3,s0327ponko@hotmail.co.jp,2019-07-10 00:32:39+09:00,64d16acffe99fe2beebd0e3629abec297005b24d,https://github.com/allenai/allennlp/commit/64d16acffe99fe2beebd0e3629abec297005b24d,fix shape comments (#3025),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1504,Pradeep Dasigi,pradeepd@allenai.org,2019-07-09 16:19:48-05:00,0663e0bb6570a59f36e9c7862d0f0bd33d46110a,https://github.com/allenai/allennlp/commit/0663e0bb6570a59f36e9c7862d0f0bd33d46110a,"Fixes to ERM decoding script (#3041)

* fixes to erm decoding script

* changed variable name",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1505,Joel Grus,joelgrus@gmail.com,2019-07-09 15:26:40-07:00,dd3476f1c825cc0810ca485bed5692f04917b04b,https://github.com/allenai/allennlp/commit/dd3476f1c825cc0810ca485bed5692f04917b04b,"simplify callback trainer (#3029)

* simplify

* simplify

* moving average as callback

* rename callbacks()

* simplify

* update comments",16,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1506,Barun Patra,codedecde@users.noreply.github.com,2019-07-09 18:44:37-07:00,a33436db02b74d4ef88732b3401f92098d19d24d,https://github.com/allenai/allennlp/commit/a33436db02b74d4ef88732b3401f92098d19d24d,"Multilabel bug (#3021)

- Fixes #2415
- Basically we don't check the configuration errors if labels is empty",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1507,Mark Neumann,markn@allenai.org,2019-07-10 15:27:29+02:00,c22ed57a40340adefa08b5d06ac0a0253a3cb3ac,https://github.com/allenai/allennlp/commit/c22ed57a40340adefa08b5d06ac0a0253a3cb3ac,"Spacy token indexer (#3040)

* add a tokenizer to ud

* add spacy indexer

* allow token_indexers to specify their own type

* dumb hack to allow a whitespace spacy tokenizer...

* pass through token embedder

* add ndarray to TokenType, tests for pass through embedder

* add doc

* remove todo, test

* fix docs

* why is this test flaky

* fix the correct test

* add as_padded_tensor method

* better place for depreciation stuff

* add warning for calling inherited get_padding_token

* ignore type for backward compatability

* mattg comments

* pylint",31,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['padded_tokens[].tolist() == [[1, 2, 3, 4, 5, 0, 0, 0, 0, 0],', 'padded[].tolist() == [[2, 3, 3, 4, 5, 6, 7, 8, 0, 0],', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'padded_tokens[].tolist() == expected_padded_tokens', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'len(array_dict[]) == 5', 'len(array_dict[][0]) == 96', 'list(array_dict[].shape) == [5, 96]', 'embedder.get_output_dim() == 3']",[],[],[],[],[],[],[],[],[],[],[],[],"['padded_tokens == {: [[1, 2, 3, 4, 5, 0, 0, 0, 0, 0],', 'padded == {: [[2, 3, 3, 4, 5, 6, 7, 8, 0, 0],', 'indexer.get_padding_token() == 0', 'padded_tokens == {: [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]}', 'padded_tokens[] == expected_padded_tokens', 'indexer.get_padding_token() == 0', 'padded_tokens == {: [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]}', 'indexer.get_padding_token() == 0', 'padded_tokens == {: [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]}', 'padded_tokens == {: [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]}']",[],[],[],[],[],[],[],[],[],[],[],[]
1508,Guo Quan,guoquanscu@gmail.com,2019-07-10 14:28:52-05:00,ebe9113938cc462519a278a5ec4bc1ed21b8d8e9,https://github.com/allenai/allennlp/commit/ebe9113938cc462519a278a5ec4bc1ed21b8d8e9,"Add options for focal loss (#3036)

* Add options for focal loss

Add focal loss to deal with class imbalance

* Fix some typing problems

* Update util.py

* Update util.py

* Update util.py

* Fix too long lines

* Fix keyword argument alert

* Update util.py

* Update util.py

* Fix a problem focal loss not activated

* Add test for focal loss gamma

* Fix some problem with decimal precision problems

* Add focal loss alpha test

* Update util_test.py

* Update util.py

* Update util_test.py

* Address some pylint and mypy problems

* Update util.py

* Update util.py

* Update util.py

* Update util.py

* Update util_test.py

* Update util_test.py

It was in the wrong place. Sorry.

* restore not-callable after torch.tensor()

* Update util_test.py

For more clear cross_entropy formulation

* Update util.py

Combine everything into `weights` and avoid reference to local variables later.

* Update util_test.py

Add `@flaky` also to token-average tests.

* Update util.py

Avoid involving `gamma` or `alpha` in average.

* Update util_test.py

* Update util_test.py

More tolerance to token average so the change it complaint < 1/1000.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1509,Joel Grus,joelgrus@gmail.com,2019-07-11 09:38:46-07:00,5c64f9d01ef39e3398372ebe4f19f864691679c0,https://github.com/allenai/allennlp/commit/5c64f9d01ef39e3398372ebe4f19f864691679c0,warn about truncation only once (#3052),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1510,Barun Patra,codedecde@users.noreply.github.com,2019-07-12 16:27:17-07:00,083f3430b8cee77e3c1c553f4cba70ad8f3594b1,https://github.com/allenai/allennlp/commit/083f3430b8cee77e3c1c553f4cba70ad8f3594b1,"Lr scheduler bug (#2905)

Fixes #2895 
Couple of things that I would like to discuss

- Currently, the design makes it necessary to specify the mode while using the reduce_on_plateau scheduler, unless its specified in a trainer (in which case the mode is set automatically, based on the validation metric)
- If the metric and the mode do not match, currently the code uses a logger.warning instead of an exception. Can change that to be an exception.",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ConfigurationError) as context:'), ('Logs', '(logger=):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in str(context.exception)', 'trainer._learning_rate_scheduler.lr_scheduler.mode == correct_mode', 'trainer._learning_rate_scheduler.lr_scheduler.mode == correct_mode', 'trainer._learning_rate_scheduler.lr_scheduler.mode == mode', 'trainer._learning_rate_scheduler.lr_scheduler.mode == mode']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1511,Mark Neumann,markn@allenai.org,2019-07-15 15:35:37+01:00,1cd21937b4b3191edecb6998122f2377edb16b3a,https://github.com/allenai/allennlp/commit/1cd21937b4b3191edecb6998122f2377edb16b3a,"Revert ""Lr scheduler bug"" (#3065)

This reverts commit 083f3430b8cee77e3c1c553f4cba70ad8f3594b1.",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('Raises', '(ConfigurationError) as context:'), ('Logs', '(logger=):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in str(context.exception)', 'trainer._learning_rate_scheduler.lr_scheduler.mode == correct_mode', 'trainer._learning_rate_scheduler.lr_scheduler.mode == correct_mode', 'trainer._learning_rate_scheduler.lr_scheduler.mode == mode', 'trainer._learning_rate_scheduler.lr_scheduler.mode == mode']",[],[],[],[],[],[],[],[],[],[],[],[]
1512,Mark Neumann,markn@allenai.org,2019-07-16 16:08:14+01:00,ec30c9021bdbf85099b3556e5a5d270124c494c8,https://github.com/allenai/allennlp/commit/ec30c9021bdbf85099b3556e5a5d270124c494c8,"remove dropout from test fixtures (#2889)

* remove dropout from test fixtures

* last bit of dropout in naqanet",26,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1513,Pradeep Dasigi,pradeepd@allenai.org,2019-07-16 15:21:04-07:00,7728b12f7af4177c7d150be328b905f0d11df70e,https://github.com/allenai/allennlp/commit/7728b12f7af4177c7d150be328b905f0d11df70e,"Minor WTQ ERM model and  dataset reader fixes for demo (#3068)

* model dataset reader fixes for demo

* fixed a typo

* mypy ignore

* make mypy happy",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1514,Eric Wallace,eswallace@comcast.net,2019-07-17 08:53:10-07:00,9166c18439eb30cea4f668d113066e2ed6cb86eb,https://github.com/allenai/allennlp/commit/9166c18439eb30cea4f668d113066e2ed6cb86eb,"AllenNLP Interpret Basic Version (#3032)

* AllenNLP Interpret basic working version

* upd simple gradient

* three more predictors that handle Interpret

* missing imports

* add attackers

* cleanup input reduction once more

* add hotflip

* cleanup hotflip more

* handle sst in the basic text classifier

* clean up pylint a bit

* add a bit more documentation

* remove util function

* 4 spaces for formatting

* named entity change variable names

* add more comments, formatting, type annotations

* some pylint things

* clean up and add more comments

* remove trailing spaces

* add copy

* more cleanup

* comments

* simplify embedder for hotflip

* forgot batch dim

* more comments for hotflip

* reorganizer directories per matt

* add tests

* rename to attackers and saliency_interpreters

* add init for tests

* pass on pylint

* wrong function def

* rename tests and slight modifications

* fix mistake in tests

* fix mistake in tests

* reorg tests according to matt comments

* add ner test and fix pylint junk

* fix default arguments

* change attack_from_json and pylint errors

* missing imports

* more pylint crap

* address matts readability x2

* fix mypy issues

* more mpyy stuff

* syntax error

* upd

* more mypy cleaning

* more mypy issues

* forgot an s

* fixing teamcity

* readability

* more cleaning up

* address matt comments

* address comments

* clean up the attackers substantially

* outputs not output in test

* add deepcopy inside predictions_to_labels

* move helper to utils

* add attacks util

* add an input reduction ner test

* another clean of pylinter

* redo token selection

* docs work now

* fix pylint

* address matts comments

* matt see this

* maybe like this

* fix smooth gradient

* fix import stuff

* almost there?

* upd

* final?

* more stupid mypy errors

* this will never end

* why doesnt enumerate work?

* idk

* fix mypy

* pylint and docs

* formatting and minor cleanup

* naqanet tests (found and fixed a bug)

* pylint

* more pylint",41,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['attack is not None', 'in attack', 'in attack', 'in attack', 'len(attack[]) # hotflip replaces words without removing', 'reduced is not None', 'in reduced', 'in reduced', 'reduced[][0] # always at least one token', 'len(reduced[]) # input reduction removes tokens', 'word in reduced[]', 'reduced is not None', 'in reduced', 'in reduced', 'reduced_input # always at least one token', 'len(reduced_input) <= len(reduced[]) # input reduction removes tokens', 'word in reduced[]', 'interpretation is not None', 'in interpretation', ']', 'len(grad_input_1) == 7  # 7 words in input', 'grad == approx(repeat_grad)', 'interpretation is not None', 'in interpretation', ']', 'len(grad_input_1) == 7  # 7 words in input', 'grad == approx(repeat_grad)', 'interpretation is not None', 'in interpretation', ']', 'len(interpretation[]) == 7  # 7 words in input', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'new_instances[0].fields[] is not None', 'len(new_instances) == 1', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'len(new_instances) == 1', 'new_instances[0][][0].label == 2', 'new_instances[0][][0] == (0, 1)  # token indices', 'new_instances[0][][0].labels == [2, 0, 0]', 'new_instances[0][][0] == (0, 1)  # token indices', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'new_instances[0].fields[] is not None', 'len(new_instances) == 1', 'in grads', 'in grads', 'grads[] is not None', 'grads[] is not None', 'len(grads[]) == 9  # 9 words in hypothesis', 'len(grads[]) == 5  # 5 words in premise', 'len(new_instances) > 1', 'in new_instance', 'len(new_instance[]) == 7 # 7 words in input', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'len(new_instances) == 1']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1515,Ilya,iliyadimov@icloud.com,2019-07-17 20:15:11+03:00,014fe3187d7314f2de3970943db5a8870ad5881b,https://github.com/allenai/allennlp/commit/014fe3187d7314f2de3970943db5a8870ad5881b,"Improve dict missing key code (#3071)

* Improve dict missing key code

* remove trailing whitespace",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1516,Eric Wallace,eswallace@comcast.net,2019-07-17 14:28:38-07:00,5014d022ef62ce1633f610d20e564d539138ff78,https://github.com/allenai/allennlp/commit/5014d022ef62ce1633f610d20e564d539138ff78,remove deprecated function call in hotflip (#3074),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1517,Eric Wallace,eswallace@comcast.net,2019-07-18 09:46:13-07:00,a1476c0414ad1e1412515c53d9e1f27b69039ead,https://github.com/allenai/allennlp/commit/a1476c0414ad1e1412515c53d9e1f27b69039ead,"add equality check for index field; allennlp interpret (#3073)

* add equality check for index field; allennlp interpret

* add test

* change hotflip to use equals method

* tests per matt

* newline

* change input reduction to eq also

* undo

* add newline

* fix pylutn",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['index_field1 == index_field2', 'index_field1 != index_field3', 'index_field2 != index_field3', 'index_field3 == index_field3', 'attack is not None', 'in attack', 'in attack', 'in attack', 'len(attack[]) # hotflip replaces words without removing', 'instance[][0] # check that the input has changed.', 'token in attack[][0] # ignore tokens should not be changed', 'original_span_start != flipped_span_start or original_span_end != flipped_span_end']",[],[],[],[],[],[],[],[],[],[],[],[],['index_field1 != index_field2'],[],[],[],[],[],[],[],[],[],[],[],[]
1518,Evan Pete Walsh,epwalsh10@gmail.com,2019-07-18 12:13:11-07:00,9ed9e2c83ce6e97fb022a6a5efab15c0c35ce3ae,https://github.com/allenai/allennlp/commit/9ed9e2c83ce6e97fb022a6a5efab15c0c35ce3ae,remove executable permission for submods (#3080),7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1519,Muhammed Yavuz Nuzumlal,manuyavuz@gmail.com,2019-07-19 11:19:21-04:00,88a61e137fa150d08203ad03d022ffab3f6f7fae,https://github.com/allenai/allennlp/commit/88a61e137fa150d08203ad03d022ffab3f6f7fae,[Embedding] Forward given padding_index param to embedding() (#2504),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1520,Evan Pete Walsh,epwalsh10@gmail.com,2019-07-19 15:05:56-07:00,428c1511e6b9fe953edeea8bbd07253c7a43f296,https://github.com/allenai/allennlp/commit/428c1511e6b9fe953edeea8bbd07253c7a43f296,fix MetadataField.batch_tensors (#3084),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1521,David Fidalgo,david@recogn.ai,2019-07-20 02:38:43+02:00,30c4271f7f04babb1cb546ab017a104bda011e7c,https://github.com/allenai/allennlp/commit/30c4271f7f04babb1cb546ab017a104bda011e7c,"Close tensorboard's event files properly at the end of the training (#3085)

* add a tensorboard close call at the end of the training

* add tensorboard.close call to the callback trainer

* make pylint happy

* make sphinx happy (I hope)",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1522,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2019-07-24 17:46:07+02:00,417a75727d4604e1da0eda461b03b29a73f0bf50,https://github.com/allenai/allennlp/commit/417a75727d4604e1da0eda461b03b29a73f0bf50,"Adding ability to choose validation DatasetReader with ""predict"" (#3033)

* Fixing name of default ATIS predictor

* Enabling using the validation DatasetReader with the 'predict' command

* Adding test case without any DatasetReader

* Adding a 'dataset_reader_to_load' option to 'Predictor.from_path'

* Removing unused import

* Changing validation to be the default dataset reader; Adding flag to override dataset reader choice

* Fixing documentation",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(NotImplementedError):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(self.outfile)', 'results[0][] is True', 'os.path.exists(self.outfile)', 'results[0][] is False', 'os.path.exists(self.outfile)', 'results[0][] is True', 'predictor._dataset_reader._keep_if_unparseable is True', 'predictor._dataset_reader._keep_if_unparseable is False', 'predictor._dataset_reader._keep_if_unparseable is True']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1523,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2019-07-29 17:30:17+02:00,0caf3640155ec5a300939d122270c5d4debb3788,https://github.com/allenai/allennlp/commit/0caf3640155ec5a300939d122270c5d4debb3788,Adding cached_path to input file of the predictor (#3098),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1524,Sundeep,pidugusundeep5@gmail.com,2019-07-29 20:50:36+05:18,031bbf956b1cb6540660874e9e44a645dced9ca2,https://github.com/allenai/allennlp/commit/031bbf956b1cb6540660874e9e44a645dced9ca2,"allenNLP broken link (#3086)

* allenNLP broken link

fix

* AI2 link update",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1525,Evan Pete Walsh,epwalsh10@gmail.com,2019-07-29 08:33:40-07:00,6746d12c51e26ea25c326b40cda4bcf4109b808d,https://github.com/allenai/allennlp/commit/6746d12c51e26ea25c326b40cda4bcf4109b808d,"pass cache_directory and cache_prefix to non-default trainers (#3077)

* pass cache_directory and prefix to other trainers

* fixes",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1526,Emil Stenstrm,em@kth.se,2019-08-06 19:58:04+02:00,9db004224adf74267cc923d45e8ecb22b53d7066,https://github.com/allenai/allennlp/commit/9db004224adf74267cc923d45e8ecb22b53d7066,"Upgrade conllu from 0.11 to 1.3.1 (#3115)

* Upgrade to latest version of conllu.

* Elided tokens are no longer None, use isinstance.

https://github.com/EmilStenstrom/conllu/wiki/Migrating-from-0.1-to-1.0#parsing-of-ids-now-include-ranges-and-decimals

* No need to cast to int, ids are already ints now.

https://github.com/EmilStenstrom/conllu/wiki/Migrating-from-0.1-to-1.0#parsing-of-ids-now-include-ranges-and-decimals

* Incremental parsing is built into conllu.

See Advanced usage under https://github.com/EmilStenstrom/conllu#use-parse-to-parse-into-a-list-of-sentences",4,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1527,Joel Grus,joelgrus@gmail.com,2019-08-08 10:36:45-07:00,0be4b4889512e9bda083031925f140433cd23de6,https://github.com/allenai/allennlp/commit/0be4b4889512e9bda083031925f140433cd23de6,fix UpdateMovingAverage.from_params (#3126),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1528,Joel Grus,joelgrus@gmail.com,2019-08-08 14:38:10-07:00,23a089c8c49fc834a1406333131066bbb6d50076,https://github.com/allenai/allennlp/commit/23a089c8c49fc834a1406333131066bbb6d50076,"pin pytorch away from 1.2 until we fix the tests (#3128)

* pin pytorch away from 1.2 until we fix the tests

* disable flaky test

* remove unused import",3,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],[],[],[],[],['if(spacy.__version__ < )'],[],[],[],[],['skipif(spacy.__version__ < )'],['mark.skipif(spacy.__version__ < )'],[],[],[]
1529,Bai Li,luckytoilet@users.noreply.github.com,2019-08-12 15:28:06-04:00,9093f475ff4ee35df6301c714d034f9c833a8566,https://github.com/allenai/allennlp/commit/9093f475ff4ee35df6301c714d034f9c833a8566,"Add dropout option for BERT Pooler (#3109)

* Add dropout option for BERT Pooler

* Change order of arguments",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1530,Santiago Castro,sacastro@umich.edu,2019-08-12 17:23:59-04:00,f9e2029fec4c66c751cad05be3dfb32a47dbe643,https://github.com/allenai/allennlp/commit/f9e2029fec4c66c751cad05be3dfb32a47dbe643,"Update HTTP links to HTTPS where possible (#3142)

* Update HTTP links to HTTPS where possible

* Fix line too long",38,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1531,Matt Gardner,mattg@allenai.org,2019-08-13 09:11:47-06:00,217022f491231ffedb82e82d27a25cb0c3d7104b,https://github.com/allenai/allennlp/commit/217022f491231ffedb82e82d27a25cb0c3d7104b,"Adding a PretrainedTransformerTokenizer (#3145)

* Adding a PretrainedTransformerTokenizer

* pylint

* doc",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['tokens == expected_tokens'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1532,Joel Grus,joelgrus@gmail.com,2019-08-13 10:13:49-07:00,bf968c6958e486bee9f008a221778e8c37b77245,https://github.com/allenai/allennlp/commit/bf968c6958e486bee9f008a221778e8c37b77245,"add keep_as_dict option to Params.pop, use in Vocab and automat (#3075)

* add keep_as_dict

* remove unnecessary test",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(a.counts, dict)', 'not isinstance(a.counts, Params)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1533,Ethan Shea,ethan.shea1@gmail.com,2019-08-13 10:14:14-07:00,0bd331942d824f5072bf7b6adffb1172f6ffe507,https://github.com/allenai/allennlp/commit/0bd331942d824f5072bf7b6adffb1172f6ffe507,Add regularization parameter to Models (#3120),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1534,Vivek Lakshmanan,vivekl@allenai.org,2019-08-13 11:41:58-07:00,fa1ff674119e20434138fee2c2eb1d3fa2e4afdb,https://github.com/allenai/allennlp/commit/fa1ff674119e20434138fee2c2eb1d3fa2e4afdb,"Add support for running preemptible workloads on beaker (#3143)

* Add support for running preemptible workloads on beaker

* Fix boolean

* Move resumable_train script to scripts/ai2-internal",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1535,Matt Gardner,mattg@allenai.org,2019-08-13 14:17:40-06:00,f111d8a77f6b98c23efd04bec016adcc397887b6,https://github.com/allenai/allennlp/commit/f111d8a77f6b98c23efd04bec016adcc397887b6,"Pretrained transformer indexer (#3146)

* wip

* Added an indexer for pretrained transformers

* doc

* pylint, mypy

* Missing import...",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexer1 == indexer2', 'indexed[] == expected_ids']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1536,Darrell Plessas,dplessas@gmail.com,2019-08-13 14:18:09-07:00,1d6e16675732e8398eccbb488dbc8362daaeca0e,https://github.com/allenai/allennlp/commit/1d6e16675732e8398eccbb488dbc8362daaeca0e,"Fixing Conda download and install link on Readme (#3151)

Old link returns a 404 now, updating to new doc location",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1537,Michael Schmitz,MichaelS@allenai.org,2019-08-13 16:34:06-07:00,3ef43c9677ba1a06a533fe30779c3cadccae016e,https://github.com/allenai/allennlp/commit/3ef43c9677ba1a06a533fe30779c3cadccae016e,"Upgrade minimum spacy to 2.1.0 (#3152)

* Upgrade minimum spacy to 2.1.0

* Fix in setup.py too.",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1538,Bai Li,luckytoilet@users.noreply.github.com,2019-08-14 17:28:30-04:00,6bbf82efd33d424255ff725a43cd9d53fcf0307f,https://github.com/allenai/allennlp/commit/6bbf82efd33d424255ff725a43cd9d53fcf0307f,Move matplotlib import into function (#3157),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1539,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2019-08-15 20:12:41+02:00,dac486ef49622f385ac478006a8e9d6de85fbe13,https://github.com/allenai/allennlp/commit/dac486ef49622f385ac478006a8e9d6de85fbe13,Fixing NaN warning with single element tensors (#3158),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1540,David Wadden,dwadden@cs.washington.edu,2019-08-15 11:12:57-07:00,111db19d041c960da308f39d1b027eebc00b415a,https://github.com/allenai/allennlp/commit/111db19d041c960da308f39d1b027eebc00b415a,"Create method to save instances to cache file. (#3131)

Allows other dataset readers to override, e.g. to use pickle instead of
jsonpickle.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1541,Martin Schmitt,mnschmit@users.noreply.github.com,2019-08-15 19:14:06+01:00,770791a2045d960beaf4e64db867f51e6021afb6,https://github.com/allenai/allennlp/commit/770791a2045d960beaf4e64db867f51e6021afb6,"switch for DataIterators whether smaller batches should be skipped (#3140)

* added a switch to bucket_iterator whether batches smaller than batch_size should be skipped

* added documentation for the new switch

* added the switch also to `HomogeneousBatchIterator`

* added unit tests for bucket and homogeneous iterator",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not iterator._skip_smaller_batches', 'iterator._skip_smaller_batches', 'all(batch_len == 2 for batch_len in stats[])', 'stats[] == len(self.instances) - 1', 'len(batch[]) == 3']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1542,Santiago Castro,santi.1410@hotmail.com,2019-08-16 10:03:49-04:00,8fffd831b87235cfd3767bf63ff92729c22c61c3,https://github.com/allenai/allennlp/commit/8fffd831b87235cfd3767bf63ff92729c22c61c3,Add missing train command cache options (#3160),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1543,Nelson Liu,nelson-liu@users.noreply.github.com,2019-08-19 13:33:24-04:00,adad1bc34f4b250942a1a058c73b42db3168c15d,https://github.com/allenai/allennlp/commit/adad1bc34f4b250942a1a058c73b42db3168c15d,"Switch SemanticRoleLabeler metric to SrlEvalScorer. (#3164)

* Switch SemanticRoleLabeler metric to SrlEvalScorer.

* Switch back to https links, per f9e2029

* Add ignore_classes to SrlEvalScorer and ignore V in SRL model

* Enable specifying path to srl-eval.pl

* Only run span metric if it is enabled, and during evaluation

* Add comment explaining ignore_classes

* Add doc for srl_util

* Add srl_util.rst to allennlp.models.rst

* Fix position of comment",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(metrics) == 15', 'len(metrics) == 9']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(metrics) == 18', 'len(metrics) == 12']",[],[],[],[],[],[],[],[],[],[],[],[]
1544,Nelson Liu,nelson-liu@users.noreply.github.com,2019-08-19 14:09:08-04:00,0f6b3b891f8110d874687e4e039cae6e7aaa7b33,https://github.com/allenai/allennlp/commit/0f6b3b891f8110d874687e4e039cae6e7aaa7b33,"Make SrlBert model use SrlEvalMetric (#3168)

* Switch SemanticRoleLabeler metric to SrlEvalScorer.

* Switch back to https links, per f9e2029

* Add ignore_classes to SrlEvalScorer and ignore V in SRL model

* Enable specifying path to srl-eval.pl

* Only run span metric if it is enabled, and during evaluation

* Add comment explaining ignore_classes

* Add doc for srl_util

* Add srl_util.rst to allennlp.models.rst

* Fix position of comment

* Use SrlEvalMetric in SrlBert",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1545,Will Kearns,kearnsw@users.noreply.github.com,2019-08-19 12:54:33-07:00,b6af6ebf8ab4f541e4da5b110344659d34597568,https://github.com/allenai/allennlp/commit/b6af6ebf8ab4f541e4da5b110344659d34597568,"bug fix for default tokenization of knowledge graph entities (#3170)

* bug fix for default tokenization of knowledge graph entities

* pylint fix",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(str(e), pytrace=True)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1546,Santiago Castro,sacastro@umich.edu,2019-08-19 15:54:43-04:00,e641543ef9d293ee61570ba569a9699a98bd3eab,https://github.com/allenai/allennlp/commit/e641543ef9d293ee61570ba569a9699a98bd3eab,"Add a test for the subcommands docstring help outputs (#3172)

* Add a test for the subcommands docstring help outputs

* Fix subcommands help outputs in their module docstrings

* Fix a PR comment",12,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Equal', '(expected_output, actual_output, f'), ('In', '(module_info.name, [parent_module.__name__ + ],')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1547,JackKuo666,41313632+JackKuo666@users.noreply.github.com,2019-08-21 02:31:14+08:00,18daa2983cec7675be6c8fc6e8784693b4b53b2b,https://github.com/allenai/allennlp/commit/18daa2983cec7675be6c8fc6e8784693b4b53b2b,"Fix pearson correlation.py (#3101)

* fix bug: ZeroDivisionError: float division by zero

Since the input tensor may be, for example, a tensor ([[0.,0.,0.,0.],
[0.,0.,0.,0. ]), there will be a case where (math.sqrt(predictions_variance) or math.sqrt(labels_variance)) is zero, so a judgment is added here to prevent the denominator from being zero. If it is zero, the denominator is assigned a value of 1.

* fix bug: ZeroDivisionError: float division by zero

Since the input tensor may be, for example, a tensor ([[0.,0.,0.,0.],
[0.,0.,0.,0. ]), there will be a case where (math.sqrt(predictions_variance) or math.sqrt(labels_variance)) is zero, so a judgment is added here to prevent the denominator from being zero. If it is zero, the denominator is assigned a value of 1.

* fix bug: ZeroDivisionError: float division by zero 

Since the input tensor may be, for example, a tensor ([[0.,0.,0.,0.],
[0.,0.,0.,0. ]), there will be a case where (math.sqrt(predictions_variance) or math.sqrt(labels_variance)) is zero, so a judgment is added here to prevent the denominator from being zero. If it is zero, the pearson_r is assigned a value of 0.

* fix bug: ZeroDivisionError: float division by zero 

Since the input tensor may be, for example, a tensor ([[0.,0.,0.,0.],
[0.,0.,0.,0. ]), there will be a case where (math.sqrt(predictions_variance) or math.sqrt(labels_variance)) is zero, so a judgment is added here to prevent the denominator from being zero. If it is zero, the pearson_r is assigned a value of 0.

* fix some  pylint things

fix some  pylint things

* Update pearson_correlation.py

* Update pearson_correlation_test.py

* Update pearson_correlation_test.py",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1548,Hunt Zhan,huntzhan.dev@gmail.com,2019-08-21 06:28:40+08:00,7bacfad56728080686bd0bfd3016b2849bac5085,https://github.com/allenai/allennlp/commit/7bacfad56728080686bd0bfd3016b2849bac5085,"Set pytorch-transformer to 1.1.0 (#3171)

* Update setup.py

* Update requirements.txt",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1549,Pradeep Dasigi,pradeepd@allenai.org,2019-08-21 09:51:59-07:00,9d8d36af18a8a97bea7f08604eed500abb0c7ae3,https://github.com/allenai/allennlp/commit/9d8d36af18a8a97bea7f08604eed500abb0c7ae3,"quoref metric and evaluator (#3153)

* quoref metric and evaluator

* added tests and sample data files

* missing prediction

* take predictions in simple format too

* added a test and fixed docs

* test running as a script

* removed metric file for quore and added more comments

* removed old import",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics == (0.5, 0.625)', 'metrics == (1.0, 1.0)', 'result == 0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1550,Joel Grus,joelgrus@gmail.com,2019-08-21 10:17:31-07:00,c8d732706df7e709ed515243db91f466ab058503,https://github.com/allenai/allennlp/commit/c8d732706df7e709ed515243db91f466ab058503,bump version number to v0.8.5,5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1551,Joel Grus,joelgrus@gmail.com,2019-08-21 10:48:41-07:00,112d8d0b53016ce1e850786aa47a8438cc8409fd,https://github.com/allenai/allennlp/commit/112d8d0b53016ce1e850786aa47a8438cc8409fd,Bump version numbers to v0.9.0-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1552,Swabha Swayamdipta,swabha@cs.cmu.edu,2019-08-21 15:48:32-07:00,817814bfa3e75f6845165170a961b659ec7ff78c,https://github.com/allenai/allennlp/commit/817814bfa3e75f6845165170a961b659ec7ff78c,"Update documentation for bert_pooler.py (#3181)

* Update documentation for bert_pooler.py

Documenting that the BertPooler actually returns just the [CLS] token from the BERT paper, followed by a non-linear transformation.

* Update bert_pooler.py",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1553,skeshaw,skeshaw@outlook.com,2019-08-22 23:32:54+05:18,ce6dc7263e9bda268261ac2b297a2f78f830fd5c,https://github.com/allenai/allennlp/commit/ce6dc7263e9bda268261ac2b297a2f78f830fd5c,"Add example of initializing weights from pretrained model to doc (#3188)

* Modify docstring with example for loading a pretrained model

The docstring for a `pretrained` initializer currently provides examples for loading weights for specific named parameters from a pretrained model.
Added example elaborating how to resume training from a pretrained checkpoint for all the weights, without explicitly naming each of them.

* Fix indentation

* Fix indentation

* Fix indentation with code block",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1554,Nelson Liu,nelson-liu@users.noreply.github.com,2019-08-22 16:52:05-04:00,7738cb586a08161bf49275740b27975213a0e16d,https://github.com/allenai/allennlp/commit/7738cb586a08161bf49275740b27975213a0e16d,"Add exist_ok parameter to registrable.register decorator. (#3190)

* Add exist_ok parameter to registrable.register decorator.

* Fix pylint.

* Fix pylint.

* Add docstring for registrable.register.

* Add a space to appease pylint.

* Switch if not exist_ok to else.

* Switch to fstrings.

* Change logger.debug to logger.info",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['base_class.by_name() == FakeAlternate'],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1555,Nelson Liu,nelson-liu@users.noreply.github.com,2019-08-23 16:59:28-04:00,155a94e5c0e67a3d98ca587a736b3b8cbe24f484,https://github.com/allenai/allennlp/commit/155a94e5c0e67a3d98ca587a736b3b8cbe24f484,Add DropEmAndF1 metric to __init__.py (#3191),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1556,Joel Grus,joelgrus@gmail.com,2019-08-23 17:23:09-07:00,23efadd9a394d9d69e10e8539a7332665b118df0,https://github.com/allenai/allennlp/commit/23efadd9a394d9d69e10e8539a7332665b118df0,"upgrade to pytorch 1.2 (#3182)

* first attempt at pytorch 1.2

* explicit is better than implicit

* more explicit

* attempt to fix flaky tests

* pylint

* no disable dropout

* disable dropout by default

* restore dropout, don't deepcopy

* change batch size for biaffine_dependency_parser_multilang_test, maybe that will make it pass? :(

* try batch size 10

* ignore bad gradient parameter

* cleanup",18,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1557,Nelson Liu,nelson-liu@users.noreply.github.com,2019-08-26 12:27:22-04:00,0e872a0d22dd7d3476e14d6c03c1e7d63960250b,https://github.com/allenai/allennlp/commit/0e872a0d22dd7d3476e14d6c03c1e7d63960250b,Clarify that scalar_mix_parameters takes unnormalized weights (#3198),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1558,yanaiela,yanaiela@gmail.com,2019-08-27 01:57:18+03:00,fb9a97180383d3d6f18be29bd7908ffb4014fb43,https://github.com/allenai/allennlp/commit/fb9a97180383d3d6f18be29bd7908ffb4014fb43,"code for mixed bert embedding layers (#3199)

* code for mixed bert embedding layery

* copying newest docstring for better explaining scalar_mix_parameters param",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1559,Matt Gardner,mattg@allenai.org,2019-08-26 16:09:46-07:00,6ec74aafca7b76c24571cfecd8c54cb3a40da5e4,https://github.com/allenai/allennlp/commit/6ec74aafca7b76c24571cfecd8c54cb3a40da5e4,Added a TokenEmbedder for use with pytorch-transformers,3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tuple(output.size()) == (1, 4, 768)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1560,Matt Gardner,mattg@allenai.org,2019-08-26 16:44:31-07:00,195bf0c368ec4369620f4c16b4c915fb456418f0,https://github.com/allenai/allennlp/commit/195bf0c368ec4369620f4c16b4c915fb456418f0,override method,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1561,Matt Gardner,mattg@allenai.org,2019-08-26 16:44:51-07:00,ed93e5235df6833990a625a79b70bea358fda811,https://github.com/allenai/allennlp/commit/ed93e5235df6833990a625a79b70bea358fda811,pylint,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1562,Matt Gardner,mattg@allenai.org,2019-08-26 17:03:26-07:00,70e92e859576813fe7f61fd961f62bb4254693ee,https://github.com/allenai/allennlp/commit/70e92e859576813fe7f61fd961f62bb4254693ee,doc,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1563,Matt Gardner,mattg@allenai.org,2019-08-26 18:21:29-06:00,993034f02078c881b737d4903b7b5bed53ead1e8,https://github.com/allenai/allennlp/commit/993034f02078c881b737d4903b7b5bed53ead1e8,Minor fixes so PretrainedTransformerIndexer works with roberta (#3203),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1564,Ana,anam@allennlp-server4.corp.ai2,2019-08-26 17:38:02-07:00,6e1e3713155c74e041cde8bb8f23535b5c84ec9c,https://github.com/allenai/allennlp/commit/6e1e3713155c74e041cde8bb8f23535b5c84ec9c,"Revert ""Merge branch 'matt-gardner-transformer-embedder'""

This reverts commit 4c7fa73769b8c6765bdd68041db2e250d658d69f, reversing
changes made to 993034f02078c881b737d4903b7b5bed53ead1e8.",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tuple(output.size()) == (1, 4, 768)']",[],[],[],[],[],[],[],[],[],[],[],[]
1565,Ana,anam@allennlp-server4.corp.ai2,2019-08-26 18:46:32-07:00,030e28c9e11d85ab674442d635d0e2f66548f211,https://github.com/allenai/allennlp/commit/030e28c9e11d85ab674442d635d0e2f66548f211,"Revert ""Revert ""Merge branch 'matt-gardner-transformer-embedder'""""

This reverts commit 6e1e3713155c74e041cde8bb8f23535b5c84ec9c.",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tuple(output.size()) == (1, 4, 768)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1566,Michael Schmitz,MichaelS@allenai.org,2019-08-27 07:48:25-07:00,1eaa1ff9ea9b2efa653327ee14da329cdba5d58b,https://github.com/allenai/allennlp/commit/1eaa1ff9ea9b2efa653327ee14da329cdba5d58b,Link to Discourse in README,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1567,Matt Gardner,mattg@allenai.org,2019-08-27 13:19:27-07:00,370d51269bc71c0fda7fadec665936e466707cdc,https://github.com/allenai/allennlp/commit/370d51269bc71c0fda7fadec665936e466707cdc,"Dataset readers for masked language modeling and next-token-language-modeling (#3147)

* Adding language modeling readers

* Added test

* Cleanup

* Test passes

* NextTokenLm test

* doc

* Revert accidental changes

* Pylint, mypy

* doc

* mypy

* Change todos to runtime errors

* pylint...",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in instance[]', '[i.sequence_index for i in instance[]] == [3]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tensor_dict[].numpy().tolist() == [2, 3, 4, 5, 6, 7]', 'tensor_dict[].numpy().tolist() == [2]', 'tensor_dict[].numpy().tolist() == [[3]]', '[t.text for t in instance[,', '[i.sequence_index for i in instance[]] == [6]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'target_ids[0] == bert_token_ids[1]', '[t.text for t in instance[]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tensor_dict[].numpy().tolist() == [2, 3, 4]', 'tensor_dict[].numpy().tolist() == [2]', '[t.text for t in instance[,', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'target_ids[0] == bert_token_ids[5]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1568,Matt Gardner,mattg@allenai.org,2019-08-27 13:21:35-07:00,8c06c4b24c8f9ed57fc0d167e5ceaa7bbd42c42a,https://github.com/allenai/allennlp/commit/8c06c4b24c8f9ed57fc0d167e5ceaa7bbd42c42a,"Adding a LanguageModelHead abstraction (#3200)

* Modules and docs

* Added tests

* Docstrings

* pylint

* moved linear layer to tests

* add todos about caching

* fix import...

* doc",11,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(head, BertLanguageModelHead)', 'head.get_input_dim() == 768', 'head.get_output_dim() == 30522', 'tuple(logits.size()) == (1, 30522)', 'isinstance(head, Gpt2LanguageModelHead)', 'head.get_input_dim() == 768', 'head.get_output_dim() == 50257', 'tuple(logits.size()) == (1, 50257)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1569,Matt Gardner,mattg@allenai.org,2019-08-28 11:46:25-07:00,d78ac70a27ced5e00ff2e51bfda424afca9e846b,https://github.com/allenai/allennlp/commit/d78ac70a27ced5e00ff2e51bfda424afca9e846b,"Language model classes for making predictions (both masked LM and next token LM) (#3201)

* Models, tests, and doc

* test fixtures

* models/__init__.py

* Fix test

* docstrings

* pylint, other cleanup

* mypy; more cleanup

* fix imports

* change runtime errors to logger.error

* pylint

* Add comment",20,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1570,Matt Gardner,mattg@allenai.org,2019-08-28 14:08:41-07:00,f2824fdcf1de60b86cf4c41f871d591c4fd4a081,https://github.com/allenai/allennlp/commit/f2824fdcf1de60b86cf4c41f871d591c4fd4a081,"Predictors for demo LMs, update for coref predictor (#3202)

* predictors for demo LMs, other fixes

* added test

* More tests

* Add missing method

* Add docstring

* Fix decode methods

* pylint, mypy

* more pylint...

* docs",12,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['new_instances is not None', 'in new_instance', 'len(new_instance[]) == 60 # 7 words in input', 'true_top_spans == pred_clust_spans', 'len(new_instances) == 1', 'in new_instances[0]', 'len(new_instances[0][].tokens) == 2  # should have added two words', 'len(new_instances) == 1', 'in new_instances[0]', 'len(new_instances[0][].tokens) == 1  # should have added one word']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1571,Matt Gardner,mattg@allenai.org,2019-08-29 10:31:15-07:00,78ee3d8532b2ec5522cce205c7221be15810ba4a,https://github.com/allenai/allennlp/commit/78ee3d8532b2ec5522cce205c7221be15810ba4a,"Targeted hotflip attacks and beam search for input reduction (#3206)

* Targeted hotflip attack, beam search for input reduction

* Adding a test

* Fix tests

* pylint, mypy, tests

* last pylint (i hope...)",11,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['span_field1 == span_field2', 'span_field1 != span_field3', 'span_field2 != span_field3', 'attack is not None', 'in attack', 'in attack', 'in attack', 'len(attack[]) # hotflip replaces words without removing', 'attack[]', 'interpretation is not None', 'in interpretation', ']', 'len(grad_input_1) == 16  # 16 words in input', 'grad == approx(repeat_grad)', 'interpretation is not None', 'in interpretation', ']', 'len(grad_input_1) == 16  # 16 words in input']",[],[],[],[],[],[],[],[],[],[],[],[],['span_field1 != span_field2'],[],[],[],[],[],[],[],[],[],[],[],[]
1572,Brendan Roof,brendanr@allenai.org,2019-08-29 12:40:19-07:00,bbaf1fc0dff3574a4cf6f8bdb5ad0713dd4f84b9,https://github.com/allenai/allennlp/commit/bbaf1fc0dff3574a4cf6f8bdb5ad0713dd4f84b9,"Benchmark iterator, avoid redundant queue, remove managers. (#3119)

- Adds a script to benchmark iterators.
  - Average speed
  - Introspects queues
- Removes a bottleneck when `MultiprocessDatasetReader` and `MultiprocessIterator` are used in conjunction.
  - Specifically, removes a redundant queue that was populated by a single process.
- Removes managers which have significant overhead.
- Results on training_config/bidirectional_language_model.jsonnet:
  - original code, no multiprocessing: 0.047 s/b over 10000 batches
  - original code, workers = 1: 0.073 s/b over 10000 batches
  - original code, workers = 10: 0.078 s/b over 10000 batches
  - this PR (-queue), workers = 1: 0.073 s/b over 10000 batches
  - this PR (-queue), workers = 10: 0.046 s/b over 10000 batches
  - this PR (-queue, - manager), workers = 1: 0.063 s/b over 10000 batches
  - this PR (-queue, - manager), workers = 10: 0.020 s/b over 10000 batches
  - Notably, previously we did not see any benefit from scaling to multiple workers. Now we do, albeit worse than linearly. More work required there.
- Related issues: https://github.com/allenai/allennlp/issues/2962, https://github.com/allenai/allennlp/issues/1890",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(all_instances) == 200', 'isinstance(qiterable, QIterable)', 'len(all_instances) == 100 * 4', 'len(counts) == 4', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1573,Suchin,sgrangan01@gmail.com,2019-08-29 14:55:52-07:00,27ebcf6ba3e02afe341a5e62cb1a7d5c6906c0c9,https://github.com/allenai/allennlp/commit/27ebcf6ba3e02afe341a5e62cb1a7d5c6906c0c9,added infer_type_and_cast flags (#3209),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1574,Ana Marasovic,anam@allenai.org,2019-09-05 11:02:35-07:00,5e2206df306d3e11640032b523dc1a6f24a1c95b,https://github.com/allenai/allennlp/commit/5e2206df306d3e11640032b523dc1a6f24a1c95b,Add a reference to Joe Barrow's blog,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1575,Evan Pete Walsh,epwalsh10@gmail.com,2019-09-06 08:34:22-07:00,4625a9d2ccd48954580ae694b9bebf9555c0ece1,https://github.com/allenai/allennlp/commit/4625a9d2ccd48954580ae694b9bebf9555c0ece1,"Improve check_links.py CI script (#3141)

* improve check_links script

* fix http session initialization",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1576,Michael Schmitz,MichaelS@allenai.org,2019-09-06 08:35:04-07:00,b1caa9e5e35b6dd12be6a4d6fdc8195f0b85451d,https://github.com/allenai/allennlp/commit/b1caa9e5e35b6dd12be6a4d6fdc8195f0b85451d,"Use an NVIDIA base image. (#3177)

* Remove some environment variables that are set in the NVIDIA base image.

* Use the nvidia base image in Dockerfile.pip.

* Use Python 3.6.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1577,Michael Schmitz,MichaelS@allenai.org,2019-09-06 10:01:58-07:00,ce50407362c3b216db220a2099b96f870c9da83b,https://github.com/allenai/allennlp/commit/ce50407362c3b216db220a2099b96f870c9da83b,"Revert ""Use an NVIDIA base image. (#3177)"" (#3222)

This reverts commit b1caa9e5e35b6dd12be6a4d6fdc8195f0b85451d.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1578,Evan Pete Walsh,epwalsh10@gmail.com,2019-09-06 12:13:45-07:00,7cfaab475ccb39d6d59a7c9ce1d7c4d85cb5ae5c,https://github.com/allenai/allennlp/commit/7cfaab475ccb39d6d59a7c9ce1d7c4d85cb5ae5c,"Add ERROR callback event (#2983)

* add TRAINING_FAIL event

* address comments

* remove unnecessary diff

* oops, revert my messing around

* been a long day

* use decorator + add test

* replace decorator with sys.excepthook

* another attempt

* pylint

* pylint

* pylint and mypy

* simplify

* remove unused EVENTS",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['error_test.exc is not None', 'error_test.exc.args == (,)', 'not error_test.finished_training']",['(RuntimeError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1579,Karen Hambardzumyan,mahnerak@gmail.com,2019-09-10 21:45:20+04:00,7b50b69f737c97da3f2ebffc84b4abae59604e4b,https://github.com/allenai/allennlp/commit/7b50b69f737c97da3f2ebffc84b4abae59604e4b,Replace staticmethods with classmethods (#3229),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1580,Matt Gardner,mattg@allenai.org,2019-09-11 12:41:51-07:00,07364c67297488b27dc390608466b8fad3735831,https://github.com/allenai/allennlp/commit/07364c67297488b27dc390608466b8fad3735831,"Make Instance in charge of when to re-index (#3239)

* Make Instance in charge of when to re-index

* Fix (most?) tests

* Fix adjacency field",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1581,Ilya,iliyadimov@icloud.com,2019-09-14 04:06:20+03:00,c732cbf10aaef0ece9e5bd63a85d8ef54c29ec90,https://github.com/allenai/allennlp/commit/c732cbf10aaef0ece9e5bd63a85d8ef54c29ec90,"Add additive attention & unittest (#3238)

* Add additive attention & unittest

* Fix test

* Fix pylint, typo & Add docs",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['result.shape == (2, 4)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1582,Brendan Roof,brendanr@allenai.org,2019-09-13 18:14:44-07:00,48de86678d1335c4e4345308d0d8e75268f8c30e,https://github.com/allenai/allennlp/commit/48de86678d1335c4e4345308d0d8e75268f8c30e,"Assorted fixes for run_with_beaker.py (#3248)

- Compile Jsonnet config locally so that `import` works.
- Add `--include-package` option so we can use the script with other repos.
- Add `--overrides`.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1583,Joel Grus,joelgrus@gmail.com,2019-09-17 15:25:48-07:00,05be16a891b19c3c73b0eb58d534f1bd5e6cda69,https://github.com/allenai/allennlp/commit/05be16a891b19c3c73b0eb58d534f1bd5e6cda69,"allow implicit package imports (#3253)

* allow implicit package imports

* tweak logic

* address PR feedback

* add pop_choice test

* add message to failure

* missing parenthesis",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['params.pop_choice(', 'params.pop_choice(', 'in str(exc.value)', 'in str(exc.value)', 'in str(exc.value)', 'duplicate_reader.__name__ == ']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1584,Matt Gardner,mattg@allenai.org,2019-09-18 09:20:05-07:00,3e0bad4a0a17647bb4f4276d1ee7512918c61753,https://github.com/allenai/allennlp/commit/3e0bad4a0a17647bb4f4276d1ee7512918c61753,"Minor fixes for interpret code (#3260)

* Minor fixes for interpret code

* pylint caught a bug!",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1585,Will Merrill,willm@allenai.org,2019-09-18 17:56:15-07:00,41a47767cc13971ff4aab4c99e5e0b5ddf7695bf,https://github.com/allenai/allennlp/commit/41a47767cc13971ff4aab4c99e5e0b5ddf7695bf,"Unidirectional LM doesn't return backward loss. (#3256)

Changed `LanguageModel` so that, if there is no backward loss, then no backward loss key is added to the state dict. This was causing an issue when using `Predictor` with trained language models.

Fixes https://github.com/allenai/allennlp/issues/3255.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(result) == self.result_keys', 'predictions is not None']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(result) == {,', 'result[] is None']",[],[],[],[],[],[],[],[],[],[],[],[]
1586,Elad Segal,eladsegal@users.noreply.github.com,2019-09-19 22:06:24+03:00,daed8359330f483405e306f8a1bf74fb1031907e,https://github.com/allenai/allennlp/commit/daed8359330f483405e306f8a1bf74fb1031907e,"Fix wrong partition to types in DROP evaluation (#3263)

* Fix wrong partition to types in drop evaluation

* add a simple test

* add another case so the issue is tested regardless of answers order",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['lines[4] == ', 'lines[4] == ']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1587,Michael Schmitz,MichaelS@allenai.org,2019-09-19 13:05:11-07:00,87fb294e75fa2565246d0356eb8b428ed78f18b5,https://github.com/allenai/allennlp/commit/87fb294e75fa2565246d0356eb8b428ed78f18b5,Update question.md (#3267),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1588,Joel Grus,joelgrus@gmail.com,2019-09-20 15:57:34-07:00,9a67546e48ea315d43607bf3bad7440606cbbac8,https://github.com/allenai/allennlp/commit/9a67546e48ea315d43607bf3bad7440606cbbac8,fix empty sequence bug (#3271),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['indexed_tokens == {'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1589,Matt Gardner,mattg@allenai.org,2019-09-21 11:57:56-07:00,76d248f814967541b8e69959ac68c6979a1d1a30,https://github.com/allenai/allennlp/commit/76d248f814967541b8e69959ac68c6979a1d1a30,"Reduce hotflip vocab size, batch input reduction beam search (#3270)

* saving state

* fixes

* Fixed tests

* remove initialize from constructor

* A couple of other minor fixes

* Fix test

* pylint, mypy

* better comments and documentation",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(grads[][0]) == 9  # 9 words in hypothesis', 'len(grads[][0]) == 5  # 5 words in premise']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(grads[]) == 9  # 9 words in hypothesis', 'len(grads[]) == 5  # 5 words in premise']",[],[],[],[],[],[],[],[],[],[],[],[]
1590,Eric Wallace,eswallace@comcast.net,2019-09-23 16:28:40-07:00,052e8d3244d540d023f85a5ced7fa95f2bcaf152,https://github.com/allenai/allennlp/commit/052e8d3244d540d023f85a5ced7fa95f2bcaf152,"Reduce number of samples in smoothgrad (#3273)

Smoothgrad is really slow with 25 samples, speed it up with only 10.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1591,Matt Gardner,mattg@allenai.org,2019-09-23 17:07:08-07:00,2a950223792ef816971e9e9aa35f38c32b9c0785,https://github.com/allenai/allennlp/commit/2a950223792ef816971e9e9aa35f38c32b9c0785,Revert batching for input reduction (#3276),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1592,Matt Gardner,mattg@allenai.org,2019-09-23 18:01:13-07:00,d09042e49226bd7fa04a4e37cd63aa46d7ccd2f1,https://github.com/allenai/allennlp/commit/d09042e49226bd7fa04a4e37cd63aa46d7ccd2f1,"Fix crash when hotflip gets OOV input (#3277)

* Fix crash when hotflip gets OOV input

* add comment",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1593,Joel Grus,joelgrus@gmail.com,2019-09-24 08:16:25-07:00,64143c41b60c7fefe2831bd2dc00bf7906676e63,https://github.com/allenai/allennlp/commit/64143c41b60c7fefe2831bd2dc00bf7906676e63,"upgrade to latest pylint (#3266)

* pylint

* update pylint

* undo a lot of the raise / else

* add bound on typed-ast",48,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,0,0,0,0,0,0,0,0,0,0,25,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.func == dry_run_from_args  # pylint: disable=comparison-with-callable', 'args.func == find_learning_rate_from_args  # pylint: disable=comparison-with-callable', 'args.func == fine_tune_model_from_args  # pylint: disable=comparison-with-callable', 'args.func == make_vocab_from_args  # pylint: disable=comparison-with-callable', 'args.func == train_model_from_args  # pylint: disable=comparison-with-callable', 'set(agenda_strings) == {,', 'set(agenda_strings) == {,', '{type(item) for item in tensor} == {int}', 'set(decode_output_dict.keys()) == {,', 'set(decode_output_dict.keys()) == {,', 'set(black_triangle_touch_forms) == {', 'set(black_triangle_touch_forms[:6]) == {', 'set(black_triangle_touch_forms[6:12]) == {', 'set(black_triangle_touch_forms[30:33]) == {', 'set(yellow_black_triangle_touch_forms) == {', 'set(agenda) == {}', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,']",[],[],[],[],[],[],[],[],[],[],[],[],"['args.func == dry_run_from_args', 'args.func == find_learning_rate_from_args', 'args.func == fine_tune_model_from_args', 'args.func == make_vocab_from_args', 'args.func == train_model_from_args', 'set(agenda_strings) == set([,', 'set(agenda_strings) == set([,', 'set([type(item) for item in tensor]) == set([int])', 'set(decode_output_dict.keys()) == set([,', 'set(decode_output_dict.keys()) == set([,', 'set(black_triangle_touch_forms) == set([', 'set(black_triangle_touch_forms[:6]) == set([', 'set(black_triangle_touch_forms[6:12]) == set([', 'set(black_triangle_touch_forms[30:33]) == set([', 'set(yellow_black_triangle_touch_forms) == set([', 'set(agenda) == set([])', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,', 'set(agenda) == set([,']",[],[],[],[],[],[],[],[],[],[],[],[]
1594,Michael Bugert,bugert@ukp.informatik.tu-darmstadt.de,2019-09-24 17:16:54+02:00,b85f29c6be4b9335b32797752f095152b1c38dae,https://github.com/allenai/allennlp/commit/b85f29c6be4b9335b32797752f095152b1c38dae,"Fix F1Measure returning true positives, false positives, et al. only for the first class (#3279)

* Fix F1Measure returning true positives, false positives et al. only for the first class.

* Remove outdated comments",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['f1_measure._true_positives == 1.0', 'f1_measure._true_negatives == 2.0', 'f1_measure._false_positives == 3.0', 'f1_measure._false_negatives == 0.0', 'isinstance(precision, float)', 'isinstance(recall, float)', 'isinstance(f1, float)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1595,Sai,sai-prasanna@users.noreply.github.com,2019-09-24 23:09:29+05:18,3b2201120b7fd8ef8065fafe301ba8f99c6e1428,https://github.com/allenai/allennlp/commit/3b2201120b7fd8ef8065fafe301ba8f99c6e1428,"Composed Sequence to Sequence Abstraction (#2913)

This completes the work started by @generall https://github.com/allenai/allennlp/pull/2517 to decompose seq2seq encoder_decoder models.

## Explanation
* `ComposedSeq2Seq` is the class which composes older `Seq2SeqEncoder` and the newly defined `SeqDecoder`.
* `SeqDecoder` is an abstract class upon which Decoder implementations are extended upon 
* `AutoRegressiveSeqDecoder` is the default implementation for `SeqDecoder`. It composes `DecoderNet`. The decoder net can implemented by anything from a transformer to a LSTMCell. In case of implementations like transformer which support parallel decoding (for training), we have a `decodes_parallel` flag. The `AutoRegressiveSeqDecoder` uses this flag to exploit single forward pass decoding in case of teacher forcing.

## Questions
* Can the current items such as the embedder  in `SeqDecoder` can be moved to the default autoregressive decoder implementation?
* Are the current tests sufficient?
* I am reusing the harvard Transformer parts in the private API to implement `StackedSelfAttentionDecoderNet`

## Help
* ~Need help testing the transformer module on actual data. I am getting NAN errors during validation phase, while running beam search.~ Fixed

Solves https://github.com/allenai/allennlp/issues/2097",31,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['reader._source_max_exceeded == 2 # pylint: disable=protected-access', 'reader._target_max_exceeded == 1 # pylint: disable=protected-access', 'len(instances) == 3', '[t.text for t in fields[,', '[t.text for t in fields[,', 'in decode_output_dict', 'in decode_output_dict', 'list(decoder_init_state[].shape) == [batch_size, decoder_inout_dim]', 'list(decoder_init_state[].shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(decoded_vec.shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(decoded_vec.shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(decoded_vec.shape) == [batch_size, decoder_inout_dim]', 'decoder_init_state == {}', 'next_state == {}', 'list(decoded_vec.shape) == [batch_size, prev_timesteps, decoder_inout_dim]', 'predicted_tokens is not None', 'isinstance(predicted_tokens, list)', 'all(isinstance(x, str) for x in predicted_tokens)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1596,Eric Wallace,eswallace@comcast.net,2019-09-24 20:47:56-07:00,ff0d44a5e21d5e6256c73b5b9f216a87c5743f91,https://github.com/allenai/allennlp/commit/ff0d44a5e21d5e6256c73b5b9f216a87c5743f91,"reversing NER for interpet UI (#3283)

* Update sentence_tagger.py

* Add comment on attacker utils",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1597,Matt Gardner,mattg@allenai.org,2019-09-25 06:47:31-07:00,052353ed62e3a54fd7b39a660e65fc5dd2f91c7d,https://github.com/allenai/allennlp/commit/052353ed62e3a54fd7b39a660e65fc5dd2f91c7d,bump version number to v0.9.0,5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1598,Matt Gardner,mattg@allenai.org,2019-09-25 07:19:52-07:00,8cee3caca13c665fc62609d08796bce46e1e4edd,https://github.com/allenai/allennlp/commit/8cee3caca13c665fc62609d08796bce46e1e4edd,Bump version numbers to v0.9.1-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1599,Santiago Castro,sacastro@umich.edu,2019-09-25 17:36:18+02:00,2e38b781cfefa6b26250ae172e04bdf3ad86ec6e,https://github.com/allenai/allennlp/commit/2e38b781cfefa6b26250ae172e04bdf3ad86ec6e,Change log level to clean up allennlp command (#3284),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1600,Michael Schmitz,MichaelS@allenai.org,2019-09-25 08:38:27-07:00,91b58a13c439ad971e3fcac379d4d03737774a79,https://github.com/allenai/allennlp/commit/91b58a13c439ad971e3fcac379d4d03737774a79,Update MODELS.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1601,Nelson Liu,nelson-liu@users.noreply.github.com,2019-09-25 09:36:24-07:00,a73283155fb0daf1f0931b1c1d8655e116417127,https://github.com/allenai/allennlp/commit/a73283155fb0daf1f0931b1c1d8655e116417127,"Optionally convert parens tokens in PTB reader (#3272)

* Optionally convert parens tokens in PTB reader

* Fix lint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1602,Joel Grus,joelgrus@gmail.com,2019-09-26 12:25:05-07:00,e85ddef63bb5bb10b72cebce28e4797ccb848eb6,https://github.com/allenai/allennlp/commit/e85ddef63bb5bb10b72cebce28e4797ccb848eb6,"upgrade to latest mypy + pylint (#3281)

* pylint

* update pylint

* undo a lot of the raise / else

* add bound on typed-ast

* first mypy fixes

* new flag

* fix mypy errors

* requirements.txt",34,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1603,Santiago Castro,santi.1410@hotmail.com,2019-09-26 22:59:28+02:00,16e765673768ce81af767d4ead3b302a828062ce,https://github.com/allenai/allennlp/commit/16e765673768ce81af767d4ead3b302a828062ce,"Use Python3-style super call (#3289)

* Use Python3-style super call

* Fix spacing issues",113,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1604,12seetharaman,53142037+12seetharaman@users.noreply.github.com,2019-09-27 18:42:06+05:18,088b2883de1a6ab03d808de4dd809041d088c5ea,https://github.com/allenai/allennlp/commit/088b2883de1a6ab03d808de4dd809041d088c5ea,sanitize function fix to convert numpy.bool_ to bool (#3290),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1605,Michael Schmitz,MichaelS@allenai.org,2019-09-27 09:53:52-07:00,9220635ae79e4d2ce003c35eb2124d54b0c119ec,https://github.com/allenai/allennlp/commit/9220635ae79e4d2ce003c35eb2124d54b0c119ec,Disable BERT SRL test as it fails in some environments. (#3268),1,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['()'],[],[],[],[],['skip()'],['mark.skip()'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1606,Brendan Roof,brendanr@allenai.org,2019-09-27 16:00:26-07:00,13e2f1e845cdcb593eb582bb8103f22a69b108c1,https://github.com/allenai/allennlp/commit/13e2f1e845cdcb593eb582bb8103f22a69b108c1,Remove non-general hack to count tokens. (#3293),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1607,Joel Grus,joelgrus@gmail.com,2019-09-30 06:45:59-07:00,c4c532d25e012dbe6ab1ac14bca75e53e0acc621,https://github.com/allenai/allennlp/commit/c4c532d25e012dbe6ab1ac14bca75e53e0acc621,"pylint -> flake8 (#3288)

* pylint

* update pylint

* undo a lot of the raise / else

* add bound on typed-ast

* first mypy fixes

* new flag

* fix mypy errors

* requirements.txt

* pylint -> flake8

* mypy 0.720 -> mypy 0.730

* add back erroneously removed initial newline

* remove .pylintrc

* remove pylintrc from Dockerfile",646,False,True,True,False,False,True,False,True,False,False,False,False,False,False,False,[],1,6,0,0,0,0,0,0,0,0,0,1,6,0,0,0,0,0,0,0,0,0,37,0,0,0,0,0,0,0,0,0,0,0,0,37,0,0,0,0,0,0,0,0,0,0,0,0,['class AllenNlpTestCase(TestCase):'],"[('Raises', '(SystemExit) as cm:'), ('Raises', '(SystemExit) as cm:'), ('Raises', '(SystemExit) as cm:'), ('Raises', '(SystemExit) as cm:'), ('Raises', '(SystemExit) as cm:'), ('Raises', '(SystemExit) as cm:')]",[],[],[],[],[],[],[],[],[],['class AllenNlpTestCase(TestCase):'],"[('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name'), ('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name'), ('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name'), ('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name'), ('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name'), ('Raises', '(SystemExit) as cm:  # pylint: disable=invalid-name')]",[],[],[],[],[],[],[],[],[],"['args.func == dry_run_from_args', 'args.func == find_learning_rate_from_args', 'args.func == fine_tune_model_from_args', 'parameter.requires_grad == name_parameters_original[name].requires_grad', 'args.func == make_vocab_from_args', 'model.forward(torch.tensor([1, 2, 3]))[] == torch.tensor(98)', 'args.func == train_model_from_args', 'all([self.span_width >= len(x) > 0 for x in candidate_mentions])', 'all([self.span_width >= len(x) > 0 for x in candidate_mentions])', 'set(spans) == {(, (1, 1))}', 'resolved == []', 'instance[][0].labels == [0] * 22', 'reader._source_max_exceeded == 2', 'reader._target_max_exceeded == 1', 'indexed_tokens[] == [0,    0, 0,  0,  0,  0, 0,  1, 1,  1,  1,  1, 1]', 'vocab._token_to_index == vocab2._token_to_index', 'vocab._index_to_token == vocab2._index_to_token', 'grammar_state._nonterminal_stack == []', 'not in output.keys()', 'vecs_p.size() == torch.Size([batch, len1, 10 + 10 * n])', 'vecs_h.size() == torch.Size([batch, len2, 10 + 10 * n])', 'list(bilinear._weight_matrix.size()) == [3, 4]', 'result.get() == {', 'not (Date(2013, 12, -1) > Date(2013, 12, 31))', 'not (Date(2013, 12, 31) > 2013)', 'not (Date(2013, 12, 31) >= 2013)', 'not (Date(2018, 1, 1) >= Date(-1, 2, 1))', 'not (Date(2018, 1, 1) < Date(-1, 2, 1))', 'not (Date(-1, -1, 1) < Date(-1, -1, 3))', 'not (Date(-1, -1, 1) >= Date(-1, -1, 3))', 'not (Date(2018, -1, 1) < Date(2018, -1, 3))', 'not (Date(2018, -1, 1) >= Date(2018, -1, 3))', 'world._get_numeric_database_values(]', 'world._get_sequence_with_spacing(world.grammar,', 'tracker._best_so_far is not None', 'tracker._best_so_far is not None', 'embedding.weight.grad.is_sparse']",[],[],[],[],[],[],[],[],[],[],[],[],"['args.func == dry_run_from_args  # pylint: disable=comparison-with-callable', 'args.func == find_learning_rate_from_args  # pylint: disable=comparison-with-callable', 'args.func == fine_tune_model_from_args  # pylint: disable=comparison-with-callable', 'parameter.requires_grad \\', 'args.func == make_vocab_from_args  # pylint: disable=comparison-with-callable', 'model.forward(torch.tensor([1, 2, 3]))[] == torch.tensor(98) # pylint: disable=not-callable', 'args.func == train_model_from_args  # pylint: disable=comparison-with-callable', 'all([self.span_width >= len(x) > 0 for x in candidate_mentions])  # pylint: disable=len-as-condition', 'all([self.span_width >= len(x) > 0 for x in candidate_mentions])  # pylint: disable=len-as-condition', 'set(spans) == {(, (1, 1))}', 'resolved == []', 'instance[][0].labels == [0,] * 22', 'reader._source_max_exceeded == 2 # pylint: disable=protected-access', 'reader._target_max_exceeded == 1 # pylint: disable=protected-access', 'indexed_tokens[] == [0,    0, 0,  0,  0,  0, 0,  1, 1,  1,  1,  1, 1]  #pylint: disable=bad-whitespace', 'vocab._token_to_index == vocab2._token_to_index  # pylint: disable=protected-access', 'vocab._index_to_token == vocab2._index_to_token  # pylint: disable=protected-access', 'grammar_state._nonterminal_stack == [] # pylint: disable=protected-access', 'not  in output.keys()', 'vecs_p.size() == torch.Size([batch, len1, 10 + 10 * l])', 'vecs_h.size() == torch.Size([batch, len2, 10 + 10 * l])', 'list(bilinear._weight_matrix.size()) == [3, 4]  # pylint: disable=protected-access', 'result.get(,', '(Date(2013, 12, -1) > Date(2013, 12, 31)) == False', '(Date(2013, 12, 31) > 2013) == False', '(Date(2013, 12, 31) >= 2013) == False', '(Date(2018, 1, 1) >= Date(-1, 2, 1)) == False', '(Date(2018, 1, 1) < Date(-1, 2, 1)) == False', '(Date(-1, -1, 1) < Date(-1, -1, 3)) == False', '(Date(-1, -1, 1) >= Date(-1, -1, 3)) == False', '(Date(2018, -1, 1) < Date(2018, -1, 3)) == False', '(Date(2018, -1, 1) >= Date(2018, -1, 3)) == False', 'world._get_numeric_database_values(] # pylint: disable=protected-access', 'world._get_sequence_with_spacing(world.grammar, # pylint: disable=protected-access', 'tracker._best_so_far is not None  # pylint: disable=protected-access', 'tracker._best_so_far is not None  # pylint: disable=protected-access', 'embedding.weight.grad.is_sparse  # pylint: disable=no-member']",[],[],[],[],[],[],[],[],[],[],[],[]
1608,Wang Ran (),wrran@outlook.com,2019-09-30 23:32:38+08:00,b6b3c9d22ed44fbe9f129f23f4fab4b0cc002300,https://github.com/allenai/allennlp/commit/b6b3c9d22ed44fbe9f129f23f4fab4b0cc002300,"Replace Invalid Link (#3297)

The URL `https://homes.cs.washington.edu/~luheng/files/acl2017_hllz.pdf` is in the state of 404.
I replace it by the url from ACL Anthology `https://www.aclweb.org/anthology/P17-1044`.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1609,Scott Condron,condronscott@gmail.com,2019-09-30 16:42:39+01:00,ba6297d30314fe43f2b143dcca9e4809135512db,https://github.com/allenai/allennlp/commit/ba6297d30314fe43f2b143dcca9e4809135512db,"Add WeightDropout (#3092)

* Add WeightDropout from Fastai

* Remove some linting errors

* Generalized WeightDrop implementation

* Added WeightDrop tests

* Changed name to DropConnect & fixed some linting errors

* Added docs

* Added DropConnect to allennlp/modules/__init__.py

* Addressed linting errors + missing docs",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('SetEqual', '(parameter_names, expected_parameter_names)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not torch.allclose(output_a, output_b)', 'torch.allclose(output_a, output_b)', 'torch.allclose(output_a[:, 0, :], output_b[:, 0, :])', 'not torch.allclose(output_a[:, 1, :], output_b[:, 1, :])', 'torch.allclose(output_a, output_b)', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1610,Gary,yugu772@yahoo.com,2019-09-30 11:50:31-04:00,2f1f9349e0bd8aba5ef3387b739d95389accae78,https://github.com/allenai/allennlp/commit/2f1f9349e0bd8aba5ef3387b739d95389accae78,"fix an annotation issue in basic_transition_function.py (#3294)

* fix an annotation issue

I also update self._input_projection_layer = Linear(output_dim + action_embedding_dim, input_dim) to self._input_projection_layer = Linear(encoder_output_dim + action_embedding_dim, input_dim). Though as a matter of fact, output_dim equals encoder_output_dim, using encoder_output_dim is more consistent in this context.

* pylint",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1611,Mark Neumann,markn@allenai.org,2019-09-30 15:13:26-07:00,91cfafab66f4bd0c4fd1a9c5cc8c678b4d06cca5,https://github.com/allenai/allennlp/commit/91cfafab66f4bd0c4fd1a9c5cc8c678b4d06cca5,"fix flake8 from #3092 (#3307)

* fix flake8 from #3092

* we don't need pylint anymore",1,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1612,Mark Neumann,markn@allenai.org,2019-09-30 15:48:14-07:00,256d4dac824cdd858ce8967febd36967207b5cd7,https://github.com/allenai/allennlp/commit/256d4dac824cdd858ce8967febd36967207b5cd7,"Pylint traces (#3309)

* bleach pylint references

* remove from verify script",12,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1613,Santiago Castro,sacastro@umich.edu,2019-10-01 02:07:37+02:00,d7b38a893cf9eea2175473c58834787ce732f4fb,https://github.com/allenai/allennlp/commit/d7b38a893cf9eea2175473c58834787ce732f4fb,`source activate` -> `conda activate` in README (#3301),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1614,Joel Grus,joelgrus@gmail.com,2019-10-01 11:43:00-07:00,3dda5ac9fcf390d8b83eb855249360711707c11c,https://github.com/allenai/allennlp/commit/3dda5ac9fcf390d8b83eb855249360711707c11c,"for discussion: incorporate black code formatter (#3308)

* setup files

* run black

* undo

* update CONTRIBUTING.md

* fix quotes in test_other_modules

* make flake8 happy

* set black to 100 characters per line

* move type: ignore to where mypy wants them

* more flake8",710,False,True,True,False,False,True,True,True,False,False,False,False,False,False,False,[],0,20,0,0,0,0,0,0,0,0,0,0,20,0,0,0,0,0,0,0,0,0,1056,10,0,8,1,0,0,7,16,16,3,0,0,1056,10,0,8,1,0,0,7,16,16,3,0,0,[],"[('_fields_equal', '('), ('_fields_equal', '('), ('_fields_equal', '('), ('Equal', '('), ('In', '('), ('AlmostEqual', '(metrics[], (70 + 18 + 12) / 13.5)'), ('Equal', '('), ('Logs', '('), ('Equal', '(PassThroughIterator().get_num_batches(self.instances), len(self.instances))'), ('Logs', '(logger, level=) as context_manager:'), ('In', '(, context_manager.output[0])'), ('Equal', '(tensor_dict[].size(), (4,))'), ('Raises', '('), ('Equal', '('), ('Equal', '('), ('Equal', '('), ('Equal', '('), ('Equal', '('), ('Raises', '(ConfigurationError, FBetaMeasure, beta=0.0)'), ('Raises', '(ConfigurationError, FBetaMeasure, average=)')]",[],[],[],[],[],[],[],[],[],[],"[('_fields_equal', '(model_predictions[key],'), ('_fields_equal', '(field1[key],'), ('_fields_equal', '(subfield1,'), ('Equal', '(expected_output, actual_output, f'), ('In', '(module_info.name, [parent_module.__name__ + ],'), ('AlmostEqual', '(metrics[], (70 + 18 + 12)/13.5)'), ('Equal', '(sorted(list(expected_batch.fields.keys())),'), ('Logs', '(logger=):'), ('Equal', '(PassThroughIterator().get_num_batches(self.instances),'), ('Logs', '(logger, level=) as context_manager:'), ('In', '(, context_manager.output[0])'), ('Equal', '(tensor_dict[].size(), (4,))'), ('Raises', '(ConfigurationError,'), ('Equal', '(log.output,'), ('Equal', '(log.output,'), ('Equal', '(log.output,'), ('Equal', '(log.output,'), ('Equal', '(log.output,'), ('Raises', '(ConfigurationError, FBetaMeasure,'), ('Raises', '(ConfigurationError, FBetaMeasure,')]",[],[],[],[],[],[],[],[],[],"['in choices', 'set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'tokens == [', 'labels == []', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'json.loads(h5py_file.get()[0]) == {', 'metrics.keys() == {}', 'set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'tokens == [', 'labels == []', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'args.func.__name__ == ', 'set(result.keys()) == {', 'set(result.keys()) == {', 'results[0][] is True', 'results[0][] is False', 'results[0][] is True', 'set(result.keys()) == {', 'set(result.keys()) == {', 'set(result.keys()) == {', 'span != ', 'lines[0] == ', 'lines[0] == ', 'in config', 'in items', 'in items', 'in items', 'in items', 'ja == {}]}', 'url_to_filename(baseurl + )', 'method_counts[] == 1', 'method_counts[] == 1', 'method_counts[] == 2', 'method_counts[] == 1', 'method_counts[] == 3', 'method_counts[] == 2', 'takes_arg(bare_function, )', 'not takes_arg(bare_function, )', 'takes_arg(SomeClass, )', 'takes_arg(SomeClass, )', 'not takes_arg(SomeClass, )', 'takes_arg(SomeClass.check_param, )', 'not takes_arg(SomeClass.check_param, )', 'takes_arg(SomeClass.set_total, )', 'not takes_arg(SomeClass.set_total, )', 'kwargs == {: True}', 'c.c[].a == 3', 'c.c[].a == [4, 5]', 'unflattened == {: 3}', 'override_dict == {: 10}}', 'params == {}', 'params[', 'params.files_to_archive == {: my_other_file}', 'params.pop_choice(', 'params.pop_choice(', 'not in base_class.list_available()', 'base_class.by_name() == Fake', 'base_class.by_name() == FakeAlternate', 'DatasetReader.by_name(', 'DatasetReader.by_name(', 'DatasetReader.by_name(', 'DatasetReader.by_name(', 'DataIterator.by_name(', 'DataIterator.by_name(', 'Tokenizer.by_name(', 'Tokenizer.by_name(', 'TokenIndexer.by_name(', 'TokenIndexer.by_name(', 'Regularizer.by_name(', 'Regularizer.by_name(', 'TokenEmbedder.by_name(', 'TokenEmbedder.by_name(', 'TextFieldEmbedder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'duplicate_reader.__name__ == ', 'util.group_by_count([1, 2, 3, 4, 5, 6, 7], 3, 20) == [', 'not in sys.modules', 'not in sys.modules', 'in sys.modules', 'in sys.modules', 'in sys.modules', 'set(frozen_parameter_names) == {}', 'set(tunable_parameter_names) == {}', '[t.text for t in instances[0].fields[][3].tokens[3:]] == [', '[t.sequence_index for t in instances[0].fields[]] == [0, 1]', '[t.text for t in instances[0].fields[]', 'reader._token_indexers[', 'tokens == [', 'ccg_categories == [', 'original_pos_tags == [', 'modified_pos_tags == [', 'predicate_arg_categories == [', 'tokens == [', 'tokens == [', 'tokens == []', 'tokens == []', 'set(self.instances[0].fields.keys()) == set(', '[t.text for t in fields[].tokens] == [', 'fields[] == [', '[t.text for t in fields[].tokens] == [', 'fields[] == [', 'list(source_token_ids) == [', 'list(target_token_ids) == [', 'text == [', 'text == [', '([], 1) in gold_mentions_with_ids', 'text == [', 'gold_mentions_with_ids == [([], 0)]', 'text == [', 'gold_mentions_with_ids == [', 'annotation.words == [', 'annotation.pos_tags == [', 'annotation.predicate_framenet_ids == [', 'annotation.srl_frames == [', 'annotation.named_entities == [', 'annotation.predicate_lemmas == [', 'annotation.speakers == [', 'annotation.parse_tree == Tree.fromstring(', 'annotation.words == [', 'annotation.pos_tags == [', 'annotation.word_senses == [', 'annotation.predicate_framenet_ids == [', 'annotation.srl_frames == [', 'annotation.named_entities == [', 'annotation.predicate_lemmas == [', 'annotation.speakers == [', 'annotation.parse_tree == Tree.fromstring(', 'annotation.document_id == ', 'annotation.words == []', 'annotation.pos_tags == []', 'annotation.named_entities == [', 'annotation.parse_tree == Tree.fromstring(', 'annotation.document_id == ', 'annotation.words == [', 'annotation.pos_tags == [', 'annotation.word_senses == [', 'annotation.predicate_framenet_ids == [', 'annotation.srl_frames == [', 'annotation.named_entities == [', 'annotation.predicate_lemmas == [', 'annotation.speakers == [', 'annotation.parse_tree == Tree.fromstring(', 'set(spans) == {', 'set(spans) == {', 'set(spans) == {(, (7, 9))}', 'set(spans) == {(, (7, 9))}', 'set(spans) == {', 'set(spans) == {', 'spans == [', 'spans == [(, (4, 4))]', 'spans == [(, (4, 4))]', 'bioul_sequence == []', 'bioul_sequence == []', 'bioul_sequence == []', 'sql_data.text == [', 'sql_data.text_with_variables == [', 'sql_data.sql == [', 'sql_data.text_variables == {', 'sql_data.sql_variables == {', 'sql_data.sql == [', 'sql_data.text_variables == {}', 'sql_data.sql_variables == {', 'tokens == [', 'tags == []', 'cleaned == [', 'cleaned == [', 'resolved == [', 'get_text(, instance) == [', 'get_text(, instance) == [', 'get_text(, instance) == [', 'get_text(, instance) == [', 'get_text(, instance) == [', 'get_text(, instance) == [', 'get_text(, instance) == [', 'get_text(, instance) == [', 'get_text(, instance) == [', '[t.text for t in instances[0].fields[].tokens] == [', '[t.text for t in instances[1].fields[].tokens] == [', '[t.text for t in instances[1].fields[].tokens] == [', '[t.text for t in instances[2].fields[].tokens] == [', '[t.text for t in instances[3].fields[].tokens] == [', '[t.text for t in instances[3].fields[].tokens] == [', '[t.text for t in instances[4].fields[].tokens] == [', '[t.text for t in instances[4].fields[].tokens] == [', '[t.text for t in instance[]', '[i.sequence_index for i in instance[]] == [3]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tensor_dict[].numpy().tolist() == [2, 3, 4, 5, 6, 7]', 'tensor_dict[].numpy().tolist() == [2]', 'tensor_dict[].numpy().tolist() == [[3]]', '[t.text for t in instance[]] == [', '[i.sequence_index for i in instance[]] == [6]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', '[t.text for t in instance[]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tensor_dict[].numpy().tolist() == [2, 3, 4]', 'tensor_dict[].numpy().tolist() == [2]', '[t.text for t in instance[]] == [', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tokens == [', 'fields[]', 'tokens == [', 'fields[].labels == [', 'fields[].labels == [', 'tokens == [', 'pos_tags == [', 'tokens == [', 'pos_tags == [', 'tree == Tree.fromstring(', 'spans == [((0, 1), )]', 'span_dict == {', 'set(instance[].metadata.keys()) == {', 'len(instance[]) == question_length + passage_length + 1', 'instance[][0] == (', 'set(instance[].metadata.keys()) == {', 'set(instance[].metadata.keys()) == {', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[][0][:3]] == [', '[t.text for t in instances[0].fields[]', 'instances[0].fields[].sequence_index == 4', 'reader._token_indexers[', '[t.text for t in instances[0].fields[].field_list[0].tokens[:3]] == [', '[x.label for x in instances[0].fields[].field_list] == [', '[x.label for x in instances[0].fields[].field_list] == [', '(', '[t.text for t in instances[0].fields[].tokens[:3]] == [', '[t.text for t in instances[1].fields[].tokens[:3]] == [', '[t.text for t in instances[1].fields[].tokens[:3]] == [', '[t.text for t in instances[3].fields[].tokens[:3]] == [', '[t.text for t in instances[3].fields[].tokens[-3:]] == [', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[', 'set(instance_x.fields[]) == set(', '[t.text for t in instances[0].fields[].tokens[:3]] == [', '[t.text for t in instances[0].fields[].tokens[:3]] == [', '[t.text for t in instances[1].fields[].tokens[:3]] == [', '[t.text for t in instances[1].fields[].tokens[-3:]] == [', '[t.text for t in instances[2].fields[].tokens[:3]] == [', 'tokens == [', 'arcs.indices == [', 'arcs.labels == [', 'tokens == [', 'arcs.indices == [', 'arcs.labels == [', 'len(instance.fields[].field_list) == 1', 'instance.fields[].field_list[0].sequence_index == -1', 'set(instance.fields.keys()) == {', '[t.text for t in instance.fields[].tokens] == [', 'isinstance(instance.fields[].as_tensor({}), AtisWorld)', 'set(world.valid_actions[]) == {', 'world.linked_entities[][2] == [', 'world.linked_entities[][', 'world.linked_entities[][2] == [', 'world.linked_entities[][2] == [', 'world.linked_entities[][', 'world.linked_entities[][2] == [', 'tokens == [', 'indices == [', 'production_rules == [', 'instance.fields.keys() == {', 'set(agenda_strings) == {', 'instance.fields.keys() == {', 'set(agenda_strings) == {', 'instance.fields.keys() == {', 'action_sequence == [', 'tokens == [', 'tags == []', '(', 'tokens == [', 'tags == []', '(', 'tokens == [', 'tags == [', '(', 'tokens == [', 'tags == []', '(', 'tokens == [', 'tags == [', '(', 'instance.fields[] == question_tokens', 'isinstance(instance.fields[].as_tensor({}), WikiTablesLanguage)', 'actions == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', 'tokens == [', 'fields[].labels == [', 'tokens == [', 'fields[].labels == [', 'tokens == [', 'fields[].labels == [', 'tokens == [', 'fields[].labels == [', 'fields[]', 'converted == [', 'converted == []', 'converted == []', 'wordpieces == [', '[wordpieces[i] for i in offsets] == []', '[wordpieces[i] for i in start_offsets] == [', 'tokens == [', 'fields[].labels == [', 'tokens == [', 'fields[].labels == [', 'tokens == [', 'fields[].labels == [', 'tokens == [', 'fields[].labels == [', 'fields[]', 'str(exec_info.value) == ', '[t.text for t in fields[].tokens] == [', 'fields[].labels == [', 'fields[].labels == [', '[t.text for t in fields[].tokens] == [', 'fields[].labels == [', 'fields[].labels == [', 'fields[].labels == [', '[t.text for t in fields[].tokens] == [', 'fields[].labels == [', 'fields[].labels == [', '[t.text for t in fields[].tokens] == [', 'fields[].labels == [', 'fields[].labels == [', '[t.text for t in fields[].tokens] == [', 'fields[]', 'fields[].labels == [', 'fields1[]', 'fields1[', '[t.text for t in fields1[].tokens] == [', 'fields1[].labels == [', 'fields1[].labels == [', 'fields2[', '[t.text for t in fields2[].tokens] == [', 'fields2[].labels == [', 'fields2[].labels == [', '[t.text for t in fields1[].tokens] == [', 'fields1[].labels == [', 'fields1[].labels == [', '[t.text for t in fields2[].tokens] == [', 'fields2[].labels == [', 'fields2[].labels == [', 'fields1[', '[t.text for t in fields1[].tokens] == [', 'fields1[]', 'fields1[]', 'fields2[', '[t.text for t in fields2[].tokens] == [', 'fields2[].labels == [', 'fields2[].labels == [', 'in processed_langs', 'counter_es > 20 or counter_fr > 20 or counter_it > 20', 'padding_lengths == {', 'self.field._indexed_entity_texts.keys() == {}', 'self.field._indexed_entity_texts[] == expected_array', 'self.field.get_padding_lengths() == {', 'self.field.get_padding_lengths() == {', 'tensor_dict.keys() == {}', 'batched_tensor_dict.keys() == {}', 'padding_lengths == {: 6}', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'field1._indexed_tokens[] == [', 'field2._indexed_tokens[] == [', 'padding_lengths == {', 'padding_lengths == {', 'list(tensors[].shape) == [7]', 'list(tensors[].shape) == [3]', 'list(tensors[].shape) == [4]', 'list(tensors[].shape) == [4, 8]', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == [0] * 8', '(', '(', 'grouped_instances == [', 'grouped_instances == [', 'grouped_instances == [', 'grouped_instances == [', 'grouped_instances == [', 'grouped_instances == [', 'all(epoch_num == epoch for epoch_num in batch[])', 'all(epoch_num == epoch for epoch_num in batch[])', 'all(epoch_num == epoch for epoch_num in batch[])', 'grouped_instances == [', 'stats[] == len(self.instances)', 'stats[] == [2, 1, 1, 1]', 'stats[] == [8, 3, 9, 1]', 'stats[] == len(token_counts)', 'stats[] == [1, 2]', 'stats[] == [10, 8]', 'grouped_instances == [', 'grouped_instances == [', 'grouped_instances == [', 'stats[] == len(self.instances)', 'stats[] == [2, 2, 1]', 'stats[] == [6, 8, 9]', 'stats[] == len(test_instances)', 'stats[] == [2, 1]', 'stats[] == [8, 10]', 'all(batch_len == 2 for batch_len in stats[])', 'stats[] == len(self.instances) - 1', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]', 'indexed_tokens[] == [', 'indexed_tokens[] == [', 'padded_tokens[].tolist() == [', 'indices == {: [[8, 3, 9], [3, 4, 5, 6, 4, 5, 6, 1, 1, 1], [8, 10, 3, 9]]}', 'padded[].tolist() == [', 'counter[] == {', 'indexer.tokens_to_indices([tokens[-1]], vocab, ) == {', 'padded_tokens[].tolist() == expected_padded_tokens', 'counter[: 6}', 'indexer.tokens_to_indices([tokens[1]], vocab, ) == {', 'indexer.tokens_to_indices([tokens[-1]], vocab, ) == {', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'not in self.vocab._index_to_token', 'not in self.vocab._token_to_index', 'indices[][:9] == [50, 4, 21, 31, 4, 0, 1, 51, 0]', 'counter[: 2}', 'counter[: 2}', 'indexed[] == expected_ids', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'in words', 'not in words', 'not in words', 'in words', 'in words', 'in words', 'in words', 'not in words', 'not in words', 'in words', 'in words', 'not in words', 'in words', 'in words', 'not in words', 'in words', 'in words', 'in words', ').values()', 'vocab.get_token_index() == word_index', 'vocab.get_token_from_index(word_index, namespace=', 'vocab.get_vocab_size(namespace=) == initial_vocab_size + 1', ').values()', ').values()', 'vocab.get_token_index() == word_index', 'vocab.get_token_index() == word2_index', 'vocab.get_token_from_index(word_index, namespace=', 'vocab.get_token_from_index(word2_index, namespace=', 'vocab.get_vocab_size(namespace=) == initial_vocab_size + 2', 'vocab.get_token_index() == 0', 'vocab.get_token_index() == 1', 'vocab.get_token_index() == 2', 'vocab.get_token_index() == 3', 'vocab.get_token_index() == 4', 'vocab.get_token_from_index(0, namespace=', 'vocab.get_token_from_index(1, namespace=', 'vocab.get_token_from_index(2, namespace=', 'vocab.get_token_from_index(3, namespace=', 'vocab.get_token_from_index(4, namespace=', 'vocab2.get_vocab_size(namespace=) == 3', 'vocab2.get_token_from_index(0, namespace=', 'vocab2.get_token_from_index(1, namespace=', 'vocab2.get_token_from_index(2, namespace=', 'vocab2.get_token_index() == 0', 'vocab2.get_token_index() == 1', 'vocab2.get_token_index() == 2', 'vocab2.get_vocab_size(namespace=) == 4  # (unk + padding + two tokens)', 'vocab2.get_token_from_index(0, namespace=) == vocab._padding_token', 'vocab2.get_token_from_index(1, namespace=) == vocab._oov_token', 'vocab2.get_token_from_index(2, namespace=', 'vocab2.get_token_from_index(3, namespace=', 'vocab2.get_token_index(vocab._padding_token, namespace=) == 0', 'vocab2.get_token_index(vocab._oov_token, namespace=) == 1', 'vocab2.get_token_index() == 2', 'vocab2.get_token_index() == 3', 'vocab2.get_index_to_token_vocabulary() == {', 'vocab.get_index_to_token_vocabulary() == {', 'extended_vocab.get_token_index()  # should be present', 'extended_vocab.get_token_index()  # should be present', 'extended_vocab.get_vocab_size() == 8  # 2 extra overlapping because padded', 'extended_vocab.get_vocab_size() == 6  # l,m,n,o + oov + padding', 'extended_vocab.get_vocab_size() == 3  # x,y,z', 'words_read == words, (', 'words_read == words, (', 'in words', 'not in words', 'not in words', 'in words', 'in words', 'not in words', 'len(vocab.get_index_to_token_vocabulary().values()) == 3  # 1 + 2', 'len(vocab.get_index_to_token_vocabulary().values()) == 28  # 26 + 2', 'in attack', 'in attack', 'in attack', 'len(attack[][0]) == len(', 'in attack', 'in attack', 'in attack', 'len(attack[][0]) == len(', 'instance[][0]  # check that the input has changed.', 'token in attack[][0]  # ignore tokens should not be changed', '(', 'in attack', 'in attack', 'in attack', 'len(attack[][0]) == len(', 'attack[]', 'in reduced', 'in reduced', 'reduced[][0]  # always at least one token', 'len(reduced[][0]) <= len(', 'word in reduced[]', 'in reduced', 'in reduced', 'reduced_input  # always at least one token', 'len(reduced_input) <= len(reduced[])  # input reduction removes tokens', 'word in reduced[]', 'in interpretation', ']', 'in interpretation', ']', 'in interpretation', ']', 'in interpretation', ']', 'in interpretation', ']', 'len(interpretation[]) == 7  # 7 words in input', 'params.get()', 'os.path.exists(params.get())', 'params.get() == str(', 'params.get() == original_train_data_path', '(', 'in output_dict.keys()', 'set(decode_output_dict.keys()) == {', 'set(result) == {', 'set(decode_output_dict.keys()) == {', 'resolved_spans == [', 'tag in {}', 'set(decode_output_dict.keys()) == {', 'metrics[] > 0', 'torch.equal(ensemble_output_dict[])', 'ensemble_output_dict[]', 'metrics[] > 0', 'span_end < self.instances[0].fields[].sequence_length()', 'isinstance(output_dict[][0], str)', 'metrics[] > 0', 'span_end < self.instances[0].fields[].sequence_length()', 'isinstance(output_dict[][0], str)', 'worlds[]', 'worlds[]', 'qr_spec_string == ', 'result[] == [', 'result[] == [', 'result[] == [', 'result[] == [', '(', 'result[]', 'result[]', 'result[] == [', 'result[] == [2, 0, 2, 2, 4, 2]', 'attention._similarity_function.__class__.__name__ == ', '(', 'viterbi_tags == [[2, 4, 3], [4, 2]]', 'viterbi_tags == [[2, 3, 3], [2, 3]]', 'set(allowed) == {  # Extra column for end tag.', 'set(allowed) == {  # Extra column for end tag.', 'set(allowed) == {  # Extra column for end tag.', 'list(elmo_representations[0].size()) == [2, 7 + 2, 32]', 'list(elmo_representations[1].size()) == [2, 7 + 2, 32]', 'list(mask.size()) == [2, 7 + 2]', 'numpy.allclose(actual_embeddings[: len(tokens)], expected_embeddings, atol=1e-6)', 'numpy.allclose(', '(', 'attention._similarity_function.__class__.__name__ == ', 'encoder.__class__.__name__ == ', 'encoder._module.__class__.__name__ == ', '(', '(', '(', '(', '(', '(', 'in exception_info.value.message', 'in exception_info.value.message', 'not (results[i] == 0.0).data.all()', '(results[i] == 0.0).data.all()', 'encoder.__class__.__name__ == ', 'encoder._module.__class__.__name__ == ', 'not (results[i] == 0.0).data.all()', '(results[i] == 0.0).data.all()', 'CosineSimilarity.from_params(Params({})).__class__.__name__ == ', '(', 'result.shape == (1, 2)', 'tokens[].tolist() == [', 'tokens[].tolist() == [', 'tokens[].tolist() == [', 'tag in {}', 'torch.equal(embeddings[i], vec),  + archive_path', '(', 'torch.all(', 'tag in {}', 'tag in {}', 'tag in {}', 'tensor.data.max() < math.sqrt(3 / 10)', 'tensor.data.min() > -math.sqrt(3 / 10)', 'tensor.data.max() < math.sqrt(3 / 10) * 1.43', 'tensor.data.min() > -math.sqrt(3 / 10) * 1.43', 'torch.equal(parameter.data, torch.ones(parameter.size()) * 10)', 'not torch.equal(parameter.data, torch.ones(parameter.size()) * 10)', 'has_tensor({: [3, [10, tensor]]}}]})', 'moved_obj[][0].a == 1', 'moved_obj[][0].b._device == new_device', 'moved_obj[][1].b._device == new_device', 'moved_obj[]._device == new_device', 'moved_obj[][0] == 1', 'moved_obj[][1]._device == new_device', 'tags == []', 'tags == []', 'len(linear_50_1[]) == 17', 'all(len(a) == 1 for a in linear_50_1[])', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'new_instances[0].fields[] is not None', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0][][0].label == 2', 'new_instances[0][][0] == (0, 1)  # token indices', 'new_instances[0][][0].labels == [2, 0, 0]', 'new_instances[0][][0] == (0, 1)  # token indices', 'len(result[]) == 21  # number of possible substrings of the sentence.', 'len(result[]) == 21  # number of possible substrings of the sentence.', 'len(result[]) == 36  # number of possible substrings of the sentence.', 'document == [', 'in new_instance', 'len(new_instance[]) == 60  # 7 words in input', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'new_instances[0].fields[] is not None', 'in new_instances[0]', 'len(new_instances[0][].tokens) == 2  # should have added two words', 'in new_instances[0]', 'len(new_instances[0][].tokens) == 1  # should have added one word', 'in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 1  # Because there is one world in the input.', 'in result', 'in result', 'len(result[][0]) == 1  # Because there is one world in the input.', 'words == [', 'result == {: []}', 'in grads', 'in grads', 'grads[] is not None', 'grads[] is not None', 'len(grads[][0]) == 9  # 9 words in hypothesis', 'len(grads[][0]) == 5  # 5 words in premise', 'in new_instance', 'len(new_instance[]) == 7  # 7 words in input', 'words == [', 'result == {: []}', 'results[0] == {: []}', 'results[1] == {', 'label in predictor._model.vocab.get_token_to_index_vocabulary(namespace=)', 'label in predictor._model.vocab.get_token_to_index_vocabulary(namespace=)', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'shortest_logical_form == ', 'shortest_logical_form == ', 'set(first_four_logical_forms) == {', 'set(first_four_logical_forms) == {', 'shortest_logical_form == ', 'set(length_three_logical_forms) == {', 'table_question_context.table_data == [', 'table_question_context.table_data == [', 'entities == [', 'numbers == [(, 9)]', 'string_entities == [', 'sorted(entities) == [', 'neighbors_with_sets == {', 'entity_text == {', 'set(neighbors.keys()) == {', 'set(neighbors[}', 'neighbors[]', 'neighbors[] == []', 'neighbors[]', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[]', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[]', 'neighbors[]', 'neighbors[] == []', 'set(neighbors[]) == {', 'neighbors[]', 'self.language.execute() == 5', 'self.language.execute() == 2', 'self.language.execute() == 20', 'self.language.execute() == 3', 'self.language.execute() == 3', 'self.language.execute() == 5', 'self.language.execute() == -1', 'self.language.execute() == 10', 'self.language.execute() == 2', 'self.language.execute() == 5', 'self.language.execute() == 5', 'self.language.execute() == 0', 'self.language.execute() == 4', 'self.language.execute() == 12', 'self.language.execute() == 1', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', '(', '(', '(', '(', '(', '(', '(', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'set(agenda) == {}', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', '(', '(', '(', '(', 'self.language.logical_form_to_action_sequence(', '(', '(', 'self.language.logical_form_to_action_sequence(', 'set(cell_list) == {}', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'self.language.evaluate_logical_form(', 'not self.language.evaluate_logical_form(', 'set(world.get_agenda()) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {}', '(', '(', 'expression == [', 'expression == []]]]', 'set(valid_actions.keys()) == {', 'set(valid_actions[}', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[}', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[}', 'set(valid_actions[}', 'set(valid_actions[}', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[}', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[}', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'world._get_numeric_database_values(]', 'world._get_sequence_with_spacing(', 'grammar_dictionary[] == [', 'grammar_dictionary[] == [', 'not world.is_global_rule()', 'in action_sequence', 'in action_sequence', 'in actions', 'in actions', 'world.base_grammar_dictionary[] == [', 'world.base_grammar_dictionary[] == [', 'argument_paths == [', 'unary_function_paths == [', 'binary_function_paths == [', 'argument_paths == [', 'identity_paths == [', '(', 'config[', 'in data', 'not in data', 'not in data', 'in data', 'in data', 'not in data', ']', ']', ']', 'in data', 'in data', 'in data', 'in data', 'in data', 'not in data', 'in data', 'not in data', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [3, 4]', 'actions[][2] == [3, 4]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'get_metrics(', 'get_metrics(', 'get_metrics(', 'get_metrics(', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics(', 'lines[4] == ', 'lines[4] == ', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', '(', 'len(kwargs[]) == batch_size, (', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], int)', 'epochs[3] == ', 'in epochs[0]', 'not in files', 'not in files', 'is_hat_shaped([float(k) for k in range(10)] + [float(10 - k) for k in range(10)])', 'not is_hat_shaped(', '(', 'self.metric._precision_totals[1] == (1 + 2 + 3)', 'self.metric._precision_matches[2] == (0 + 0 + 1)', 'self.metric._precision_totals[2] == (0 + 1 + 2)', 'accuracy.get_metric() == 2.0 / 4', 'accuracy.get_metric() == 5.0 / 8', 'accuracy.get_metric() == 8.0 / 12', 'accuracy.get_metric() == 3.0 / 4', 'accuracy.get_metric(reset=True) == (0.25 + 1 + 0.5) / 3.0', 'accuracy.get_metric(reset=True) == (0.25 + 0.5) / 2.0', 'isclose(', 'isclose(', 'isclose(optimizer.param_groups[0][], self.base_momentum / 5)', 'isclose(', 'isclose(optimizer.param_groups[0][], self.base_momentum)', 'isclose(optimizer.param_groups[0][], self.base_momentum)', 'isclose(optimizer.param_groups[0][], self.base_momentum)', 'param_groups[0][] == 1', 'param_groups[0][] == 2', 'param_groups[1][] == 3', 'param_groups[2][] == 1', 'param_groups[k][] == 5', 'len(param_groups[0][]) == 6', 'len(param_groups[1][]) == 2', 'len(param_groups[2][]) == 3', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', '(', 'len(kwargs[]) == batch_size, (', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], int)', 'epochs[3] == ', 'in epochs[0]', 'saved_params == self.params.pop().as_dict(quiet=True)']","['(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)']",[],"['', 'if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)']",[''],[],[],"['', '())', '())', '(, (True, False))', '()))', '()))', '']","['skip(', 'skipif(torch.cuda.device_count() < 2, reason=)', 'xfail(', 'parametrize(', 'parametrize())', 'parametrize())', 'parametrize(, (True, False))', 'parametrize()))', 'parametrize()))', 'skipif(torch.cuda.device_count() < 2, reason=)', 'skipif(torch.cuda.device_count() < 2, reason=)', 'parametrize(', 'skipif(torch.cuda.device_count() < 2, reason=)', 'skipif(torch.cuda.device_count() < 2, reason=)', 'skipif(torch.cuda.device_count() < 2, reason=)', 'skipif(torch.cuda.device_count() < 2, reason=)']","['mark.skip(', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.xfail(', 'mark.parametrize(', 'mark.parametrize())', 'mark.parametrize())', 'mark.parametrize(, (True, False))', 'mark.parametrize()))', 'mark.parametrize()))', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.parametrize(', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.skipif(torch.cuda.device_count() < 2, reason=)']","['setattr(BertModel, , lambda _: BertModel(config))', 'setattr(BertModel, , lambda _: BertModel(config))', 'setattr(']",[],[],"['in choices', 'set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'tokens == [,', 'labels == []', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', '(json.loads(h5py_file.get()[0]) ==', 'metrics.keys() == {}', 'set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'tokens == [,', 'labels == []', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'args.func.__name__ == ', 'set(result.keys()) == {,', 'set(result.keys()) == {,', 'results[0][] is True', 'results[0][] is False', 'results[0][] is True', 'set(result.keys()) == {,', 'set(result.keys()) == {,', 'set(result.keys()) == {,', 'span != ', 'lines[0] == ', 'lines[0] == ', 'in config', 'in items', 'in items', 'in items', 'in items', 'ja == {', 'url_to_filename(baseurl + )', 'method_counts[] == 1', 'method_counts[] == 1', 'method_counts[] == 2', 'method_counts[] == 1', 'method_counts[] == 3', 'method_counts[] == 2', 'takes_arg(bare_function, )', 'not takes_arg(bare_function, )', 'takes_arg(SomeClass, )', 'takes_arg(SomeClass, )', 'not takes_arg(SomeClass, )', 'takes_arg(SomeClass.check_param, )', 'not takes_arg(SomeClass.check_param, )', 'takes_arg(SomeClass.set_total, )', 'not takes_arg(SomeClass.set_total, )', 'kwargs == {', 'c.c[].a == 3', 'c.c[].a == [4, 5]', 'unflattened == {', 'override_dict == {', 'params == {}', 'params[', 'params.files_to_archive == {', 'params.pop_choice(', 'params.pop_choice(', 'not in base_class.list_available()', 'base_class.by_name() == Fake', 'base_class.by_name() == FakeAlternate', 'DatasetReader.by_name(', 'DatasetReader.by_name(', 'DatasetReader.by_name(', 'DatasetReader.by_name(', 'DataIterator.by_name(', 'DataIterator.by_name(', 'Tokenizer.by_name(', 'Tokenizer.by_name(', 'TokenIndexer.by_name(', 'TokenIndexer.by_name(', 'Regularizer.by_name(', 'Regularizer.by_name(', 'TokenEmbedder.by_name(', 'TokenEmbedder.by_name(', 'TextFieldEmbedder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'duplicate_reader.__name__ == ', 'util.group_by_count([1, 2, 3, 4, 5, 6, 7], 3, 20) == [[1, 2, 3], [4, 5, 6], [7, 20, 20]]', 'not in sys.modules', 'not in sys.modules', 'in sys.modules', 'in sys.modules', 'in sys.modules', 'set(frozen_parameter_names) == {}', 'set(tunable_parameter_names) == {}', '[t.text for t in instances[0].fields[]', '[t.sequence_index for t in instances[0].fields[]] == [0, 1]', '[t.text for t in instances[0].fields[]', 'reader._token_indexers[', 'tokens == [,', 'ccg_categories == [,', 'original_pos_tags == [,', 'modified_pos_tags == [,', 'predicate_arg_categories == [,', 'tokens == [,', 'tokens == [,', 'tokens == []', 'tokens == []', 'set(self.instances[0].fields.keys()) == set((,', '[t.text for t in fields[].tokens] == \\', 'fields[] == \\', '[t.text for t in fields[].tokens] == \\', 'fields[] == \\', 'list(source_token_ids) == [0,   # these', 'list(target_token_ids) == [9,   # @start@', 'text == [,', 'text == [,', '([], 1) in gold_mentions_with_ids', 'text == [,', 'gold_mentions_with_ids == [([], 0)]', 'text == [,', 'gold_mentions_with_ids == [([], 0),', 'annotation.words == [,', 'annotation.pos_tags == [,', 'annotation.predicate_framenet_ids == [None, None, None, , None,', 'annotation.srl_frames == [(,', 'annotation.named_entities == [,', 'annotation.predicate_lemmas == [None, None, , None,', 'annotation.speakers == [None, None, None, None, None, None,', 'annotation.parse_tree == Tree.fromstring(', 'annotation.words == [,', 'annotation.pos_tags == [,', 'annotation.word_senses == [None, 2, 5, None, 2, None, None,', 'annotation.predicate_framenet_ids == [None, None, , None, None, None,', 'annotation.srl_frames == [(,', 'annotation.named_entities == [,', 'annotation.predicate_lemmas == [None, ,', 'annotation.speakers == [None, None, None, None, None, None,', 'annotation.parse_tree == Tree.fromstring(', 'annotation.document_id == ', 'annotation.words == []', 'annotation.pos_tags == []', 'annotation.named_entities == [,', 'annotation.parse_tree == Tree.fromstring(', 'annotation.document_id == ', 'annotation.words == [,', 'annotation.pos_tags == [,', 'annotation.word_senses == [None, None, None, 4.0, None, None, None, None,', 'annotation.predicate_framenet_ids == [None, None, None, , None, None,', 'annotation.srl_frames == [(,', 'annotation.named_entities == [,', 'annotation.predicate_lemmas == [None, None, None, , None, None, None,', 'annotation.speakers == [,', 'annotation.parse_tree == Tree.fromstring(', 'set(spans) == {(, (7, 7))}', 'set(spans) == {(, (7, 7)),', 'set(spans) == {(, (7, 9))}', 'set(spans) == {(, (7, 9))}', 'set(spans) == {(, (4, 5)),', 'set(spans) == {(, (5, 6)),', 'spans == [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 1), (1, 2),', 'spans == [(, (4, 4))]', 'spans == [(, (4, 4))]', 'bioul_sequence == []', 'bioul_sequence == []', 'bioul_sequence == []', 'sql_data.text == []', 'sql_data.text_with_variables == []', 'sql_data.sql == [,', 'sql_data.text_variables == {}', 'sql_data.sql_variables == {},', 'sql_data.sql == [,', 'sql_data.text_variables == {}', 'sql_data.sql_variables == {},', 'tokens == []', 'tags == []', 'cleaned == [,', 'cleaned == [,', 'resolved == []', 'get_text(,', 'get_text(,', 'get_text(,', 'get_text(,', 'get_text(,', 'get_text(,', 'get_text(,', 'get_text(,', 'get_text(,', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[2].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[4].fields[]', '[t.text for t in instances[4].fields[]', '[t.text for t in instance[]', '[i.sequence_index for i in instance[]] == [3]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tensor_dict[].numpy().tolist() == [2, 3, 4, 5, 6, 7]', 'tensor_dict[].numpy().tolist() == [2]', 'tensor_dict[].numpy().tolist() == [[3]]', '[t.text for t in instance[,', '[i.sequence_index for i in instance[]] == [6]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', '[t.text for t in instance[]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tensor_dict[].numpy().tolist() == [2, 3, 4]', 'tensor_dict[].numpy().tolist() == [2]', '[t.text for t in instance[,', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tokens == [,', 'fields[]', 'tokens == [,', 'fields[,', 'fields[]', 'tokens == [,', 'pos_tags == [,', 'tokens == [,', 'pos_tags == [,', 'tree == Tree.fromstring()', 'spans == [((0, 1), )]', 'span_dict == {(1, 1): ,', 'set(instance[].metadata.keys()) == {', 'len(instance[]) == question_length + passage_length + 1', 'instance[][0] == (question_length + 1 + 46,', 'set(instance[].metadata.keys()) == {', 'set(instance[].metadata.keys()) == {', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', 'instances[0].fields[].sequence_index == 4', 'reader._token_indexers[', '[t.text for t in instances[0].fields[]', '[x.label for x in instances[0].fields[]', '[x.label for x in instances[0].fields[]', 'instances[0].fields[] * passage_length', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', '([t.text for t in instances[3].fields[].tokens[:3]] ==', '[t.text for t in instances[3].fields[]', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[', 'set(instance_x.fields[]) \\', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[2].fields[]', 'tokens == [,', 'arcs.indices == [(1, 0), (1, 5), (1, 8), (4, 3), (5, 4),', 'arcs.labels == [,', 'tokens == [,', 'arcs.indices == [(1, 0), (1, 2), (3, 2), (3, 4), (5, 4), (5, 6),', 'arcs.labels == [,', 'len(instance.fields[].field_list) == 1', 'instance.fields[].field_list[0].sequence_index == -1', 'set(instance.fields.keys()) == \\', '[t.text for t in instance.fields[].tokens] == \\', 'isinstance(instance.fields[].as_tensor({}), AtisWorld)', 'set(world.valid_actions[]) == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'world.linked_entities[][2] == \\', 'tokens == []', 'indices == [93, 75, 78, 88, 86, 82, 39, 113, 48, 42, 2, 46, 91, 90, 102, 92, 90, 103, 118, 34, 5,', 'production_rules == [(, True),', 'instance.fields.keys() == {,', 'set(agenda_strings) == {,', 'instance.fields.keys() == {,', 'set(agenda_strings) == {,', 'instance.fields.keys() == {,', 'action_sequence == [,', 'tokens == []', 'tags == []', 'fields[ \\', 'tokens == []', 'tags == []', 'fields[\\', 'tokens == []', 'tags == []', 'fields[\\', 'tokens == []', 'tags == []', 'fields[\\', 'tokens == []', 'tags == []', 'fields[\\', 'instance.fields[] == question_tokens', 'isinstance(instance.fields[].as_tensor({}), WikiTablesLanguage)', 'actions == [,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[]', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[,', '[t.text for t in fields[]', '[t.text for t in fields[]', 'tokens == [,', 'fields[,', 'tokens == [,', 'fields[,', 'tokens == [,', 'fields[,', 'tokens == [,', 'fields[]', 'fields[]', 'converted == [,', 'converted == []', 'converted == []', 'wordpieces == [,', '[wordpieces[i] for i in offsets] == []', '[wordpieces[i] for i in start_offsets] == []', 'tokens == [,', 'fields[,', 'tokens == [,', 'fields[,', 'tokens == [,', 'fields[,', 'tokens == [,', 'fields[,', 'fields[]', 'str(exec_info.value) == ', '[t.text for t in fields[,', 'fields[]', 'fields[,', '[t.text for t in fields[,', 'fields[,', 'fields[,', 'fields[].labels == [0, 4, 4, 1, 15, 15, 9, 9, 15, 9, 13, 13,', '[t.text for t in fields[,', 'fields[,', 'fields[,', '[t.text for t in fields[,', 'fields[,', 'fields[,', '[t.text for t in fields[,', 'fields[]', 'fields[,', 'fields1[]', 'fields1[', '[t.text for t in fields1[,', 'fields1[,', 'fields1[,', 'fields2[', '[t.text for t in fields2[,', 'fields2[,', 'fields2[,', '[t.text for t in fields1[,', 'fields1[,', 'fields1[,', '[t.text for t in fields2[,', 'fields2[,', 'fields2[,', 'fields1[', '[t.text for t in fields1[,', 'fields1[]', 'fields1[]', 'fields2[', '[t.text for t in fields2[,', 'fields2[,', 'fields2[,', 'in processed_langs', '(counter_es > 20 or counter_fr > 20 or counter_it > 20)', 'padding_lengths == {: 5},', 'self.field._indexed_entity_texts.keys() == {}', 'self.field._indexed_entity_texts[] == expected_array', 'self.field.get_padding_lengths() == {: 3,', 'self.field.get_padding_lengths() == {: 3,', 'tensor_dict.keys() == {}', 'batched_tensor_dict.keys() == {}', 'padding_lengths == {: 6}', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'tensor_tuple[0] == ', 'field1._indexed_tokens[] == [[capital_a_char_index],', 'field2._indexed_tokens[] == [[capital_a_char_index],', 'padding_lengths == {: 8}', 'padding_lengths == {: 5,', 'list(tensors[].shape) == [7]', 'list(tensors[].shape) == [3]', 'list(tensors[].shape) == [4]', 'list(tensors[].shape) == [4, 8]', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == [0] * 8', 'BasicIterator(batch_size=2, instances_per_epoch=21).get_num_batches(self.lazy_instances) == 11', 'BasicIterator(batch_size=2, instances_per_epoch=21).get_num_batches(self.instances) == 11', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[3], self.instances[4]],', 'grouped_instances == [[self.instances[1], self.instances[2]],', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'grouped_instances == [[self.instances[2], self.instances[3]],', 'all(epoch_num == epoch for epoch_num in batch[])', 'all(epoch_num == epoch for epoch_num in batch[])', 'all(epoch_num == epoch for epoch_num in batch[])', 'grouped_instances == [[self.instances[0], self.instances[1]],', 'stats[] == len(self.instances)', 'stats[] == [2, 1, 1, 1]', 'stats[] == [8, 3, 9, 1]', 'stats[] == len(token_counts)', 'stats[] == [1, 2]', 'stats[] == [10, 8]', 'grouped_instances == [[self.instances[4], self.instances[2]],', 'grouped_instances == [[self.instances[2], self.instances[0]],', 'grouped_instances == [[self.instances[3]],', 'stats[] == len(self.instances)', 'stats[] == [2, 2, 1]', 'stats[] == [6, 8, 9]', 'stats[] == len(test_instances)', 'stats[] == [2, 1]', 'stats[] == [8, 10]', 'all(batch_len == 2 for batch_len in stats[])', 'stats[] == len(self.instances) - 1', 'indexed_tokens[] == [0,    0, 0,  0,  0,  0, 0,  1, 1,  1,  1,  1, 1]', 'indexed_tokens[] == [16,   2,  3,    4,  3,    5,    17,   8,     9,   17,', 'indexed_tokens[] == [0,    0,  0,    0,  0,    0,    0,    1,     1,   1,', 'padded_tokens[].tolist() == [[1, 2, 3, 4, 5, 0, 0, 0, 0, 0],', 'indices == {: [[8, 3, 9],', 'padded[].tolist() == [[2, 3, 3, 4, 5, 6, 7, 8, 0, 0],', 'counter[: 1,', 'indexer.tokens_to_indices([tokens[-1]], vocab, : [none_index]}', 'padded_tokens[].tolist() == expected_padded_tokens', 'counter[: 6}', 'indexer.tokens_to_indices([tokens[1]], vocab, : [person_index]}', 'indexer.tokens_to_indices([tokens[-1]], vocab, : [none_index]}', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'not in self.vocab._index_to_token', 'not in self.vocab._token_to_index', 'indices[][:9] == [50, 4, 21, 31, 4, 0, 1, 51, 0]', 'counter[: 2}', 'counter[: 2}', 'indexed[] == expected_ids', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'in words', 'not in words', 'not in words', 'in words', 'in words', 'in words', 'in words', 'not in words', 'not in words', 'in words', 'in words', 'not in words', 'in words', 'in words', 'not in words', 'in words', 'in words', 'in words', ').values()', 'vocab.get_token_index() == word_index', 'vocab.get_token_from_index(word_index, namespace=', 'vocab.get_vocab_size(namespace=) == initial_vocab_size + 1', ').values()', ').values()', 'vocab.get_token_index() == word_index', 'vocab.get_token_index() == word2_index', 'vocab.get_token_from_index(word_index, namespace=', 'vocab.get_token_from_index(word2_index, namespace=', 'vocab.get_vocab_size(namespace=) == initial_vocab_size + 2', 'vocab.get_token_index() == 0', 'vocab.get_token_index() == 1', 'vocab.get_token_index() == 2', 'vocab.get_token_index() == 3', 'vocab.get_token_index() == 4', 'vocab.get_token_from_index(0, namespace=', 'vocab.get_token_from_index(1, namespace=', 'vocab.get_token_from_index(2, namespace=', 'vocab.get_token_from_index(3, namespace=', 'vocab.get_token_from_index(4, namespace=', 'vocab2.get_vocab_size(namespace=) == 3', 'vocab2.get_token_from_index(0, namespace=', 'vocab2.get_token_from_index(1, namespace=', 'vocab2.get_token_from_index(2, namespace=', 'vocab2.get_token_index() == 0', 'vocab2.get_token_index() == 1', 'vocab2.get_token_index() == 2', 'vocab2.get_vocab_size(namespace=) == 4  # (unk + padding + two tokens)', 'vocab2.get_token_from_index(0, namespace=) == vocab._padding_token', 'vocab2.get_token_from_index(1, namespace=) == vocab._oov_token', 'vocab2.get_token_from_index(2, namespace=', 'vocab2.get_token_from_index(3, namespace=', 'vocab2.get_token_index(vocab._padding_token, namespace=) == 0', 'vocab2.get_token_index(vocab._oov_token, namespace=) == 1', 'vocab2.get_token_index() == 2', 'vocab2.get_token_index() == 3', 'vocab2.get_index_to_token_vocabulary(,', 'vocab.get_index_to_token_vocabulary(,', 'extended_vocab.get_token_index() # should be present', 'extended_vocab.get_token_index() # should be present', 'extended_vocab.get_vocab_size() == 8 # 2 extra overlapping because padded', 'extended_vocab.get_vocab_size() == 6 # l,m,n,o + oov + padding', 'extended_vocab.get_vocab_size() == 3 # x,y,z', 'words_read == words, f \\', 'words_read == words, f \\', 'in words', 'not in words', 'not in words', 'in words', 'in words', 'not in words', 'len(vocab.get_index_to_token_vocabulary().values()) == 3 # 1 + 2', 'len(vocab.get_index_to_token_vocabulary().values()) == 28 # 26 + 2', 'in attack', 'in attack', 'in attack', 'len(attack[]) # hotflip replaces words without removing', 'in attack', 'in attack', 'in attack', 'len(attack[]) # hotflip replaces words without removing', 'instance[][0] # check that the input has changed.', 'token in attack[][0] # ignore tokens should not be changed', 'original_span_start != flipped_span_start or original_span_end != flipped_span_end', 'in attack', 'in attack', 'in attack', 'len(attack[]) # hotflip replaces words without removing', 'attack[]', 'in reduced', 'in reduced', 'reduced[][0] # always at least one token', 'len(reduced[]) # input reduction removes tokens', 'word in reduced[]', 'in reduced', 'in reduced', 'reduced_input # always at least one token', 'len(reduced_input) <= len(reduced[]) # input reduction removes tokens', 'word in reduced[]', 'in interpretation', ']', 'in interpretation', ']', 'in interpretation', ']', 'in interpretation', ']', 'in interpretation', ']', 'len(interpretation[]) == 7  # 7 words in input', 'params.get()', 'os.path.exists(params.get())', 'params.get()', 'params.get() == original_train_data_path', 'sql_query ==  \\', 'in output_dict.keys()', 'set(decode_output_dict.keys()) == {,', 'set(result) == {,', 'set(decode_output_dict.keys()) == {,', 'resolved_spans == [SpanInformation(start=2, end=7, no_label_prob=0.5,', 'tag in {}', 'set(decode_output_dict.keys()) == {,', 'metrics[] > 0', 'torch.equal(ensemble_output_dict[])', 'ensemble_output_dict[]', 'metrics[] > 0', 'span_end < self.instances[0].fields[].sequence_length()', 'isinstance(output_dict[][0], str)', 'metrics[] > 0', 'span_end < self.instances[0].fields[].sequence_length()', 'isinstance(output_dict[][0], str)', 'worlds[]', 'worlds[]', 'qr_spec_string == ', 'result[] == [[[0, 0], [10, 10]],', 'result[,', 'result[]', 'result[]', 'result[', 'result[]', 'result[]', 'result[]', 'result[] == [2, 0, 2, 2, 4, 2]', 'attention._similarity_function.__class__.__name__ == ', 'ml_fw.get_output_dim() == ml_bw.get_output_dim() == vecs_p.size(2) // 2 == vecs_h.size(2) // 2', 'viterbi_tags == [', 'viterbi_tags == [', 'set(allowed) == {                         # Extra column for end tag.', 'set(allowed) == {                                                   # Extra column for end tag.', 'set(allowed) == {                            # Extra column for end tag.', 'list(elmo_representations[0].size()) == [2, 7+2, 32]', 'list(elmo_representations[1].size()) == [2, 7+2, 32]', 'list(mask.size()) == [2, 7+2]', 'numpy.allclose(actual_embeddings[:len(tokens)], expected_embeddings, atol=1e-6)', 'numpy.allclose(embeddings[0, correct_index, :].data.numpy(), embeddings[0, 1, :].data.numpy())', 'self.encoder_base._get_initial_states(self.batch_size, self.num_valid, self.sorting_indices) is None', 'attention._similarity_function.__class__.__name__ == ', 'encoder.__class__.__name__ == ', 'encoder._module.__class__.__name__ == ', '(forward_mask[0].data == torch.IntTensor([[1, 0, 0, 0, 0, 0],', '(forward_mask[1].data == torch.IntTensor([[1, 0, 0, 0, 0, 0],', '(forward_mask[2].data == torch.IntTensor([[1, 0, 0, 0, 0, 0],', '(backward_mask[0].data == torch.IntTensor([[1, 1, 1, 0, 0, 0],', '(backward_mask[1].data == torch.IntTensor([[1, 1, 1, 1, 1, 0],', '(backward_mask[2].data == torch.IntTensor([[1, 1, 1, 1, 1, 1],', 'in exception_info.value.message', 'in exception_info.value.message', 'not (results[i] == 0.).data.all()', '(results[i] == 0.).data.all()', 'encoder.__class__.__name__ == ', 'encoder._module.__class__.__name__ == ', 'not (results[i] == 0.).data.all()', '(results[i] == 0.).data.all()', 'CosineSimilarity.from_params(Params({})).__class__.__name__ == ', 'DotProductSimilarity.from_params(Params({})).__class__.__name__ == ', 'result.shape == (1, 2,)', 'tokens[].tolist() == [[16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 14, 12, 17, 0],', 'tokens[].tolist() == [[1, 3, 4, 5, 6, 7, 8, 9, 10, 11],', 'tokens[].tolist() == [[16, 2, 3, 4, 3, 5, 6, 17,', 'tag in {}', 'torch.equal(embeddings[i], vec),  + archive_path', 'f.num_tokens == expected_num_tokens, f', 'torch.all(embedder.weight[2:, :] == torch.Tensor([[2.0, 3.3, 0.0], [1.1, 1.4, -3.0]]))', 'tag in {}', 'tag in {}', 'tag in {}', 'tensor.data.max() < math.sqrt(3/10)', 'tensor.data.min() > -math.sqrt(3/10)', 'tensor.data.max() < math.sqrt(3/10) * 1.43', 'tensor.data.min() > -math.sqrt(3/10) * 1.43', 'torch.equal(parameter.data, torch.ones(parameter.size())*10)', 'not torch.equal(parameter.data, torch.ones(parameter.size())*10)', 'has_tensor({', 'moved_obj[][0].a == 1', 'moved_obj[][0].b._device == new_device', 'moved_obj[][1].b._device == new_device', 'moved_obj[]._device == new_device', 'moved_obj[][0] == 1', 'moved_obj[][1]._device == new_device', 'tags == []', 'tags == []', 'len(linear_50_1[]) == 17', 'all(len(a) == 1 for a in linear_50_1[])', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'new_instances[0].fields[] is not None', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0][][0].label == 2', 'new_instances[0][][0] == (0, 1)  # token indices', 'new_instances[0][][0].labels == [2, 0, 0]', 'new_instances[0][][0] == (0, 1)  # token indices', 'len(result[]) == 21 # number of possible substrings of the sentence.', 'len(result[]) == 21 # number of possible substrings of the sentence.', 'len(result[]) == 36 # number of possible substrings of the sentence.', 'document == [,', 'in new_instance', 'len(new_instance[]) == 60 # 7 words in input', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'new_instances[0].fields[] is not None', 'in new_instances[0]', 'len(new_instances[0][].tokens) == 2  # should have added two words', 'in new_instances[0]', 'len(new_instances[0][].tokens) == 1  # should have added one word', 'in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 1  # Because there is one world in the input.', 'in result', 'in result', 'len(result[][0]) == 1  # Because there is one world in the input.', 'words == [,', 'result == {: []}', 'in grads', 'in grads', 'grads[] is not None', 'grads[] is not None', 'len(grads[][0]) == 9  # 9 words in hypothesis', 'len(grads[][0]) == 5  # 5 words in premise', 'in new_instance', 'len(new_instance[]) == 7 # 7 words in input', 'words == [,', 'result == {: []}', 'results[0] == {: []}', 'results[1] == {],', 'label in predictor._model.vocab.get_token_to_index_vocabulary(namespace=)', 'label in predictor._model.vocab.get_token_to_index_vocabulary(namespace=)', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'shortest_logical_form == ', 'shortest_logical_form == ', 'set(first_four_logical_forms) == {,', 'set(first_four_logical_forms) == {,', 'shortest_logical_form == ', 'set(length_three_logical_forms) == {,', 'table_question_context.table_data == [{: Date(2001, -1, -1),', 'table_question_context.table_data == [{: 2001.0,', 'entities == [(]),', 'numbers == [(, 9)]', 'string_entities == [(]),', 'sorted(entities) == [,', 'neighbors_with_sets == {},', 'entity_text == {,', 'set(neighbors.keys()) == {,', 'set(neighbors[}', 'neighbors[]', 'neighbors[] == []', 'neighbors[]', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[]', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[]', 'neighbors[]', 'neighbors[] == []', 'set(neighbors[,', 'neighbors[]', 'self.language.execute() == 5', 'self.language.execute() == 2', 'self.language.execute() == 20', 'self.language.execute() == 3', 'self.language.execute() == 3', 'self.language.execute() == 5', 'self.language.execute() == -1', 'self.language.execute() == 10', 'self.language.execute() == 2', 'self.language.execute() == 5', 'self.language.execute() == 5', 'self.language.execute() == 0', 'self.language.execute() == 4', 'self.language.execute() == 12', 'self.language.execute() == 1', 'action_sequence == [,', 'action_sequence == [,', 'action_sequence == [,', 'action_sequence == [,', 'self.custom_language.execute(', 'self.custom_language.execute(', 'self.custom_language.execute(', 'self.custom_language.execute(', 'self.custom_language.execute(', 'self.custom_language.execute(', 'self.custom_language.execute(', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'action_sequence == [,', 'action_sequence == [,', 'action_sequence == [,', 'set(agenda) == {}', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'set(agenda) == {,', 'self.language.execute((', 'self.language.execute((', 'self.language.execute((', 'self.language.execute((', 'self.language.logical_form_to_action_sequence((', 'self.language.execute((', 'self.language.execute((', 'self.language.logical_form_to_action_sequence((', 'set(cell_list) == {}', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'self.language.evaluate_logical_form(logical_form, [,', 'not self.language.evaluate_logical_form(logical_form, [,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {,', 'set(world.get_agenda(conservative=True)) == {}', 'executor.evaluate_sql_query(postprocessed_sql_query_label,', 'executor.evaluate_sql_query(postprocessed_predicted_sql_query,', 'expression == [[]]', 'expression == []]]]', 'set(valid_actions.keys()) == \\', 'set(valid_actions[}', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'set(world.valid_actions[]) == \\', 'action_sequence == [,', 'action_sequence == \\', 'action_sequence == \\', 'action_sequence == \\', 'action_sequence == \\', 'world._get_numeric_database_values(]', 'world._get_sequence_with_spacing(world.grammar,', 'grammar_dictionary[,', 'grammar_dictionary[,', 'not world.is_global_rule()', 'in action_sequence', 'in action_sequence', 'in actions', 'in actions', 'world.base_grammar_dictionary[,', 'world.base_grammar_dictionary[,', 'argument_paths == [[],', 'unary_function_paths == [[,', 'binary_function_paths == [[,', 'argument_paths == [[],', 'identity_paths == [[,', ']', 'config[', 'in data', 'not in data', 'not in data', 'in data', 'in data', 'not in data', ']', ']', ']', 'in data', 'in data', 'in data', 'in data', 'in data', 'not in data', 'in data', 'not in data', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [3, 4]', 'actions[][2] == [3, 4]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'get_metrics(predicted=[],', 'get_metrics(predicted=[],', 'get_metrics(predicted=[],', 'get_metrics([],', 'get_metrics([],', 'get_metrics([],', 'get_metrics([],', 'lines[4] == ', 'lines[4] == ', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in kwargs, \\', 'len(kwargs[]) == batch_size, \\', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], int)', 'epochs[3] == ', 'in epochs[0]', 'not in files', 'not in files', 'is_hat_shaped([float(k) for k in range(10)] +', 'not is_hat_shaped([float(k) for k in range(10)] +', 'lr == lr_check, f', 'self.metric._precision_totals[1] == (', 'self.metric._precision_matches[2] == (', 'self.metric._precision_totals[2] == (', 'accuracy.get_metric() == 2. / 4', 'accuracy.get_metric() == 5. / 8', 'accuracy.get_metric() == 8. / 12', 'accuracy.get_metric() == 3. / 4', 'accuracy.get_metric(reset=True) == (0.25 + 1 + 0.5)/3.0', 'accuracy.get_metric(reset=True) == (0.25 + 0.5)/2.0', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'isclose(optimizer.param_groups[0][],', 'param_groups[0][] == 1', 'param_groups[0][] == 2', 'param_groups[1][] == 3', 'param_groups[2][] == 1', 'param_groups[k][] == 5', 'len(param_groups[0][]) == 6', 'len(param_groups[1][]) == 2', 'len(param_groups[2][]) == 3', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in kwargs, \\', 'len(kwargs[]) == batch_size, \\', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], int)', 'epochs[3] == ', 'in epochs[0]', 'saved_params == self.params.pop().as_dict(quiet=True)']","['(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)']",[],"['(reason=)', 'if(torch.cuda.device_count()', 'if(torch.cuda.device_count()', 'if(torch.cuda.device_count()', 'if(torch.cuda.device_count()', 'if(torch.cuda.device_count()', 'if(torch.cuda.device_count()', 'if(torch.cuda.device_count()']",['(not os.path.exists(AllenNlpTestCase.PROJECT_ROOT / )'],[],[],"['(, [(False, False), (False, True), (True, False), (True, True)])', '())', '())', '(, (True, False))', '', '', '']","['skip(reason=)', 'skipif(torch.cuda.device_count() < 2,', 'xfail(not os.path.exists(AllenNlpTestCase.PROJECT_ROOT / ),', 'parametrize(, [(False, False), (False, True), (True, False), (True, True)])', 'parametrize())', 'parametrize())', 'parametrize(, (True, False))', 'parametrize(, (', 'parametrize(, (', 'skipif(torch.cuda.device_count() < 2,', 'skipif(torch.cuda.device_count() < 2,', 'parametrize(,', 'skipif(torch.cuda.device_count() < 2,', 'skipif(torch.cuda.device_count() < 2,', 'skipif(torch.cuda.device_count() < 2,', 'skipif(torch.cuda.device_count() < 2,']","['mark.skip(reason=)', 'mark.skipif(torch.cuda.device_count() < 2,', 'mark.xfail(not os.path.exists(AllenNlpTestCase.PROJECT_ROOT / ),', 'mark.parametrize(, [(False, False), (False, True), (True, False), (True, True)])', 'mark.parametrize())', 'mark.parametrize())', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (', 'mark.parametrize(, (', 'mark.skipif(torch.cuda.device_count() < 2,', 'mark.skipif(torch.cuda.device_count() < 2,', 'mark.parametrize(,', 'mark.skipif(torch.cuda.device_count() < 2,', 'mark.skipif(torch.cuda.device_count() < 2,', 'mark.skipif(torch.cuda.device_count() < 2,', 'mark.skipif(torch.cuda.device_count() < 2,']","['setattr(BertModel, , lambda _: BertModel(config))', 'setattr(BertModel, , lambda _: BertModel(config))', 'setattr(BertTokenizer, , lambda _: BertTokenizer(vocab_path))']",[],[]
1615,Marcin Kardas,marcin.kardas@gmail.com,2019-10-02 05:44:23+02:00,32e37f0027edf4231570e0db5466cc94188094b1,https://github.com/allenai/allennlp/commit/32e37f0027edf4231570e0db5466cc94188094b1,"Add question id to MetadataField (#3314)

According to docstring of SquadReader the instance's ID should be
accessible as metadata['id'].",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1616,Nelson Liu,nelson-liu@users.noreply.github.com,2019-10-03 08:57:11-07:00,4fcedb149859916502cc430341612d226c3552c0,https://github.com/allenai/allennlp/commit/4fcedb149859916502cc430341612d226c3552c0,"Add token offsets to bidaf output (#3316)

* Add token offsets to bidaf output

* Add changes lost from merge commit

* Fix TestPredict

* Reformat with black",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1617,Eric Wallace,eswallace@comcast.net,2019-10-03 13:21:20-07:00,c3f9508d861b29373c8399180daad6e7f68a05fe,https://github.com/allenai/allennlp/commit/c3f9508d861b29373c8399180daad6e7f68a05fe,"add basic SST training config (#3320)

* add basic SST training config

* rename and add comment",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1618,Michael Schmitz,MichaelS@allenai.org,2019-10-03 14:33:05-07:00,811e8292a089ed660126d1102514dd8fea69f402,https://github.com/allenai/allennlp/commit/811e8292a089ed660126d1102514dd8fea69f402,"Use a NVIDIA base image (#3236)

* Use an NVIDIA base image for Dockerfile.pip

* Use the nvidia base image.

* Update Dockerfile.pip

`s/pip3/pip/`

* Update Dockerfile to use an NVIDIA base image.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1619,Michael Schmitz,MichaelS@allenai.org,2019-10-03 15:00:41-07:00,8e9ce6cc661cc8b7330d27ece6399e3e98b78098,https://github.com/allenai/allennlp/commit/8e9ce6cc661cc8b7330d27ece6399e3e98b78098,"Revert ""Use a NVIDIA base image (#3236)"" (#3321)

This reverts commit 811e8292a089ed660126d1102514dd8fea69f402.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1620,Santiago Castro,sacastro@umich.edu,2019-10-05 00:02:31+02:00,aab7f13e759df1f31e01236c61996868d2712269,https://github.com/allenai/allennlp/commit/aab7f13e759df1f31e01236c61996868d2712269,"Make the subcommand docstring test faster (#3185)

* Make the subcommand docstring test faster

* Fix mypy errors

* Remove pylint comments

* Remove more pylint comments

* Black

* Re-enable the test

* Remove the pytorch_pretrained_bert warning check",2,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[''],[],[],[],[],['skip('],['mark.skip('],[],[],['import pytest']
1621,Rik van Noord,31345314+RikVN@users.noreply.github.com,2019-10-05 00:45:20+02:00,dfe72ac17d202cda30218dcb52b269ce0376fa54,https://github.com/allenai/allennlp/commit/dfe72ac17d202cda30218dcb52b269ce0376fa54,"#3213 - try to use default mapping if key mapping is not in embedding_to_indexer_map (#3234)

* #3213 - try to use default mapping if key mapping is not in embedding_to_indexer_map

* Run black.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1622,Eric Wallace,eswallace@comcast.net,2019-10-04 15:52:14-07:00,135db83a151179715e32e9093cde0ac9bd17ec20,https://github.com/allenai/allennlp/commit/135db83a151179715e32e9093cde0ac9bd17ec20,init,4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1623,Nelson Liu,nelson-liu@users.noreply.github.com,2019-10-06 23:01:58-07:00,200239712738815a49c24f86961762b6f1636513,https://github.com/allenai/allennlp/commit/200239712738815a49c24f86961762b6f1636513,Don't crash SQuAD dataset reader if ID doesn't exist. (#3330),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1624,Matt Gardner,mattg@allenai.org,2019-10-09 13:28:10-07:00,4e33a87b602d9236443d50b56e2cac291eda42eb,https://github.com/allenai/allennlp/commit/4e33a87b602d9236443d50b56e2cac291eda42eb,"Revert ""init"" (#3340)

This reverts commit 135db83a151179715e32e9093cde0ac9bd17ec20.",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1625,Yu Gu,yugu772@yahoo.com,2019-10-09 16:54:29-04:00,fa78ab5769541e552c592f0c196a4d6dc402c02a,https://github.com/allenai/allennlp/commit/fa78ab5769541e552c592f0c196a4d6dc402c02a,fix an annotation error in linking_transition_function.py (#3338),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1626,Ryo Takahashi,reiyw.setuve+github@gmail.com,2019-10-10 23:08:36+09:00,02eeccdca1ed49175147c5fb45b0c432216a637c,https://github.com/allenai/allennlp/commit/02eeccdca1ed49175147c5fb45b0c432216a637c,Fix typo (#3341),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1627,Matt Gardner,mattg@allenai.org,2019-10-10 16:59:23-07:00,841ec870b03c4af2f42711670d7de8c641fe11a4,https://github.com/allenai/allennlp/commit/841ec870b03c4af2f42711670d7de8c641fe11a4,"Remove semantic parsing code (#3207)

* Remove semantic parsing code

* Fix module imports, remove more tests

* More fixes

* fix predict test

* fix another test

* remove more docs

* last doc errors, i think...

* Remove unnecessary requirements

* Removing some fixutre data that I missed earlier

* Fix merge conflicts with black

* More merge conflicts, pin to pytorch 1.2

* black merge conflicts

* Remove unidecode",279,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,12,25,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,590,28,0,3,1,0,0,0,4,4,0,0,8,[],[],[],[],[],[],[],[],[],[],[],[],"[('Raises', '(AssertionError, msg=f):'), ('Logs', '() as log:'), ('Equal', '('), ('Logs', '() as log:'), ('Equal', '('), ('Logs', '() as log:'), ('Equal', '('), ('Logs', '() as log:'), ('Equal', '('), ('Logs', '() as log:'), ('Equal', '('), ('Raises', '(ParseError):')]","['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['results[0][] == 1000', 'results[0][] == 400', 'results[0][] == 1000', 'predictor._dataset_reader.passage_length_limit == 1000', 'predictor._dataset_reader.passage_length_limit == 400', 'predictor._dataset_reader.passage_length_limit == 1000']",[],[],[],[],[],[],[],[],[],[],[],[],"['results[0][] is True', 'results[0][] is False', 'results[0][] is True', 'len(dataset) == 1', 'sql_data.text == [', 'sql_data.text_with_variables == [', 'sql_data.sql == [', 'sql_data.text_variables == {', 'sql_data.sql_variables == {', 'sql_data.sql == [', 'sql_data.text_variables == {}', 'sql_data.sql_variables == {', 'sql_data.text == correct_text[i][0]', 'sql_data.text_with_variables == correct_text[i][1]', 'len(dataset) == 3', 'tokens == [', 'tags == []', 'cleaned == [', 'cleaned == [', 'text2sql_utils.clean_unneeded_aliases([]', 'text2sql_utils.clean_unneeded_aliases(sql) == sql', 'schema == {', 'resolved == [', 'len(instance.fields[].field_list) == 1', 'instance.fields[].field_list[0].sequence_index == -1', 'len(instances) == 13', 'set(instance.fields.keys()) == {', '[t.text for t in instance.fields[].tokens] == [', 'isinstance(instance.fields[].as_tensor({}), AtisWorld)', 'set(world.valid_actions[]) == {', 'world.linked_entities[][2] == [', 'world.linked_entities[][', 'world.linked_entities[][2] == [', 'world.linked_entities[][2] == [', 'world.linked_entities[][', 'world.linked_entities[][2] == [', 'len(instances) == 5', 'tokens == [', 'indices == [', 'production_rules == [', 'len(instances) == 3', 'instance.fields.keys() == {', '[t.text for t in sentence_tokens] == expected_tokens', 'len(actions) == 115', 'set(agenda_strings) == {', 'isinstance(worlds[0], NlvrLanguage)', 'label == ', 'expected_agenda_actions == agenda_actions', 'len(instances) == 2', 'instance.fields.keys() == {', '[t.text for t in sentence_tokens] == expected_tokens', 'len(actions) == 115', 'set(agenda_strings) == {', 'all([isinstance(world, NlvrLanguage) for world in worlds])', 'labels == []', 'len(instances) == 2', 'instance.fields.keys() == {', 'len(all_action_sequence_indices) == 20', 'action_sequence == [', 'tokens == [', 'tags == []', '(', 'tokens == [', 'tags == []', '(', 'tokens == [', 'tags == [', '(', 'tokens == [', 'tags == []', '(', 'tokens == [', 'tags == [', '(', 'len(instances) == 2', 'instance.fields.keys() == {', '[t.text for t in instance.fields[].tokens] == question_tokens', 'instance.fields[] == question_tokens', 'isinstance(instance.fields[].as_tensor({}), WikiTablesLanguage)', 'num_action_sequences == 10', 'actions == [', 'namespace_token_counts[] == {', 'self.field._indexed_entity_texts.keys() == {}', 'self.field._indexed_entity_texts[] == expected_array', 'self.field.get_padding_lengths() == {', 'self.field.get_padding_lengths() == {', 'tensor_dict.keys() == {}', 'lemma_feature == 1', 'feature_values == [0, 0, 0, 1, 1, 1, 0, 0, 0]', 'batched_tensor_dict.keys() == {}', 'namespace_token_counts[] == 1', 'namespace_token_counts[] == 0', 'field._rule_id == self.s_rule_index', 'field.get_padding_lengths() == {}', 'isinstance(tensor_tuple, tuple)', 'len(tensor_tuple) == 4', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'isinstance(tensor_tuple, tuple)', 'len(tensor_tuple) == 4', 'tensor_tuple[0] == ', 'tensor_tuple[1] is False', 'tensor_tuple[2] is None', 'field.batch_tensors(tensor_list) == tensor_list', 'isinstance(tensors, list)', 'len(tensors) == 2', 'isinstance(tensors[0], list)', 'len(tensors[0]) == 3', 'isinstance(tensors[1], list)', 'len(tensors[1]) == 3', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'tensor_tuple[0] == ', 'tensor_tuple[1] is False', 'tensor_tuple[2] is None', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'tensor_tuple[0] == ', 'tensor_tuple[1] is True', 'tensor_tuple[0] == ', 'tensor_tuple[1] is False', 'tensor_tuple[2] is None', '(', 'grammar_state._nonterminal_stack == []', 'model._checklist_cost_weight == 0.8', 'mapping == expected_mapping', 'mapping == [(0, 0), (1, 1), (5, 2), (7, 3), (10, 4)]', 'worlds[]', 'worlds[]', 'qr_spec_string == ', 'grammar_state._nonterminal_stack == []', 'in decode_output', 'len(action_sequence) > 1', 'all([isinstance(action, str) for action in action_sequence])', 'predicted_sql_query is not None', 'predicted_sql_query is not None', 'predicted_sql_query is not None', 'in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 2  # Because there are two worlds in the input.', 'in result', 'in result', 'len(result[][0]) == 1  # Because there is one world in the input.', 'in result', 'in result', 'len(result[][0]) == 1  # Because there is one world in the input.', 'predictor._dataset_reader._keep_if_unparseable is True', 'predictor._dataset_reader._keep_if_unparseable is False', 'predictor._dataset_reader._keep_if_unparseable is True', 'answer_index is not None', 'answer_index is not None', 'len(action_sequence) > 1', 'all([isinstance(action, str) for action in action_sequence])', 'logical_form is not None', 'answer is not None', 'best_action_sequence', 'best_action_sequence[:2] != initial_tokens', 'best_action_sequence[:2] == initial_tokens', 'any(token == initial_token for _, token in choices)', 'len(beam_snapshots) == 1', '0 in beam_snapshots', 'all(len(sequence) == idx + 1 for _, sequence in beam)', 'any(sequence[-1] == action for _, sequence in beam)', 'answer is not None', 'len(black_logical_forms) == 25', 'shortest_logical_form == ', 'set(black_triangle_touch_forms) == {', 'len(black_logical_forms) == 25', 'shortest_logical_form == ', 'set(black_triangle_touch_forms[:6]) == {', 'set(black_triangle_touch_forms[6:12]) == {', 'set(black_triangle_touch_forms[30:33]) == {', 'set(first_four_logical_forms) == {', 'set(first_four_logical_forms) == {', 'empty_set == []', 'set(yellow_black_triangle_touch_forms) == {', 'shortest_logical_form == ', 'set(length_three_logical_forms) == {', 'Date(2013, 12, 31) > Date(2013, 12, 30)', 'Date(2013, 12, 31) == Date(2013, 12, -1)', 'Date(2013, -1, -1) >= Date(2013, 12, 31)', 'not (Date(2013, 12, -1) > Date(2013, 12, 31))', 'not (Date(2013, 12, 31) > 2013)', 'not (Date(2013, 12, 31) >= 2013)', 'Date(2013, 12, 31) != 2013', 'not (Date(2018, 1, 1) >= Date(-1, 2, 1))', 'not (Date(2018, 1, 1) < Date(-1, 2, 1))', 'Date(-1, 2, 1) < Date(-1, 2, 3)', 'not (Date(-1, -1, 1) < Date(-1, -1, 3))', 'not (Date(-1, -1, 1) >= Date(-1, -1, 3))', 'not (Date(2018, -1, 1) < Date(2018, -1, 3))', 'not (Date(2018, -1, 1) >= Date(2018, -1, 3))', 'len(explanation) == 4', 'table_question_context.table_data == [', 'table_question_context.table_data == [', 'number_entities == [(, 16)]', 'number_entities == [(, 11)]', 'number_entities == [(, 12)]', 'entities == [', 'numbers == [(, 9)]', 'entities == []', 'numbers == []', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'in column_names', 'string_entities == [', 'number_entities == [(, 7)]', 'sorted(entities) == [', 'neighbors_with_sets == {', 'entity_text == {', 'set(neighbors.keys()) == {', 'set(neighbors[}', 'neighbors[]', 'neighbors[] == []', 'neighbors[]', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[]', 'neighbors[] == []', 'neighbors[] == []', 'neighbors[]', 'neighbors[]', 'neighbors[] == []', 'set(neighbors[]) == {', 'neighbors[]', 'set(actual_right_sides) == set(expected_right_sides)', 'self.language.execute() == 5', 'self.language.execute() == 2', 'self.language.execute() == 20', 'self.language.execute() == 3', 'self.language.execute() == 3', 'self.language.execute() == 5', 'self.language.execute() == -1', 'self.language.execute() == 10', 'self.language.execute() == 2', 'self.language.execute() == 5', 'self.language.execute() == 5', 'self.language.execute() == 0', 'self.language.execute() == 4', 'self.language.execute() == 12', 'self.language.execute() == 1', 'self.language.execute_action_sequence(action_sequence) == 4', 'self.language.execute_action_sequence(action_sequence) == 12', 'self.language.execute_action_sequence(action_sequence) == 1', 'self.language.execute_action_sequence(action_sequence) == 2', 'set(valid_actions.keys()) == {', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'recovered_logical_form == logical_form', 'recovered_logical_form == logical_form', 'recovered_logical_form == logical_form', 'language.execute_action_sequence(action_sequence, state) == 4', 'language.execute_action_sequence(action_sequence, state) == 11', 'executor.execute(logical_form_true) is True', 'executor.execute(logical_form_false) is False', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is False', 'executor.execute(logical_form) is True', 'executor.execute(logical_form) is True', '(', '(', 'self.custom_language.execute(logical_form) is True', 'self.custom_language.execute(logical_form) is True', '(', '(', '(', '(', '(', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'in action_sequence', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'set(agenda) == {}', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'set(agenda) == {', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', 'not in agenda', 'in agenda', '(', '(', '(', '(', 'self.language.logical_form_to_action_sequence(', '(', '(', 'self.language.logical_form_to_action_sequence(', 'recovered_logical_form == logical_form', 'self.language.execute(logical_form) == -1', 'set(productions.keys()) == {', 'set(cell_list) == {}', 'selected_number == 2.0', 'cell_list == []', 'cell_list == []', 'cell_list == Date(2005, 3, -1)', 'cell_list == []', 'cell_value_list == []', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'cell_value_list == []', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'count_result == 0', 'cell_value_list == []', 'count_result == 2', 'cell_value_list == []', 'cell_list == []', 'row_list == self.language.execute()', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'cell_list == []', 'str(cell_list) == ', 'str(cell_list) == ', 'cell_list == 2.0', 'cell_list == 2.0', 'cell_list == []', 'str(cell_list) == ', 'cell_list == []', 'sum_value == 13197', 'sum_value == 13197', 'avg_value == 6598.5', 'avg_value == 6598.5', 'avg_value == 1141', 'result == Date(-1, 11, 10)', 'self.language.evaluate_logical_form(', 'not self.language.evaluate_logical_form(', 'set(productions.keys()) == {', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'self.language.logical_form_to_action_sequence(logical_form) == expected_sequence', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'self.language.action_sequence_to_logical_form(action_sequence) == logical_form', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {}', 'set(world.get_agenda()) == {', 'set(world.get_agenda(conservative=True)) == {}', '(', '(', 'type_a.resolve(type_b) is None', 'unary_type.resolve(ROW_TYPE) is None', 'unary_type.resolve(ComplexType(CELL_TYPE, ROW_TYPE)) is None', 'resolution == UnaryOpType(ROW_TYPE)', 'resolution == UnaryOpType(CELL_TYPE)', 'resolution == UnaryOpType(ComplexType(CELL_TYPE, ROW_TYPE))', 'binary_type.resolve(CELL_TYPE) is None', 'binary_type.resolve(ComplexType(CELL_TYPE, ROW_TYPE)) is None', 'binary_type.resolve(complex_type) is None', 'binary_type.resolve(complex_type) is None', 'binary_type.resolve(complex_type) is None', 'binary_type.resolve(complex_type) == BinaryOpType(ROW_TYPE)', 'binary_type.resolve(complex_type) == BinaryOpType(ROW_TYPE)', 'binary_type.resolve(complex_type) == BinaryOpType(ROW_TYPE)', 'len(valid_actions) == 3', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'len(valid_actions) == 5', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'len(valid_actions) == 5', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'valid_actions[]', 'expression == [', 'expression == []]]]', 'set(valid_actions.keys()) == {', 'set(valid_actions[}', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[}', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[}', 'set(valid_actions[}', 'set(valid_actions[}', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[}', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[]) == {', 'set(world.valid_actions[}', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'action_sequence == [', 'action_sequence is not None', 'approximate_times == [1830, 1930]', 'approximate_times == [445, 545]', 'pm_times == [[1200], [1300], [2030], [1230], [1315]]', 'world.dates == [datetime(1993, 6, 4, 0, 0)]', 'world._get_numeric_database_values(]', 'world._get_sequence_with_spacing(', 'world.dates == [datetime(1993, 7, 10, 0, 0)]', 'key not in {}', 'all([ not in production for production in value])', 'all([ not in production for production in value])', 'all([ not in production for production in value])', 'all([ not in production for production in value])', 'grammar_dictionary[]', 'grammar_dictionary[] == [', 'grammar_dictionary[] == [', 'not in productions', 'not world.is_global_rule()', 'in action_sequence', 'in action_sequence', 'in actions', 'in actions', 'world.base_grammar_dictionary[] == [', 'world.base_grammar_dictionary[] == [', 'argument_paths == [', 'unary_function_paths == [', 'binary_function_paths == [', 'argument_paths == [', 'identity_paths == [', 'len(best_states) == 2', 'best_states[0][0].action_history[0] == [-1, 1, 3, 4]', 'best_states[1][0].action_history[0] == [3, 4]', 'len(best_states) == 4', 'best_states[0][0].action_history[0] == [-1, 1, 3, 4]', 'best_states[1][0].action_history[0] == [3, 4]', 'best_states[2][0].action_history[0] == [-18, -16, -14, -12, -10]', 'best_states[3][0].action_history[0] == [7, 9, 11, 13, 15]', 'len(best_states) == 1', 'best_states[0][0].action_history[0] == [-2, -1, 0, 1, 3, 4]', 'best_states[0][1].action_history[0] == [-2, -1, 0, 1, 2, 4]', 'best_states[0][2].action_history[0] == [-2, -1, 0, 1, 3, 5, 7]', 'len(best_states) == 1', 'len(best_states[0]) == 3', 'best_states[0][0].action_history[0] == [-2, -1, 0, 1, 3, 4]', 'best_states[0][1].action_history[0] == [-2, -1, 0, 1, 2, 4]', 'best_states[0][2].action_history[0] == [-2, -1, 0, 1, 2, 3, 4]', 'len(beam_snapshots) == 1', 'beam_snapshots0 is not None', 'all(len(sequence) == i + 1 for _, sequence in beam)', 'any(sequence[-1] == best_action_sequence[i] for _, sequence in beam)', 'len(best_states) == 1', 'best_states[0][0].action_history[0] == [-1, 1, 3, 4]', 'best_states[0][1].action_history[0] == [-1, 1, 2, 3, 4]', 'best_states[0][2].action_history[0] == [-1, 0, 1, 2, 3, 4]', 'len(best_states) == 1', 'best_states[0][0].action_history[0] == [-1, 1, 3, 4]', 'best_states[0][1].action_history[0] == [-2, 0, 2, 4]', 'not state.is_finished()', 'state.is_finished()', 'state.get_valid_actions() == s_actions', 'state.get_valid_actions() == t_actions', 'state.get_valid_actions() == e_actions', 'not state.is_finished()', 'state.is_finished()', 'state.get_valid_actions() == s_actions', 'state.get_valid_actions() == t_actions', 'state.get_valid_actions() == e_actions', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [1, 2, 5]', 'actions[][2] == [3, 4]', 'actions[][2] == [3, 4]', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'next_state.__dict__ == expected_next_state.__dict__', 'len(finished_states) == 5', '([0, 2, 4], -2) in state_info', '([0, 1, 2, 4], -3) in state_info', '([0, 1, 3, 4], -3) in state_info', '([0, 2, 3, 4], -3) in state_info', '([0, 1, 2, 3, 4], -4) in state_info', 'best_state.action_history[0] == [0, 2, 4]', 'len(new_states) == 2', 'new_state.batch_indices == [0]', 'actual in expected_possibilities', 'new_state.possible_actions == self.possible_actions', 'new_state.batch_indices == [1]', 'new_state.action_history == [[3, 4, 0]]', 'new_state.grammar_state[0]._nonterminal_stack == []', 'new_state.possible_actions == self.possible_actions', 'len(prefix_tree) == 2', 'len(prefix_tree[0]) == 6', 'prefix_tree[0][()] == {1, 2}', 'prefix_tree[0][(1,)] == {2, 3}', 'prefix_tree[0][(1, 2)] == {4}', 'prefix_tree[0][(1, 3)] == {4}', 'prefix_tree[0][(2,)] == {3}', 'prefix_tree[0][(2, 3)] == {4}', 'len(prefix_tree[1]) == 4', 'prefix_tree[1][()] == {2, 3}', 'prefix_tree[1][(2,)] == {3}', 'prefix_tree[1][(2, 3)] == {4}', 'prefix_tree[1][(3,)] == {4}']","['(AssertionError)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError, match=)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ParsingError, match=)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(ExecutionError)', '(AssertionError)', '(AssertionError)']",[],"['(reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)']","['(str(e), pytrace=True)']",[],[],[],"['skip(reason=)', 'java', 'skipif(torch.cuda.device_count() < 2, reason=)', 'skipif(torch.cuda.device_count() < 2, reason=)']","['mark.skip(reason=)', 'mark.java', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.skipif(torch.cuda.device_count() < 2, reason=)']",[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest']"
1628,Matt Gardner,mattg@allenai.org,2019-10-10 19:44:52-07:00,93024e53c1445cb4630ee5c07926abff8943715f,https://github.com/allenai/allennlp/commit/93024e53c1445cb4630ee5c07926abff8943715f,Pin to pytorch 1.3 in setup.py (#3346),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1629,Yaroslav Emelianov,mojesty@users.noreply.github.com,2019-10-12 00:07:23+03:00,27d2a6d49da7f7ae00cbf64e3f5ccd09b8cfca8e,https://github.com/allenai/allennlp/commit/27d2a6d49da7f7ae00cbf64e3f5ccd09b8cfca8e,"#3335 fixed FBetaMeasure with both average and labels specified (#3347)

* #3335 fixed FBetaMeasure with both average and labels specified

* conform to black formatting",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ConfigurationError, FBetaMeasure, labels=[])')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1630,Michael Schmitz,MichaelS@allenai.org,2019-10-11 14:53:39-07:00,0b1b782e754b6e6a34a3464d652fe5c6847ce5b2,https://github.com/allenai/allennlp/commit/0b1b782e754b6e6a34a3464d652fe5c6847ce5b2,"Update docs to refer to 3.7 instead of 3.6 (#3349)

* Upgrade Dockerfiles to Python 3.7.

* Upgrade documentation to refer to 3.7 over 3.6.

* Ignore a mypy line that causes an error.

* Revert ""Upgrade Dockerfiles to Python 3.7.""

This reverts commit acd68e39dc7aabfdc3bc52bd24d7810f3f1c4e78.

* Update setup.py",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1631,Surya Kasturi,kasturisurya@gmail.com,2019-10-11 17:54:06-04:00,11c4f7ed6defe98005ae62ec06d90bc9d9705389,https://github.com/allenai/allennlp/commit/11c4f7ed6defe98005ae62ec06d90bc9d9705389,"Support tqdm in interactive shells (#3124)

* Support tqdm in interactive shells

* Update tqdm.py

* Fix pylint errors.

* Ignore undefined variable (ipython creates it).

* Ignore via mypy

* Run black.

* Ignore flake8 violations.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1632,Sai,sai-prasanna@users.noreply.github.com,2019-10-13 20:46:39+05:18,3b5753c3a602b9d44c7f3817d58e869fac463732,https://github.com/allenai/allennlp/commit/3b5753c3a602b9d44c7f3817d58e869fac463732,"Unpin pytorch to support 1.3 (#3353)

Convert torch.bool to unit8 to support argmax.",3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1633,Sai,sai-prasanna@users.noreply.github.com,2019-10-13 22:58:48+05:18,6d5bcaf11e12938c4d6da1f04c05bf17bf2f2c92,https://github.com/allenai/allennlp/commit/6d5bcaf11e12938c4d6da1f04c05bf17bf2f2c92,"Fix random seeds not saving in config. (#3354)

Call prepare_environment after saving config as it consumes the seeds.

Add tests to check config gets saved with all the necessary keys.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['params_as_dict == saved_config_as_dict'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1634,Nelson Liu,nelson-liu@users.noreply.github.com,2019-10-14 22:00:24-07:00,c75adfe33d1d746aec3681cd7d11080e75e43afd,https://github.com/allenai/allennlp/commit/c75adfe33d1d746aec3681cd7d11080e75e43afd,"Expose -e flag in EVALB scorer (#3328)

* Expose -e flag in EVALB scorer

* Convert to string",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1635,Brendan Roof,brendanr@allenai.org,2019-10-15 21:08:45-07:00,3c38347a728a4a961fd780c009d77055ca02032c,https://github.com/allenai/allennlp/commit/3c38347a728a4a961fd780c009d77055ca02032c,"Add resume daemon for Beaker experiments. (#3350)

- Compatible with basic experiments created with `scripts/ai2_internal/run_with_beaker.py`.
- Intended to be run locally, e.g. via cron, to ensure experiments are resumed.",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,6,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[' unittest.mock '],[],[],[],[],[],[],[],[],[],[],[],[],"['status.name == ', 'status.name == ', 'not beaker.method_calls', 'len(beaker.method_calls) == 1', 'len(beaker.method_calls) == 1', 'len(beaker.method_calls) == 2']",['(ValueError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1636,Ilya,iliyadimov@icloud.com,2019-10-16 18:11:46+03:00,6373bbba690cf8a33f0320ae9a1e43259317d12e,https://github.com/allenai/allennlp/commit/6373bbba690cf8a33f0320ae9a1e43259317d12e,"Remove ignored do_lowercase argument to transformer tokenizers (#3364)

* Improvements on issue #3360

* Add tests for cased/uncased tokenizers

* Add function to detect lowercase style

* Remove do_lowercase parameter

Parameter removed, because it is ignored by
tokenizer.

* Remove do_lowercase from tests & from indexer",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed[] == expected_ids', 'tokens == expected_tokens']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1637,Sai,sai.r.prasanna@gmail.com,2019-10-17 00:31:05+05:18,2850579831f392467276f1ab6d5cda3fdb45c3ba,https://github.com/allenai/allennlp/commit/2850579831f392467276f1ab6d5cda3fdb45c3ba,"Replace existing WordSplitter with Tokenizers (#3361)

* WIP: Remove splitter

* Convert WordSplitters to Tokenizers

Remove WordSplitter and move the existing splitters to tokenizer.

* Move Tokenizers to separate files.

Move legacy handling into Tokenizer.from_params.

* Add legacy tokenizer loading test.

And move tokenizer tests to individual files.

* Rename white_space_tokenizer to whitespace_tokenizer

And add it to registry under ""whitespace"".",76,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,2,4,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,31,0,0,0,0,0,0,0,0,0,0,0,0,43,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError):')]","['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['Tokenizer.by_name(', 'reader._tokenizer.__class__.__name__ == ', 'reader._tokenizer.__class__.__name__ == ', 'tokens == expected_tokens', '[t.text for t in tokens] == [t.text for t in expected_tokens]', '[t.idx for t in tokens] == [t.idx for t in expected_tokens]', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'token_text == expected_tokens', 'sentence[start:end] == token.text', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'len(batch_split) == len(separately_split)', 'len(batch_sentence) == len(separate_sentence)', 'batch_word.text == separate_word.text', 'tokens', 'all(isinstance(token, Token) for token in tokens)', 'tokens', 'all(isinstance(token, spacy.tokens.Token) for token in tokens)', 'isinstance(tokenizer, SpacyTokenizer)', 'tokenizer._start_tokens == params[]', 'tokenizer._end_tokens == params[]', 'in tokenizer.spacy.pipe_names', 'isinstance(tokenizer, SpacyTokenizer)', 'isinstance(tokenizer, WhitespaceTokenizer)', 'isinstance(tokenizer, SpacyTokenizer)']",[],[],[],[],[],[],[],[],[],[],[],[],"['Tokenizer.by_name(', 'reader._tokenizer.__class__.__name__ == ', 'reader._tokenizer.__class__.__name__ == ', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'filter_.stopwords == {}', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'len(batch_split) == len(separately_split)', 'len(batch_sentence) == len(separate_sentence)', 'batch_word.text == separate_word.text', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', '[t.text for t in tokens] == [t.text for t in expected_tokens]', '[t.idx for t in tokens] == [t.idx for t in expected_tokens]', 'tokens == expected_tokens', 'token_text == expected_tokens', 'sentence[start:end] == token.text', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'len(batch_split) == len(separately_split)', 'len(batch_sentence) == len(separate_sentence)', 'batch_word.text == separate_word.text', 'tokens', 'all(isinstance(token, Token) for token in tokens)', 'tokens', 'all(isinstance(token, spacy.tokens.Token) for token in tokens)', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens', 'len(batch_tokenized) == len(separately_tokenized)', 'len(batch_sentence) == len(separate_sentence)', 'batch_word.text == separate_word.text', 'tokens == expected_tokens']",[],[],[],[],[],[],[],[],[],[],[],[]
1638,Nelson Liu,nelson-liu@users.noreply.github.com,2019-10-16 22:06:52-07:00,7afe9712f502dfdc6941bb03d3029a7eb6e0bca9,https://github.com/allenai/allennlp/commit/7afe9712f502dfdc6941bb03d3029a7eb6e0bca9,Add optional FeedForward to BasicClassifier (#3370),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1639,Brendan Roof,brendanr@allenai.org,2019-10-18 11:47:06-07:00,d6f5a000bf5ff84b45185b2875cea604d0a9cf80,https://github.com/allenai/allennlp/commit/d6f5a000bf5ff84b45185b2875cea604d0a9cf80,"Make run_with_beaker.py automatically resume (#3374)

- Simply pass, e.g., `--max-resumes=10`.
- Modifies `resume_daemon.py` to automatically install itself.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1640,Brendan Roof,brendanr@allenai.org,2019-10-18 17:04:22-07:00,457a85bde57ba58289d32e4e1d07df1f94c813b0,https://github.com/allenai/allennlp/commit/457a85bde57ba58289d32e4e1d07df1f94c813b0,"Pin away from torch 1.3.0. (#3381)

- For https://github.com/allenai/allennlp/issues/3367
- I've verified that this fixes the aforementioned bug using a fresh conda environment in Mac OS 10.13.6.",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1641,Brendan Roof,brendanr@allenai.org,2019-10-24 13:13:54-07:00,a17ef2d45cd53384bdbc0bd6ce99d9cc1d798f60,https://github.com/allenai/allennlp/commit/a17ef2d45cd53384bdbc0bd6ce99d9cc1d798f60,"Fix several resume daemon bugs. (#3393)

- Execute w/ `python3 resume_daemon.py` in case the exec bit isn't set.
- Create `~/.allennlp` if it wasn't already in case `allennlp` hadn't been run locally.
- Handle empty crontab case where `crontab -l` has a non-zero exit code.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1642,Brendan Roof,brendanr@allenai.org,2019-10-24 15:01:06-07:00,1852f6130cafbef51a9cd3ec76dfe8d9dbd76f20,https://github.com/allenai/allennlp/commit/1852f6130cafbef51a9cd3ec76dfe8d9dbd76f20,"Tighten pin to avoid only broken binaries and allow 1.3.0. (#3396)

Resolution of https://github.com/allenai/allennlp/issues/3367. Pytorch has fixed their binaries for 1.3.0. Now we'll use 1.3.0.post2.

I've tested this locally on macOS 10.13.6 and both `pip install -r requirements.txt` and `pip install --editable allennlp` fix broken installations.",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1643,David Wadden,dwadden@cs.washington.edu,2019-10-25 10:56:38-07:00,891327dad87ce60005c6ae089ad6b688dddb6ba1,https://github.com/allenai/allennlp/commit/891327dad87ce60005c6ae089ad6b688dddb6ba1,"Fix tensorboard logging edge case. (#3382)

When a parameter has no elements, do not log its mean. Otherwise a warning is
thrown.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1644,Zheng Gao,simon.gaozheng@gmail.com,2019-10-25 18:57:17+01:00,57cdffb45205f1eeeff0737e9f3bb8f57103a29f,https://github.com/allenai/allennlp/commit/57cdffb45205f1eeeff0737e9f3bb8f57103a29f,Fix the annotation for a method's return type (#3376),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1645,Dheeru Dua,ddua@uci.edu,2019-10-27 23:47:54-07:00,ca23d4ad4ea0782cc82169e5feb5928415c5dddd,https://github.com/allenai/allennlp/commit/ca23d4ad4ea0782cc82169e5feb5928415c5dddd,adding version to overrides packages (#3402),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1646,Nelson Liu,nelson-liu@users.noreply.github.com,2019-10-28 06:53:32-07:00,e785f04366f2c7f8ec51fa25cdf9b1e5d0287595,https://github.com/allenai/allennlp/commit/e785f04366f2c7f8ec51fa25cdf9b1e5d0287595,Pin overrides to 2.0 in setup.py (#3403),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1647,Felipe Rodrigues,felipe@felipevr.com,2019-10-28 14:26:14-03:00,99125490e1e82e95c99792b0873309f93f706ec0,https://github.com/allenai/allennlp/commit/99125490e1e82e95c99792b0873309f93f706ec0,Add a package name in Pyproject (#3379),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1648,Nitish Gupta,gnnitish@gmail.com,2019-10-29 13:35:11-04:00,35b285585e0677b1025eac1c19b5eefe7e2a70db,https://github.com/allenai/allennlp/commit/35b285585e0677b1025eac1c19b5eefe7e2a70db,"fix epoch tracking in cache_instances feature of the iterator (#3384)

* fix epoch tracking in cache_instances feature of the iterator

* type ignore for mypy test

* fix spacing",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1649,Mike Ross,mikenon@gmail.com,2019-11-01 22:05:41-07:00,f3083c8fb9150f07e3ca98bb3ea9368a081df028,https://github.com/allenai/allennlp/commit/f3083c8fb9150f07e3ca98bb3ea9368a081df028,"Add top-k sequence decoding (#3226)

Adds a top_k option to `viterbi_decode`, `ConditionalRandomField` and `CrfTagger` 

To maintain backwards compatibility the returned value types are different depending on whether `top_k` is supplied. Another option would be to implement `viterbi_decode` as a thin wrapper around a separate `top_k_viterbi_decode` function. I wasn't sure which was the preferred method.

This can be used for prediction on models serialized before this feature, e.g. by calling `allennlp predict --overrides {""model"": ""top_k"": 10}` I wasn't sure where to document this use case.

The code is based on the implementation at https://gist.github.com/PetrochukM/afaa3613a99a8e7213d2efdd02ae4762 (which is in turn based on AllenNLPs implementation)",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['first_choices == output_dict[]', 'set(lengths) == {5}', 'all(tag in {} for tag in tags_used)', 'top_path_and_score == self.crf.viterbi_tags(self.logits, mask)', 'next_viterbi_tags == [[4, 2, 3], [3, 2]]', 'indices[0] == argmax_indices.data.squeeze().tolist()', 'indices[0] == [3, 4, 3, 4, 3, 4]', 'indices[0] == [3, 3, 3, 3, 3, 3]', 'indices[0] == [3, 2, 1]', 'value[0] == 18']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1650,Michael Schmitz,MichaelS@allenai.org,2019-11-05 15:23:12-08:00,9a6962f00d2b0d30b81900b4e9764ddc3433f400,https://github.com/allenai/allennlp/commit/9a6962f00d2b0d30b81900b4e9764ddc3433f400,Update requirements.txt (#3431),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1651,tamuhey,tamuhey@gmail.com,2019-11-09 08:09:57+09:00,4f5a9fbc7ccb502025b7bca8088269832b3a2420,https://github.com/allenai/allennlp/commit/4f5a9fbc7ccb502025b7bca8088269832b3a2420,"Add support for spacy >= 2.2  (#3432)

* change spacy < 2.3

* test: modified some spacy tests

* test: modified for spacy2.2

* modified:   allennlp/tests/models/sniff_test.py

* modified:   tests/predictors/biaffine_dependency_parser_test.py

* modified:   allennlp/tests/predictors/biaffine_dependency_parser_test.py

* modified:   allennlp/tests/predictors/srl_test.py

* modified:   Info.plist",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['counter[: 2}', 'indices[][1] == aux_index']",[],[],[],[],[],[],[],[],[],[],[],[],"['counter[: 2}', 'indices[][1] == verb_index']",[],[],[],[],[],[],[],[],[],[],[],[]
1652,Ryo Takahashi,reiyw.setuve@gmail.com,2019-11-12 17:15:52+09:00,cd1d1b6bbd203e894aed5651a7938c0b09c2f773,https://github.com/allenai/allennlp/commit/cd1d1b6bbd203e894aed5651a7938c0b09c2f773,Fix verb_index condition in CoNLL formatter (#3445),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['len(metrics) == 18'],[],[],[],[],[],[],[],[],[],[],[],[],['len(metrics) == 15'],[],[],[],[],[],[],[],[],[],[],[],[]
1653,Nicola De Cao,nicola.decao@uva.nl,2019-11-13 17:09:40+00:00,5238561412d1f63fa47512b7d6726dee9ed5ae88,https://github.com/allenai/allennlp/commit/5238561412d1f63fa47512b7d6726dee9ed5ae88,"Adding padding_token and oov_token as parameters of Vocabulary (#3446)

* custom padding_token and oov_token in Vocabulary

* custom padding_token and oov_token in Vocabulary with docs

* adding test for OOV and fixing other classes for this pull request",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab._oov_token == ', 'vocab._padding_token == ', 'vocab._oov_token == ', 'vocab._padding_token == ', 'in str(excinfo.value)']",['(AssertionError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1654,Maksym Del,max.del.edu@gmail.com,2019-11-13 20:28:27+02:00,2389e62bf576f4170287dcaee815af295db8c35d,https://github.com/allenai/allennlp/commit/2389e62bf576f4170287dcaee815af295db8c35d,"pytorch_transformers -> transformers (#3449)

* pytorch_transformers -> transformers

* Fix setup.py

* Remove pytorch_transformers dependancy

* Fix typo",10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1655,Nelson Liu,nelson-liu@users.noreply.github.com,2019-11-13 13:08:09-08:00,88fe0075c28babb20f076c43f932b77d80ce81a3,https://github.com/allenai/allennlp/commit/88fe0075c28babb20f076c43f932b77d80ce81a3,Specify batch size through CLI flag in allennlp evaluate (#3375),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1656,Michael Schmitz,MichaelS@allenai.org,2019-11-15 15:22:17-08:00,5003eddd9ed9667c5e44cb5933fef42b85dc252c,https://github.com/allenai/allennlp/commit/5003eddd9ed9667c5e44cb5933fef42b85dc252c,"Clarify wording on the Jsonnet loading error. (#3444)

* Clarify wording on the Jsonnet loading error.

A user was confused by this message (see https://discourse.allennlp.org/t/jsonnet-configuration-file-cannot-be-interpreted/127/2) so I'm improving the wording.

* Run Black.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1657,Nicola De Cao,nicola.decao@uva.nl,2019-11-17 22:10:16+00:00,e0f573a4d3a3ecbc1b0e10dd7fd7f48f6269e744,https://github.com/allenai/allennlp/commit/e0f573a4d3a3ecbc1b0e10dd7fd7f48f6269e744,"Adding source_add_end_token to Seq2SeqDatasetReader (#3441)

* added source_add_end_token to Seq2SeqDatasetReader

* fix typo in docs",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1658,Michael Schmitz,MichaelS@allenai.org,2019-11-19 09:59:57-08:00,cfc964a6a70618d5bdfa7f4f7adba80e4e0ee6ce,https://github.com/allenai/allennlp/commit/cfc964a6a70618d5bdfa7f4f7adba80e4e0ee6ce,Update auto_regressive_seq_decoder.py (#3415),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1659,Mark Neumann,markn@allenai.org,2019-11-19 13:49:59-08:00,ffde8d2c271eb0ef3df00c582bb1526b01b6ee83,https://github.com/allenai/allennlp/commit/ffde8d2c271eb0ef3df00c582bb1526b01b6ee83,"Fix and simplify spacy tests (#3468)

* fix and simplify

* black

* fix sniff tests",3,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['if(spacy.__version__ < )'],[],[],[],[],['skipif(spacy.__version__ < )'],['mark.skipif(spacy.__version__ < )'],[],[],[]
1660,Maksym Del,max.del.edu@gmail.com,2019-11-20 01:15:51+02:00,bb1b1c6e27b273a66135d02a04232835d5bfc3ca,https://github.com/allenai/allennlp/commit/bb1b1c6e27b273a66135d02a04232835d5bfc3ca,"Rework Pretrained Tokenizer and Indexer (#3453)

* New Pretrained Tokenizer and Indexer

* Fix formatting

* Fix ident

* Fix commas

* Fix docs

* Allow future transformers versions

* Address feedback

* Introduce tokenize_sentences method to tokenizer

* Improve tests, partially fix vocab issue, fix typos

* Adapt existing dataset readers to work with new tokenizer

* tokenize_sentences -> tokenize_sentence_pair

* Make mypy happy

* Add transformers vocab on Vocabualry constructor

* Make mypy happy

* Remove tokenizer field

* Address feedback",10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed[] == expected_ids', 'indexed[] == expected_ids', 'indexed[] == expected_ids', 'vocab.get_vocab_size(namespace=namespace) == tokenizer.vocab_size', 'vocab.get_token_to_index_vocabulary(namespace=namespace) == tokenizer.encoder', 'tokens == expected_tokens', 'tokens == expected_tokens', 'tokens == expected_tokens']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1661,Nicola De Cao,nicola.decao@uva.nl,2019-11-21 20:17:19+00:00,8040e40e2a17bac9a48346c92b6f2be4a80fa482,https://github.com/allenai/allennlp/commit/8040e40e2a17bac9a48346c92b6f2be4a80fa482,"Fixing some bugs in auto_regressive_seq_decoder (#3433)

Fixing for https://github.com/allenai/allennlp/issues/3407 and https://github.com/allenai/allennlp/issues/3426.

In https://github.com/allenai/allennlp/blob/f3083c8fb9150f07e3ca98bb3ea9368a081df028/allennlp/modules/seq2seq_decoders/auto_regressive_seq_decoder.py#L433

target_tokens[""tokens""] is a torch.Tensor so its elements do not have the attribute text.",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['auto_regressive_seq_decoder.forward(encoder_out) == {}', 'loss.shape == torch.Size([]) and loss.requires_grad', 'in auto_regressive_seq_decoder.forward(encoder_out)', 'predicted_tokens == tokens_ground_truth', 'predicted_tokens == tokens_ground_truth', 'auto_regressive_seq_decoder.get_metrics()[] == 1.388809517005903e-11', 'auto_regressive_seq_decoder.get_metrics()[] == 0.0', 'auto_regressive_seq_decoder.get_metrics()[] == 1 / 3']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1662,Ben Eyal,bene@post.bgu.ac.il,2019-11-22 08:02:24+02:00,3ee3cf4a9211d13176df1b8cc53d69c83896751c,https://github.com/allenai/allennlp/commit/3ee3cf4a9211d13176df1b8cc53d69c83896751c,Change SrlEvalScorer to use UTF-8 encoded files (#3474),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1663,Brendan Roof,brendanr@allenai.org,2019-11-22 16:13:56-08:00,a8c44aeeb0a60142021f94d967a5377b3ccd7a3c,https://github.com/allenai/allennlp/commit/a8c44aeeb0a60142021f94d967a5377b3ccd7a3c,"Remove DEPRECATION.md (#3477)

- By and large we haven't been following this proposal. I'd like remove it to avoid confusion.
- Further, I'm not sure it's the approach we'd like to take going forward.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1664,John Giorgi,johnmgiorgi@gmail.com,2019-11-26 15:17:19-05:00,9fa0bde5ce99abf2d5ec12a36366e662241f7099,https://github.com/allenai/allennlp/commit/9fa0bde5ce99abf2d5ec12a36366e662241f7099,"Fix an f-formatted string (#3483)

There is a `KeyError` message in `pretrained_transformer_indexer.py` that appears to be an f-formatted string with broken syntax. This resulted in the literal string `token.text` being printed when the error is raised, instead of the value of the `text` attribute of `token`.

I simply fixed the syntax, so now this error message will print the value of `token.text` to screen when the error is raised.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1665,John Giorgi,johnmgiorgi@gmail.com,2019-12-03 18:03:41-05:00,9920ba8da83b91ff412a50d2ab220250236d7040,https://github.com/allenai/allennlp/commit/9920ba8da83b91ff412a50d2ab220250236d7040,Update code fences in getting started tutorial (#3501),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1666,Michael Schmitz,MichaelS@allenai.org,2019-12-03 15:06:11-08:00,3dc26102a7fd52e2db273be80604970dfa62a3c6,https://github.com/allenai/allennlp/commit/3dc26102a7fd52e2db273be80604970dfa62a3c6,Add ROADMAP.md to share our quarterly plans publicly. (#3427),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1667,Marc Hbner,marchbnr@users.noreply.github.com,2019-12-04 18:35:39+01:00,b89ff098372656b674ec71457dda071222fd05ae,https://github.com/allenai/allennlp/commit/b89ff098372656b674ec71457dda071222fd05ae,"Fix incorrect label namespace in the simple tagger model (#3429)

* Fix incorrect label namespace in the simple tagger model

* Apply black formatting to simple tagger change",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1668,ananda seelan,ananda.seelan@gmail.com,2019-12-10 01:18:27+00:00,b70891e252cd223c920c37ba7873f7ab6a338589,https://github.com/allenai/allennlp/commit/b70891e252cd223c920c37ba7873f7ab6a338589,"Fix OOM while loading best model state (#3506)

Fixes #3499",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1669,Dirk Groeneveld,dirkg@allenai.org,2019-12-10 16:48:31-08:00,95ef61d5407c761fd94ccb8ef908096eaccdd590,https://github.com/allenai/allennlp/commit/95ef61d5407c761fd94ccb8ef908096eaccdd590,"Pins the version of python-dateutil to one that works (#3509)

* Pins the version of python-dateutil to one that works.\nPip should do this for us, but it does not.

* Version 2.2.1 of the transformers library comes with a broken tokenizer

See https://github.com/huggingface/transformers/issues/2132

* Fixed some typos",3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1670,Will Frey,jfrey89@gmail.com,2019-12-13 17:27:39-05:00,6dfa2327b5380860b6054b44cde39ed5b5999896,https://github.com/allenai/allennlp/commit/6dfa2327b5380860b6054b44cde39ed5b5999896,"Remove [tool.poetry] and add [build-system] (#3508)

* Remove [tool.poetry] and add [build-system]

* Remove [tool.poetry] and add [build-system]",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1671,TheresaSchmidt,36304889+TheresaSchmidt@users.noreply.github.com,2019-12-13 23:31:57+01:00,6f5b8d5f5a79a52230a6d899230c0d9dc3e5eb66,https://github.com/allenai/allennlp/commit/6f5b8d5f5a79a52230a6d899230c0d9dc3e5eb66,Corrected outdated links to models (#3397),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1672,Ryan Sivek,9834834+nanowizard@users.noreply.github.com,2019-12-13 16:57:25-07:00,831daeb5c96957d8bf94a716fd240aa7cfedecac,https://github.com/allenai/allennlp/commit/831daeb5c96957d8bf94a716fd240aa7cfedecac,"import spaCy model module directly instead of forcing a link after download (#3503)

* import spaCy model module directly instead of forcing a link after download

* mypy",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1673,Brendan Roof,brendanr@allenai.org,2019-12-13 16:13:07-08:00,360e4d0e6ef3e00da34e5040a3f55b9dd259dd86,https://github.com/allenai/allennlp/commit/360e4d0e6ef3e00da34e5040a3f55b9dd259dd86,"Deprecate old language modeling dataset reader (#3325)

- This is confusing users who really need `SimpleLanguageModelingDatasetReader`.
- For #3324",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1674,Elad Segal,eladsegal@users.noreply.github.com,2019-12-17 00:35:01+02:00,058c2e6963c597d8c613d85646e200c38c059971,https://github.com/allenai/allennlp/commit/058c2e6963c597d8c613d85646e200c38c059971,Fix mask usage in CRF decoding (#3522),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['viterbi_tags == most_likely_tags'],[],[],[],[],[],[],[],[],[],[],[],[],"['viterbi_tags == [[2, 4, 3], [4, 2]]', 'viterbi_scores == best_scores']",[],[],[],[],[],[],[],[],[],[],[],[]
1675,Mark Neumann,markn@allenai.org,2019-12-16 15:44:42-08:00,41b5a4d56f84a03f7fe9d11fb667471528a289a8,https://github.com/allenai/allennlp/commit/41b5a4d56f84a03f7fe9d11fb667471528a289a8,"remove make vocab (#3527)

* deprecate make vocab

* remove make vocab directly

* compat",5,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,1,0,0,0,0,0,0,0,0,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'tokens == [', 'labels == []', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'len(tokens) == 3', 'args.func == make_vocab_from_args', 'args.param_path == ', 'args.serialization_dir == ']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest']
1676,Mark Neumann,markn@allenai.org,2019-12-16 16:53:14-08:00,ca453c8b1186b4f346e70428c889a139ca21f794,https://github.com/allenai/allennlp/commit/ca453c8b1186b4f346e70428c889a139ca21f794,"Torch distributed (#3529)

* Logging and metrics changes for distributed training (#3372)

* Refactor logging setup to support distributed attrs

* `cleanup_logging()` is replaced with stdlib's `logging.shutdown()`
* Remove `TeeLogger` and use standard log handlers
* Remove `replace_cr_with_newline` and use the standard logging practice of using
`logging.Filter`
* Introduce `rank` and `world_size` optional attributes to support
distributed workers

* Support for distributed training in `get_metrics`

* Remove bad import

* Fix duplicate log messages in stdout

* Remove preemptive `logging.shutdown`

`logging.shutdown` is called by the logging module
by default during exit which makes it unnecessary to
be called from `train_model`

* Fix black formatting issues

* Remove `tee_logger` references in API doc

* Set log level from `ALLENNLP_DEBUG` env

* Changes to `train_model` for distributed training support (#3390)

* High level API changes to support distributed training

* Fix flake8 error

* Fix mypy error

* Add docstring and misc fixes

* Fix flake tests

* `Trainer` changes for distributed training (#3414)

Followup PR to #3390 and #3372 to bring in distributed training support. Following are the major changes done:

* Workers are spawned using `mp.spawn` and each worker creates its own `Trainer` instance
* `Trainer.__init__` wraps up `self.model` with `DistributedDataParallel`
*  Logging and metric aggregation are already done in the previous PRs
* `Vocabulary` creation in case of distributed training is done before spawning the workers and creating `Trainer` class

To run distributed training, the trainer needs to have the following flag to be enabled:

```jsonnet
{
    ""trainer"": {
        ""distributed"": true,
        // ...
    }
}
```

TODO:
* Try to reproduce comparable results and share extensive results for existing/selected models
* Check if other commands like `evaluate`, `predict`, `fine-tune` works well with the new changes
* Should all the callbacks need to be called from every worker in case callback based training?
* Should the current dataset readers be changed to support distributed training as well?(to selectively yield data based on their rank)
* Write tests - _would be happy to get some suggestions on how to write tests for this_

* Dist tests (#3515)

* add some tests

* another test, fix incorrect type annotations

* torch mp uses it's own context, no need to set default

* lint

* strip out old DP stuff, ensure multiple cuda devices raises err (#3516)

* strip out old DP stuff, ensure multiple cuda devices raises errors

* lint

* remove unused attribute

* remove _cuda_devices everywhere

* fixes

* move distributed config up to top level

* lint

* clean up

* rename occurences of batch_group

* remove hack from find_learning_rate

* fix last tests

* black

* use a top level distributed config

* correct error for int

* change up parse_cuda_devices to raise good error and be strongly typed

* fix merge",22,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,3,0,3,0,0,0,0,3,3,0,0,0,8,0,0,2,0,0,0,0,2,2,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'load_archive(out_dir).model']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],"['if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)']",[],[],[],[],"['skipif(torch.cuda.device_count() < 2, reason=)', 'skipif(torch.cuda.device_count() < 2, reason=)', 'skipif(torch.cuda.device_count() < 2, reason=)']","['mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.skipif(torch.cuda.device_count() < 2, reason=)']",[],[],[],"['(', 'len(kwargs[]) == batch_size, (', 'in metrics', 'isinstance(metrics[], int)', '(', 'len(kwargs[]) == batch_size, (', 'in metrics', 'isinstance(metrics[], int)']",[],[],"['if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)']",[],[],[],[],"['skipif(torch.cuda.device_count() < 2, reason=)', 'skipif(torch.cuda.device_count() < 2, reason=)']","['mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.skipif(torch.cuda.device_count() < 2, reason=)']",[],[],[]
1677,Michael Bugert,bugert@ukp.informatik.tu-darmstadt.de,2019-12-17 02:08:25+01:00,50759d78142c6c6d62f2782a372b9bb00b762152,https://github.com/allenai/allennlp/commit/50759d78142c6c6d62f2782a372b9bb00b762152,"Fix char_span_to_token_span breaking from under tokenization (#3417)

* Fix char_span_to_token_span breaking from under tokenization

* Fix char_span_to_token_span breaking from out-of-bounds spans. Fix lint errors.",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['token_span == expected_span', 'error', 'token_span == expected_span', 'error', 'token_span == expected_span', 'error', 'token_span == expected_span', 'error', 'token_span == expected_span', 'error', 'token_span == expected_span', 'error']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1678,Brendan Roof,brendanr@allenai.org,2019-12-16 17:10:47-08:00,71a57133be5749851f807ea0ab44a15011848fa6,https://github.com/allenai/allennlp/commit/71a57133be5749851f807ea0ab44a15011848fa6,"Remove pretrained models and sniff tests. (#3478)

- Pretrained models are now available from `allennlp-hub`. See https://github.com/allenai/allennlp-hub/blob/master/allennlp_hub/pretrained/__init__.py.
  - So if you were previously using them with `from allennlp import pretrained`, now you should use `from allennlp_hub import pretrained`.
- Sniff tests for same are at http://build.allennlp.org/viewType.html?buildTypeId=AllenNLPHub_Master.
- There's a bit of a race condition with respect to actually releasing this change. `allennlp-hub` should ideally depend on `allennlp` 1.0 -- indeed, the release build for `allennlp-hub` is broken because the expected outputs changed with the new Spacy models -- but if we release `allennlp` 1.0 first, then users will briefly not have access to `pretrained.py`. Perhaps releasing an alpha `allennlp-hub` dependent on `allennlp` via a github sha will be sufficient to iron out any release issues. Then we could quickly cut over to `allennlp` 1.0 and re-release.
- This is a breaking change. Noted in the v1.0 draft release notes. Link that may become stale: https://github.com/allenai/allennlp/releases/tag/untagged-9ecb65d3368d2841e938.",4,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,0,0,1,0,0,0,0,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['correct == result[]', 'result[] == [', 'result[] == [', 'result[][0] > 0.7  # entailment', 'result[][1] > 0.8  # contradiction', 'result[][2] > 0.6  # neutral', 'result[] == [', 'result[] == [', 'result[] == [', 'result[]', 'result[] == [', '(', 'result[]', 'result[]', 'result[] == [', 'result[] == [2, 0, 2, 2, 4, 2]']",[],[],['if(spacy.__version__ < )'],[],[],[],[],['skipif(spacy.__version__ < )'],['mark.skipif(spacy.__version__ < )'],[],[],['import pytest']
1679,Mark Neumann,markn@allenai.org,2019-12-16 18:09:07-08:00,e2160913d6eb8b4c37fe944f2f70c3dda9d2efa0,https://github.com/allenai/allennlp/commit/e2160913d6eb8b4c37fe944f2f70c3dda9d2efa0,"Remove service (#3526)

* remove service entirely

* move configure command to new repo

* drop server requirements :fire:

* strip service from docs

* more docs

* more references to server

* change name",34,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):']",[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in choices', 'in html', 'data[', 'items[0] == {', '(', 'config[', 'items[0][', 'in data', 'not in data', 'not in data', 'in data', 'in data', 'not in data', 'config[', 'any(item[ for item in items)', 'config[', 'any(item[ for item in items)', ']', ']', 'config[', 'any(item[ for item in items)', ']', 'config[', 'any(item[ for item in items)', ']', ']', ']', ']', 'b in data', 'b in data', 'in data', 'in data', 'len(data_list) == batch_size', 'in data', 'in data', 'in data', 'not in data', 'len(data_list) == batch_size', 'in data', 'not in data', 'data == html', 'data == jpg']",[],[],[],[],[],[],[],[],[],[],[],[]
1680,Michael Schmitz,MichaelS@allenai.org,2019-12-17 07:58:03-08:00,2b3bb0d4e86192b8fe8c4cc866292692a5c33c9f,https://github.com/allenai/allennlp/commit/2b3bb0d4e86192b8fe8c4cc866292692a5c33c9f,"Improve docs and delete MODELS.md (#3530)

* A few fixes to the README.

* Deprecate MODELS.md in favor of pretrained.py

* Attempt to use proper doc formatting.

* Use proper doc formatting.",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1681,Dirk Groeneveld,dirkg@allenai.org,2019-12-17 10:31:36-08:00,f17e39f079fdb279494b72e87006d0debec05329,https://github.com/allenai/allennlp/commit/f17e39f079fdb279494b72e87006d0debec05329,"Fix for infinite iterator (#3531)

* Fix for infinite iterator

* Incorporate code review feedback",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1682,Dirk Groeneveld,dirkg@allenai.org,2019-12-17 15:06:03-08:00,b85c86cff6f0995002dca6216ba2e3aefe403d11,https://github.com/allenai/allennlp/commit/b85c86cff6f0995002dca6216ba2e3aefe403d11,"Gradient accumulation with the distributed trainer (#3537)

* Gradient accumulation with the distributed trainer

* Productivity through formatting

* Productivity through formatting

* Changed names everywhere and fix wrong count in TQDM",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['trainer._num_gradient_accumulation_steps == steps_to_accumulate', 'num_batches_trained_per_epoch == num_batches_expected']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1683,Michael Schmitz,MichaelS@allenai.org,2019-12-19 10:20:57-08:00,b5d153b3998e5abafe55543bc39dc18143d7acef,https://github.com/allenai/allennlp/commit/b5d153b3998e5abafe55543bc39dc18143d7acef,Remove unidecode as it's GPLv2 and isn't in requirements.txt. (#3543),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1684,JackKuo666,41313632+JackKuo666@users.noreply.github.com,2019-12-20 02:22:31+08:00,8ecaf777d036f4b6052a2190470936aef588aa15,https://github.com/allenai/allennlp/commit/8ecaf777d036f4b6052a2190470936aef588aa15,Add spearman correlation (#3189),4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(expected_spearman_correlation * spearman_correlation.get_metric()) > 0', 'spearman_correlation.get_metric() == temp', 'spearman_correlation.get_metric() != np.nan', 'math.isnan(spearman_correlation.get_metric())']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1685,Dirk Groeneveld,dirkg@allenai.org,2019-12-19 13:08:37-08:00,fc753f7cc9cf15e3c77caa35ed2c0415908e2687,https://github.com/allenai/allennlp/commit/fc753f7cc9cf15e3c77caa35ed2c0415908e2687,"Typos and optimizers (#3548)

* Typos

* Optimizers",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1686,Dirk Groeneveld,dirkg@allenai.org,2019-12-19 16:30:19-08:00,c570497eea1cc711f7ff7c1c2b7db86e13ce6fb7,https://github.com/allenai/allennlp/commit/c570497eea1cc711f7ff7c1c2b7db86e13ce6fb7,Excludes flaky tokenizer (#3552),2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1687,Dirk Groeneveld,dirkg@allenai.org,2019-12-23 14:34:39-08:00,276c14db0dc8114ce43f3e5a3239dadd79a6fd5b,https://github.com/allenai/allennlp/commit/276c14db0dc8114ce43f3e5a3239dadd79a6fd5b,"Token offsets for transformer tokenizers (#3538)

* Typos in comments

* Calculate character offsets in transformer tokenizers

* Productivity through formatting

* One more test

* Formatting

* Adds a performance test

* Adds docstring

* Adds comment

* Less pithy comment about Roberta

* Use time.monotonic()

* Test for sentence pairs

* Detect, rather than divine, whether a tokenizer lowercases

* More productivity",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == expected_tokens', 'idxs == expected_idxs', 'tokens == expected_tokens', 'idxs == expected_idxs', 'tokens == expected_tokens', 'idxs == expected_idxs', 'tokenized[-2].text == ', 'tokenized[-2].idx == len(sentence) - 1', 'with_idx_time <= 2 * without_idx_time', 'tokens == expected_tokens', 'idxs == expected_idxs', '(']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1688,John Giorgi,johnmgiorgi@gmail.com,2019-12-23 18:13:48-05:00,ec441a3efbb0bd7c98af7202ca1e4c4086747ba2,https://github.com/allenai/allennlp/commit/ec441a3efbb0bd7c98af7202ca1e4c4086747ba2,"Add missing type hint (#3554)

The input argument `file_path` to the `_read` method of `Seq2SeqDatasetReader` was missing a type hint (`str`)

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1689,Emil Stenstrm,em@kth.se,2020-01-02 15:16:41+01:00,e4f75f3f7aeef6606a47e19e5f000500fabb12fe,https://github.com/allenai/allennlp/commit/e4f75f3f7aeef6606a47e19e5f000500fabb12fe,Update conllu to 2.2 (#3573),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1690,Can Udomcharoenchaikit,udomc.can@gmail.com,2020-01-03 00:04:10+07:00,c54f971f526cbbabde242473b54695701542cb0b,https://github.com/allenai/allennlp/commit/c54f971f526cbbabde242473b54695701542cb0b,"Add GPU capability to HotFlip (#3555)

* Add GPU capability to HotFlip

- edit hotflip.py and predictor.py to allow GPU acceleration on a GPU

* Remove unwanted blank spaces

* Remove unwanted blank spaces

* Fix formatting

* Fix format using Black formatter

* Fix format using Black formatter

* Fix format using black and flake8

* Revert attacker to allennlp original version

* Fix mypy error

-allennlp/predictors/predictor.py:118: error: Too many arguments for ""forward"" of ""Model""

* Fix code formatting error using black==19.3b0",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1691,Will Merrill,vikingarnir.will@gmail.com,2020-01-02 13:49:05-05:00,515fdc9ae328879661b924a4105b1443d2423b62,https://github.com/allenai/allennlp/commit/515fdc9ae328879661b924a4105b1443d2423b62,"Add ability to compose Seq2SeqEncoders. (#3549)

* Add ability to compose Seq2SeqEncoders.

* Fixed lint errors.

* Add missing import to __init__.py.

* Applied black reformatting.

* Auto PEP.

* Applied black after auto PEP.

* Added documentation for ComposeEncoder.

Co-authored-by: Michael Schmitz <michael@schmitztech.com>
Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ValueError):'), ('Raises', '(ValueError):'), ('Raises', '(ValueError):')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.encoder.get_input_dim() == 9', 'self.encoder.get_output_dim() == 3']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1692,ananda seelan,ananda.seelan@gmail.com,2020-01-02 23:08:17+00:00,27bcca4374948a456b456029a8f9e2854e0d2b5d,https://github.com/allenai/allennlp/commit/27bcca4374948a456b456029a8f9e2854e0d2b5d,"Create model archive for multi-GPU training (#3567)

* Create model archive for multi-GPU training

* Add test for model archive creation",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['in serialized_files'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1693,RyujiTamaki,e44119rt@gmail.com,2020-01-04 00:36:42+09:00,b41a0440333380953add96d69f0d56a15821ecf0,https://github.com/allenai/allennlp/commit/b41a0440333380953add96d69f0d56a15821ecf0,"Use attention_mask in pretrained transformers (#3560)

* Add attention_mask to PretrainedTransformerIndexer

* Add attention_mask to PretrainedTransformerEmbedder

* delete mask_padding_with_zero

* set model_type for xlnet

* Rename attention_mask -> mask

* Fix PretrainedTransformerEmbedder

* Add end-to-end test

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed[] == expected_masks', 'len(padded_tokens[]) == max_length', 'padded_tokens[].tolist() == expected_masks', '[t.text for t in tokens1] == expected_tokens1', '[t.text for t in tokens2] == expected_tokens2', 'tokens[].shape == (2, max_length)', 'tokens[].tolist() == [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0]]', 'bert_vectors.size() == (2, 9, 768)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1694,ananda seelan,ananda.seelan@gmail.com,2020-01-03 15:59:47+00:00,1aebef5c87833a613404e1c9f44f7cf04c51dbe0,https://github.com/allenai/allennlp/commit/1aebef5c87833a613404e1c9f44f7cf04c51dbe0,Allow one GPU multi-node distributed training (#3578),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1695,ananda seelan,ananda.seelan@gmail.com,2020-01-03 16:00:13+00:00,89bc57185c831eb3fd79d03ef2ab7aec4cc49fd2,https://github.com/allenai/allennlp/commit/89bc57185c831eb3fd79d03ef2ab7aec4cc49fd2,Set `find_unused_parameters` to True (#3575),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1696,Andrew Moore,andrew.p.moore94@gmail.com,2020-01-03 16:06:46+00:00,107c7c7206a7fe463a3e4a02bf5317cd85692929,https://github.com/allenai/allennlp/commit/107c7c7206a7fe463a3e4a02bf5317cd85692929,"Added Typing List (#3525)

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",1,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(, (None, 5))']","['parametrize(, (None, 5))']","['mark.parametrize(, (None, 5))']",[],[],[],[],[],[],['(reason=)'],[],[],[],[],['skip(reason=)'],['mark.skip(reason=)'],[],[],[]
1697,jianliu-ml,57948262+jianliu-ml@users.noreply.github.com,2020-01-04 00:07:26+08:00,ba012f02c02b921b8b9bd5eb0b79e0d3ec99790a,https://github.com/allenai/allennlp/commit/ba012f02c02b921b8b9bd5eb0b79e0d3ec99790a,remove `sequence_mask` in self_attentive_span_extractor.py (#3582),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1698,Emil Stenstrm,em@kth.se,2020-01-03 18:16:26+01:00,1d7a3784c28df53414edf5bd83e5131d8afdd758,https://github.com/allenai/allennlp/commit/1d7a3784c28df53414edf5bd83e5131d8afdd758,"Filter by int instead of None to remove elided tokens (#3571)

* Filter by int instead of None to remove elided tokens

This changed in conllu==1.0 (https://github.com/EmilStenstrom/conllu/wiki/Migrating-from-0.1-to-1.0#parsing-of-ids-now-include-ranges-and-decimals) which is what allennlp uses since 9db004224adf74267cc923d45e8ecb22b53d7066.

* Update comment to correspond with universal_dependencies_multilang.py

Co-authored-by: Mark Neumann <markn@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1699,Michael Schmitz,MichaelS@allenai.org,2020-01-03 11:21:53-08:00,3336e06b4041b01ac13430b1693560863ecc7388,https://github.com/allenai/allennlp/commit/3336e06b4041b01ac13430b1693560863ecc7388,Upgrade base image to 3.8.10. (#3583),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1700,Michael Schmitz,MichaelS@allenai.org,2020-01-06 10:16:27-08:00,8e2c414ff1f54ee62f53331d4875c25421f2ff6e,https://github.com/allenai/allennlp/commit/8e2c414ff1f54ee62f53331d4875c25421f2ff6e,"Remove requirements.txt as we install via setup.py. (#3580)

* Remove requirements.txt as we install via setup.py.

* Add instructions to install dev-requirements.txt.

* Copy setup.py.

* Fixup.

* Add files required for setup.py.

* Add dev-requirements.txt",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1701,hayata-yamamoto,hayata.yamamoto.work@gmail.com,2020-01-07 04:08:49+09:00,3fb854221f6c9f268801ad74b21364e8e8d7721c,https://github.com/allenai/allennlp/commit/3fb854221f6c9f268801ad74b21364e8e8d7721c,add double backquotes to separate arguments and types (#3563),27,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1702,Michael Schmitz,MichaelS@allenai.org,2020-01-06 15:38:13-08:00,d118a25562f89d564f89f280c6a2c3f67e4f3642,https://github.com/allenai/allennlp/commit/d118a25562f89d564f89f280c6a2c3f67e4f3642,Consistently format docstrings. (#3588),104,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1703,Michael Schmitz,MichaelS@allenai.org,2020-01-07 08:26:31-08:00,94341e2501ec7d054e793266379d85564c76df2a,https://github.com/allenai/allennlp/commit/94341e2501ec7d054e793266379d85564c76df2a,"Unpin black and flake8 for development (#3587)

* Unpin black and flake8.

* Run updated black on the codebase.

* Run black on scripts.",12,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1704,Michael Schmitz,MichaelS@allenai.org,2020-01-07 08:26:52-08:00,7f44a928d2a69fcbf4609b93470c1bd8a8b035a6,https://github.com/allenai/allennlp/commit/7f44a928d2a69fcbf4609b93470c1bd8a8b035a6,Fixup to a single docstring. (#3589),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1705,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-01-07 12:49:38-08:00,5806a8f1cf05fee933c6f6007e247f4906bb93fd,https://github.com/allenai/allennlp/commit/5806a8f1cf05fee933c6f6007e247f4906bb93fd,"Fix tutorial code/description inconsistency. (#3592)

* Fix tutorial code/description inconsistency.

* Update tutorial descriptions",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1706,Brendan Roof,brendanr@allenai.org,2020-01-07 18:14:45-08:00,b8fdc9c988e0fbb73acd73205c4c464f8cf5a9c3,https://github.com/allenai/allennlp/commit/b8fdc9c988e0fbb73acd73205c4c464f8cf5a9c3,"Be robust to not having torch.distributed. (#3594)

- One can't call `distributed.is_initialized()` if `not distributed.is_available()`.
- This caused test failures on macOS High Sierra.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1707,Matt Gardner,mattg@allenai.org,2020-01-08 11:42:44-08:00,bd9fea0a6797877444cc5bdf0a029454c3ee6132,https://github.com/allenai/allennlp/commit/bd9fea0a6797877444cc5bdf0a029454c3ee6132,"Removing the reading comprehension code (#3348)

* Removing the reading comprehension code

* Fix predict tests

* clean up requirements

* Remove some old scripts while we're at it

* remove pretrained bidaf model

* remove pretrained naqanet model

* Remove eval scripts

* Removing metrics

* Removing test fixtures

* removing docs

* Formatting changes

* Remove pretrained.py

* Remove requirements.txt

* Changes from master

* Removing the reading comprehension code

* Fix predict tests

* clean up requirements

* Remove some old scripts while we're at it

* Remove eval scripts

* Removing metrics

* Removing test fixtures

* removing docs

* Fix setup.py

* Formatting changes

* Remove squad metric reference

* Remove reference to bidaf from tests

* Fix typo

* Remove reference to squad metric

* Productivity through formatting

* Fixes one test by removing it

* Fix another test

* Productivity through formatting

* Fixes another test

* Fix test by moving it into the rc repo

* Fixes another two tests

* Formatting again

* Brings back the old simple-tagger model

I don't know how Eric created this, so I can't fix it. Now we have two models.

* Formatting

* Remove more references to models that have moved

* Make the other simple_tagger model trainable by script

* Remove dependency on 2.2MB model

* Two more fixed tests

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",109,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,16,0,0,0,0,0,0,0,0,0,0,0,0,250,3,0,1,0,0,0,5,6,6,0,0,7,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['metrics.keys() == {', 'set(result.keys()) == {}', 'len(results) == 3', 'set(result.keys()) == {}', 'results[0][', 'results[0][', 'results[0][', 'set(result.keys()) == {}', 'set(result.keys()) == {}', 'set(result.keys()) == {}', 'len(row) == 3  # label and 2 class probabilities', 'label != ', 'model_params.pop(', 'len(predictor._dataset_reader._token_indexers) == 2', 'len(predictor._dataset_reader._token_indexers) == 1', 'len(predictor._dataset_reader._token_indexers) == 2']",[],[],[],[],[],[],[],[],[],[],[],[],"['metrics.keys() == {}', 'set(result.keys()) == {', 'len(results) == 5', 'set(result.keys()) == {', 'results[0][] == 1000', 'results[0][] == 400', 'results[0][] == 1000', 'set(result.keys()) == {', 'set(result.keys()) == {', 'set(result.keys()) == {', 'len(row) == 5', '0 <= int(span_start) <= int(span_end) <= 8', 'span != ', 'model_params.pop(', 'DatasetReader.by_name(', 'len(instances) == 19', 'set(instance.fields.keys()) == {', '[t.text for t in instance[]', '[t.text for t in instance[]', '[t.text for t in instance[]', '[f.sequence_index for f in instance[]] == [', 'len(instance[]) == 1', 'instance[][0] == (46, 47)', 'len(instance[]) == 1', 'instance[][0] == (5, 6)', 'len(instance[]) == 1', 'instance[][0].labels == [0] * 22', 'len(instance[]) == 1', 'instance[][0].label == -1', 'set(instance[].metadata.keys()) == {', 'len(instances) == 19', 'set(instance.fields.keys()) == {', '[t.text for t in instance[]', '[t.text for t in instance[]', '[t.text for t in instance[]', 'len(instance[]) == question_length + passage_length + 1', 'len(instance[]) == 1', 'instance[][0] == (', 'set(instance[].metadata.keys()) == {', 'len(instances) == 19', 'set(instance.fields.keys()) == {', '[t.text for t in instance[]', '[t.text for t in instance[]', '[t.text for t in instance[]', 'instance[] == 46', 'instance[] == 47', 'set(instance[].metadata.keys()) == {', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[', 'len(instances) == 2', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[][0][:3]] == [', '[t.text for t in instances[0].fields[]', 'instances[0].fields[].sequence_index == 4', 'reader._token_indexers[', 'instances[0].fields[].sequence_length() == 6', 'instances[0].fields[].sequence_length() == 6', '[t.text for t in instances[0].fields[].field_list[0].tokens[:3]] == [', 'len(instances) == 2', '[t.text for t in instances[0].fields[]', '[x.label for x in instances[0].fields[].field_list] == [', '[x.label for x in instances[0].fields[].field_list] == [', '(', 'instances[0].fields[].field_list[1].labels == prev_1_list', 'instances[0].fields[].field_list[2].labels == prev_2_list', 'len(instances) == 5', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[].tokens[:3]] == [', '[t.text for t in instances[0].fields[]', 'instances[0].fields[].sequence_index == 102', 'instances[0].fields[].sequence_index == 104', '[t.text for t in instances[1].fields[].tokens[:3]] == [', '[t.text for t in instances[1].fields[].tokens[:3]] == [', '[t.text for t in instances[1].fields[]', 'instances[1].fields[].sequence_index == 17', 'instances[1].fields[].sequence_index == 23', '[t.text for t in instances[3].fields[].tokens[:3]] == [', '[t.text for t in instances[3].fields[]', '[t.text for t in instances[3].fields[].tokens[-3:]] == [', '[t.text for t in answer_tokens] == expected_answer_tokens', 'reader._tokenizer.__class__.__name__ == ', 'reader._token_indexers[', 'len(instances[0].fields[].tokens) == 10', 'len(instances[0].fields[].tokens) == 30', 'len(instances) == 3', 'len(instances[0].fields[].tokens) == 10', 'len(instances[0].fields[].tokens) == 30', 'len(instances) == 5', 'set(instance_x.fields[]) == set(', 'len(instances) == 3', '[t.text for t in instances[0].fields[].tokens[:3]] == [', '[t.text for t in instances[0].fields[].tokens[:3]] == [', '[t.text for t in instances[0].fields[]', 'instances[0].fields[].sequence_index == 12', 'instances[0].fields[].sequence_index == 13', '[t.text for t in instances[1].fields[].tokens[:3]] == [', '[t.text for t in instances[1].fields[]', '[t.text for t in instances[1].fields[].tokens[-3:]] == [', 'instances[1].fields[].sequence_index == 38', 'instances[1].fields[].sequence_index == 39', '[t.text for t in instances[2].fields[].tokens[:3]] == [', '[t.text for t in instances[2].fields[]', '[t.text for t in instances[2].fields[]', 'instances[2].fields[].sequence_index == 16', 'instances[2].fields[].sequence_index == 16', 'token_span == (1, 4)', 'token_span == (22, 24)', 'token_span == (22, 28)', 'token_span == (184, 185)', 'token_span == expected_span', 'error', 'token_span == expected_span', 'error', 'token_span == expected_span', 'error', 'token_span == expected_span', 'error', 'token_span == expected_span', 'error', 'token_span == expected_span', 'error', 'attack is not None', 'in attack', 'in attack', 'in attack', 'len(attack[][0]) == len(', 'instance[][0]  # check that the input has changed.', 'token in attack[][0]  # ignore tokens should not be changed', '(', 'metrics[] > 0', 'torch.equal(ensemble_output_dict[])', 'ensemble_output_dict[]', 'metrics[] > 0', 'span_start >= 0', 'span_start <= span_end', 'span_end < self.instances[0].fields[].sequence_length()', 'isinstance(output_dict[][0], str)', 'in output_dict', 'in output_dict', 'metrics[] > 0', 'span_start >= 0', 'span_start <= span_end', 'span_end < self.instances[0].fields[].sequence_length()', 'isinstance(output_dict[][0], str)', 'best_span is not None', 'isinstance(best_span, list)', 'len(best_span) == 2', 'all(isinstance(x, int) for x in best_span)', 'best_span[0] <= best_span[1]', 'isinstance(best_span_str, str)', 'best_span_str != ', 'probs is not None', 'all(isinstance(x, float) for x in probs)', 'sum(probs) == approx(1.0)', 'len(results) == 2', 'best_span is not None', 'isinstance(best_span, list)', 'len(best_span) == 2', 'all(isinstance(x, int) for x in best_span)', 'best_span[0] <= best_span[1]', 'isinstance(best_span_str, str)', 'best_span_str != ', 'probs is not None', 'all(isinstance(x, float) for x in probs)', 'sum(probs) == approx(1.0)', 'internals is not None', 'len(internals) == 25', ']', 'len(linear_50_1[]) == 17', 'all(len(a) == 1 for a in linear_50_1[])', 'not module._forward_hooks', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'new_instances[0].fields[] is not None', 'len(new_instances) == 1', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'in new_instances[0].fields', 'len(new_instances) == 1', 'new_instances[0][][0].label == 2', 'new_instances[0][][0] == (0, 1)  # token indices', 'new_instances[0][][0].labels == [2, 0, 0]', 'new_instances[0][][0] == (0, 1)  # token indices', 'isinstance(best_span_str, str)', 'best_span_str != ', 'len(results) == 2', 'predictor._dataset_reader.passage_length_limit == 1000', 'predictor._dataset_reader.passage_length_limit == 400', 'predictor._dataset_reader.passage_length_limit == 1000', '_normalize_answer()', '_normalize_answer()', '_normalize_answer()', '_normalize_answer()', '_normalize_answer(', '_normalize_answer(', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics(predicted=[]) == (0.0, 0.5)', 'get_metrics(]) == (0.0, 0.5)', 'get_metrics(predicted=[]) == (0.0, 0.5)', 'get_metrics(predicted=[) == (0.0, 0.5)', 'get_metrics(', 'get_metrics(', 'get_metrics(', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (0.0, 1.0)', 'get_metrics([]) == (0.0, 1.0)', 'get_metrics([]) == (0.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (0.0, 0.67)', 'get_metrics([]) == (0.0, 0.67)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (1.0, 1.0)', 'get_metrics([]) == (0.0, 0.0)', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics([]) == (0.0, 0.0)', 'get_metrics([]) == (0.0, 0.0)', 'get_metrics([]) == (0.0, 0.0)', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics(', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics([]) == (0.0, 0.5)', 'get_metrics(', 'get_metrics([]) == (0, 0.5)', 'get_metrics([]) == (0, 0.5)', 'get_metrics([]) == (0, 0.5)', 'evaluate_json(annotation, prediction) == (1.0, 1.0)', 'evaluate_json(annotation, prediction) == (1.0, 1.0)', 'evaluate_json(annotation, prediction) == (1.0, 1.0)', 'evaluate_json(annotation, prediction) == (1.0, 1.0)', 'evaluate_json(annotation, prediction) == (0.0, 0.5)', 'evaluate_json(annotation, prediction) == (0.0, 0.0)', 'evaluate_json(annotation, prediction) == (0.0, 0.0)', 'evaluate_json(annotation, prediction) == (0.5, 0.5)', 'lines[4] == ', 'lines[4] == ', 'metrics == (0.5, 0.625)', 'metrics == (1.0, 1.0)', 'result == 0']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],"['if(torch.cuda.device_count() < 2, reason=)']",[],[],[],"['(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))']","['parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'skipif(torch.cuda.device_count() < 2, reason=)']","['mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.skipif(torch.cuda.device_count() < 2, reason=)']",[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest']"
1708,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-01-08 14:27:42-08:00,c68862ed7efc1010816a848669e1016c721f326c,https://github.com/allenai/allennlp/commit/c68862ed7efc1010816a848669e1016c721f326c,"No longer requires a predictor to be supplied when doing prediction (#3593)

* No longer requires a predictor to be supplied when doing prediction

* Add test for base predictor fallthrough

* Update qanet paths to esim as RC is being moved to a new repo",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model_type not in DEFAULT_PREDICTORS', 'os.path.exists(self.outfile)', 'len(results) == 3', 'set(result.keys()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1709,Dirk Groeneveld,dirkg@allenai.org,2020-01-08 16:51:39-08:00,8bc5da2d7d0050374c78b52adde7149425e3b52a,https://github.com/allenai/allennlp/commit/8bc5da2d7d0050374c78b52adde7149425e3b52a,"Factor out a single function I need in allennlp_reading_comprehension (#3596)

* Factor out a single function I need in allennlp_reading_comprehension

* Undo nonsensical change that some automatic tool makes",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1710,Matt Gardner,mattg@allenai.org,2020-01-10 16:23:58-08:00,46223a0bc56135e3694945243e6d89253388f5c2,https://github.com/allenai/allennlp/commit/46223a0bc56135e3694945243e6d89253388f5c2,"Guess sorting keys when none are given to BucketIterator (#3603)

* Guess sorting keys when none are given to BucketIterator

* flake and black

* mypy

* address PR comments",2,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['iterator._sorting_keys is None', 'iterator._sorting_keys == [()]']",[],[],[],[],[],[],[],[],[],[],[],[],[],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[]
1711,Can Udomcharoenchaikit,udomc.can@gmail.com,2020-01-11 08:23:09+07:00,02c8154b1efd1b857668bacbe7babf1e765751b7,https://github.com/allenai/allennlp/commit/02c8154b1efd1b857668bacbe7babf1e765751b7,"Fix HotFlip padding error in ``_make_embedder_input"" module  (#3595)

* Add GPU capability to HotFlip

- edit hotflip.py and predictor.py to allow GPU acceleration on a GPU

* Remove unwanted blank spaces

* Remove unwanted blank spaces

* Fix formatting

* Fix format using Black formatter

* Fix format using Black formatter

* Fix format using black and flake8

* Revert attacker to allennlp original version

* Fix mypy error

-allennlp/predictors/predictor.py:118: error: Too many arguments for ""forward"" of ""Model""

* Fix code formatting error using black==19.3b0

* Fix HotFlip padding error in _make_embedder_input module

- Sometime if all the tokens are very short you might get this error:
RuntimeError: Calculated padded input size per channel: (2). Kernel size: (3). Kernel size can't be greater than actual input size allennlp
- This commit fixes this problem.

* Remove unwanted comment

* Fix formatting

Co-authored-by: Matt Gardner <mattg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1712,Mark Neumann,markn@allenai.org,2020-01-13 09:56:43-08:00,7d0d0d9c43c00febf9286bad0bab497b1fc11911,https://github.com/allenai/allennlp/commit/7d0d0d9c43c00febf9286bad0bab497b1fc11911,"New docs (#3602)

* alter build scripts

* completely remove old docs

* remove old docs packages

* add new build docs script

* new build process

* add mkdocs yaml

* move how_to and getting_started to docs folder

* remove useless makefile

* black

* add option to check if docs need regenerating

* refine

* add packages to dev requirements

* add mkdocs config to dockerfile, add another requirement

* revert adding all md docs

* add non-generated parts of docs only

* remove checks from verify

* remove more duplicate files

* format

* remove autogenerated bit of yaml

* generate site in script, remove duplicated tutorial

* absolute links in docs

* PR comments

* bulk change Parameter and Return docstrings

* first pass for urls

* fix added hash in comment

* fix test",420,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1713,Santiago Castro,sacastro@umich.edu,2020-01-14 11:51:58-05:00,4694a547e6b0d80c6ac813e2f1004b934971a738,https://github.com/allenai/allennlp/commit/4694a547e6b0d80c6ac813e2f1004b934971a738,Update the help command output in the README (#3607),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1714,Michael Schmitz,MichaelS@allenai.org,2020-01-14 09:34:28-08:00,ca30e2ca64b135ff61b13cc1ca22027d15982934,https://github.com/allenai/allennlp/commit/ca30e2ca64b135ff61b13cc1ca22027d15982934,"Remove reference to MODELS.md (#3613)

* Remove reference to non-existent MODELS.md.

* Update using_pretrained_models.md

* Update using_pretrained_models.md

* Remove reference in README.md",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1715,Matt Gardner,mattg@allenai.org,2020-01-14 10:25:17-08:00,ae69b9ea7807e25c1cab23c4d148a15f1eaaa180,https://github.com/allenai/allennlp/commit/ae69b9ea7807e25c1cab23c4d148a15f1eaaa180,"Allow registering specific methods to use as constructors (#3550)

* Got initial version working

* Revert checkpointer change, remove prints

* Revert Embedding -> TokenEmbedder change, other minor things

* black

* flake

* mypy

* failing test and mypy

* Revert changes to pos tag indexer test

* flake

* Add examples to docstring",47,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,12,4,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['TokenEmbedder.by_name(', 'extended_vocab.get_token_index() == 0 + extra_count', 'extended_vocab.get_token_index() == 1 + extra_count', 'extended_vocab.get_token_index() == 2 + extra_count', 'extended_vocab.get_token_index()  # should be present', 'extended_vocab.get_token_index()  # should be present', 'extended_vocab.get_vocab_size() == 5 + extra_count', 'len(extended_vocab._token_to_index) == 2', 'extended_vocab.get_vocab_size() == 1 + extra_count', 'extended_vocab.get_vocab_size() == 1 + extra_count']",[],[],[],[],[],[],[],[],[],[],[],[],"['TokenEmbedder.by_name(', 'extended_vocab.get_token_index() == 0 + extra_count', 'extended_vocab.get_token_index() == 1 + extra_count', 'extended_vocab.get_token_index() == 2 + extra_count', 'extended_vocab.get_token_index()  # should be present', 'extended_vocab.get_token_index()  # should be present', 'extended_vocab.get_vocab_size() == 5 + extra_count', 'len(extended_vocab._token_to_index) == 2', 'extended_vocab.get_vocab_size() == 1 + extra_count', 'extended_vocab.get_vocab_size() == 1 + extra_count', 'old_embedder._token_embedders.keys() == new_embedder._token_embedders.keys()', 'new_embedder(self.inputs).size() == (1, 4, 10)']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[]
1716,loopylangur,43548542+loopylangur@users.noreply.github.com,2020-01-14 14:36:44-06:00,500f0f1a1e6b25399bc1fd8d02b4e3b6b6f7e2ab,https://github.com/allenai/allennlp/commit/500f0f1a1e6b25399bc1fd8d02b4e3b6b6f7e2ab,"Bug fix for flaky test in AucTest, resolving issue #3608 (#3615)

* bug fix for flaky test in AucTest, resolving issue #3608

* Minor fixes.

* Better fix

* positive_label did not do what I expected...

Co-authored-by: Matt Gardner <mattg@allenai.org>",1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1717,nadgeri14,abhishek22596@gmail.com,2020-01-15 02:33:45+05:18,9e9600e2486d6e3d927fba709cfd1736dd45eb94,https://github.com/allenai/allennlp/commit/9e9600e2486d6e3d927fba709cfd1736dd45eb94,"fixed the fix-endpoint_span_extractor issue (#3611)

* fixed the fix-endpoint_span_extractor issue

* changes to add if ValueError block and follow code conventions

Co-authored-by: Nelson Liu <nelson-liu@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1718,Dirk Groeneveld,dirkg@allenai.org,2020-01-14 14:40:18-08:00,b1c06efdfa8ceffb46cabe6c56bcd2bde8975754,https://github.com/allenai/allennlp/commit/b1c06efdfa8ceffb46cabe6c56bcd2bde8975754,Unpins the version of datautil (#3618),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1719,Mark Neumann,markn@allenai.org,2020-01-14 14:50:14-08:00,4a858c40731bf6cae80e281321e129e7051e1cc4,https://github.com/allenai/allennlp/commit/4a858c40731bf6cae80e281321e129e7051e1cc4,"make matplotlib optional (#3616)

* make matplotlib optional

* lint",3,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1720,Mark Neumann,markn@allenai.org,2020-01-14 15:19:40-08:00,0d996db6fb5e39f1cca9394e6723df358b9be8de,https://github.com/allenai/allennlp/commit/0d996db6fb5e39f1cca9394e6723df358b9be8de,"remove configuration for config wizard, remove numpydoc (#3617)",4,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,2,0,0,0,0,0,0,0,0,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['config == BASE_CONFIG', 'isinstance(config, list)', 'in config', 'isinstance(config, Config)', 'len(items) == 4', 'in items', 'token_indexers.default_value is None', 'in items', 'domain_identifier.annotation == str', 'domain_identifier.default_value is None', 'in items', 'domain_identifier.annotation == str', 'domain_identifier.default_value is None', 'in items', 'lazy.annotation == bool', 'not lazy.default_value', 'isinstance(config, Config)', 'len(items) == 9', 'in items', 'in items', 'ja == {}]}']","['(ModuleNotFoundError)', '(AttributeError)']",[],[],[],[],[],[],[],[],[],[],['import pytest']
1721,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-01-14 16:04:07-08:00,030a91c11d61679bea50e3b37f1dac4c3bebd695,https://github.com/allenai/allennlp/commit/030a91c11d61679bea50e3b37f1dac4c3bebd695,"Bump pre-commit from 1.18.3 to 1.21.0 (#3622)

Bumps [pre-commit](https://github.com/pre-commit/pre-commit) from 1.18.3 to 1.21.0.
- [Release notes](https://github.com/pre-commit/pre-commit/releases)
- [Changelog](https://github.com/pre-commit/pre-commit/blob/master/CHANGELOG.md)
- [Commits](https://github.com/pre-commit/pre-commit/compare/v1.18.3...v1.21.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1722,Mark Neumann,markn@allenai.org,2020-01-14 16:17:26-08:00,27c430e070b4627f61e355195d1c36eeca196ef7,https://github.com/allenai/allennlp/commit/27c430e070b4627f61e355195d1c36eeca196ef7,dataset.py -> batch.py (#3621),26,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1723,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-01-14 16:25:03-08:00,d4b1af68bf99c9033ca814327364f4b3d749ca3f,https://github.com/allenai/allennlp/commit/d4b1af68bf99c9033ca814327364f4b3d749ca3f,"Bump conllu from 1.3.1 to 2.2 (#3623)

Bumps [conllu](https://github.com/EmilStenstrom/conllu) from 1.3.1 to 2.2.
- [Release notes](https://github.com/EmilStenstrom/conllu/releases)
- [Commits](https://github.com/EmilStenstrom/conllu/commits)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>",1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1724,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-01-14 16:25:20-08:00,aa1e7608a7eb7312d66c93d19d7ac2d469718efc,https://github.com/allenai/allennlp/commit/aa1e7608a7eb7312d66c93d19d7ac2d469718efc,"Bump overrides from 2.0 to 2.8.0 (#3624)

Bumps [overrides](https://github.com/mkorpela/overrides) from 2.0 to 2.8.0.
- [Release notes](https://github.com/mkorpela/overrides/releases)
- [Commits](https://github.com/mkorpela/overrides/commits/2.8.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>",1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1725,Mark Neumann,markn@allenai.org,2020-01-14 16:53:31-08:00,9704ba55f27440d65e16c3b9e53a83da1a3e6e78,https://github.com/allenai/allennlp/commit/9704ba55f27440d65e16c3b9e53a83da1a3e6e78,"remove deprecated language modelling reader (#3620)

* remove deprecated language modelling reader

* catch another LM reader ref",4,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,1,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['DatasetReader.by_name(', 'len(instances) == 5', '[t.text for t in instances[0].fields[]', '[t.text for t in instances[0].fields[].tokens] == [', '[t.text for t in instances[1].fields[].tokens] == [', '[t.text for t in instances[1].fields[].tokens] == [', '[t.text for t in instances[2].fields[].tokens] == [', '[t.text for t in instances[2].fields[]', '[t.text for t in instances[3].fields[].tokens] == [', '[t.text for t in instances[3].fields[].tokens] == [', '[t.text for t in instances[4].fields[].tokens] == [', '[t.text for t in instances[4].fields[].tokens] == [']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest']
1726,Santiago Castro,sacastro@umich.edu,2020-01-15 00:41:44-05:00,55147761ca3b46a9ce994532e2451af95088258c,https://github.com/allenai/allennlp/commit/55147761ca3b46a9ce994532e2451af95088258c,Remove extra quotes from string literals (#3626),15,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1727,Dirk Groeneveld,dirkg@allenai.org,2020-01-15 09:52:26-08:00,922b6fdefad2d8c648c87589c54cefb7058603e4,https://github.com/allenai/allennlp/commit/922b6fdefad2d8c648c87589c54cefb7058603e4,"Skip a test that we know will fail (#3619)

* Skip a test that we know will fail

* Productivity through formatting",1,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[''],[],[],[],[],['skipif('],['mark.skipif('],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1728,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-01-15 09:55:00-08:00,56a3966053b6ebc47b23942b8ccbd9cc5193eecd,https://github.com/allenai/allennlp/commit/56a3966053b6ebc47b23942b8ccbd9cc5193eecd,"Bump mypy from 0.730 to 0.761 (#3625)

Bumps [mypy](https://github.com/python/mypy) from 0.730 to 0.761.
- [Release notes](https://github.com/python/mypy/releases)
- [Commits](https://github.com/python/mypy/compare/v0.730...v0.761)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1729,ananda seelan,ananda.seelan@gmail.com,2020-01-15 18:43:51+00:00,a86dfef8c84707826dddf53d1e9acacaa902625a,https://github.com/allenai/allennlp/commit/a86dfef8c84707826dddf53d1e9acacaa902625a,"Fix master process computation for multi-node training (#3601)

* Remove env vars as tcp based init doesn't need them

* Rename rank to local_rank for less ambiguity

* Disambiguate `master` proc to local and global cases

* Format with black

* Remove is_global_master as it itself is a local_master anyways

* Add fallback value for PROCS_PER_NODE env var

* Fix sphinx error

Co-authored-by: Brendan Roof <brendanr@allenai.org>
Co-authored-by: Mark Neumann <markn@allenai.org>",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1730,Shaleen Gupta,shaleenx@gmail.com,2020-01-16 00:19:21+05:18,2f33b5263a6bf4e3ff1b8e2b708c579c296c38dd,https://github.com/allenai/allennlp/commit/2f33b5263a6bf4e3ff1b8e2b708c579c296c38dd,"Add bleu_ngram_weights option to SimpleSeq2Seq (#3491)

* Add bleu_ngram_weights option to SimpleSeq2Seq

This commit adds an option to specify n-gram weights for calculating
the bleu score weighted for each n-gram size. SimpleSeq2Seq passes
these weights to the BLEU class constructor as is.
Default value is set to (0.25, 0.25, 0.25, 0.25).

modified: models/encoder_decoders/simple_seq2seq.py

* Run Black.

* add import

Co-authored-by: Michael Schmitz <michael@schmitztech.com>
Co-authored-by: Mark Neumann <markn@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1731,Diganta Misra,mishradiganta91@gmail.com,2020-01-16 00:26:16+05:18,f60d826307243f5f5d9ccdb05903dfaa4a5055ca,https://github.com/allenai/allennlp/commit/f60d826307243f5f5d9ccdb05903dfaa4a5055ca,"Feature Request: Adding Mish and Swish Activation function (#3466)

* Added Mish and Swish Activation function

* Added type ignore statement for mypy check

* Run black.

Co-authored-by: Michael Schmitz <michael@schmitztech.com>
Co-authored-by: Mark Neumann <markn@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1732,Santiago Castro,sacastro@umich.edu,2020-01-15 18:32:23-05:00,4b4d8be6b2f1cc818eaaf25513749350f762db84,https://github.com/allenai/allennlp/commit/4b4d8be6b2f1cc818eaaf25513749350f762db84,"Refactor out fine-tune command (#3404)

* WIP: refactor subcommands

* Fix the fine-tune help output in the docstring

* Change `get_frozen_and_tunable_parameter_names` after a PR comment

* Fix warning message after a PR comment

* Avoid creating unnecessary lists

* Fix warning message after a PR comment

* Move tests

* Refactor vocabulary manipulation to a new method

* black

* Fix missing arg passing in train

* Change 'embedding_sources_mapping_str' default value so it makes more sense

* Parse the embedding json when reading from the args

* Fix docstring test issue

* Add tests for 'create_or_extend_vocab'

* Fix test

Co-authored-by: Matt Gardner <mattg@allenai.org>",14,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,4,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,3,0,0,0,0,0,0,0,0,0,0,0,9,3,0,0,0,0,0,0,0,0,0,0,1,[],"[('Equal', '('), ('Equal', '(vocab.get_vocab_size(}))'), ('Equal', '('), ('Equal', '(vocab.get_vocab_size(}))')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tuple(original_weight.shape) == (24, 300)', 'tuple(extended_weight.shape) == (25, 300)', 'torch.all(original_weight == extended_weight[:24, :])', 'original_weight.shape[0] + 1 == extended_weight.shape[0] == 25', 'torch.all(original_weight == extended_weight[:24, :])', 'torch.all(extended_weight[24, :] == extra_token_vector)', 'torch.all(extended_weight[24, :] != extra_token_vector)', 'not parameter.requires_grad', 'parameter.requires_grad == name_parameters_original[name].requires_grad']","['(Exception)', '(ConfigurationError)', '(Exception)']",[],[],[],[],[],[],[],[],[],[],[],"['tuple(original_weight.shape) == (24, 300)', 'tuple(extended_weight.shape) == (25, 300)', 'torch.all(original_weight == extended_weight[:24, :])', 'original_weight.shape[0] + 1 == extended_weight.shape[0] == 25', 'torch.all(original_weight == extended_weight[:24, :])', 'torch.all(extended_weight[24, :] == extra_token_vector)', 'torch.all(extended_weight[24, :] != extra_token_vector)', 'not parameter.requires_grad', 'parameter.requires_grad == name_parameters_original[name].requires_grad']","['(ConfigurationError)', '(Exception)', '(Exception)']",[],[],[],[],[],[],[],[],[],[],['import pytest']
1733,Santiago Castro,sacastro@umich.edu,2020-01-16 11:56:23-05:00,c9bd9b294df102fd35dc93b62f9c900a142ab297,https://github.com/allenai/allennlp/commit/c9bd9b294df102fd35dc93b62f9c900a142ab297,"Remove pypandoc (#3632)

It's not used anymore.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1734,Matt Gardner,mattg@allenai.org,2020-01-16 12:31:22-08:00,62e3d1dbdc88af9ed8afb37f7e8ecc011f5486a3,https://github.com/allenai/allennlp/commit/62e3d1dbdc88af9ed8afb37f7e8ecc011f5486a3,"Scope TokenIndexer output by indexer name (#3597)

* Indexer tests are now passing, at least

* Fixed some masking issues, and padding keys for one config file

* TextFieldEmbedder tests pass

* Fixing fixtures, some more tests passing

* Fixed weird ordering bug

* All TokenEmbedder tests passing?

* Update fixtures

* Fix more hard-coded references

* fix field tests

* fix dataset reader tests

* Fix iterator tests

* More tests passing

* fix hotflip and some other tests

* more tests

* more test fixes

* more tests

* most tests passing; I think the remaining ones are spacy model changes

* hard-code POS tag test

* last test, I think

* black

* updated black

* flake8

* mypy

* black again

* fix training configs

* remove reference to embedder_to_indexer_map

* Other fixes from PR comments

* fix breakage from incorrect merge during rebase

* flake, some docstring formatting",156,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,90,1,0,0,0,0,0,0,0,0,0,0,1,95,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Equal', '(tensor_dict[].size(), (4,))')]",[],[],[],[],[],[],[],[],[],[],"[('Equal', '(tensor_dict[].size(), (4,))'), ('Raises', '(')]",[],[],[],[],[],[],[],[],[],"['tensor_dict[].numpy().tolist() == [2, 3, 4, 5, 6, 7]', 'tensor_dict[].numpy().tolist() == [2]', 'tensor_dict[].numpy().tolist() == [2, 3, 4]', 'tensor_dict[].numpy().tolist() == [2]', 'padding_lengths == {: 6}}', 'lengths == {: 5}', 'field._indexed_tokens[] == [capital_a_index, sentence_index]', 'field1._indexed_tokens[] == [', 'field2._indexed_tokens[] == [capital_a_index, sentence_index]', 'field2._indexed_tokens[] == [', 'padding_lengths == {: 5}', 'list(tensors[].shape) == [7]', 'list(tensors[].shape) == [3]', 'list(tensors[].shape) == [4]', 'list(tensors[].shape) == [4, 8]', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == [0] * 8', 'iterator._sorting_keys == [()]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [1, 2, 3, 4, 5, 6, 7, 10, 11, 12]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [1, 2, 3, 4, 5, 6, 7, 8, 11, 12]', 'indexed_tokens[] == [16, 2, 1, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [16, 2, 15, 10, 11, 6, 0, 17]', 'indexed_tokens[] == [16, 2, 15, 10, 11, 6, 1, 17]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]', 'indexed_tokens[] == [', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9, 10, 11]', 'indexed_tokens[] == [', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8, 9]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 3, 4, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8, 9, 10]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 3, 4, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9, 11]', 'padded_tokens[].tolist() == [', 'indices == {: [[3, 4, 5, 6, 4, 5, 6, 1, 1, 1]]}', 'indices == {', 'padded[].tolist() == [', 'indexer.tokens_to_indices([tokens[1]], vocab) == {: [root_index]}', 'indexer.tokens_to_indices([tokens[-1]], vocab) == {: [none_index]}', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'padded_tokens[].tolist() == expected_padded_tokens', 'indices[] == expected_indices', 'indexer.tokens_to_indices([tokens[1]], vocab) == {: [person_index]}', 'indexer.tokens_to_indices([tokens[-1]], vocab) == {: [none_index]}', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', '{: [none_index, none_index, none_index, none_index]} == indices', 'set(indices.keys()) == {}', 'indices[][:9] == [50, 4, 21, 31, 4, 0, 1, 51, 0]', 'counter[: 2}', 'indices[][1] == verb_index', 'indexer.tokens_to_indices([tokens[1]], vocab) == {: [cop_index]}', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', '{: [none_index, none_index, none_index, none_index]} == indices', 'indexed[] == expected_ids', 'indexed[] == expected_ids', 'indexed[] == expected_ids', 'indexed[] == expected_ids', 'indexed[] == expected_ids', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'len(array_dict[]) == 5', 'len(array_dict[][0]) == 96', 'list(array_dict[].shape) == [5, 96]', 'exc.match()', 'tokens[].tolist() == [', 'tokens[].tolist() == [', 'tokens[].tolist() == [[16, 2, 3, 5, 6, 8, 9, 2, 14, 12, 17]]', 'tokens[].tolist() == [[1, 2, 3, 4, 5, 6, 7, 8, 9]]', 'tokens[].tolist() == [', 'tokens[].tolist() == [[1, 3, 4, 5, 6, 7, 8, 9, 10, 11]]', 'tokens[].shape == (2, max_length)', 'tokens[].tolist() == [', 'predictor._dataset_reader._token_indexers[', 'predictor._dataset_reader._token_indexers[', 'predictor._dataset_reader._token_indexers[']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['DatasetReader.by_name(', 'DatasetReader.by_name(', 'tensor_dict[].numpy().tolist() == [2, 3, 4, 5, 6, 7]', 'tensor_dict[].numpy().tolist() == [2]', 'tensor_dict[].numpy().tolist() == [2, 3, 4]', 'tensor_dict[].numpy().tolist() == [2]', 'padding_lengths == {', 'lengths == {: 5}', 'field._indexed_tokens[] == [capital_a_index, sentence_index]', 'field1._indexed_tokens[] == [', 'field2._indexed_tokens[] == [capital_a_index, sentence_index]', 'field2._indexed_tokens[] == [', 'padding_lengths == {: 5}', 'list(tensors[].shape) == [7]', 'list(tensors[].shape) == [3]', 'list(tensors[].shape) == [4]', 'list(tensors[].shape) == [4, 8]', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == 0', 'tensors[].tolist()[-1] == [0] * 8', 'iterator._sorting_keys == [()]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [1, 2, 3, 4, 5, 6, 7, 10, 11, 12]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [1, 2, 3, 4, 5, 6, 7, 8, 11, 12]', 'indexed_tokens[] == [16, 2, 1, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [16, 2, 15, 10, 11, 6, 0, 17]', 'indexed_tokens[] == [16, 2, 15, 10, 11, 6, 1, 17]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]', 'indexed_tokens[] == [', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9, 10, 11]', 'indexed_tokens[] == [', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8, 9]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 3, 4, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8, 9, 10]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 3, 4, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9, 11]', 'padded_tokens[].tolist() == [', 'indices == {: [[3, 4, 5, 6, 4, 5, 6, 1, 1, 1]]}', 'indices == {: [[8, 3, 9], [3, 4, 5, 6, 4, 5, 6, 1, 1, 1], [8, 10, 3, 9]]}', 'padded[].tolist() == [', 'indexer.tokens_to_indices([tokens[1]], vocab, : [root_index]}', 'indexer.tokens_to_indices([tokens[-1]], vocab, ) == {', 'indexer.get_padding_lengths(0) == {}', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'padded_tokens[].tolist() == expected_padded_tokens', 'indices == expected_indices', 'indexer.tokens_to_indices([tokens[1]], vocab, ) == {', 'indexer.tokens_to_indices([tokens[-1]], vocab, ) == {', 'indexer.get_padding_lengths(0) == {}', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', '{: [none_index, none_index, none_index, none_index]} == indices', 'set(indices.keys()) == {}', 'indices[][:9] == [50, 4, 21, 31, 4, 0, 1, 51, 0]', 'counter[: 2}', 'indices[][1] == aux_index', 'indexer.tokens_to_indices([tokens[1]], vocab, : [cop_index]}', 'indexer.get_padding_lengths(0) == {}', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', '{: [none_index, none_index, none_index, none_index]} == indices', 'indexed[] == expected_ids', 'indexed[] == expected_ids', 'indexed[] == expected_ids', 'indexed[] == expected_ids', 'indexed[] == expected_ids', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'len(array_dict[]) == 5', 'len(array_dict[][0]) == 96', 'list(array_dict[].shape) == [5, 96]', 'exc.match()', 'tokens[].tolist() == [', 'tokens[].tolist() == [', 'tokens[].tolist() == [[16, 2, 3, 5, 6, 8, 9, 2, 14, 12, 17]]', 'tokens[].tolist() == [[1, 2, 3, 4, 5, 6, 7, 8, 9]]', 'tokens[].tolist() == [', 'tokens[].tolist() == [[1, 3, 4, 5, 6, 7, 8, 9, 10, 11]]', 'tokens[].shape == (2, max_length)', 'tokens[].tolist() == [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0]]', 'len(predictor._dataset_reader._token_indexers) == 2', 'len(predictor._dataset_reader._token_indexers) == 1', 'len(predictor._dataset_reader._token_indexers) == 2']",[],[],[],[],[],[],[],[],[],[],[],[]
1735,Matt Gardner,mattg@allenai.org,2020-01-16 14:11:10-08:00,8cb07b261c4825e56ec0925f05412fca70d19a57,https://github.com/allenai/allennlp/commit/8cb07b261c4825e56ec0925f05412fca70d19a57,"Allow FromParams to handle **kwargs passed to superclass constructors (#3633)

* Allow FromParams to handle **kwargs passed to superclass constructors

* black

* breaking ""e"" key strikes again...

* multiprocess docstring

* fix typo

* remove caching from trainer, as it is now in the dataset reader

* fix usage string

* I thought I already removed this...

* remove cache params from other trainers

* Remove .dSYM; it was already in .gitignore

* flake and mypy",38,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],"['reader.lazy is True', 'str(reader._cache_directory) == ']",[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(expected_cache_file)', 'os.path.exists(expected_param_file)', 'saved_params == self.params.pop().as_dict(quiet=True)', 'os.path.exists(expected_cache_file)']",[],[],[],[],[],[],[],[],[],[],[],[]
1736,Mark Neumann,markn@allenai.org,2020-01-16 16:54:36-08:00,737111c28c428aa9e2badc70cf7682ffae42ea75,https://github.com/allenai/allennlp/commit/737111c28c428aa9e2badc70cf7682ffae42ea75,"Remove pytorch-pretrained-bert (#3635)

* remove all usages of pytorch-pretrained-bert

* remove from setup

* update config

* fix huggingface bug via temporary monkeypatch

* fix bert for classification",15,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1737,Mark Neumann,markn@allenai.org,2020-01-16 17:50:47-08:00,309b76d8400f6193f4ff9623ec75d927728ad3e4,https://github.com/allenai/allennlp/commit/309b76d8400f6193f4ff9623ec75d927728ad3e4,xfail dropconnect lstm test (#3638),1,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(reason=)'],[],[],[],['xfail(reason=)'],['mark.xfail(reason=)'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1738,Santiago Castro,sacastro@umich.edu,2020-01-16 21:12:35-05:00,2eefffaf71612263a1c20e8ce4107849cfd5efe3,https://github.com/allenai/allennlp/commit/2eefffaf71612263a1c20e8ce4107849cfd5efe3,Remove code for a previous PyTorch version (#3639),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1739,Mark Neumann,markn@allenai.org,2020-01-17 10:37:43-08:00,cc914864f4235ebed5a81eb4c8e485353ec4b9f8,https://github.com/allenai/allennlp/commit/cc914864f4235ebed5a81eb4c8e485353ec4b9f8,remove unused library (#3643),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1740,Michael Schmitz,MichaelS@allenai.org,2020-01-17 10:58:29-08:00,52bece613672d8b289b722ddc86731ded07cca3f,https://github.com/allenai/allennlp/commit/52bece613672d8b289b722ddc86731ded07cca3f,"Add bulldozer configuration to allennlp. (#3636)

Co-authored-by: Vivek Lakshmanan <vivekl@allenai.org>
Co-authored-by: Brendan Roof <brendanr@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1741,Mark Neumann,markn@allenai.org,2020-01-17 11:42:00-08:00,dc92af22e76887b2cd31144a1dced20da8a6c9ef,https://github.com/allenai/allennlp/commit/dc92af22e76887b2cd31144a1dced20da8a6c9ef,":wave: openai_transformers (#3647)

* :wave: openai_transformers

* more references",18,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,1,0,3,0,0,0,0,3,3,0,0,2,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'self.indexer.byte_pair_encode(token) == []', 'not in self.vocab._index_to_token', 'not in self.vocab._token_to_index', 'len(i2t) == 5 * 5 * 2', 'len(t2i) == 5 * 5 * 2', 'set(indices.keys()) == {}', 'text_tokens[:6] == [', 'offsets == [', 'indices[][:9] == [50, 4, 21, 31, 4, 0, 1, 51, 0]', 'non_padded_indices == expected_indices[k]', 'tokens == expected_tokens', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}', 'list(output.shape) == [2, 7, 10]', 'list(output.shape) == [2, 2, 10]']",['(RuntimeError)'],[],"['()', '()', '()']",[],[],[],[],"['skip()', 'skip()', 'skip()']","['mark.skip()', 'mark.skip()', 'mark.skip()']",[],[],"['import pytest', 'import pytest']"
1742,Michael Schmitz,MichaelS@allenai.org,2020-01-17 13:11:44-08:00,336de620317db7ea80a8d0a11c7e049b33e5a339,https://github.com/allenai/allennlp/commit/336de620317db7ea80a8d0a11c7e049b33e5a339,Remove some Sphynx artifacts from the docs (#3642),254,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1743,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-01-17 15:45:40-08:00,2e811b2796f77e9e796fc3a91f6618fdac68973b,https://github.com/allenai/allennlp/commit/2e811b2796f77e9e796fc3a91f6618fdac68973b,"Factor out batched_span_select code (#3648)

* Factor out batched_span_select code

* black

* double backtick to single

* remove stray comment

* s/it's/its/",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1744,Mark Neumann,markn@allenai.org,2020-01-20 11:08:17-08:00,876d838b6eabce82225577a7938df3792012da68,https://github.com/allenai/allennlp/commit/876d838b6eabce82225577a7938df3792012da68,remove drop connect (#3655),3,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,1,0,0,0,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],"[('SetEqual', '(parameter_names, expected_parameter_names)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not torch.allclose(output_a, output_b)', 'torch.allclose(output_a, output_b)', 'torch.allclose(output_a[:, 0, :], output_b[:, 0, :])', 'not torch.allclose(output_a[:, 1, :], output_b[:, 1, :])', 'torch.allclose(output_a, output_b)', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())', 'all(parameter.is_leaf for parameter in weight_dropped_linear.parameters())']",[],[],[],['(reason=)'],[],[],[],['xfail(reason=)'],['mark.xfail(reason=)'],[],[],['import pytest']
1745,Brendan Roof,brendanr@allenai.org,2020-01-20 15:56:43-08:00,79601fa6f09d3fb6fedc3965850e5df907b716ea,https://github.com/allenai/allennlp/commit/79601fa6f09d3fb6fedc3965850e5df907b716ea,Assorted fixes for distributed training and LM. (#3651),5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1746,Vivek Lakshmanan,vivekl@allenai.org,2020-01-21 08:13:22-08:00,6f65eac1dd028e160a8b230a6efbbaf9876b5f3e,https://github.com/allenai/allennlp/commit/6f65eac1dd028e160a8b230a6efbbaf9876b5f3e,Update run_with_beaker.py to avoid dropped single-file dataset support (#3656),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1747,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-01-21 10:44:28-08:00,7960a7c84fc17150b87dc5735c5026219c4d1a35,https://github.com/allenai/allennlp/commit/7960a7c84fc17150b87dc5735c5026219c4d1a35,"Add PretrainedTransformerMismatched{Indexer, Embedder} (#3634)

* Make the tokenizer property of PretrainedTransformerTokenizer public

* Add intra_word_tokenization option on PretrainedTransformerIndexer

* Add  argument to PretrainedTransformerEmbedder

* Add tests for intra-word tokenization and some bug fixes

* black

* Add another check

* Some simplification

* Move __init__ doc to class level

* Minor improvements

* Let the user specify the number of added start/end tokens; bug fixes

* mypy

* bug fix

* fix docs

* remove config file that wasn't supposed to be commited

* Resolve some comments

* Fix typo

* Refactor pretokeinzed case into a new indexer class; embedder factoring coming

* Refactor pretokenized case into a new embedder class

* orig_token_mask -> mask; mask -> wordpiece_mask

* Use util.batch_span_select to simply embedder

* typo fixes

* Change tests and __init__.py to use new factored classes

* Misc fixes

* black

* mypy

* `` -> `

* Improve how as_padded_tensor_dict is overriden

* fix

* typo

* fix

* Rename files: pretokenized -> mismatched

* Move _determine_num_special_tokens_added to mismatched indexer class

* More pretokenized -> mismatched

* Improve docstring

* Indexer: inheritance -> composition

* Embedder: inheritance -> composition

* kwargs and doc updates

* fix

* test fix

* revert some change

* add test

* Add docs and fix typo",10,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed[] == expected_ids', 'indexed[] == [1] * len(text)', 'indexed[] == [(1, 3), (4, 4), (5, 5)]', 'indexed[] == [1] * len(expected_ids)', 'indexer.get_empty_token_list() == {key: [] for key in keys}', 'len(padded_tokens[key]) == max_length', 'padded_tokens[key].tolist() == expected_value', 'indexer._determine_num_special_tokens_added() == (1, 1)', 'tokens[].tolist() == [', 'bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)', 'not torch.isnan(bert_vectors).any()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1748,Brendan Roof,brendanr@allenai.org,2020-01-21 13:06:50-08:00,c6c2ffcc5a9bc0a09421537c1a57c2f3a814b51a,https://github.com/allenai/allennlp/commit/c6c2ffcc5a9bc0a09421537c1a57c2f3a814b51a,"Assert that distributed config is not used with find-lr. (#3659)

- It would have no effect currently. We should fix this. See https://github.com/allenai/allennlp/issues/3658.
- Unbreaks multi-GPU tests in the interim by correcting the config, but asserting failure.",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['in str(execinfo.value)'],['(AssertionError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1749,Mark Neumann,markn@allenai.org,2020-01-21 15:47:14-08:00,3ca8035a3a0e8f9f6049e9632267f394dca5abad,https://github.com/allenai/allennlp/commit/3ca8035a3a0e8f9f6049e9632267f394dca5abad,update relative links in interpret and predictor folders (#3667),14,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1750,Mark Neumann,markn@allenai.org,2020-01-21 19:02:08-08:00,629ad22ae10a0291164702d18a051c79c10ab289,https://github.com/allenai/allennlp/commit/629ad22ae10a0291164702d18a051c79c10ab289,"update md links for models and modules (#3668)

* update md links for models and modules

* format

* add missing backticks",31,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1751,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-01-22 11:13:28-08:00,70f937e9c381b6cbb9be0cf00036e2fe26f70415,https://github.com/allenai/allennlp/commit/70f937e9c381b6cbb9be0cf00036e2fe26f70415,"Bump conllu from 2.2 to 2.2.1 (#3669)

Bumps [conllu](https://github.com/EmilStenstrom/conllu) from 2.2 to 2.2.1.
- [Release notes](https://github.com/EmilStenstrom/conllu/releases)
- [Commits](https://github.com/EmilStenstrom/conllu/commits)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>",1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1752,Matt Gardner,mattg@allenai.org,2020-01-23 17:06:11-08:00,75ffe070940da87c718d013765718f2520aa9e5b,https://github.com/allenai/allennlp/commit/75ffe070940da87c718d013765718f2520aa9e5b,"Remove files_to_archive from Params (#3674)

* Remove files_to_archive from Params

* failing tests

* black",10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['params.files_to_archive == {: my_other_file}', 'params.files_to_archive == {', 'new_params.loading_from_archive', 'new_params.files_to_archive == {}', 'params.get()', 'os.path.exists(params.get())', 'params.get() == str(', 'params.get() == original_train_data_path', 'os.path.exists(fta_file)', 'files_to_archive == {', 'filecmp.cmp(original_filename, new_filename)', 'os.path.exists(fta_file)', 'files_to_archive == {', 'filecmp.cmp(original_filename, new_filename)']",[],[],[],[],[],[],[],[],[],[],[],[]
1753,Dirk Groeneveld,dirkg@allenai.org,2020-01-24 14:37:01-08:00,4adad1ca217fa5154937946350e0a8d1a05b410d,https://github.com/allenai/allennlp/commit/4adad1ca217fa5154937946350e0a8d1a05b410d,"Changes I need for the TransformerQA model (#3646)

* Adds a vocab class for transformer vocabularies

* Tix fypo

* Remove special token stuff from vocab

* Include type ids in the output if we have them

* Use correct padding value even if the padding token id isn't 0

* The tokenizer knows about special tokens

* Typo

* Don't complain about too many tensors if we are going to use those tensors

* Support token type ids in the pretrained transformer wrapper

* Adds the threaded generator

* Fixed type annotations for token

* Fix problem introduced with the merge

* Productivity through formatting

* Removes test we no longer need

* Productivity through formatting

* Better documentation

* Add helpful documentation

* Remove unused import

* Fix tests

* Fix another test

* Make mypy happy

* Remove the special token functions

Now that `tokenizer` is public, we don't need them like this.

* Fix flake8

* Fixes the treatment of type_ids in the mismatched embedder and indexer

* Productivity through formatting

* Don't save the padding value anymore

* Adds test for different padding values

* Productivity through formatting

* Brendan doesn't like threaded_generator

* Better comments

* Remove unused imports

* Provide a clear error message when your type ids are too big

* Adds code coverage test

* Mark flaky test as flaky",10,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,1,0,0,0,0,0,0,0,0,0,0,1,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed[] == expected_masks', 'len(padded_tokens[]) == max_length', 'padded_tokens[].tolist() == expected_masks', 'len(padded_tokens[]) == max_length', 'padded_tokens[][-padding_length:].tolist() == padding_suffix']",['(ValueError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['indexed[] == expected_masks', 'len(padded_tokens[]) == max_length', 'padded_tokens[].tolist() == expected_masks']",[],[],[],[],[],[],[],[],[],[],[],[]
1754,Mark Neumann,markn@allenai.org,2020-01-27 09:31:35-08:00,30d687c0a419eaa05a5a6505e1e42848303ced5c,https://github.com/allenai/allennlp/commit/30d687c0a419eaa05a5a6505e1e42848303ced5c,change where we block in the distributed case (#3676),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1755,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-01-27 13:00:06-08:00,5bec95c4061946a436d965d1620306511ebba831,https://github.com/allenai/allennlp/commit/5bec95c4061946a436d965d1620306511ebba831,"Support splitting long sequences into multiple segments for transformers (#3666)

* First pass at folding long sequences

* bug fix

* various fixes

* more fixes

* More fixes

* Add tests

* fix and flake8

* black

* mypy

* make language consistent

* misc improvments

* max_len -> max_length

* Default max_length to None rather than -1

* Clean tokens_to_indices

* Add documentation

* Factor out long sequence handling logic in embedder in separate functions

* Add tests

* black

* typo fix

* Make end token embeddings robust

* bug fix

* improve unfold test

* black

* Add documentation

* Rebase fixes

* More fixes for type_id

* More fixes from rebase

* black

* Minor doc fixes

* mypy

* Resolving comments

* minor fixes

* black",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['PretrainedTransformerIndexer.determine_num_special_tokens_added(tokenizer) == (1, 1)', 'len(expected_ids) == 7  # just to make sure itre expecting', 'indexed[] == expected_ids', 'indexed[] == [1] * len(expected_ids)', 'indexed[] == [1] * 7  # original length', 'len(expected_ids) == 7  # just to make sure itre expecting', 'indexed[] == expected_ids', 'indexed[] == [1] * len(expected_ids)', 'indexed[] == [1] * len(text)', 'indexed[] == [1] * 7', 'tokens[].shape == (2, segment_concat_length)', 'tokens[].tolist() == [', 'tokens[].tolist() == [', 'bert_vectors.size() == (2, 9, 768)', '(folded_token_ids_out == folded_token_ids).all()', '(folded_segment_concat_mask_out == folded_segment_concat_mask).all()', '(unfolded_embeddings_out == unfolded_embeddings).all()', 'tokens[].tolist() == [', 'tokens[].tolist() == [', 'bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)', 'not torch.isnan(bert_vectors).any()']",[],[],[],[],[],[],[],[],[],[],[],[],"['indexer._determine_num_special_tokens_added() == (1, 1)']",[],[],[],[],[],[],[],[],[],[],[],[]
1756,Brendan Roof,brendanr@allenai.org,2020-01-27 13:31:22-08:00,4b08f3ecb8e35c05f17c82145ad05e2bd36844bd,https://github.com/allenai/allennlp/commit/4b08f3ecb8e35c05f17c82145ad05e2bd36844bd,Remove spurious part of condition (#3683),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1757,Will Frey,jfrey89@gmail.com,2020-01-28 12:32:24-05:00,540f7ec76cf17a1d87eb7de12f9b2598ca4a6a6e,https://github.com/allenai/allennlp/commit/540f7ec76cf17a1d87eb7de12f9b2598ca4a6a6e,"Fix AutoRegressiveSeqDecoder annotations and refactor to use get_token_ids_from_text_field_tensors (#3687)

*  Annotate target_tokens with TextFieldTensors

*  Use get_token_ids_from_text_field_tensors",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1758,Avinash Madasu,avinash.sai001@gmail.com,2020-01-28 23:14:57+05:18,f1402336455d21e15aec8635f0d44b3c36faad57,https://github.com/allenai/allennlp/commit/f1402336455d21e15aec8635f0d44b3c36faad57,Added SELU activation function (#3688),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1759,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-01-28 11:57:54-08:00,477eb9590e0110e643ebad3383052757ece01c9f,https://github.com/allenai/allennlp/commit/477eb9590e0110e643ebad3383052757ece01c9f,Coref reader test bug fix (#3689),1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['('],[],[],[],[],[],[],[],[],[],[],[],[],"['not ([], 1) in gold_mentions_with_ids']",[],[],[],[],[],[],[],[],[],[],[],[]
1760,Matt Gardner,mattg@allenai.org,2020-01-28 16:44:15-08:00,ea715d4d9fd1bb6a5b52b13c6ad0a8e450ff76a3,https://github.com/allenai/allennlp/commit/ea715d4d9fd1bb6a5b52b13c6ad0a8e450ff76a3,Add a Lazy[] annotation for simpler FromParams construction (#3627),27,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('Equal', '('), ('Equal', '(vocab.get_vocab_size(}))'), ('Equal', '('), ('Equal', '(vocab.get_vocab_size(}))')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['original_vocab.get_vocab_size() == 24', 'transferred_model.vocab.get_vocab_size() == 25', 'original_weight.shape[0] + 1 == extended_weight.shape[0] == 25', 'torch.all(original_weight == extended_weight[:24, :])', 'tuple(original_weight.shape) == (24, 300)', 'tuple(extended_weight.shape) == (25, 300)', 'torch.all(original_weight == extended_weight[:24, :])', 'original_weight.shape[0] + 1 == extended_weight.shape[0] == 25', 'torch.all(original_weight == extended_weight[:24, :])', 'torch.all(extended_weight[24, :] == extra_token_vector)', 'torch.all(extended_weight[24, :] != extra_token_vector)']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[]
1761,Santiago Castro,santi.1410@hotmail.com,2020-01-29 01:23:43-05:00,9799e48991dac848a8e3081e493199630e7e3112,https://github.com/allenai/allennlp/commit/9799e48991dac848a8e3081e493199630e7e3112,Add a plugin discovery mechanism (#3671),48,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,52,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,6,0,2,0,0,0,0,2,2,0,0,1,13,6,0,0,0,0,0,0,0,0,0,0,0,[],"[('SetEqual', '(set(), available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('In', '(, subcommands_available)'), ('In', '(, output)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '('), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '('), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('NotIn', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('NotIn', '(, subcommands_available)'), ('SetEqual', '({}, available_plugins)'), ('NotIn', '(, subcommands_available)'), ('In', '(, subcommands_available)')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['called', 'os.path.exists(self.outfile)', 'len(results) == 2', 'set(result.keys()) == {}', 'in str(exc.value)', 'in str(exc.value)', 'in str(exc.value)', 'duplicate_reader.__name__ == ', 'not in sys.modules', 'not in sys.modules', 'in sys.modules', 'in sys.modules', 'in sys.modules']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],"['()', '()']",[],[],[],[],"['skip()', 'skip()']","['mark.skip()', 'mark.skip()']",[],[],['import pytest'],"['fake_evaluate.add_subparser_called', 'os.path.exists(self.outfile)', 'len(results) == 2', 'set(result.keys()) == {}', 'in str(exc.value)', 'in str(exc.value)', 'in str(exc.value)', 'duplicate_reader.__name__ == ', 'not in sys.modules', 'not in sys.modules', 'in sys.modules', 'in sys.modules', 'in sys.modules']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[]
1762,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-01-29 19:49:57+00:00,da1553fb5b8d7ca073be3ed22d6dcc2cecfa28b7,https://github.com/allenai/allennlp/commit/da1553fb5b8d7ca073be3ed22d6dcc2cecfa28b7,Bump pre-commit from 1.21.0 to 2.0.0 (#3692),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1763,Matt Gardner,mattg@allenai.org,2020-01-29 15:14:05-08:00,f44d3dbdbe77e93476192fa74aae651449e4e4ad,https://github.com/allenai/allennlp/commit/f44d3dbdbe77e93476192fa74aae651449e4e4ad,Fix handling of TokenCharactersIndexer in Hotflip (#3695),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['attack is not None', 'in attack', 'in attack', 'in attack', 'len(attack[][0]) == len(']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1764,Brendan Roof,brendanr@allenai.org,2020-01-29 17:20:13-08:00,d23c0cdd7412e4dfe1b88343fef29645728bcaa4,https://github.com/allenai/allennlp/commit/d23c0cdd7412e4dfe1b88343fef29645728bcaa4,More fixes for training the LM in the distributed setting (#3691),6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(all_instances) == 100 * 4', 'len(counts) == 4', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100']",[],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1765,Brendan Roof,brendanr@allenai.org,2020-01-29 18:19:55-08:00,a5876250c0b24ba7e8a77cfc24ed7097c13389e5,https://github.com/allenai/allennlp/commit/a5876250c0b24ba7e8a77cfc24ed7097c13389e5,"Revert ""More fixes for training the LM in the distributed setting (#3691)"" (#3696)

- This broke the GPU unit tests.
  - http://build.allennlp.org/viewLog.html?buildId=25064&buildTypeId=AllenNLP_GpuUnitTests&tab=buildLog&_focus=439
- Reverts commit d23c0cdd7412e4dfe1b88343fef29645728bcaa4.",6,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(all_instances) == 100 * 4', 'len(counts) == 4', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100']",[],[],[],[],[],[],[],[],[],[],[],['import pytest']
1766,Santiago Castro,sacastro@umich.edu,2020-01-30 11:16:43-05:00,d52b56002ca12c32d61587961164285a1e3f58d3,https://github.com/allenai/allennlp/commit/d52b56002ca12c32d61587961164285a1e3f58d3,Check for exceptions when importing plugins (#3693),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1767,Brendan Roof,brendanr@allenai.org,2020-01-30 11:05:06-08:00,5421a4deb27097bbd57791e050a3d47fcf0a402a,https://github.com/allenai/allennlp/commit/5421a4deb27097bbd57791e050a3d47fcf0a402a,Roll forward PR #3691 (#3697),6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(all_instances) == 100 * 4', 'len(counts) == 4', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100']",[],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1768,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-01-30 11:18:39-08:00,60f0529dd2ca13747710d2ce233e73ae4b831c90,https://github.com/allenai/allennlp/commit/60f0529dd2ca13747710d2ce233e73ae4b831c90,Add label distribution logic to coref (#3684),10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 4', 'len(instances) == 4', 'text == [', 'all(span_start > 0 for span_start in span_starts)', 'all(span_end < len(text) - 1 for span_end in span_ends)', '([], 0) in gold_mentions_with_ids', '([], 0) not in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', 'len(documents) == 4', 'tokenizer._determine_num_special_tokens_added() == (1, 1)']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'len(documents) == 2', 'PretrainedTransformerIndexer.determine_num_special_tokens_added(tokenizer) == (1, 1)']",[],[],[],[],[],[],[],[],[],[],[],[]
1769,Dirk Groeneveld,dirkg@allenai.org,2020-01-30 16:54:23-08:00,5fc0414b444c19048d05413631aff5d0651b1d26,https://github.com/allenai/allennlp/commit/5fc0414b444c19048d05413631aff5d0651b1d26,"Adds a utility function to open potentially compressed files (#3701)

* Adds a utility function to open potentially compressed files

* Make mypy happy

* Adds ability to open path objects

* Test for open_compressed

* Productivity through formatting",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['compressed_lines == uncompressed_lines'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1770,Brendan Roof,brendanr@allenai.org,2020-01-31 14:19:27-08:00,953267105e0b5a271d4dae3dfef756c4f4b55693,https://github.com/allenai/allennlp/commit/953267105e0b5a271d4dae3dfef756c4f4b55693,Fix typo in elmo.py (#3704),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1771,Mark Neumann,markn@allenai.org,2020-01-31 15:13:06-08:00,27a6e6be8644c164cbde517f531a19b60acfe751,https://github.com/allenai/allennlp/commit/27a6e6be8644c164cbde517f531a19b60acfe751,update tutorial readme to reflect new docs (#3681),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1772,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-01-31 16:25:52-08:00,c6147ad3126be083f40a12ce7888042d3d83fca6,https://github.com/allenai/allennlp/commit/c6147ad3126be083f40a12ce7888042d3d83fca6,Support tokenizer_kwargs and fix lowercasing determination heuristics (#3703),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['forced_lowercase_tokenizer._tokenizer_lowercases', 'tokenized == lowercase_tokens', 'not tokenizer._tokenizer_lowercases', 'tokenized == original_tokens']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1773,Mark Neumann,markn@allenai.org,2020-02-03 09:49:03-08:00,3fffc33c02a7a5b1308f1a87ac8778650d2e6458,https://github.com/allenai/allennlp/commit/3fffc33c02a7a5b1308f1a87ac8778650d2e6458,"remove generated mkdocs (#3680)

Co-authored-by: Brendan Roof <brendanr@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1774,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-02-03 09:49:29-08:00,2b9f53dfaa13ea9ff1bbe914f2695759429dce11,https://github.com/allenai/allennlp/commit/2b9f53dfaa13ea9ff1bbe914f2695759429dce11,"Bump pre-commit from 2.0.0 to 2.0.1 (#3699)

Bumps [pre-commit](https://github.com/pre-commit/pre-commit) from 2.0.0 to 2.0.1.
- [Release notes](https://github.com/pre-commit/pre-commit/releases)
- [Changelog](https://github.com/pre-commit/pre-commit/blob/master/CHANGELOG.md)
- [Commits](https://github.com/pre-commit/pre-commit/compare/v2.0.0...v2.0.1)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: Brendan Roof <brendanr@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1775,Dirk Groeneveld,dirkg@allenai.org,2020-02-03 10:35:54-08:00,9f238b9996bcb569e58f143f779faab8cd09b971,https://github.com/allenai/allennlp/commit/9f238b9996bcb569e58f143f779faab8cd09b971,"Workaround for DistilBERT being weird (#3710)

* Workaround for DistilBERT being weird

* Grammar

* Re-jigger the checks so they don't run all the time",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1776,Matt Gardner,mattg@allenai.org,2020-02-03 12:46:47-08:00,700abc65fd2172a2c6809dd9b72cf50fc2407772,https://github.com/allenai/allennlp/commit/700abc65fd2172a2c6809dd9b72cf50fc2407772,"Remove RegularizerApplicator.from_params, move models to **kwargs (#3705)

* Remove RegularizerApplicator.from_params, move models to **kwargs

* Initial tests passing

* Actually remove method I cut out

* minor stuff, black

* fix bug

* fix more bugs

* fix fixture configs

* more bug fixes

* better parameter inference for kwargs

* Fix formatting errors

* more bugs

* flake, mypy

* black

* Tests for #3653
* Test if FromParams can handle deeper kwarg param type inference
* Test if FromParams infers params types only for unknown ones

* black

* black caused a flake8 error?

* Added some more comments

Co-authored-by: Karen Hambardzumyan <mahnerak@gmail.com>",32,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['instance.x == 42', 'instance.a == -1', 'len(instance.rest) == 1', 'type(instance.rest[]) == str', 'instance.rest[', 'instance.a == ', 'instance.b == ', 'instance.c == ']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1777,Michael Schmitz,MichaelS@allenai.org,2020-02-03 16:07:48-08:00,248ad3fed7a7a2cf7bfb27c0518ce7ca3751dd16,https://github.com/allenai/allennlp/commit/248ad3fed7a7a2cf7bfb27c0518ce7ca3751dd16,"Configure Bulldozer to update PRs when tagged with 'Update Me'. (#3717)

* Configure Bulldozer to update PRs when tagged with 'Update Me'.

* Add merge when ready to update section.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1778,Mark Neumann,markn@allenai.org,2020-02-03 16:53:57-08:00,03a566b0c45fdc4a111646f4f8eba1833f3e255c,https://github.com/allenai/allennlp/commit/03a566b0c45fdc4a111646f4f8eba1833f3e255c,"recursively sort docs (#3714)

Co-authored-by: Michael Schmitz <michael@schmitztech.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1779,Mark Neumann,markn@allenai.org,2020-02-04 14:06:43-08:00,3c3349eb7eb720d3b9cbcfabb86d15d29be49702,https://github.com/allenai/allennlp/commit/3c3349eb7eb720d3b9cbcfabb86d15d29be49702,update docs for common (#3723),6,False,True,True,True,True,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1780,Dirk Groeneveld,dirkg@allenai.org,2020-02-04 14:50:54-08:00,931a12f572c143c23c24b9dde59bc7c48b1bd876,https://github.com/allenai/allennlp/commit/931a12f572c143c23c24b9dde59bc7c48b1bd876,New transformers version (#3725),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1781,Mark Neumann,markn@allenai.org,2020-02-04 15:17:45-08:00,c188d0b4ac19f90a1d18ba7f57864111867f3c08,https://github.com/allenai/allennlp/commit/c188d0b4ac19f90a1d18ba7f57864111867f3c08,update more docs (#3724),6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1782,Michael Schmitz,MichaelS@allenai.org,2020-02-04 15:56:42-08:00,4c663bbc675e773440be9356dfbadf441d19ab70,https://github.com/allenai/allennlp/commit/4c663bbc675e773440be9356dfbadf441d19ab70,Update .bulldozer.yml (#3727),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1783,Mark Neumann,markn@allenai.org,2020-02-04 18:43:32-08:00,bae0c55e8c447811d9fa13f1c48f3e2576ab0dcc,https://github.com/allenai/allennlp/commit/bae0c55e8c447811d9fa13f1c48f3e2576ab0dcc,update docs for nn (#3726),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1784,zulushakaka,chenxianyang.tom@gmail.com,2020-02-05 09:32:01-05:00,beb07be50a8c0267b1ff398793ecde1194a538fe,https://github.com/allenai/allennlp/commit/beb07be50a8c0267b1ff398793ecde1194a538fe,"fix MultiLabelField (#3722)

* fix MultiLabelField

* reformat with black & fixes #3721

Co-authored-by: XyCheN-ets <58861903+XyCheN-ets@users.noreply.github.com>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1785,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-02-05 18:26:47+00:00,235c45ec9f0e44500f4c9bafc39346712336c189,https://github.com/allenai/allennlp/commit/235c45ec9f0e44500f4c9bafc39346712336c189,Bump conllu from 2.2.1 to 2.2.2 (#3730),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1786,Guo Quan,guoquanscu@gmail.com,2020-02-05 14:06:10-05:00,82b36957ca8305704d092460f583c7e53871faa6,https://github.com/allenai/allennlp/commit/82b36957ca8305704d092460f583c7e53871faa6,Update gpu_memory_mb() not to log at error level (#3729),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1787,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-05 11:24:52-08:00,95650acb46c034f7d963af966f987899bcbde5a1,https://github.com/allenai/allennlp/commit/95650acb46c034f7d963af966f987899bcbde5a1,Add coref + bert training config (#3728),3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1788,Matt Gardner,mattg@allenai.org,2020-02-06 09:06:37-08:00,a5bd0557c677364ab7a29e3ce8ab0ffd71eaefa9,https://github.com/allenai/allennlp/commit/a5bd0557c677364ab7a29e3ce8ab0ffd71eaefa9,"Removing more custom from_params methods (#3735)

* Removing more custom from_params methods

* update basic classifier fixture

* remove now-unnecessary test file

* update event2mind model fixture

* fix momentum tests

* flake",16,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(tokenizer, SpacyTokenizer)', 'tokenizer._start_tokens == params[]', 'tokenizer._end_tokens == params[]', 'in tokenizer.spacy.pipe_names', 'isinstance(tokenizer, SpacyTokenizer)', 'isinstance(tokenizer, WhitespaceTokenizer)', 'isinstance(tokenizer, SpacyTokenizer)']",[],[],[],[],[],[],[],[],[],[],[],[]
1789,Matt Gardner,mattg@allenai.org,2020-02-06 10:58:46-08:00,59b70108ec2bab36837563d9c31a44616a1d9c90,https://github.com/allenai/allennlp/commit/59b70108ec2bab36837563d9c31a44616a1d9c90,"Removed LearningRateScheduler.from_params (#3734)

* Removed LearningRateScheduler.from_params

* mypy, flake, black

* fixed some failing tests

* fix more tests

* remove registry test

* black

* Make config params always take precedence over **extras

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",12,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,2,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError):')]",[],[],[],[],[],[],[],[],[],[],"[('Raises', '(TypeError):'), ('Raises', '(TypeError):')]",[],[],[],[],[],[],[],[],[],"['isinstance(trainer._learning_rate_scheduler, SlantedTriangular)', 'trainer._learning_rate_scheduler.num_epochs == 5', 'trainer._learning_rate_scheduler.num_steps_per_epoch == 4', 'trainer._learning_rate_scheduler.num_epochs == 3']",[],[],[],[],[],[],[],[],[],[],[],[],['LearningRateScheduler.by_name(key) == value'],[],[],[],[],[],[],[],[],[],[],[],[]
1790,Matt Gardner,mattg@allenai.org,2020-02-06 13:00:48-08:00,8e3c612815cb03dfaf4f17f9ce79fcfe03088e30,https://github.com/allenai/allennlp/commit/8e3c612815cb03dfaf4f17f9ce79fcfe03088e30,"Removing custom from_params from initializers (#3739)

* Remove custom from_params from initializers

* retrain esim fixtures

* remove old registry tests

* fix failing test

* mypy, flake",13,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['Initializer.by_name(key)()._init_function == value'],[],[],[],[],[],[],[],[],[],[],[],[]
1791,Matt Gardner,mattg@allenai.org,2020-02-06 14:45:36-08:00,04323d762a0f44fc49026fa8f53f2a6a0bdd1085,https://github.com/allenai/allennlp/commit/04323d762a0f44fc49026fa8f53f2a6a0bdd1085,"Removing custom from_params methods from seq2{seq,vec} encoders (#3740)

* Removed custom from_params from seq2{seq,vec} classes

* black

* flake, mypy

* fix typo...

* bias should default to true

* remove old registry tests

* fix another couple of tests",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['encoder.__class__.__name__ == ', 'encoder.__class__.__name__ == ']",[],[],[],[],[],[],[],[],[],[],[],[],"['Seq2SeqEncoder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2SeqEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'Seq2VecEncoder.by_name(', 'encoder.__class__.__name__ == ', 'encoder.__class__.__name__ == ']",[],[],[],[],[],[],[],[],[],[],[],[]
1792,Dirk Groeneveld,dirkg@allenai.org,2020-02-06 15:33:32-08:00,1c65070ace204462eb4db08588e65ed94d6451b3,https://github.com/allenai/allennlp/commit/1c65070ace204462eb4db08588e65ed94d6451b3,max_instances for DatasetReader (#3736),2,True,True,False,False,False,True,True,False,False,True,False,False,False,False,True,"['fixture_migration', 'adds_parametrized_test']",0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,3,0,0,0,0,1,0,2,2,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],"['instance_count == 2', 'instance_count > 2', 'instance_count == 2']",[],[],[],[],['(autouse=True)'],[],"['(, (True, False))', '(, (True, False))']","['parametrize(, (True, False))', 'parametrize(, (True, False))']","['fixture(autouse=True)', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1793,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-07 10:56:03-08:00,afbdd93a381f154c03ad5e6a39aac8137b08916f,https://github.com/allenai/allennlp/commit/afbdd93a381f154c03ad5e6a39aac8137b08916f,"Support sequence pair for some functions in PretrainedTransformerTokenizer (#3741)

* Support sequence pair for intra_word_tokenize and _determine_num_special_tokens_added

* mypy

* Refactor

* Break intra_word_tokenize() into two functions

* mypy",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == expected_tokens', 'offsets == expected_offsets', 'tokens == expected_tokens', 'offsets_a == expected_offsets_a', 'offsets_b == expected_offsets_b', 'tokenizer._determine_num_special_tokens_added() == (1, 1, 1)', 'tokenizer._determine_num_special_tokens_added() == (0, 1, 2)']",[],[],[],[],[],[],[],[],[],[],[],[],"['tokenizer._determine_num_special_tokens_added() == (1, 1)']",[],[],[],[],[],[],[],[],[],[],[],[]
1794,Akash S M,47632450+h3lio5@users.noreply.github.com,2020-02-08 04:13:49+05:18,ff3ed1c89ed10e55da5532ad3fcde9d89747d431,https://github.com/allenai/allennlp/commit/ff3ed1c89ed10e55da5532ad3fcde9d89747d431,Enable the PositionalEncoding class to be controlled by config.json. (#3737),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1795,Matt Gardner,mattg@allenai.org,2020-02-08 14:10:52-08:00,eb9abcf370fed33dc0e47b8420c2f5b96de0de70,https://github.com/allenai/allennlp/commit/eb9abcf370fed33dc0e47b8420c2f5b96de0de70,Removed custom Optimizer.from_params (#3743),6,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(TypeError)'],[],[],[],[],[],[],[],[],[],[],[]
1796,Matt Gardner,mattg@allenai.org,2020-02-09 16:09:44-08:00,c4559f3751775aa8bc018db417edc119d29d8051,https://github.com/allenai/allennlp/commit/c4559f3751775aa8bc018db417edc119d29d8051,"Removing fine-tune command by enabling train to handle fine tuning (#3747)

* Removing fine-tune command by enabling train to handle fine tuning

* black

* make test slightly less brittle",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('Raises', '(SystemExit) as context:'), ('Raises', '(SystemExit) as context:'), ('Raises', '(SystemExit) as context:')]",['def setUp(self):'],[],[],[],[],[],[],[],[],"['train_loop.model.vocab.get_vocab_size() > model.vocab.get_vocab_size()', 'vocab1.get_namespaces() == {}', 'vocab1._non_padded_namespaces == {}', 'vocab1.get_token_to_index_vocabulary() == {', 'vocab1.get_token_to_index_vocabulary() == {', 'vocab1.get_token_to_index_vocabulary() == {']",[],[],[],[],[],[],[],[],[],[],[],[],"['args.func == fine_tune_model_from_args', 'args.model_archive == self.model_archive', 'args.config_file == self.config_file', 'args.serialization_dir == self.serialization_dir', 'context.exception.code == 2  # argparse code for incorrect usage', 'context.exception.code == 2  # argparse code for incorrect usage', 'context.exception.code == 2  # argparse code for incorrect usage']",[],[],[],[],[],[],[],[],[],[],[],[]
1797,Matt Gardner,mattg@allenai.org,2020-02-09 20:13:04-08:00,60a822d7ac527632ee9cbb7c1f1dd427ac8bc84f,https://github.com/allenai/allennlp/commit/60a822d7ac527632ee9cbb7c1f1dd427ac8bc84f,"Removing old BERT files (#3746)

* Removed old bert files

* removing pretrained model caching

* fix bug

* black, flake",17,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,63,0,0,0,0,0,0,0,0,0,2,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],['def tearDown(self):'],[],[],[],[],[],[],"['list(pooled.size()) == [5, 7]']",[],[],[],[],[],[],[],[],[],[],[],[],"['indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [1, 2, 3, 4, 5, 6, 7, 10, 11, 12]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [1, 2, 3, 4, 5, 6, 7, 8, 11, 12]', 'indexer1 == indexer2', 'indexed_tokens[] == [16, 2, 1, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [16, 2, 3, 5, 6, 8, 9, 2, 15, 10, 11, 14, 1, 17]', 'indexed_tokens[] == [16, 2, 15, 10, 11, 6, 0, 17]', 'indexed_tokens[] == [16, 2, 15, 10, 11, 6, 1, 17]', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', '_get_token_type_ids(wordpiece_ids, separator_ids) == desired_token_type_ids', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]', 'indexed_tokens[] == [', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9, 10, 11]', 'indexed_tokens[] == [', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8, 9]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 3, 4, 17]', 'indexed_tokens[] == [1, 2, 4, 5, 6, 7, 8, 9, 10]', 'indexed_tokens[] == [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]', 'indexed_tokens[] == [16, 2, 3, 4, 3, 5, 6, 8, 9, 2, 3, 4, 17]', 'indexed_tokens[] == [1, 3, 4, 5, 6, 7, 8, 9, 11]', 'indexed_tokens == {', 'tokens == expected_tokens', 'tokens == expected_tokens', 'in decoded', 'model1 is model2', 'model3 is not model4', 'model5 is not model6', 'list(result.shape) == [2, 5, 12]', 'list(result.shape) == [2, 3, 12]', 'tokens[].tolist() == [', 'tokens[].tolist() == [', 'list(bert_vectors.shape) == [2, 14, 12]', 'list(bert_vectors.shape) == [2, 10, 12]', 'list(bert_vectors.shape) == [2, 14, 12]', 'list(bert_vectors.shape) == [2, 10, 12]', 'tokens[].tolist() == [[16, 2, 3, 5, 6, 8, 9, 2, 14, 12, 17]]', 'tokens[].tolist() == [[1, 2, 3, 4, 5, 6, 7, 8, 9]]', 'list(bert_vectors.shape) == [2, 2, 14, 12]', 'list(bert_vectors.shape) == [2, 2, 10, 12]', 'list(bert_vectors.shape) == [2, 2, 14, 12]', 'list(bert_vectors.shape) == [2, 2, 10, 12]', 'tokens[].tolist() == [', 'tokens[].tolist() == [[1, 3, 4, 5, 6, 7, 8, 9, 10, 11]]', 'list(bert_vectors.shape) == [1, 13, 12]', 'list(bert_vectors.shape) == [1, 10, 12]', 'list(bert_vectors.shape) == [1, 10, 12]', 'bert_vectors is not None', 'bert_vectors is not None']",[],[],[],[],[],[],[],[],[],"['setattr(BertModel, , lambda _: BertModel(config))', 'undo()']",[],[]
1798,Santiago Castro,santi.1410@hotmail.com,2020-02-09 23:54:21-05:00,745c144eedbb3c985a0448fd318c606c7decf38e,https://github.com/allenai/allennlp/commit/745c144eedbb3c985a0448fd318c606c7decf38e,"Remove unused args from fine-tune (#3750)

* Remove unused args from fine-tune

* Fix an occurrence of 'fine-tune'",3,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not parameter.requires_grad', 'parameter.requires_grad == name_parameters_original[name].requires_grad']",['(Exception)'],[],[],[],[],[],[],[],[],[],[],[]
1799,Justin DuJardin,justindujardin@users.noreply.github.com,2020-02-10 09:49:05-08:00,939a7a05a52a350ef20c2d729fa474000d121d41,https://github.com/allenai/allennlp/commit/939a7a05a52a350ef20c2d729fa474000d121d41,"Use mathy_pydoc for better docs type formatting (#3748)

- it's a stripped down version of the official pydoc-markdown library, but I only needed part of its functionality. It looks like AllenNLP uses a mathy-like API docs build script (:heart:) so it was an easy drop-in to fix your type printing woes.
  - fixes #3731, #3738

Co-authored-by: Mark Neumann <markn@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1800,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-02-10 18:06:54+00:00,f41c78f6ce23ab8b31986d432cb69fda159cb7e1,https://github.com/allenai/allennlp/commit/f41c78f6ce23ab8b31986d432cb69fda159cb7e1,Bump mkdocs-material from 4.6.0 to 4.6.2 (#3754),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1801,Santiago Castro,sacastro@umich.edu,2020-02-10 14:48:49-05:00,c215525c543cba0014d3c08bae78567ff81e6d4c,https://github.com/allenai/allennlp/commit/c215525c543cba0014d3c08bae78567ff81e6d4c,Remove default None in dict get calls (#3755),6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1802,Santiago Castro,sacastro@umich.edu,2020-02-10 15:13:46-05:00,fdc472577588af93b850fb0a0d114da931a49df8,https://github.com/allenai/allennlp/commit/fdc472577588af93b850fb0a0d114da931a49df8,"Remove unnecessary list creations (#3752)

* Remove unnecessary list creations

* Fix PR comments

* Fix tests

* Fix a PR comment

* Fix typing and py2 usage in conll script

* Fix a PR comment

* Fix a PR comment",28,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['all(x.b == y for x, y in zip(d.arg1, vals))', 'all(x.a == tval1 for x in d.arg1)', 'all(self.span_width >= len(x) > 0 for x in candidate_mentions)', 'all(self.span_width >= len(x) > 0 for x in candidate_mentions)', 'all(grad is not None for grad in elmo_grads)', 'all(grad is None for grad in elmo_grads)']",[],[],[],[],[],[],[],[],[],[],[],[],"['all([x.b == y for x, y in zip(d.arg1, vals)])', 'all([x.a == tval1 for x in d.arg1])', 'all([self.span_width >= len(x) > 0 for x in candidate_mentions])', 'all([self.span_width >= len(x) > 0 for x in candidate_mentions])', 'all([grad is not None for grad in elmo_grads])', 'all([grad is None for grad in elmo_grads])']",[],[],[],[],[],[],[],[],[],[],[],[]
1803,Santiago Castro,sacastro@umich.edu,2020-02-11 10:27:34-05:00,ddb886b889232b9c28ee9389039067d6af6fa5c6,https://github.com/allenai/allennlp/commit/ddb886b889232b9c28ee9389039067d6af6fa5c6,Remove unused variable recover (#3759),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1804,Santiago Castro,sacastro@umich.edu,2020-02-11 10:56:32-05:00,5434a720f7f5dc1e21fb952c12d73c7ac602a6dc,https://github.com/allenai/allennlp/commit/5434a720f7f5dc1e21fb952c12d73c7ac602a6dc,Add missing plugin import in distributed training (#3760),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1805,Brendan Roof,brendanr@allenai.org,2020-02-11 08:59:25-08:00,5fc3719f26d836de33ca91262988a7240afbbc76,https://github.com/allenai/allennlp/commit/5fc3719f26d836de33ca91262988a7240afbbc76,Fix `allennlp test-install` (#3708),1,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['if(not is_matplotlib_installed(), reason=)']",[],[],[],[],"['skipif(not is_matplotlib_installed(), reason=)']","['mark.skipif(not is_matplotlib_installed(), reason=)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1806,Mark Neumann,markn@allenai.org,2020-02-11 12:01:05-08:00,ac19db22a18baf6ca82254481271c4dd2024d31a,https://github.com/allenai/allennlp/commit/ac19db22a18baf6ca82254481271c4dd2024d31a,"less verbose pytest, summary of failed tests at end of report (#3764)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1807,Dirk Groeneveld,dirkg@allenai.org,2020-02-11 16:57:17-08:00,49e8be84645bc61ec97ee990f70687630d61adb5,https://github.com/allenai/allennlp/commit/49e8be84645bc61ec97ee990f70687630d61adb5,Adds defaults to the elmo token embedder (#3766),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1808,Santiago Castro,sacastro@umich.edu,2020-02-12 10:14:10-05:00,c64fb9d54ebf595e3ce859ed715007d52c2c6abf,https://github.com/allenai/allennlp/commit/c64fb9d54ebf595e3ce859ed715007d52c2c6abf,"Remove unnecessary flake8 exceptions (#3762)

* Remove unnecessary flake8 exceptions

* Fix missing import

* Fix a PR comment",47,False,True,True,True,True,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,3,2,0,0,0,0,0,0,0,0,0,0,0,7,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab1.get_token_to_index_vocabulary(: 2}', 'vocab1.get_token_to_index_vocabulary(: 2}']",[],[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest', 'import pytest']","['vocab1.get_token_to_index_vocabulary() == {', 'vocab1.get_token_to_index_vocabulary() == {']",[],[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest']"
1809,Mark Neumann,markn@allenai.org,2020-02-12 10:42:51-08:00,200948d804dcdb1e5c2bc4b5846dd8aff2e73953,https://github.com/allenai/allennlp/commit/200948d804dcdb1e5c2bc4b5846dd8aff2e73953,"test out github actions for automated nightly releases (#3765)

* Create nightly.yml

* check diff from 24 hr ago, use environment for version.py

* get things, not call

* add 24 hr diff script

* typo

* add dev, check for tests to pass

* santiago's suggested change

Co-Authored-By: Santiago Castro <sacastro@umich.edu>

* fix flake from #3762

* change time to 11

Co-authored-by: Santiago Castro <bryant@montevideo.com.uy>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1810,Brendan Roof,brendanr@allenai.org,2020-02-12 15:03:03-08:00,1a8a12cd1b065d74fec3d2e80105a684736ff709,https://github.com/allenai/allennlp/commit/1a8a12cd1b065d74fec3d2e80105a684736ff709,"Add date to the nightly build. (#3768)

- Adds a test to ensure we're compatible with semantic versioning.",4,False,True,True,True,False,True,False,False,False,False,False,False,False,False,False,[],1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,['class TestVersion(TestCase):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['version.prerelease == (,)', 'version.build == ()', 'version.prerelease == ()', 'version.build == ()', 'version.prerelease == (,)', 'version.build == (,)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1811,Mark Neumann,markn@allenai.org,2020-02-13 10:03:39-08:00,900d2737fd59083eec90d9c1eeb03e33faee44c3,https://github.com/allenai/allennlp/commit/900d2737fd59083eec90d9c1eeb03e33faee44c3,add missing dependencies for build (#3775),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1812,Santiago Castro,sacastro@umich.edu,2020-02-13 16:16:05-05:00,ee7e248b3e5849f07e2121d5521cad58cb318347,https://github.com/allenai/allennlp/commit/ee7e248b3e5849f07e2121d5521cad58cb318347,Remove occurrences of 'pylint' (#3776),6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1813,Santiago Castro,sacastro@umich.edu,2020-02-13 17:19:20-05:00,f4284dca4932d5623e36c5ffe3462104a370fe7d,https://github.com/allenai/allennlp/commit/f4284dca4932d5623e36c5ffe3462104a370fe7d,Update STYLE.md to match current approach (#3777),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1814,Vinit Ravishankar,vinit.ravishankar@gmail.com,2020-02-14 15:03:01+01:00,0158253142430b78701b1825c99ece36bc1b8e31,https://github.com/allenai/allennlp/commit/0158253142430b78701b1825c99ece36bc1b8e31,"Add util to extend layer sizes (#3774)

* extend layers

* test, fixes, etc.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['lin_layer.weight.data.shape == (8, 10)', 'lin_layer.bias.data.shape == (8,)', '(lin_layer.weight.data[:5] == old_weights).all()', '(lin_layer.bias.data[:5] == old_bias).all()', 'lin_layer.out_features == new_dim']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1815,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-02-14 19:43:49+00:00,6018f25d2dc5dc75c24476ef1358ae38dd698ec9,https://github.com/allenai/allennlp/commit/6018f25d2dc5dc75c24476ef1358ae38dd698ec9,Bump mkdocs-material from 4.6.2 to 4.6.3 (#3782),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1816,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-14 12:05:21-08:00,e20848b4fed286414c0f4ff66fba52ca715754cb,https://github.com/allenai/allennlp/commit/e20848b4fed286414c0f4ff66fba52ca715754cb,"Change ClsPooler to be compatible with cls-final models (#3780)

* Change ClsPooler to be compatible with cls-final models

* black

* flake

* Use exising util function to get last token embeddings",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(pooled.size()) == [5, 7]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1817,Dirk Groeneveld,dirkg@allenai.org,2020-02-14 12:51:44-08:00,28028a0544632307fe48e66a15a4b2a22c3dddda,https://github.com/allenai/allennlp/commit/28028a0544632307fe48e66a15a4b2a22c3dddda,"More restrictive argument parsing (#3778)

* More restrictive argument parsing

* Allow paths in strings

* Fix test that uses strings as learning rates

* Don't cast ints to float, just leave them be

* Test for the new union behavior

* Test the actual new checks

* Productivity through formatting

* Remove outdated comment

* Remove whole test because it doesn't make sense anymore",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['type(c.a) == expected_type'],"['(TypeError)', '(TypeError)']",[],[],[],[],[],[],[],[],[],[],[],['optimizer.defaults[] == 0.1'],[],[],[],[],[],[],[],[],[],[],[],[]
1818,Dirk Groeneveld,dirkg@allenai.org,2020-02-14 14:53:20-08:00,320243ee8feebcbe9c63f86075e5864461bc1659,https://github.com/allenai/allennlp/commit/320243ee8feebcbe9c63f86075e5864461bc1659,"Moving the Quarel configs (#3771)

* Removes the quarel configs

* More restrictive argument parsing

* Make mypy happy",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1819,Brendan Roof,brendanr@allenai.org,2020-02-14 15:56:10-08:00,73bc922ad7a1d2265f84e4f15e15d9fc3345ecee,https://github.com/allenai/allennlp/commit/73bc922ad7a1d2265f84e4f15e15d9fc3345ecee,"Fix hang, make sharded reader rank aware (#3781)

- Previously imbalanced data would lead to workers hanging.
- I fixed this by adding code to detect this and stop the workers with excess data. This doesn't seem ideal, but I'm not sure of cleaner fix.
  - A user can mitigate this by ensuring that the number of shards is divisible by the number of workers. If the shards are also equally sized then no (or little -- depending on your batching mechanism) data will be lost.
- Makes the `ShardedDatasetReader` return data based on its rank.",7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'archive.model', 'tokens == {', 'train_early in worker0_log', 'validation_early in worker0_log', 'train_complete not in worker0_log', 'validation_complete not in worker0_log', 'train_early not in worker1_log', 'validation_early not in worker1_log', 'train_complete in worker1_log', 'validation_complete in worker1_log']",[],[],"['if(torch.cuda.device_count() < 2, reason=)']",[],[],[],[],"['skipif(torch.cuda.device_count() < 2, reason=)']","['mark.skipif(torch.cuda.device_count() < 2, reason=)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1820,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-14 17:53:51-08:00,3f15a8bdcae366f3ef732eec1e9df26d91521582,https://github.com/allenai/allennlp/commit/3f15a8bdcae366f3ef732eec1e9df26d91521582,Fixes contiguous whitespaces causing coref model to produce bad results (#3786),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1821,Mark Neumann,markn@allenai.org,2020-02-15 16:48:10-08:00,15613e863ae356901d20d25be65216d9bf51b0ec,https://github.com/allenai/allennlp/commit/15613e863ae356901d20d25be65216d9bf51b0ec,"more fixes to the nightly deploy (#3784)

* more fixes to the nightly deploy

* spelling

* correct yaml",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1822,Santiago Castro,sacastro@umich.edu,2020-02-17 10:41:23-05:00,c231f02e5ae7d81a9aadcd92eae3ac82c95ae801,https://github.com/allenai/allennlp/commit/c231f02e5ae7d81a9aadcd92eae3ac82c95ae801,Fix the nightly build version number (#3789),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1823,Santiago Castro,sacastro@umich.edu,2020-02-17 12:20:18-05:00,8c2c5903e7f1bbd4bb8391393fec698d0e119dfe,https://github.com/allenai/allennlp/commit/8c2c5903e7f1bbd4bb8391393fec698d0e119dfe,"Remove dry-run command (#3751)

* Refactor out duplicate code

* Remove dry-run

* Add missing print of stats

* Avoid archiving the model

* Fix PR comments and checks

* Remove double backticks

* Fix missing import

* Update command output in README

* flake8

* Fix a PR comment

* Revert ""flake8""

This reverts commit fc204598a3ced17f574f5faa2b2f6bfc3490519a.

* flake8

Co-authored-by: Mark Neumann <markn@allenai.org>",10,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,17,1,0,0,0,0,0,0,0,0,0,0,0,16,1,0,0,0,0,0,0,0,0,0,0,1,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],"['set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'tokens == [', 'labels == []', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'len(tokens) == 3', 'args.func == train_model_from_args', 'args.param_path == ', 'args.serialization_dir == ', 'args.dry_run']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],"['set(vocab_files) == {}', 'tokens == []', 'labels == []', 'set(vocab_files) == {}', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'tokens == [', 'labels == []', 'tokens[0] == ', 'tokens[1] == ', 'tokens[2] == ', 'len(tokens) == 3', 'args.func == dry_run_from_args', 'args.param_path == ', 'args.serialization_dir == ']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest']
1824,Bruno Cabral,brataodream@gmail.com,2020-02-17 15:39:36-03:00,8532dc5d906e29e055f36b7d76ec0a84453181f6,https://github.com/allenai/allennlp/commit/8532dc5d906e29e055f36b7d76ec0a84453181f6,"Enable other features in Token (#3769)

* Enable Other features in token

* Use dataclass for token. Enable the use for extended features in the SingleIdTokenIndexer

* dataclass do not have _replace. It is mutable

* Run black

* Add docstring, run black with the right version

* Run black",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['counter[: 1}'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1825,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-17 16:02:12-08:00,ca0e3c733ec495e3823b866d2cb0f0178b0a44f5,https://github.com/allenai/allennlp/commit/ca0e3c733ec495e3823b866d2cb0f0178b0a44f5,"Add RoBERTa SST model, 95.64 dev 95.11 test (#3796)",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1826,Mark Neumann,markn@allenai.org,2020-02-17 17:05:02-08:00,1e923fd19c8eda2719c150e9716eeb1374a049bb,https://github.com/allenai/allennlp/commit/1e923fd19c8eda2719c150e9716eeb1374a049bb,"Embedding api (#3763)

* test for constructing embedding directly

* rework embedding to work via direct construction

* update docs

* explicit None comparison

* grammar

* remove custom from params from Embedding

* Revert ""remove custom from params from Embedding""

This reverts commit 276d8c1a2f48ad1fcee557b90e67818e6d9d61f3.",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['numpy.allclose(word_vector.numpy(), numpy.array([1.0, 2.3, -1.0]))', 'numpy.allclose(word_vector.numpy(), numpy.array([3.4, 3.3, 5.0]))', 'not numpy.allclose(word_vector.numpy(), numpy.array([1.0, 2.3, -1.0]))']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1827,Santiago Castro,sacastro@umich.edu,2020-02-18 10:57:46-05:00,ba67cb36cde2f9452157a2e0cf2bd17c7d0300ad,https://github.com/allenai/allennlp/commit/ba67cb36cde2f9452157a2e0cf2bd17c7d0300ad,Remove some unused imports (#3801),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1828,Santiago Castro,sacastro@umich.edu,2020-02-18 11:02:53-05:00,ccd2d5ac5b6d42224f45e58f18fe1cf02d839ae9,https://github.com/allenai/allennlp/commit/ccd2d5ac5b6d42224f45e58f18fe1cf02d839ae9,Exclude .DS_Store files from the Pip package (#3800),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1829,Santiago Castro,sacastro@umich.edu,2020-02-18 12:00:28-05:00,a9606418d65548be911a24f0b93899b10f119103,https://github.com/allenai/allennlp/commit/a9606418d65548be911a24f0b93899b10f119103,Remove unused old BERT test files and references (#3799),4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1830,Mark Neumann,markn@allenai.org,2020-02-18 09:21:16-08:00,b134ba2d85fa8d4e04e5cfee4bf7838c7037b662,https://github.com/allenai/allennlp/commit/b134ba2d85fa8d4e04e5cfee4bf7838c7037b662,separate repo doesn't work (#3804),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1831,Santiago Castro,sacastro@umich.edu,2020-02-18 12:40:18-05:00,e132333c36e4711a78514f564a27a24df72fa9a6,https://github.com/allenai/allennlp/commit/e132333c36e4711a78514f564a27a24df72fa9a6,Add support for previous pip versions (#3798),3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1832,Mark Neumann,markn@allenai.org,2020-02-18 13:44:57-08:00,c2d5704a78aa5be63f01981862762f6838c37d2a,https://github.com/allenai/allennlp/commit/c2d5704a78aa5be63f01981862762f6838c37d2a,add note to readme about nightly binaries (#3805),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1833,Dirk Groeneveld,dirkg@allenai.org,2020-02-18 15:32:42-08:00,17c2ff1ce2cb5e84ab9a0f524e6c01362c242cae,https://github.com/allenai/allennlp/commit/17c2ff1ce2cb5e84ab9a0f524e6c01362c242cae,Lets start_token and end_token be ints as well (#3806),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1834,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-02-19 08:02:13-08:00,5356062f57146a6bf1268b6c04f954e15b3a81b5,https://github.com/allenai/allennlp/commit/5356062f57146a6bf1268b6c04f954e15b3a81b5,"Bump pre-commit from 2.0.1 to 2.1.0 (#3809)

Bumps [pre-commit](https://github.com/pre-commit/pre-commit) from 2.0.1 to 2.1.0.
- [Release notes](https://github.com/pre-commit/pre-commit/releases)
- [Changelog](https://github.com/pre-commit/pre-commit/blob/master/CHANGELOG.md)
- [Commits](https://github.com/pre-commit/pre-commit/compare/v2.0.1...v2.1.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1835,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-19 10:50:57-08:00,dd4ee62cf55e5fe50c870152501f909203a6b1d7,https://github.com/allenai/allennlp/commit/dd4ee62cf55e5fe50c870152501f909203a6b1d7,"Add PreCo dataset reader (#3808)

* Add PreCo dataset reader

* black

* Pull out make_coref_instance method

* Better handle empty tokens and add test

* Add preco reader test

* mypy, flake8",9,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', 'text == [', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 2) in gold_mentions_with_ids', 'not any(_ for _, id_ in gold_mentions_with_ids if id_ == 2)', '([], 24) in gold_mentions_with_ids', '(', 'all(self.span_width >= len(x) > 0 for x in candidate_mentions)', 'tokens == expected_tokens', 'offsets == expected_offsets']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1836,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-19 13:07:08-08:00,e31cd671b81758a3e0985f7b5ccc9731c378725b,https://github.com/allenai/allennlp/commit/e31cd671b81758a3e0985f7b5ccc9731c378725b,Pin transformers < 2.5.0 (#3813),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1837,Matt Gardner,mattg@allenai.org,2020-02-19 16:07:06-08:00,9414f5293dd2664766a277d1081c7e4760840db2,https://github.com/allenai/allennlp/commit/9414f5293dd2664766a277d1081c7e4760840db2,Removing multi-lang code (#3818),28,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,38,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['tokens is not None', 'extra_arg is not None']",[],[],[],[],[],[],[],[],[],[],[],[],"['fields1[]', 'fields1[', '[t.text for t in fields1[].tokens] == [', 'fields1[].labels == [', 'fields1[].labels == [', 'fields1[].labels == [2, 4, 4, 0, 6, 4, 6, 9, 6, 4]', 'fields2[', '[t.text for t in fields2[].tokens] == [', 'fields2[].labels == [', 'fields2[].labels == [', 'fields2[].labels == [2, 6, 2, 6, 6, 0, 6, 7, 6]', '[t.text for t in fields1[].tokens] == [', 'fields1[].labels == [', 'fields1[].labels == [', 'fields1[].labels == [0, 1, 5, 5, 2, 9, 6, 6, 1, 12, 12, 9, 1]', '[t.text for t in fields2[].tokens] == [', 'fields2[].labels == [', 'fields2[].labels == [', 'fields2[].labels == [0, 3, 1, 3, 4, 5, 8, 9, 1, 11, 9, 1]', 'fields1[', '[t.text for t in fields1[].tokens] == [', 'fields1[]', 'fields1[]', 'fields1[].labels == [2, 0, 2, 5, 3, 2]', 'fields2[', '[t.text for t in fields2[].tokens] == [', 'fields2[].labels == [', 'fields2[].labels == [', 'fields2[].labels == [2, 4, 4, 0, 4, 5, 4, 9, 7, 4]', 'len(instances) == 6', 'in processed_langs', 'counter_es > 20 or counter_fr > 20 or counter_it > 20', 'len(batches) == 3', 'lang == batch_lang', 'np.count_nonzero(embedded_en) == 0', 'np.count_nonzero(embedded_fr) > 0', 'np.count_nonzero(embedded_en) == 0', 'np.count_nonzero(embedded_fr) > 0']",[],[],[],[],[],[],[],[],[],[],[],[]
1838,Matt Gardner,mattg@allenai.org,2020-02-19 16:17:47-08:00,bc356f29bb5825a08eff0d59f1aa8205166b5bd4,https://github.com/allenai/allennlp/commit/bc356f29bb5825a08eff0d59f1aa8205166b5bd4,"Removing event2mind model and data code (#3816)

* Removing event2mind model and data code

* remove test I missed",18,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,0,0,0,0,0,0,2,2,2,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 13', 'get_text(, instance) == [', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(, instance) == [', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(, instance) == [', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(, instance) == [', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(, instance) == [', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(, instance) == [', 'get_text(]', 'get_text(]', 'get_text(]', 'len(instances) == 17', 'get_text(, instance) == [', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(, instance) == [', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(]', 'get_text(, instance) == [', 'get_text(]', 'get_text(]', 'get_text(]', 'logits.size()[0] == 10', 'cur_logit <= prev_logit', 'beam_tokens == greedy_tokens', 'isinstance(predicted_tokens, list)', 'all(isinstance(x, str) for x in predicted_tokens)']",[],[],[],[],[],[],"['(, (True, False))', '(, (True, False))']","['parametrize(, (True, False))', 'parametrize(, (True, False))']","['mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))']",[],[],['import pytest']
1839,Matt Gardner,mattg@allenai.org,2020-02-19 17:00:54-08:00,4a0d007d5b5fb069bdcd6c66b1c05ea4518169ae,https://github.com/allenai/allennlp/commit/4a0d007d5b5fb069bdcd6c66b1c05ea4518169ae,"Remove embedding from params (#3815)

* Cherry-pick Mark's commit

* rename vocabulary to vocab

* fix coref model

* fix embedding tests

* Fix remaining calls to Embedding()

* flake",12,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['TokenEmbedder.by_name('],[],[],[],[],[],[],[],[],[],[],[],[],['TokenEmbedder.by_name('],[],[],[],[],[],[],[],[],[],[],[],[]
1840,Dirk Groeneveld,dirkg@allenai.org,2020-02-20 10:54:08-08:00,65ff0d87a30e6532cb21ea5fe8b7bd436445c128,https://github.com/allenai/allennlp/commit/65ff0d87a30e6532cb21ea5fe8b7bd436445c128,"Looks like the way to call tokens_to_indices changed (#3817)

* Looks like the way to call tokens_to_indices changed.

* Productivity through formatting",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1841,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-20 12:07:00-08:00,fa14bd8c177a12709a2fac0616eafaa9ad430b0a,https://github.com/allenai/allennlp/commit/fa14bd8c177a12709a2fac0616eafaa9ad430b0a,"Allow specifying max_sentences in coref readers (#3814)

* Allow specifying max_sentences in coref readers

* Add test

* black

* Add missing docstring

* random sample to truncation

* black

* flake8",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(limited_instances) == len(instances) == 4', 'limited_docs[1] == docs[1]', 'limited_docs[3] == docs[3]', 'len(limited_docs[0]) < len(docs[0])', 'len(limited_docs[2]) < len(docs[2])', 'not in text_of(limited_docs[0])', 'not in text_of(limited_docs[2])', 'limited_docs[0] == docs[0][: len(limited_docs[0])]', 'limited_docs[2] == docs[2][: len(limited_docs[2])]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1842,Mark Neumann,markn@allenai.org,2020-02-20 17:35:29-08:00,930c19f9e875f893814feff38901d9aee6e07485,https://github.com/allenai/allennlp/commit/930c19f9e875f893814feff38901d9aee6e07485,remove callback trainer (#3828),13,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,91,4,0,2,0,0,0,0,2,2,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], float)', 'in metrics', 'isinstance(metrics[], int)', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'len(responses.calls) == 1', 'responses.calls[0].response.request.body == b', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], int)', 'new_trainer.epoch_number == 1', 'tracker is not None', 'tracker.is_best_so_far()', 'tracker._best_so_far is not None', 'new_trainer.epoch_number == 1', 'tracker.is_best_so_far()', 'tracker._best_so_far is not None', 'metrics1.keys() == metrics2.keys()', 'metrics1.keys() == metrics2.keys()', 'new_tracker.is_best_so_far()', 'not new_tracker.is_best_so_far()', 'new_tracker.is_best_so_far()', 'not new_tracker.is_best_so_far()', 'new_tracker.is_best_so_far()', 'not new_tracker.is_best_so_far()', 'new_tracker.is_best_so_far()', 'new_tracker.should_stop_early()', 'not new_tracker.should_stop_early()', 'new_tracker.should_stop_early()', 'not new_tracker.should_stop_early()', 'new_tracker.should_stop_early()', 'not tracker.should_stop_early()', 'not tracker.should_stop_early()', 'new_trainer.epoch_number == 4', 'new_scheduler.last_epoch == 3', 'new_trainer.epoch_number == 2', 'new_lr_scheduler.lr_scheduler.last_epoch == 1', 'sorted(epochs) == [2, 3, 4]', 'epoch_file.exists()', 'in metrics', 'in metrics', 'metrics.get() == epoch', 'sorted(epochs) == [1, 3, 4, 5]', 'len(epochs) == 4', 'epochs[3] == ', 'in epochs[0]', 'restore_trainer.epoch_number == 2', 'restore_trainer.batch_num_total == 2', 'isinstance(best_validation_metrics_epoch_1, dict)', 'in best_validation_metrics_epoch_1', 'best_epoch_1 == 0 and best_epoch_2 == 1', 'best_validation_metrics_epoch_2 != best_validation_metrics_epoch_1', 'isinstance(best_validation_metrics_epoch_1, dict)', 'in best_validation_metrics_epoch_1', 'best_epoch_1 == best_epoch_2 == 0', 'best_validation_metrics_epoch_2 == best_validation_metrics_epoch_1', 'in restored_metrics', 'in restored_metrics', 'in restored_metrics', 'in restored_metrics', 'training_metrics[]', 'training_metrics[] == 0', 'training_metrics[]', 'error_test.exc is not None', 'error_test.exc.args == (,)', 'not error_test.finished_training']","['(ConfigurationError)', '(ConfigurationError)', '(RuntimeError)', '(RuntimeError)']",[],"['if(not torch.cuda.is_available(), reason=)', 'if(torch.cuda.device_count() < 2, reason=)']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)', 'skipif(torch.cuda.device_count() < 2, reason=)']","['mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.skipif(torch.cuda.device_count() < 2, reason=)']",[],[],['import pytest']
1843,Matt Gardner,mattg@allenai.org,2020-02-20 17:41:02-08:00,7fcab4e6c4f26369bfcde4c8b10f36bb831d8dd0,https://github.com/allenai/allennlp/commit/7fcab4e6c4f26369bfcde4c8b10f36bb831d8dd0,Renaming Model.decode to Model.make_output_human_readable (#3827),30,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1844,Santiago Castro,sacastro@umich.edu,2020-02-20 21:09:40-05:00,0cf98c27d7e6fd1244e7335115e3fc64c9d5850a,https://github.com/allenai/allennlp/commit/0cf98c27d7e6fd1244e7335115e3fc64c9d5850a,"Add support for weighted F1, Precision and Recall (#3807)",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1845,Matt Gardner,mattg@allenai.org,2020-02-21 13:18:35-08:00,4e94318a7e904ce91132516eb833a06aac94222e,https://github.com/allenai/allennlp/commit/4e94318a7e904ce91132516eb833a06aac94222e,"Allow multiple calls to Lazy.construct() (#3832)

* Allow multiple calls to Lazy.construct()

* use deepcopy instead of duplicate()",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['first_time.string == test_string', 'first_time.extra == extra_string', 'second_time.string == test_string', 'second_time.extra == extra_string']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1846,Santiago Castro,sacastro@umich.edu,2020-02-21 17:59:59-05:00,5daea1b7c1ad0a7704d3c14802866894edc2add0,https://github.com/allenai/allennlp/commit/5daea1b7c1ad0a7704d3c14802866894edc2add0,Rename run.py to __main__.py (#3830),7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(os.path.join(project_root, ))']",[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(os.path.join(project_root, ))']",[],[],[],[],[],[],[],[],[],[],[],[]
1847,Matt Gardner,mattg@allenai.org,2020-02-21 15:09:23-08:00,0b68e8e41d23b2fada2497102925809ede126602,https://github.com/allenai/allennlp/commit/0b68e8e41d23b2fada2497102925809ede126602,"Removing unnecessary indexers (#3826)

* Removing unnecessary indexers

* fix bug

* mypy, flake

* fix seq2seq fixtures

* revert unintentional changes to train_fixtures

* use optional type annotation

* actually running at least one test before pushing is a good idea...

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",21,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,5,1,0,0,0,0,0,0,0,0,0,0,1,20,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['counter[] == {', 'indexer.tokens_to_indices([tokens[1]], vocab) == {: [root_index]}', 'indexer.tokens_to_indices([tokens[-1]], vocab) == {: [none_index]}', 'False', 'indexer.tokens_to_indices([Token(text_id=23)], None) == {: [23]}']",['(ValueError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['counter[] == {', 'indexer.tokens_to_indices([tokens[1]], vocab) == {: [root_index]}', 'indexer.tokens_to_indices([tokens[-1]], vocab) == {: [none_index]}', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'counter[: 6}', 'indexer.tokens_to_indices([tokens[1]], vocab) == {: [person_index]}', 'indexer.tokens_to_indices([tokens[-1]], vocab) == {: [none_index]}', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'counter[] == 4', '{: [none_index, none_index, none_index, none_index]} == indices', 'counter[: 2}', 'counter[: 2}', 'len(indices) == 1', 'in indices', 'indices[][1] == verb_index', 'indices[][-1] == none_index', 'indexer.tokens_to_indices([tokens[1]], vocab) == {: [cop_index]}', 'padded_tokens[].tolist() == [1, 2, 3, 4, 5, 0, 0, 0, 0, 0]', 'counter[] == 4', '{: [none_index, none_index, none_index, none_index]} == indices']",[],[],[],[],[],[],[],[],[],[],[],[]
1848,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-22 11:06:13-08:00,e19605aae05eff60b0f41dc521b9787867fa58dd,https://github.com/allenai/allennlp/commit/e19605aae05eff60b0f41dc521b9787867fa58dd,"Add GatedSum (#3834)

* Add GatedSum

* More tests

* Even more tests

* Fix test",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ValueError)', '(ValueError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1849,Matt Gardner,mattg@allenai.org,2020-02-23 10:04:47-08:00,465224f867701f83ec3866b5913cfb96e74a4e80,https://github.com/allenai/allennlp/commit/465224f867701f83ec3866b5913cfb96e74a4e80,Make instantiation logging in FromParams use debug instead of info (#3835),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1850,Santiago Castro,sacastro@umich.edu,2020-02-23 14:42:56-05:00,bc4f0a3d61320ed9d9270b9a3c5a70edffaf5df6,https://github.com/allenai/allennlp/commit/bc4f0a3d61320ed9d9270b9a3c5a70edffaf5df6,Fix class creation `from_params` with `Iterable`s and `Mapping`s (#3838),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(d.items, Iterable)', 'len(items) == 2', 'all(isinstance(item, B) for item in items)', 'items[0].size == 1', 'items[1].size == 2', 'isinstance(d.items, Mapping)', 'len(d.items) == 2', 'all(isinstance(key, str) for key in d.items.keys())', 'all(isinstance(value, B) for value in d.items.values())', 'd.items[].size == 1', 'd.items[].size == 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1851,jspreston,j.sam.preston@gmail.com,2020-02-24 12:50:55-08:00,4831ab4a895b7568a358fb90279eed702a169846,https://github.com/allenai/allennlp/commit/4831ab4a895b7568a358fb90279eed702a169846,Avoid race condition in tensorboard directory creation (#3843),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1852,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-24 13:05:19-08:00,04c7204c2f1c9d84e0c52ee456b1b1a34ef0a4ca,https://github.com/allenai/allennlp/commit/04c7204c2f1c9d84e0c52ee456b1b1a34ef0a4ca,"Revert ""Fixes contiguous whitespaces causing coref model to produce bad results"" (#3842)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1853,Santiago Castro,sacastro@umich.edu,2020-02-24 19:17:12-05:00,62aa963cf95f843ddc57612523fecae8149a3b9f,https://github.com/allenai/allennlp/commit/62aa963cf95f843ddc57612523fecae8149a3b9f,Fix plugins were not discovered from the current directory (#3829),4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1854,Santiago Castro,sacastro@umich.edu,2020-02-24 21:41:31-05:00,09fff3d4128d7037ae1422ebcecbb8aca62b81bd,https://github.com/allenai/allennlp/commit/09fff3d4128d7037ae1422ebcecbb8aca62b81bd,Fix a comment about the nightly builds (#3837),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1855,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-25 10:30:12-08:00,a066c15e83c261e9e677bde3ada85ff35a72a94c,https://github.com/allenai/allennlp/commit/a066c15e83c261e9e677bde3ada85ff35a72a94c,Remove Pruner module and replace it with a masked_topk util function (#3825),8,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,[],"[('_array_equal_with_mask', '(correct_scores, pruned_scores, pruned_mask)'), ('_array_equal_with_mask', '(correct_scores, pruned_scores, pruned_mask)'), ('_array_equal_with_mask', '(correct_scores, pruned_scores, pruned_mask)'), ('_array_equal_with_mask', '(correct_scores, pruned_scores, pruned_mask)'), ('_array_equal_with_mask', '(pruned_items, target_items, pruned_mask)'), ('_array_equal_with_mask', '(pruned_indices, target_indices, pruned_mask)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(ValueError)'],[],[],[],[],[],[],[],[],[],[],['import pytest']
1856,Bruno Cabral,brataodream@gmail.com,2020-02-25 20:06:52-03:00,0ac261a2a9856b788d01ce2ee68198d2f5bfc182,https://github.com/allenai/allennlp/commit/0ac261a2a9856b788d01ce2ee68198d2f5bfc182,"Rewrite the augmented LSTM to use the improvments from PyText (#3772)

* Rewrite the augmented LSTM to use the improvments from PyText rewrite. Fixes #2482

* Run black, fix name

* Keep using the just a unidirectional layer as AllenNLP used to have

* Fix mypy

* Fix mypy

* Fix Mypy

* Formatting

* Adds simple test for BiAugmentedLstm

* Re-word docs

* Typos

* There are no directions in AugmentedLstm.

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1857,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-02-26 00:06:38+00:00,8dc3a5b45f5b6441ca0acbf225a8d259522f02e3,https://github.com/allenai/allennlp/commit/8dc3a5b45f5b6441ca0acbf225a8d259522f02e3,Bump pre-commit from 2.1.0 to 2.1.1 (#3847),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1858,Mark Neumann,markn@allenai.org,2020-02-26 09:33:36-08:00,d5a9696fc0eb1d78a0848954a2ad6ed1167808a6,https://github.com/allenai/allennlp/commit/d5a9696fc0eb1d78a0848954a2ad6ed1167808a6,"Data V2 (#3700)

* example for feedback

* remove all existing multiprocessing

* sneak torch datasets inside DatasetReader

* lint

* trainer_v2, We Love To See It

* datasets have index_with now, not iterators

* use iter, custom collate function in allennlp wrapper

* we don't even need the data in the trainer anymore

* all trainer tests passing

* black

* make find learning rate work

* update test fixtures to new config

* get train command tests mostly working

* lazily construct samplers, index lazy datasets

* update some fixtures

* evaluate tests passing

* all command tests passing

* lint

* update model test case, common and module tests passing

* fix test interdependence introduced by #3762

* more test interdependence

* tests tests tests

* remove unnecessary brackets

Co-Authored-By: Santiago Castro <bryant@montevideo.com.uy>

* update a chunk of the configs

* fix archival test, couple more configs

* rm pointless gan test

* more tests passing

* add current state of from params changes

* Revert ""add current state of from params changes""

This reverts commit ad45659886a7e17c5b23a376da13a6547a2bab8c.

* updated understanding of Lazy

* add discussion of None comparison to Lazy

* lint

* it's a hard doc life

* pull samplers into separate file

* more docs updates

* fold in #3812

* remove torch dataset

* add example to lazy

* rename to collate

* no kwargs

* Revert ""fold in #3812""

This reverts commit 8a08899efad7ca04dd90acc19db62cfa59cac55e.

* don't break up dataset

* add comment to iterable dataset len

* improve docstrings, build dataloader using partial_objects

* flake

* give dataloader a default implementation

* safer default for DataLoader init

* more coherent dir structure

* update imports

* add a test for the BucketBatchSampler

* split bucket sampler into own file, tests

* PR comments

Co-authored-by: Santiago Castro <bryant@montevideo.com.uy>",85,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,13,0,0,0,0,0,0,0,0,0,0,0,0,26,0,0,1,0,0,0,0,1,1,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['params[', 'grouped_instances == [', 'sampler.sorting_keys is None', 'sampler.sorting_keys == [()]', 'sampler.sorting_keys == sorting_keys', 'sampler.padding_noise == 0.1', 'sampler.batch_size == 32', 'sampler.sorting_keys == sorting_keys', 'sampler.padding_noise == 0.5', 'sampler.batch_size == 100', 'sampler.drop_last', 'all(batch_len == 2 for batch_len in stats[])', 'stats[] == len(self.instances) - 1']",[],[],[],[],[],[],[],[],[],[],[],[],"['params[', 'len(all_instances) == 100 * 4', 'len(counts) == 4', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'len(all_instances) == 200', 'isinstance(qiterable, QIterable)', 'len(all_instances) == 100 * 4', 'len(counts) == 4', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'counts[()] == 100', 'len(actual_fingerprints) == 100', 'actual_fingerprints == expected_fingerprints', 'len(all_instances) == 100 * 4 * 3', 'len(counts) == 4', 'counts[()] == 300', 'counts[()] == 300', 'counts[()] == 300', 'counts[()] == 300', 'sizes == [16] + 12 * [32]', 'len(instances) == 5', 'sum(sizes) == 400']",[],[],[''],[],[],[],[],['skipif('],['mark.skipif('],[],[],['import pytest']
1859,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-26 10:24:23-08:00,4b4843d8dc358e6aa06784054b077d363bc12683,https://github.com/allenai/allennlp/commit/4b4843d8dc358e6aa06784054b077d363bc12683,Pad only when necessary when max length is specified (#3850),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1860,Mark Neumann,markn@allenai.org,2020-02-26 13:26:10-08:00,121d3eca77716336707c0e53dec22c3d80d038cc,https://github.com/allenai/allennlp/commit/121d3eca77716336707c0e53dec22c3d80d038cc,"Remove iterators (#3853)

* remove iterators

* remove iterator tests, move base test class

* catch other tests

* catch some more references to DataIterator

* fix test

* remove validate callback we aren't going to use

* fix comment",23,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,6,2,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,63,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],"[('_instances_are_correct', '(instances)'), ('_instances_are_correct', '(instances)'), ('Equal', '(PassThroughIterator().get_num_batches(self.instances), len(self.instances))'), ('Logs', '(logger, level=) as context_manager:'), ('In', '(, context_manager.output[0])'), ('Equal', '(tensor_dict[].size(), (4,))')]","['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['Sampler.by_name(', 'Sampler.by_name(', 'BatchSampler.by_name(', 'set(candidate_instances) == set(expected_instances)']",[],[],[],[],[],[],[],[],[],[],[],[],"['DataIterator.by_name(', 'DataIterator.by_name(', 'set(candidate_instances) == set(expected_instances)', 'BasicIterator(batch_size=2).get_num_batches(self.lazy_instances) == 1', '(', '(', 'BasicIterator(batch_size=2).get_num_batches(self.instances) == 3', 'len(instances) == 5', 'len(instances) == 5 * 6', 'grouped_instances == [', 'grouped_instances == [', 'grouped_instances == [', 'grouped_instances == [', 'grouped_instances == [', 'grouped_instances == [', 'all(epoch_num == epoch for epoch_num in batch[])', 'len(all_batches) == 10 * 3', 'all(epoch_num == epoch for epoch_num in batch[])', 'len(all_batches) == 30', 'all(epoch_num == epoch for epoch_num in batch[])', 'len(in_order_batches) == len(shuffled_batches)', 'in_order_batches != shuffled_batches', 'in_order_counts == shuffled_counts', 'grouped_instances == [', 'grouped_instances == [[self.instances[0]], [self.instances[1]]]', 'grouped_instances == [[self.instances[0]], [self.instances[1]]]', 'grouped_instances == [[self.instances[2]], [self.instances[3]]]', 'grouped_instances == [[self.instances[2]], [self.instances[3]]]', 'iterator._batch_size == 32  # default value', 'iterator._batch_size == 10', 'stats[] == len(self.instances)', 'stats[] == [2, 1, 1, 1]', 'stats[] == [8, 3, 9, 1]', 'stats[] == len(token_counts)', 'stats[] == [1, 2]', 'stats[] == [10, 8]', 'grouped_instances == [', 'iterator._sorting_keys is None', 'iterator._sorting_keys == [()]', 'grouped_instances == [', 'grouped_instances == [', 'iterator._sorting_keys == sorting_keys', 'iterator._padding_noise == 0.1', 'not iterator._biggest_batch_first', 'iterator._batch_size == 32', 'not iterator._skip_smaller_batches', 'iterator._sorting_keys == sorting_keys', 'iterator._padding_noise == 0.5', 'iterator._biggest_batch_first', 'iterator._batch_size == 100', 'iterator._skip_smaller_batches', 'stats[] == len(self.instances)', 'stats[] == [2, 2, 1]', 'stats[] == [6, 8, 9]', 'stats[] == len(test_instances)', 'stats[] == [2, 1]', 'stats[] == [8, 10]', 'all(batch_len == 2 for batch_len in stats[])', 'stats[] == len(self.instances) - 1', 'len(instance_types) == 1', 'observed_instance_type_counts == actual_instance_type_counts', 'len(batch[]) == 3', 'os.path.exists(os.path.join(self.TEST_DIR, ))']",[],[],[],[],[],[],[],[],[],[],[],[]
1861,Dirk Groeneveld,dirkg@allenai.org,2020-02-26 13:44:01-08:00,cd5b4692e1ced9cf584944b4891b0adbfdd13ba2,https://github.com/allenai/allennlp/commit/cd5b4692e1ced9cf584944b4891b0adbfdd13ba2,"Fixes XLNet, and adds a test for it (#3855)",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1862,Santiago Castro,sacastro@umich.edu,2020-02-27 14:48:58-05:00,ddebbdc53544c64a1957cf0ec04a34578e9b57ba,https://github.com/allenai/allennlp/commit/ddebbdc53544c64a1957cf0ec04a34578e9b57ba,"Make most metrics work on GPU (#3851)

* Make most metrics work on GPU

* Make metric tests work on both GPU and CPU

* Add a test for the test utility

* mypy

* Update allennlp/common/testing/test_case.py

Co-Authored-By: Mark Neumann <markn@allenai.org>

* Fix a PR comment

* flake8

Co-authored-by: Mark Neumann <markn@allenai.org>",38,False,True,True,False,False,True,True,True,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,1,8,0,0,0,0,0,0,0,0,0,0,0,1,[],"[('SetEqual', '(expected_devices, actual_devices)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['accuracy.get_metric() == 2 / 4', 'accuracy.get_metric() == 5 / 8', 'accuracy.get_metric() == 8 / 12', 'accuracy.get_metric() == 3 / 4', 'metric._ignore_classes == []  # type: ignore', 'metric._label_vocabulary == self.vocab.get_index_to_token_vocabulary(  # type: ignore', 'spearman_correlation.get_metric() != float()']",[],[],[],[],[],[],[],[],[],[],[],['import pytest'],"['accuracy.get_metric() == 2.0 / 4', 'accuracy.get_metric() == 5.0 / 8', 'accuracy.get_metric() == 8.0 / 12', 'accuracy.get_metric() == 3.0 / 4', 'actual_accuracy == 0.50', 'metric._ignore_classes == []', 'metric._label_vocabulary == self.vocab.get_index_to_token_vocabulary()', 'spearman_correlation.get_metric() != np.nan']",[],[],[],[],[],[],[],[],[],[],[],['import pytest']
1863,Mark Neumann,markn@allenai.org,2020-02-27 12:31:33-08:00,1dd2ba55caa1d8d9ad466466d8970aef5ed9f0c6,https://github.com/allenai/allennlp/commit/1dd2ba55caa1d8d9ad466466d8970aef5ed9f0c6,"update training configs (#3856)

* update training configs

* fix coref config

* Revert ""fix coref config""

This reverts commit 6aa0e977b586f604b060f2352b00483b11ae3511.

* remove more sorting keys

* remove accidentally checked in file

* indent

Co-Authored-By: Santiago Castro <bryant@montevideo.com.uy>

* indent

Co-Authored-By: Santiago Castro <bryant@montevideo.com.uy>

* indent

Co-Authored-By: Santiago Castro <bryant@montevideo.com.uy>

Co-authored-by: Santiago Castro <bryant@montevideo.com.uy>
Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",26,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1864,Santiago Castro,sacastro@umich.edu,2020-02-27 15:32:02-05:00,94d2f1511e0d46191e4f230615da3d5882474a41,https://github.com/allenai/allennlp/commit/94d2f1511e0d46191e4f230615da3d5882474a41,Remove the unused `Trainer.shuffle` (#3861),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1865,Santiago Castro,sacastro@umich.edu,2020-02-27 16:41:59-05:00,a357ea19bb5b1a9a4591b3ffff180b9605213d37,https://github.com/allenai/allennlp/commit/a357ea19bb5b1a9a4591b3ffff180b9605213d37,Fix samplers inheritance order (#3863),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1866,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-27 13:56:12-08:00,e2577b4f49cdae20351a363e4e0f340933998fcb,https://github.com/allenai/allennlp/commit/e2577b4f49cdae20351a363e4e0f340933998fcb,Add coarse-to-fine and second order inference for coref. Also a new coref config (#3848),4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1867,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-27 15:38:25-08:00,8b9ce9cc112574b5bb305b4b84dc015bb82d407c,https://github.com/allenai/allennlp/commit/8b9ce9cc112574b5bb305b4b84dc015bb82d407c,Add NLI models (#3865),4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', '[t.text for t in fields[]', 'fields[]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1868,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-02-27 22:09:33-08:00,4b467ec2882c49c9162d37f40fb55e08d7f5fee0,https://github.com/allenai/allennlp/commit/4b467ec2882c49c9162d37f40fb55e08d7f5fee0,Update some training configs to match Data V2 (#3867),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1869,Santiago Castro,sacastro@umich.edu,2020-03-01 21:29:32-05:00,9080cde6128c828f86ae8f58839321a01512f9e5,https://github.com/allenai/allennlp/commit/9080cde6128c828f86ae8f58839321a01512f9e5,Fix `num_serialized_models_to_keep` in config files (#3882),7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1870,Michael Schmitz,MichaelS@allenai.org,2020-03-02 08:08:51-08:00,f0c8fc563f6eeed24f11a8d34e3fe1d681e05096,https://github.com/allenai/allennlp/commit/f0c8fc563f6eeed24f11a8d34e3fe1d681e05096,Various documentation fixes (#3874),14,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1871,Mark Neumann,markn@allenai.org,2020-03-02 09:19:55-08:00,cb00b8b6ad57680127cd69294c329b040ee1f66a,https://github.com/allenai/allennlp/commit/cb00b8b6ad57680127cd69294c329b040ee1f66a,add ref to winobias dataset reader (#3885),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1872,Santiago Castro,sacastro@umich.edu,2020-03-02 12:36:54-05:00,a63d6efd57464004521b0954a98d45c514d6f40b,https://github.com/allenai/allennlp/commit/a63d6efd57464004521b0954a98d45c514d6f40b,"Show ""Training"" before tqdm (#3879)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1873,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-03-02 18:15:53+00:00,2942d10bffe8fbb80dd6082c48dd86a64b49888b,https://github.com/allenai/allennlp/commit/2942d10bffe8fbb80dd6082c48dd86a64b49888b,Bump conllu from 2.2.2 to 2.3 (#3883),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1874,Mark Neumann,markn@allenai.org,2020-03-02 10:46:17-08:00,1b2f1a7388e028c6c2f3c5e5beb9dba062294c69,https://github.com/allenai/allennlp/commit/1b2f1a7388e028c6c2f3c5e5beb9dba062294c69,update pytorch version to include 1.4 and exclude 1.2 (#3886),2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1875,John Giorgi,johnmgiorgi@gmail.com,2020-03-02 14:25:29-05:00,44ed34c3e332fceabb39d28728b01834f8a89e5f,https://github.com/allenai/allennlp/commit/44ed34c3e332fceabb39d28728b01834f8a89e5f,Enable AMP with Apex (#3866),3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['if(not torch.cuda.is_available(), reason=)', 'if(amp is None, reason=)']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)', 'skipif(amp is None, reason=)']","['mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.skipif(amp is None, reason=)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1876,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-03-02 11:42:17-08:00,ff8f9668ef339efaee3ff0b56dbe04f85a183794,https://github.com/allenai/allennlp/commit/ff8f9668ef339efaee3ff0b56dbe04f85a183794,Fixes some things to allow easier coref experiments (#3887),5,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,1,1,1,0,0,0,4,0,0,0,0,0,0,1,1,1,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['([], 2) in gold_mentions_with_ids', 'not any(_ for _, id_ in gold_mentions_with_ids if id_ == 2)', '([], 24) in gold_mentions_with_ids', '(', '([], 2) not in gold_mentions_with_ids']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],[],"['([], 2) in gold_mentions_with_ids', 'not any(_ for _, id_ in gold_mentions_with_ids if id_ == 2)', '([], 24) in gold_mentions_with_ids', '(']",[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],[]
1877,Santiago Castro,sacastro@umich.edu,2020-03-02 17:26:36-05:00,8465d42fb4c6a50be7cd1aa0766c306b0ddf2a24,https://github.com/allenai/allennlp/commit/8465d42fb4c6a50be7cd1aa0766c306b0ddf2a24,Fix `BucketBatchSampler.__len__` edge case (#3878),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(dataloader) == 3', 'len(dataloader) == 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1878,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-03-02 16:31:11-08:00,95b6d985ffb231d9a2047c039c95660913063b9d,https://github.com/allenai/allennlp/commit/95b6d985ffb231d9a2047c039c95660913063b9d,"Change all masks to type torch.bool (#3890)

* get_text_field_mask

* masked_softmax

* masked_log_softmax

* masked_max/mean

* get_lengths_from_binary_sequence_mask

* get_final_encoder_states

* replace_masked_values

* batched_span_select

* sequence_cross_entropy_with_logits

* add_sentence_boundary_token_ids/remove_sentence_boundaries

* scalar mix

* More changes

* Fix tests

* More changes, mostly in tests

* Test fix

* black

* More changes

* More cahnges",107,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1879,meghana1697,meghanakalidindi1997@gmail.com,2020-03-03 23:03:02+05:18,c6baa8b60c11e96b6429e73ae041a395a12564fd,https://github.com/allenai/allennlp/commit/c6baa8b60c11e96b6429e73ae041a395a12564fd,Fix for --recover with distributed training. (#3873),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1880,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-03-03 10:38:12-08:00,b9989913ee510401f0510b7fb2aacd829cc881e2,https://github.com/allenai/allennlp/commit/b9989913ee510401f0510b7fb2aacd829cc881e2,Change torch.BoolTensor(...) to torch.tensor(...) (#3892),15,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1881,Mark Neumann,markn@allenai.org,2020-03-03 12:39:27-08:00,4749fc3671a40ca3cd6eafc65e2d95bf3dead82c,https://github.com/allenai/allennlp/commit/4749fc3671a40ca3cd6eafc65e2d95bf3dead82c,"Remove legacy attention (#3891)

* remove similarity functions

* remove legacy attentions

* remove intra sentence self attention

* update models and tests which used legacy attention

* update training config

* update two relevant model fixtures",40,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,5,0,0,0,0,0,0,0,0,0,0,2,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'SimilarityFunction.by_name(', 'attention._similarity_function.__class__.__name__ == ', 'attention._normalize is False', 'result.shape == (1, 2, 3)', 'attention._similarity_function.__class__.__name__ == ', 'encoder.get_input_dim() == 5', 'encoder.get_output_dim() == 9', 'encoder.get_input_dim() == 5', 'encoder.get_output_dim() == 5', 'encoder.get_input_dim() == 8', 'encoder.get_output_dim() == 24', 'in exception_info.value.message', 'in exception_info.value.message', 'in exception_info.value.message', 'list(encoder_output.size()) == [4, 3, 4]  # default combination is 1,2', 'list(encoder_output.size()) == [4, 6, 24]', 'list(bilinear._weight_matrix.size()) == [5, 2]', 'list(bilinear._bias.size()) == [1]', 'result.shape == (2,)', 'result.shape == (5, 4, 3, 6)', 'list(bilinear._weight_matrix.size()) == [3, 4]', 'result.shape == (1, 2)', 'desired_result.shape == (1, 2)', 'result.shape == (5, 4, 3, 6)', 'CosineSimilarity.from_params(Params({})).__class__.__name__ == ', 'result.shape == (2,)', 'numpy.all(result == [2, -1])', 'result.shape == (5, 4, 3, 6)', '(', 'list(linear._weight_vector.size()) == [9]', 'list(linear._bias.size()) == [1]', 'result.shape == (1, 2)', 'result.shape == (5, 4, 3, 6)', 'result.shape == (2,)', 'result.shape == (2,)', 'result.shape == (2,)', 'result.shape == (2,)', 'list(linear._weight_vector.size()) == [16]', 'list(similarity._tensor_1_projection.size()) == [9, 6]', 'list(similarity._tensor_2_projection.size()) == [6, 12]', 'result.shape == (1, 1, 2, 3)']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest']"
1882,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-03-03 12:56:48-08:00,1697dcb5ebc2cddd1332a74167a8f91257600865,https://github.com/allenai/allennlp/commit/1697dcb5ebc2cddd1332a74167a8f91257600865,More changes: torch.BoolTensor(...) -> torch.tensor(...) (#3894),12,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1883,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-03-03 15:04:48-08:00,4e3daab26c6694202d0d34b648ab6512f27d95d9,https://github.com/allenai/allennlp/commit/4e3daab26c6694202d0d34b648ab6512f27d95d9,Make tensors_equal work for bools and add test (#3897),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['util.tensors_equal(torch.tensor([1]), torch.tensor([1]))', 'not util.tensors_equal(torch.tensor([1]), torch.tensor([2]))', 'util.tensors_equal(torch.tensor([True]), torch.tensor([True]))', 'util.tensors_equal(torch.tensor([1]), torch.tensor([1.0]))', 'util.tensors_equal(torch.tensor([1]), torch.tensor([True]))', 'util.tensors_equal([torch.tensor([1])], [torch.tensor([1])])', 'not util.tensors_equal([torch.tensor([1])], [torch.tensor([2])])', 'util.tensors_equal({: torch.tensor([1])})']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1884,Will Frey,jfrey89@gmail.com,2020-03-03 20:14:15-05:00,4434a83c27dd57dee3bf7989507e2d4271749a37,https://github.com/allenai/allennlp/commit/4434a83c27dd57dee3bf7989507e2d4271749a37,Return BoolTensor from get_mask_from_sequence_lengths (#3893),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1885,Mark Neumann,markn@allenai.org,2020-03-04 10:45:57-08:00,72acdd1e76fc98887af126213b1fc4982b1c7ab3,https://github.com/allenai/allennlp/commit/72acdd1e76fc98887af126213b1fc4982b1c7ab3,"fix install order, only run publish on allenai/allennlp (#3896)

* fix install order, only run publish on allenai/allennlp

* better way of preventing running on forks",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1886,Mark Neumann,markn@allenai.org,2020-03-05 10:38:15-08:00,644ef22e90c8493af8e14e81a1e10839a8f0b62a,https://github.com/allenai/allennlp/commit/644ef22e90c8493af8e14e81a1e10839a8f0b62a,"Sorting keys api (#3902)

* new idea for sorting

* add len to all fields

* update references to sorting keys",19,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['params[', 'sampler.sorting_keys == []']",[],[],[],[],[],[],[],[],[],[],[],[],"['params[', 'sampler.sorting_keys == [()]']",[],[],[],[],[],[],[],[],[],[],[],[]
1887,Mark Neumann,markn@allenai.org,2020-03-05 13:38:08-08:00,fb07846e1d38540aab3298e633d09735e44af144,https://github.com/allenai/allennlp/commit/fb07846e1d38540aab3298e633d09735e44af144,"single quoted strings because github (#3907)

* single quoted strings because github

* fix",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1888,Michael Schmitz,MichaelS@allenai.org,2020-03-05 15:58:28-08:00,36d46acd19857c3dc64b4427590f7d9672714420,https://github.com/allenai/allennlp/commit/36d46acd19857c3dc64b4427590f7d9672714420,Fix a few code block references. (#3908),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1889,Santiago Castro,sacastro@umich.edu,2020-03-06 12:13:14-05:00,db427982da14be330bbcec5b9dcf23f0d196afb7,https://github.com/allenai/allennlp/commit/db427982da14be330bbcec5b9dcf23f0d196afb7,"Fix trainer tests in GPU (#3903)

Co-authored-by: Mark Neumann <markn@allenai.org>",1,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['spawn'],['mark.spawn'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1890,Mark Neumann,markn@allenai.org,2020-03-06 09:26:42-08:00,cc10c0bd5e87198e6ec6143781f711d1eb93b13a,https://github.com/allenai/allennlp/commit/cc10c0bd5e87198e6ec6143781f711d1eb93b13a,"Docs tidy (#3916)

* remove invalid import

* remove edit url",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1891,Michael Schmitz,MichaelS@allenai.org,2020-03-06 11:19:48-08:00,4fd76b65e00194fe187b3d62f15bb7352f64cffc,https://github.com/allenai/allennlp/commit/4fd76b65e00194fe187b3d62f15bb7352f64cffc,"Remove codeblocks from docstrings in commands package. (#3915)

* Remove codeblocks in commands docs.

* Update build_docs.sh

* Add an additional space.",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1892,Dirk Groeneveld,dirkg@allenai.org,2020-03-06 14:02:02-08:00,7b315d61062770b20e7741cdc050880e03922afc,https://github.com/allenai/allennlp/commit/7b315d61062770b20e7741cdc050880e03922afc,Wrap the pytorch transformer (#3898),3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,3,3,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not torch.isnan(inputs).any()', 'torch.isfinite(inputs).all()', 'outputs.size() == inputs.size()', 'not torch.isnan(outputs).any()', 'torch.isfinite(outputs).all()', 'not torch.allclose(', 'torch.allclose(', 'torch.allclose(', 'not torch.allclose(']",[],[],[],[],[],[],"['(])', '(])', '(])']","['parametrize(])', 'parametrize(])', 'parametrize(])']","['mark.parametrize(])', 'mark.parametrize(])', 'mark.parametrize(])']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1893,Evan Pete Walsh,epwalsh10@gmail.com,2020-03-06 15:26:28-08:00,d34579b9bce8744d22817ba74ac9b09995ec4b26,https://github.com/allenai/allennlp/commit/d34579b9bce8744d22817ba74ac9b09995ec4b26,Fix trainer tests when Apex installed (#3919),1,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,3,3,0,0,0,0,0,0,2,0,0,0,0,3,3,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['if(not torch.cuda.is_available(), reason=)', 'if(amp is None, reason=)']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)', 'skipif(amp is None, reason=)', 'spawn']","['mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.skipif(amp is None, reason=)', 'mark.spawn']",[],[],[],[],[],[],"['if(not torch.cuda.is_available(), reason=)', 'if(amp is None, reason=)']",[],[],[],[],"['skipif(not torch.cuda.is_available(), reason=)', 'skipif(amp is None, reason=)', 'spawn']","['mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.skipif(amp is None, reason=)', 'mark.spawn']",[],[],[]
1894,Nicola De Cao,nicola.decao@uva.nl,2020-03-07 00:02:28+00:00,724e1b9f5bda6aed035fdea9744729b20bd1f0c2,https://github.com/allenai/allennlp/commit/724e1b9f5bda6aed035fdea9744729b20bd1f0c2,Fix bug for RNNs for AutoRegressiveSeqDecoder (#3464),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1895,Yaroslav Emelianov,mojesty@users.noreply.github.com,2020-03-07 03:24:55+03:00,bdb29a831ed68cb948b18b42fa61646b9ec11bf8,https://github.com/allenai/allennlp/commit/bdb29a831ed68cb948b18b42fa61646b9ec11bf8,Add check that model overfits when training on a tiny dataset into ModelTestCase (#3912),3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,3,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Raises', '('), ('Raises', '('), ('Raises', '(')]",['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metric_value is not None, f', 'metric_terminal_value is not None, ', 'abs(metric_value - metric_terminal_value) < metric_tolerance']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1896,Michael Schmitz,MichaelS@allenai.org,2020-03-09 08:56:07-07:00,fb792121df0841105a06cae487446dad677b4eef,https://github.com/allenai/allennlp/commit/fb792121df0841105a06cae487446dad677b4eef,Speed up docs generation. (#3920),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1897,Michael Schmitz,MichaelS@allenai.org,2020-03-09 10:27:23-07:00,a88c3f86d7929e2fe0bba225232177d720246bc5,https://github.com/allenai/allennlp/commit/a88c3f86d7929e2fe0bba225232177d720246bc5,Remove the edit link from the docs. (#3929),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1898,Michael Schmitz,MichaelS@allenai.org,2020-03-09 13:09:22-07:00,b420689722880a2156703802b15f0250e0196b73,https://github.com/allenai/allennlp/commit/b420689722880a2156703802b15f0250e0196b73,Update README.md (#3930),7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1899,Michael Schmitz,MichaelS@allenai.org,2020-03-09 14:27:55-07:00,4b4ffb0ebe7a369c63d7a617621bda9118722a87,https://github.com/allenai/allennlp/commit/4b4ffb0ebe7a369c63d7a617621bda9118722a87,Fix doc links in tutorials. (#3933),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1900,Michael Schmitz,MichaelS@allenai.org,2020-03-10 12:25:34-07:00,5ba77d44d9c87f1a12ec4ea63aca1d965399090f,https://github.com/allenai/allennlp/commit/5ba77d44d9c87f1a12ec4ea63aca1d965399090f,Use docs.allennlp.org for documentation URLs. (#3934),7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1901,Daniel King,43149077+danielkingai2@users.noreply.github.com,2020-03-10 15:28:24-07:00,3a15029c0ced1dcd1d1976722b1ae05c4d45607a,https://github.com/allenai/allennlp/commit/3a15029c0ced1dcd1d1976722b1ae05c4d45607a,Fix repo check for nightly build (#3935),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1902,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-03-11 15:14:45-07:00,fb07fcb349c3590f55fa8f9f67552a7a1ee46198,https://github.com/allenai/allennlp/commit/fb07fcb349c3590f55fa8f9f67552a7a1ee46198,"Update mathy-pydoc requirement from <0.7.0,>=0.6.7 to >=0.6.7,<0.8.0 (#3928)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1903,Dirk Groeneveld,dirkg@allenai.org,2020-03-11 16:11:42-07:00,25d627439ba1b5f40b2dbb87735023ed855c6e73,https://github.com/allenai/allennlp/commit/25d627439ba1b5f40b2dbb87735023ed855c6e73,Remove dependency parser from the core repo (#3939),21,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,40,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[].tokens] == [', 'fields[].labels == [', 'fields[].labels == [', 'fields[].labels == [0, 4, 4, 1, 6, 4, 4]', '[t.text for t in fields[].tokens] == [', 'fields[].labels == [', 'fields[].labels == [', 'fields[].labels == [', '[t.text for t in fields[].tokens] == [', 'fields[].labels == [', 'fields[].labels == [', 'fields[].labels == [4, 4, 4, 0, 6, 4, 6, 6, 4]', '[t.text for t in fields[].tokens] == [', 'fields[].labels == [', 'fields[].labels == [', 'fields[].labels == [2, 3, 5, 5, 0, 5, 8, 5, 8, 11, 5, 11, 5]', '[t.text for t in fields[].tokens] == [', 'fields[]', 'fields[].labels == [', 'fields[].labels == [0, 4, 4, 1, 6, 4, 4]', 'set(decode_output_dict.keys()) == {', 'list(heads) == [-1, 0, 0]', 'heads_model.tolist()[0] == [0, 0, 1]', 'heads.tolist()[0] == [0, 0, 1]', 'tags.tolist()[0] in ([0, 1, 0], [0, 1, 1])', 'len(predicted_heads) == len(words)', 'len(predicted_dependencies) == len(words)', 'isinstance(predicted_dependencies, list)', 'all(isinstance(x, str) for x in predicted_dependencies)', 'result.get() is not None', 'result.get() is not None', 'result.get() is not None', 'result.get() == {', 'len(results) == 2', 'len(predicted_heads) == sequence_length', 'len(predicted_dependencies) == sequence_length', 'isinstance(predicted_dependencies, list)', 'all(isinstance(x, str) for x in predicted_dependencies)', 'tags == []', 'tags == []']",[],[],[],[],[],[],[],[],[],[],[],[]
1904,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-03-12 11:43:53-07:00,593dd8cf58fcd2fc0ba48aa81724cd82b904f7cf,https://github.com/allenai/allennlp/commit/593dd8cf58fcd2fc0ba48aa81724cd82b904f7cf,Fix special values overflow/underflow for amp (#3901),20,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['util.min_value_of_dtype(torch.half) == -65504.0', 'util.max_value_of_dtype(torch.half) == 65504.0', 'util.tiny_value_of_dtype(torch.half) == 1e-4', 'util.min_value_of_dtype(torch.float) == -3.4028234663852886e38', 'util.max_value_of_dtype(torch.float) == 3.4028234663852886e38', 'util.tiny_value_of_dtype(torch.float) == 1e-13', 'util.min_value_of_dtype(torch.uint8) == 0', 'util.max_value_of_dtype(torch.uint8) == 255', 'util.min_value_of_dtype(torch.long) == -9223372036854775808', 'util.max_value_of_dtype(torch.long) == 9223372036854775807']",['(TypeError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1905,Dirk Groeneveld,dirkg@allenai.org,2020-03-12 17:41:30-07:00,5c022069dcd8af2ae219a09462cb069102505660,https://github.com/allenai/allennlp/commit/5c022069dcd8af2ae219a09462cb069102505660,"Removes a bunch of syntax related models (#3941)

* Removes a bunch of syntax related models

* Unused imports

* Removing coref related stuff",78,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,4,4,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,230,1,0,2,0,0,0,5,7,7,4,0,8,[],[],[],[],[],[],[],[],[],[],[],[],"[('_predict_result', '(result)'), ('_predict_result', '(result_doc_words)'), ('_predict_result', '(result_json)'), ('_predict_result', '(result_words)')]","['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 4', 'text == [', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', '(', 'text == [', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', '([], 1) in gold_mentions_with_ids', 'len(instances) == 4', 'text == [', 'all(span_start > 0 for span_start in span_starts)', 'all(span_end < len(text) - 1 for span_end in span_ends)', '([], 0) in gold_mentions_with_ids', '([], 0) not in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', 'all(self.span_width >= len(x) > 0 for x in candidate_mentions)', 'len(limited_instances) == len(instances) == 4', 'limited_docs[1] == docs[1]', 'limited_docs[3] == docs[3]', 'len(limited_docs[0]) < len(docs[0])', 'len(limited_docs[2]) < len(docs[2])', 'not in text_of(limited_docs[0])', 'not in text_of(limited_docs[2])', 'limited_docs[0] == docs[0][: len(limited_docs[0])]', 'limited_docs[2] == docs[2][: len(limited_docs[2])]', 'len(instances) == 3', 'text == [', '([], 0) in gold_mentions_with_ids', '([], 0) in gold_mentions_with_ids', '([], 2) in gold_mentions_with_ids', 'not any(_ for _, id_ in gold_mentions_with_ids if id_ == 2)', '([], 24) in gold_mentions_with_ids', '(', '([], 2) not in gold_mentions_with_ids', 'all(self.span_width >= len(x) > 0 for x in candidate_mentions)', 'len(instances) == 2', 'text == [', 'gold_mentions_with_ids == [([], 0)]', 'text == [', 'gold_mentions_with_ids == [', 'all(self.span_width >= len(x) > 0 for x in candidate_mentions)', 'annotation.document_id == ', 'annotation.sentence_id == 0', 'annotation.words == [', 'annotation.pos_tags == [', 'annotation.word_senses == [None, None, 1, 1, None, 2, None, None, 1, None, None]', 'annotation.predicate_framenet_ids == [', 'annotation.srl_frames == [', 'annotation.named_entities == [', 'annotation.predicate_lemmas == [', 'annotation.speakers == [', 'annotation.parse_tree == Tree.fromstring(', 'annotation.coref_spans == {(1, (4, 6)), (3, (4, 7))}', 'annotation.document_id == ', 'annotation.sentence_id == 0', 'annotation.words == [', 'annotation.pos_tags == [', 'annotation.word_senses == [', 'annotation.predicate_framenet_ids == [', 'annotation.srl_frames == [', 'annotation.named_entities == [', 'annotation.predicate_lemmas == [', 'annotation.speakers == [', 'annotation.parse_tree == Tree.fromstring(', 'annotation.coref_spans == {(2, (0, 1)), (2, (3, 3))}', 'annotation.document_id == ', 'annotation.sentence_id == 0', 'annotation.words == []', 'annotation.pos_tags == []', 'annotation.word_senses == [None, None, None, None, None]', 'annotation.predicate_framenet_ids == [None, None, None, None, None]', 'annotation.srl_frames == []', 'annotation.named_entities == [', 'annotation.predicate_lemmas == [None, None, None, None, None]', 'annotation.speakers == [None, None, None, None, None]', 'annotation.parse_tree == Tree.fromstring(', 'annotation.coref_spans == {(2, (0, 1))}', 'annotation.document_id == ', 'annotation.sentence_id == 0', 'annotation.words == [', 'annotation.pos_tags == [', 'annotation.word_senses == [', 'annotation.predicate_framenet_ids == [', 'annotation.srl_frames == [', 'annotation.named_entities == [', 'annotation.predicate_lemmas == [', 'annotation.speakers == [', 'annotation.parse_tree == Tree.fromstring(', 'annotation.coref_spans == {(14, (6, 6))}', 'len(files) == len(expected_paths)', 'set(files) == set(expected_paths)', 'len(documents) == 4', 'tokens == [', 'fields[]', 'tokens == [', 'fields[].labels == [', 'tokens == []', 'fields[].labels == [', 'len(instances) == 1', 'tokens == [', 'fields[].labels[3] == 1', 'fields[].labels == [', 'fields[] == tokens', 'fields[] == tokens[3]', 'fields[].labels', 'tokens == [', 'fields[].labels[8] == 1', 'fields[].labels == [', 'fields[] == tokens', 'fields[] == tokens[8]', 'fields[].labels', 'tokens == [', 'fields[].labels[2] == 1', 'fields[].labels == [', 'fields[] == tokens', 'fields[] == tokens[2]', 'fields[].labels', 'tokens == [', 'fields[].labels[11] == 1', 'fields[].labels == [', 'fields[] == tokens', 'fields[] == tokens[11]', 'fields[].labels', 'tokens == []', 'fields[].labels == [0, 0, 0, 0, 0]', 'fields[]', 'fields[] == tokens', 'fields[] is None', 'fields[].labels', 'len(instances) == 2', 'converted == wordpiece_tags', 'converted == [', 'converted == []', 'converted == []', 'wordpieces == [', '[wordpieces[i] for i in offsets] == []', '[wordpieces[i] for i in start_offsets] == [', 'tokens == [', 'fields[].labels[4] == 1', 'fields[].labels == [', 'tokens == [', 'fields[].labels[10] == 1', 'fields[].labels == [', 'tokens == [', 'fields[].labels[3] == 1', 'fields[].labels == [', 'tokens == [', 'fields[].labels[12] == 1', 'fields[].labels == [', 'tokens == []', 'fields[].labels == [0, 0, 0, 0, 0, 0, 0]', 'fields[]', 'interpretation is not None', 'in interpretation', ']', 'len(grad_input_1) == 16  # 16 words in input', 'grad == approx(repeat_grad)', 'len(prediction) == length', 'len(clusters) == 2', 'gold1 in clusters', 'gold2 in clusters', 'len(prediction) == length', 'conll_tags == []', 'exit_code == 0', 'isinstance(encoder, MultiHeadSelfAttention)', 'encoder.get_input_dim() == 2', 'encoder.get_output_dim() == 2', 'list(attention(inputs).size()) == [2, 12, 5]', 'isinstance(encoder, QaNetEncoder)', 'encoder.get_input_dim() == 16', 'encoder.get_output_dim() == 16', 'list(encoder(inputs).size()) == [2, 12, 16]', 'encoder.get_input_dim() == 9', 'encoder.get_output_dim() == 12', 'list(encoder_output.size()) == [3, 5, 12]', 'list(encoder_output.size()) == [3, 5, 12]', 'document == [', 'isinstance(clusters, list)', 'isinstance(cluster, list)', 'isinstance(mention[0], int)', 'isinstance(mention[1], int)', '0 < mention[0] <= len(document)', '0 < mention[1] <= len(document)', 'isinstance(result, str)', 'text == inputs[i]', 'output == expected_outputs[i]', 'new_instances is not None', 'in new_instance', 'len(new_instance[]) == 60  # 7 words in input', 'true_top_spans == pred_clust_spans', 'words == [', 'verbs is not None', 'isinstance(verbs, list)', 'tags is not None', 'isinstance(tags, list)', 'all(isinstance(tag, str) for tag in tags)', 'len(tags) == num_words', 'sanitize_label(', 'result == {: []}', 'len(pred_dict) == 1', 'get_predicate_text(sent_tokens, tags) == ', 'len(pred_dict) == 1', 'get_predicate_text(sent_tokens, tags) == ', 'words == [', 'verbs is not None', 'isinstance(verbs, list)', 'any(v[ for v in verbs)', 'any(v[ for v in verbs)', 'any(v[ for v in verbs)', 'tags is not None', 'isinstance(tags, list)', 'all(isinstance(tag, str) for tag in tags)', 'len(tags) == num_words', 'result[0] == result[1]', 'result == {: []}', 'results[0] == {: []}', 'results[1] == {', 'len(clusters) == 1', 'set(clusters[0]) == {(4, 6), (8, 9)}', 'mention_to_cluster == {(4, 6): clusters[0], (8, 9): clusters[0]}', 'metric._true_positives[] == 1', 'not in metric._true_positives.keys()', 'metric._true_positives[] == 1', 'metric._true_positives[] == 1', 'num_correct_arg1_instances_from_perl_evaluation == metric._true_positives[]', 'len(metrics) == 18', 'len(metrics) == 9']",['(ConfigurationError)'],[],"['()', 'if(torch.cuda.device_count() < 2, reason=)']",[],[],[],"['(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))']","['parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'skip()', 'skipif(torch.cuda.device_count() < 2, reason=)']","['mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.skip()', 'mark.skipif(torch.cuda.device_count() < 2, reason=)']","['setattr(BertModel, , lambda _: BertModel(config))', 'setattr(', 'undo()', 'undo()']",[],"['import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest']"
1906,Santiago Castro,sacastro@umich.edu,2020-03-13 18:31:53-04:00,0c1ac68e0125b0cc871f7d9d5c630c32cf82c2ac,https://github.com/allenai/allennlp/commit/0c1ac68e0125b0cc871f7d9d5c630c32cf82c2ac,Fix `ArrayField.__len__` for scalars (#3940),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['len(array) == 1'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1907,Andrew Moore,andrew.p.moore94@gmail.com,2020-03-13 22:47:40+00:00,d0ddfc81baa1371ba9ab9774e7c82e0251dac1ac,https://github.com/allenai/allennlp/commit/d0ddfc81baa1371ba9ab9774e7c82e0251dac1ac,Test the ELMoTokenCharactersIndexer get_empty_token_list function (#3936),2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['{: []} == indexer.get_empty_token_list()'],['(AssertionError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1908,Dirk Groeneveld,dirkg@allenai.org,2020-03-13 15:57:53-07:00,ebf246b6b2fc21dafde77ea82cd67c4e9efed7cc,https://github.com/allenai/allennlp/commit/ebf246b6b2fc21dafde77ea82cd67c4e9efed7cc,Removes the constituency parser (#3944),23,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,3,2,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,37,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('AlmostEqual', '(sum(class_distribution), 1.0, places=4)'), ('AlmostEqual', '(sum(class_distribution), 1.0, places=4)'), ('AlmostEqual', '(sum(class_distribution), 1.0, places=4)')]","['def setUp(self):', 'def setUp(self):']",[],['def tearDown(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'tokens == [', 'pos_tags == [', 'spans == enumerate_spans(tokens)', 'fields[] == gold_tree', 'fields[] == tokens', 'correct_spans_and_labels[span] == label', 'tokens == [', 'pos_tags == [', 'spans == enumerate_spans(tokens)', 'fields[] == gold_tree', 'fields[] == tokens', 'correct_spans_and_labels[span] == label', 'tree == Tree.fromstring(', 'spans == [((0, 1), )]', 'span_dict == {', 'set(decode_output_dict.keys()) == {', 'in metric_keys', 'in metric_keys', 'in metric_keys', 'resolved_spans == [', 'tree == correct_tree', 'tree == correct_tree', 'tree == correct_tree', 'len(result[]) == 21  # number of possible substrings of the sentence.', 'len(result[]) == 21', 'result[]', 'isinstance(result[], str)', 'len(result[]) == 21  # number of possible substrings of the sentence.', 'len(result[]) == 21', 'result[]', 'isinstance(result[], str)', 'len(result[]) == 36  # number of possible substrings of the sentence.', 'len(result[]) == 36', 'result[]', 'isinstance(result[], str)', 'correct_tree == hierplane_tree']",[],[],[],[],[],[],[],[],[],[],[],[]
1909,Evan Pete Walsh,epwalsh10@gmail.com,2020-03-13 16:51:17-07:00,b41f90ec23cc43ac380b14aa314e2975d67e857d,https://github.com/allenai/allennlp/commit/b41f90ec23cc43ac380b14aa314e2975d67e857d,Remove unnecessary epoch param in Scheduler.step() (#3945),10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['optimizer.param_groups[0][] == 0.5 ** 3', 'new_trainer._learning_rate_scheduler.last_epoch == 1']",[],[],[],[],[],[],[],[],[],[],[],[],"['optimizer.param_groups[0][] == 1.0', 'new_trainer._learning_rate_scheduler.lr_scheduler.last_epoch == 1']",[],[],[],[],[],[],[],[],[],[],[],[]
1910,Evan Pete Walsh,epwalsh10@gmail.com,2020-03-14 09:09:39-07:00,0fefe24fd42f5f0ac160b363f800de88076e1335,https://github.com/allenai/allennlp/commit/0fefe24fd42f5f0ac160b363f800de88076e1335,"clean up copynet (#3943)

Co-authored-by: Michael Schmitz <MichaelS@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1911,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-03-16 09:45:04-07:00,3b8e6e39882123762d275be882fcbfdf77afbf6e,https://github.com/allenai/allennlp/commit/3b8e6e39882123762d275be882fcbfdf77afbf6e,"Bump conllu from 2.3 to 2.3.2 (#3952)

Bumps [conllu](https://github.com/EmilStenstrom/conllu) from 2.3 to 2.3.2.
- [Release notes](https://github.com/EmilStenstrom/conllu/releases)
- [Commits](https://github.com/EmilStenstrom/conllu/commits)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1912,Matt Gardner,mattg@allenai.org,2020-03-16 09:55:10-07:00,5ff70e92d20d63989072caeb1faff16654e14dde,https://github.com/allenai/allennlp/commit/5ff70e92d20d63989072caeb1faff16654e14dde,"Simplifying some parameters in the trainer (#3949)

* Simplifying some parameters in the trainer

* remove old test, fix last old name problem

* remove unused imports",14,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],"[('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError):')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1913,Santiago Castro,sacastro@umich.edu,2020-03-16 12:58:36-04:00,0608f58ca54c35011704a75f295ef8c053c622b1,https://github.com/allenai/allennlp/commit/0608f58ca54c35011704a75f295ef8c053c622b1,Remove non-existent `batch_first` usage (#3950),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1914,Matt Gardner,mattg@allenai.org,2020-03-16 10:21:21-07:00,dcc78d84c50449b7178f3c26307618c2e22aa35f,https://github.com/allenai/allennlp/commit/dcc78d84c50449b7178f3c26307618c2e22aa35f,Fix bare string from params error (#3946),3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['data_loader.batch_sampler.sampler.__class__.__name__ == ', 'data_loader.batch_sampler.sampler.data_source is dataset']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1915,Matt Gardner,mattg@allenai.org,2020-03-16 10:29:07-07:00,58dd029793d8f8e7f496c28b379f663b8962bbc1,https://github.com/allenai/allennlp/commit/58dd029793d8f8e7f496c28b379f663b8962bbc1,"Give better error message for malformed configuration file (#3948)

* Give better error message for malformed configuration file

* black

* flake

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError, match=)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1916,Matt Gardner,mattg@allenai.org,2020-03-16 10:31:39-07:00,be62ec35c160dd893b4524255a7d4b75076143c6,https://github.com/allenai/allennlp/commit/be62ec35c160dd893b4524255a7d4b75076143c6,"Make kwargs inference work with arbitrary multiple inheritance order (#3947)

* Make kwargs inference work with arbitrary multiple inheritance order

* black

* remove extra import

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['b.b == 5', 'b.a == 4', 'b.b == 5', 'b.a == 4']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1917,Dirk Groeneveld,dirkg@allenai.org,2020-03-16 10:43:33-07:00,c26f04a0b5f7af87316c011f917cafe3b20b8c83,https://github.com/allenai/allennlp/commit/c26f04a0b5f7af87316c011f917cafe3b20b8c83,Ignore IntelliJ files,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1918,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-03-16 18:06:18+00:00,a078c91eaba4b78c21a65bec9fa98275de31e5fc,https://github.com/allenai/allennlp/commit/a078c91eaba4b78c21a65bec9fa98275de31e5fc,Bump pre-commit from 2.1.1 to 2.2.0 (#3942),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1919,Wei Qiu,wei@qiu.es,2020-03-17 22:36:32+08:00,9bbf415e0cb3e4b9761acacdee3c9813937c12e0,https://github.com/allenai/allennlp/commit/9bbf415e0cb3e4b9761acacdee3c9813937c12e0,pads in a more pythonic way which is significantly faster. (#3956),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1920,Dirk Groeneveld,dirkg@allenai.org,2020-03-17 10:54:04-07:00,61ec73b3ad9d8c4524789814bfa687888a71b996,https://github.com/allenai/allennlp/commit/61ec73b3ad9d8c4524789814bfa687888a71b996,"Removes language models and seq2seq models (#3957)

* Removes language models and seq2seq models

* Fix import

* Remove some seq2seq tests

* We need this test fixture after all",133,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,5,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,161,3,0,0,0,0,0,3,3,3,0,0,3,[],[],[],[],[],[],[],[],[],[],[],[],"[('Equal', '(text, [])'), ('Equal', '('), ('True', '(str(expected_batch.fields[k]) == str(batch.fields[k]))'), ('Equal', '(k, 99)'), ('Equal', '(k, 7)')]","['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self.vocab.get_vocab_size() > 5', 'len(self.instances) == 2', 'set(self.instances[0].fields.keys()) == set(', '[t.text for t in fields[].tokens] == [', 'fields[] == [', '[t.text for t in fields[].tokens] == [', 'fields[] == [', 'list(source_token_ids) == [', 'list(target_token_ids) == [', 'tensor[1].item() != self.vocab.get_token_index(DEFAULT_OOV_TOKEN, )', '[t.text for t in instance[]', '[i.sequence_index for i in instance[]] == [3]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tensor_dict[].numpy().tolist() == [2, 3, 4, 5, 6, 7]', 'tensor_dict[].numpy().tolist() == [2]', 'tensor_dict[].numpy().tolist() == [[3]]', '[t.text for t in instance[]] == [', '[i.sequence_index for i in instance[]] == [6]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'target_ids[0] == bert_token_ids[1]', '[t.text for t in instance[]', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'tensor_dict[].numpy().tolist() == [2, 3, 4]', 'tensor_dict[].numpy().tolist() == [2]', '[t.text for t in instance[]] == [', '[t.text for t in instance[]', 'tensor_dict.keys() == {}', 'target_ids[0] == bert_token_ids[5]', 'len(instances) == 3', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', 'len(instances) == 3', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', 'len(instances) == 3', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', 'reader._source_max_exceeded == 2', 'reader._target_max_exceeded == 1', 'len(instances) == 3', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', 'len(instances) == 3', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', 'len(instances) == 1', '[t.text for t in fields[].tokens] == [', '[t.text for t in fields[].tokens] == [', 'attack is not None', 'in attack', 'in attack', 'in attack', 'len(attack[][0]) == len(', 'attack[]', 'interpretation is not None', 'in interpretation', ']', 'len(grad_input_1) == 16  # 16 words in input', 'set(result) == {', 'tuple(embeddings.shape) == self.expected_embedding_shape', 'in decode_output_dict', 'in decode_output_dict', 'vocab.get_vocab_size(self.model._target_namespace) == 8', 'not in vocab._token_to_index[self.model._target_namespace]', 'not in vocab._token_to_index[self.model._target_namespace]', ']', 'list(source_tokens[].size()) == [11]', 'list(target_tokens[].size()) == [10]', 'target_tokens[][0] == self.model._start_index', 'target_tokens[][4] == self.model._oov_index', 'target_tokens[][5] == self.model._oov_index', 'target_tokens[][-1] == self.model._end_index', 'list(input_choices.size()) == [3]', 'list(selective_weights.size()) == [3, 3]', 'target_vocab_size == 8', 'oov_index not in [5, 6]', 'list(final_probs.size()) == [2, target_vocab_size + 3]', 'tok_index not in [end_index, pad_index, oov_index]', 'len(predicted_tokens) == 2', 'len(predicted_tokens[0]) == 2', 'len(predicted_tokens[1]) == 2', 'predicted_tokens[0][0] == []', 'predicted_tokens[0][1] == []', 'len(predicted_tokens) == 2', 'predicted_tokens[0] == []', 'predicted_tokens[1] == []', 'numpy.equal(expected_loss.data.numpy(), actual_loss.data.numpy())', 'in decode_output_dict', 'in decode_output_dict', 'output_dict_greedy[]', 'set(result) == self.result_keys', 'tuple(embeddings.shape) == self.expected_embedding_shape', 'predictions is not None', 'isinstance(head, BertLanguageModelHead)', 'head.get_input_dim() == 768', 'head.get_output_dim() == 30522', 'tuple(logits.size()) == (1, 30522)', 'isinstance(head, Gpt2LanguageModelHead)', 'head.get_input_dim() == 768', 'head.get_output_dim() == 50257', 'tuple(logits.size()) == (1, 50257)', 'auto_regressive_seq_decoder.forward(encoder_out) == {}', 'loss.shape == torch.Size([]) and loss.requires_grad', 'in auto_regressive_seq_decoder.forward(encoder_out)', 'predicted_tokens == tokens_ground_truth', 'predicted_tokens == tokens_ground_truth', 'auto_regressive_seq_decoder.get_metrics()[] == 1.388809517005903e-11', 'auto_regressive_seq_decoder.get_metrics()[] == 0.0', 'auto_regressive_seq_decoder.get_metrics()[] == 1 / 3', 'list(decoder_init_state[].shape) == [batch_size, decoder_inout_dim]', 'list(decoder_init_state[].shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(decoded_vec.shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(decoded_vec.shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(next_state[].shape) == [batch_size, decoder_inout_dim]', 'list(decoded_vec.shape) == [batch_size, decoder_inout_dim]', 'decoder_init_state == {}', 'next_state == {}', 'list(decoded_vec.shape) == [batch_size, prev_timesteps, decoder_inout_dim]', 'list(output.size()) == [5, 10, 64]', 'len(output) == 2', 'list(concat_layers.size()) == [5, 2, 10, 64]', '(', '(', '(', '(', '(', '(', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}', 'len(new_instances) == 1', 'in new_instances[0]', 'len(new_instances[0][].tokens) == 2  # should have added two words', 'len(new_instances) == 1', 'in new_instances[0]', 'len(new_instances[0][].tokens) == 1  # should have added one word', 'predicted_tokens is not None', 'isinstance(predicted_tokens, list)', 'all(isinstance(x, str) for x in predicted_tokens)', 'predicted_tokens is not None', 'isinstance(predicted_tokens, list)', 'all(isinstance(x, str) for x in predicted_tokens)', 'len(output_dict[]) == model._beam_search.beam_size', 'len(output_dict[]) == model._beam_search.beam_size', 'all(isinstance(x, str) for x in predicted_tokens)', 'end_token not in predicted_tokens']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],"['(, (True, False))', '()))', '()))']","['parametrize(, (True, False))', 'parametrize()))', 'parametrize()))']","['mark.parametrize(, (True, False))', 'mark.parametrize()))', 'mark.parametrize()))']",[],[],"['import pytest', 'import pytest', 'import pytest']"
1921,Evan Pete Walsh,epwalsh10@gmail.com,2020-03-17 13:54:05-07:00,76535ed3b0bcec68cd97e7179aed0631cae3488c,https://github.com/allenai/allennlp/commit/76535ed3b0bcec68cd97e7179aed0631cae3488c,gitignore doc artifacts so you can easily build docs locally (#3958),4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1922,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-03-17 15:31:17-07:00,02d5ddeef16a767bc77f9845bccc9ad4c47ad239,https://github.com/allenai/allennlp/commit/02d5ddeef16a767bc77f9845bccc9ad4c47ad239,Make masks in indexers bools (#3959),12,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indexed[] == [True] * len(expected_ids)', 'indexed[] == [True] * 7  # original length', 'indexed[] == [True] * len(text)', 'indexed[] == [True] * len(expected_ids)', 'indexed[] == [True] * len(expected_ids)', 'indexed[] == [True] * len(text)', 'indexed[] == [True] * 7', 'output_dict[] < 50']",[],[],[],[],[],[],[],[],[],[],[],[],"['indexed[] == [1] * len(expected_ids)', 'indexed[] == [1] * 7  # original length', 'indexed[] == [1] * len(text)', 'indexed[] == [1] * len(expected_ids)', 'indexed[] == [1] * len(expected_ids)', 'indexed[] == [1] * len(text)', 'indexed[] == [1] * 7']",[],[],[],[],[],[],[],[],[],[],[],[]
1923,Dirk Groeneveld,dirkg@allenai.org,2020-03-18 11:56:38-07:00,e20997059a6d7db32cdd56df77d710b564349957,https://github.com/allenai/allennlp/commit/e20997059a6d7db32cdd56df77d710b564349957,Moving some more seq2seq code that I missed the first time (#3961),4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1924,Matt Gardner,mattg@allenai.org,2020-03-20 16:34:47-07:00,d1a0c56d52aeb224fd836d87d9098a03dbef7980,https://github.com/allenai/allennlp/commit/d1a0c56d52aeb224fd836d87d9098a03dbef7980,"Move Tensorboard logic into TensorboardWriter (#3963)

* Move Tensorboard logic into TensorboardWriter

* black",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1925,Matt Gardner,mattg@allenai.org,2020-03-21 08:59:57-07:00,236e1fd01ca30409cd736625901292609009f5c4,https://github.com/allenai/allennlp/commit/236e1fd01ca30409cd736625901292609009f5c4,"Move checkpointing logic into checkpointer, remove old callbacks (#3968)

* Move checkpointing logic into checkpointer

* use contextmanager

* fix test that was checking default num checkpoints

* fix more tests that depended on more than 2 checkpoints",17,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1926,Matt Gardner,mattg@allenai.org,2020-03-23 11:37:22-07:00,83163aab50108ce7f891cd73e940bfe60439a098,https://github.com/allenai/allennlp/commit/83163aab50108ce7f891cd73e940bfe60439a098,"A few misc doc fixes (#3975)

* find learning rate

* Remove some module docstrings, test better param formatting",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1927,Matt Gardner,mattg@allenai.org,2020-03-23 11:38:18-07:00,34ebca646cb3956b868e2c4d06069443e11f42e9,https://github.com/allenai/allennlp/commit/34ebca646cb3956b868e2c4d06069443e11f42e9,"Add register information to all docstrings (#3972)

* Add register information to all docstrings

* black",88,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1928,Matt Gardner,mattg@allenai.org,2020-03-23 13:35:06-07:00,2a1b528f402adf8c773b032cd59d54d45e7bcf6f,https://github.com/allenai/allennlp/commit/2a1b528f402adf8c773b032cd59d54d45e7bcf6f,"Allow CRF to compute loss just for single span prediction (#3971)

* Allow CRF to compute loss just for single span prediction

* Don't assume O is index 0

* also fix simple tagger

* Don't break models that don't have O tags...

* remove prescriptive comment",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,3,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['flag_field.get_padding_lengths() == {}', 'FlagField(value).as_tensor({}) == value', 'batched_value == value']","['(ValueError)', '(ValueError)', '(ValueError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
1929,Matt Gardner,mattg@allenai.org,2020-03-23 17:32:03-07:00,15df437c202a678aa6e8c16a3567f14bdcef547b,https://github.com/allenai/allennlp/commit/15df437c202a678aa6e8c16a3567f14bdcef547b,Add batch and epoch callbacks to the trainer (#3970),5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['trainer.batch_callback_calls == expected_calls', 'trainer.epoch_callback_calls == expected_calls']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1930,Matt Gardner,mattg@allenai.org,2020-03-24 09:56:14-07:00,c578eeb4135ae52e66b44799399ae05f17ddd755,https://github.com/allenai/allennlp/commit/c578eeb4135ae52e66b44799399ae05f17ddd755,Remove dataset.py (#3980),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1931,Matt Gardner,mattg@allenai.org,2020-03-24 10:04:54-07:00,6c02b743ad3859e05eeb980298e54acf3fbd9788,https://github.com/allenai/allennlp/commit/6c02b743ad3859e05eeb980298e54acf3fbd9788,Add __len__ to FlagField (#3981),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1932,Dirk Groeneveld,dirkg@allenai.org,2020-03-25 10:20:55-07:00,95380aacbfa612d28ce71d8fc957877a60bff60e,https://github.com/allenai/allennlp/commit/95380aacbfa612d28ce71d8fc957877a60bff60e,Fix typo,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1933,Matt Gardner,mattg@allenai.org,2020-03-25 11:45:54-07:00,d595f2754b75adb9e210a2cec8d51d74d471cba2,https://github.com/allenai/allennlp/commit/d595f2754b75adb9e210a2cec8d51d74d471cba2,"Shuffle batches in bucket sampler (#3985)

* Shuffle batches in bucket sampler

* fix test

* make test more aggressive

* better version of more aggressive test",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['group in expected_groups', 'expected_groups == []']",[],[],[],[],[],[],[],[],[],[],[],[],['grouped_instances == ['],[],[],[],[],[],[],[],[],[],[],[],[]
1934,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-03-25 13:37:56-07:00,085fb502bec2747d86def0a344619349b0f7a5b4,https://github.com/allenai/allennlp/commit/085fb502bec2747d86def0a344619349b0f7a5b4,"Bump mypy from 0.761 to 0.770 (#3938)

* Bump mypy from 0.761 to 0.770

Bumps [mypy](https://github.com/python/mypy) from 0.761 to 0.770.
- [Release notes](https://github.com/python/mypy/releases)
- [Commits](https://github.com/python/mypy/compare/v0.761...v0.770)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* Add type annotation

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Zhaofeng Wu <wuzhaofeng1997@gmail.com>",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1935,Dirk Groeneveld,dirkg@allenai.org,2020-03-26 11:32:16-07:00,04a3bde737f7896a7d04ff24a38b105914a2c5c3,https://github.com/allenai/allennlp/commit/04a3bde737f7896a7d04ff24a38b105914a2c5c3,Export Batch at the appropriate level (#3991),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1936,Dirk Groeneveld,dirkg@allenai.org,2020-03-27 09:46:11-07:00,adeb1b1278619ff2d74d4fd82825e50a36f95ff4,https://github.com/allenai/allennlp/commit/adeb1b1278619ff2d74d4fd82825e50a36f95ff4,Find the vocab even in Albert (#3993),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1937,Jacob Danovitch,jacobdanovitch@cmail.carleton.ca,2020-03-29 17:45:41-04:00,4b7fafaaac52371f2d536fef07a5615a28097d53,https://github.com/allenai/allennlp/commit/4b7fafaaac52371f2d536fef07a5615a28097d53,Predictor eval by default (#3899),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1938,Dirk Groeneveld,dirkg@allenai.org,2020-03-31 17:28:08-07:00,01e2ad83afd612d5ebbb5ef93d0004a4d6dfd9a1,https://github.com/allenai/allennlp/commit/01e2ad83afd612d5ebbb5ef93d0004a4d6dfd9a1,"Pad empty text fields (#3999)

* Fix for padding empty text fields

* Test for padding empty text fields

* PretrainedTransformerIndexer should now always return a type_id field

* Fix test",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tensors[].size() == (2, 10)', 'tensors[][0, 0] == True  # noqa: E712', 'tensors[][0, 9] == False  # noqa: E712', '(tensors[][1, :] == False).all()  # noqa: E712', 'tensors[].size() == (2, 10)', 'tensors[][0, 0] == 2', 'tensors[][0, 9] == 0', '(tensors[][1, :] == 0).all()', 'tensors[].size() == (2, 10)', 'tensors[][0, 0] == 1', 'tensors[][0, 9] == 0', '(tensors[][1, :] == 0).all()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1939,Mateusz Klimaszewski,mk.klimaszewski@gmail.com,2020-04-03 21:08:30+02:00,3af8b29079b435e3cf227dd4685c9cba2f21972a,https://github.com/allenai/allennlp/commit/3af8b29079b435e3cf227dd4685c9cba2f21972a,Add env variable for log level configuration (#4006),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1940,Mateusz Klimaszewski,mk.klimaszewski@gmail.com,2020-04-04 00:10:55+02:00,a5bf029a996c3ed827a2b23a2d4636aa8b680dd6,https://github.com/allenai/allennlp/commit/a5bf029a996c3ed827a2b23a2d4636aa8b680dd6,"Add separate logging for regularization loss. (#4008)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(penalty == training_batch_outputs[]).all()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1941,John Giorgi,johnmgiorgi@gmail.com,2020-04-03 19:17:10-04:00,b837ad93df81b743ebc22647c842c38c500c617f,https://github.com/allenai/allennlp/commit/b837ad93df81b743ebc22647c842c38c500c617f,"Persist/load amp state during training (#3992)

* Persist/load amp state during training

* Intialize model when loading if trained with amp

* Persist/load amp state during training

* Intialize model when loading if trained with amp

* Log warning if loading amp model but amp is none

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1942,Dirk Groeneveld,dirkg@allenai.org,2020-04-03 17:39:43-07:00,59bb3321a477130550eee1b1a899494db34f3d73,https://github.com/allenai/allennlp/commit/59bb3321a477130550eee1b1a899494db34f3d73,"Docs script fixes (#4016)

* Pipefail

* Makes the doc script work on MacOS",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1943,Dirk Groeneveld,dirkg@allenai.org,2020-04-03 18:23:49-07:00,49c17a3cc4a49318fa1d2c74795782d646674bc9,https://github.com/allenai/allennlp/commit/49c17a3cc4a49318fa1d2c74795782d646674bc9,"New version of transformers (#4018)

* New version of transformers

* Specify an upper bound for the transformers",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1944,Max Del,max.del.edu@gmail.com,2020-04-04 18:32:12+03:00,59144b4657762a825157c7b309c694f52909a370,https://github.com/allenai/allennlp/commit/59144b4657762a825157c7b309c694f52909a370,"Fetch transformers vocabs automatically (#4019)

* Fetch transformers vocab automatically

* Make linter happy",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1945,sun-xiaoyu,43569888+sun-xiaoyu@users.noreply.github.com,2020-04-04 23:33:39+08:00,478a2b0b183703251b1d78d0f4851ca054f5214e,https://github.com/allenai/allennlp/commit/478a2b0b183703251b1d78d0f4851ca054f5214e,"Add sanitize_wordpiece for ALBERT (#4020)

Co-authored-by: sunxiaoyu <xiaoyu_sun@shannonai.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1946,John Giorgi,johnmgiorgi@gmail.com,2020-04-04 11:42:59-04:00,b49aff6aac4e9912564ee8235250d50c9d17e53f,https://github.com/allenai/allennlp/commit/b49aff6aac4e9912564ee8235250d50c9d17e53f,"Fix amp initialize issues in Model._load (#4022)

* Fix mispelling in amp initialize method

* Fix mispelling in doc string

* Move model to device before amp.initialize call",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1947,Max Del,max.del.edu@gmail.com,2020-04-05 18:19:37+03:00,2ca9b5eb84f6128349b803a8b8a79c2c041e6632,https://github.com/allenai/allennlp/commit/2ca9b5eb84f6128349b803a8b8a79c2c041e6632,"Add ability to specify custom epoch size (#4021)

* Add cusom epoch size feature

* Make flake happy

* Add unit tests

* Move functionality from trainer to Allennlp's DataLoader

* Fix doc

Co-Authored-By: Matt Gardner <mattg@allenai.org>

* Revert trainer

* Fix tests

* Add newline

Co-authored-by: Matt Gardner <mattg@allenai.org>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['trainer._batch_num_total == 0', 'epoch == num_epochs - 1', 'trainer._batch_num_total == num_epochs * batches_per_epoch', 'trainer._batch_num_total == 0', 'epoch == num_epochs - 1', 'trainer._batch_num_total == num_epochs * batches_per_epoch', 'trainer._batch_num_total == 0', 'epoch == num_epochs - 1', 'trainer._batch_num_total == num_epochs * batches_per_epoch']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1948,John Giorgi,johnmgiorgi@gmail.com,2020-04-05 11:31:11-04:00,d66db44dfe8072f0b8bac2770968d996664e683b,https://github.com/allenai/allennlp/commit/d66db44dfe8072f0b8bac2770968d996664e683b,"Decouple generator and filepath to fix pickle bug (#4026)

* Decouple generator and filepath to fix pickle bug

* Update allennlp/data/dataset_readers/dataset_reader.py

Co-authored-by: Matt Gardner <mattg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1949,Mateusz Klimaszewski,mk.klimaszewski@gmail.com,2020-04-08 00:08:32+02:00,9a015bb0eb0a69c4d58759414e0cdfc99fdddd4e,https://github.com/allenai/allennlp/commit/9a015bb0eb0a69c4d58759414e0cdfc99fdddd4e,Fix some external url formatting. (#4004),10,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1950,Max Del,max.del.edu@gmail.com,2020-04-08 02:03:10+03:00,0018ff82a99860f7a9350eff88b7c03789d46224,https://github.com/allenai/allennlp/commit/0018ff82a99860f7a9350eff88b7c03789d46224,"Fix for loading IterableDatasets with undefined length (#4028)

* Make DataLoader better work with IterableDatasets

* Simplify

* Simplify

* Fix length method

* Fix typoin loader, improve test

* Add test for lazy loader

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['trainer._batch_num_total == 0', 'epoch == num_epochs - 1', 'trainer._batch_num_total == num_epochs * 2', 'trainer._batch_num_total == 0', 'epoch == num_epochs - 1', 'trainer._batch_num_total == num_epochs * batches_per_epoch']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1951,Dirk Groeneveld,dirkg@allenai.org,2020-04-07 16:13:00-07:00,6a940f92ab2ff1ae1fa91b10f8ff130355c6bc7f,https://github.com/allenai/allennlp/commit/6a940f92ab2ff1ae1fa91b10f8ff130355c6bc7f,Moving NER models to allennlp_models (#4032),20,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,27,1,0,0,0,0,0,4,4,4,0,0,3,[],[],[],[],[],[],[],[],[],[],[],[],"[('SetEqual', '(')]",['def setUp(self):'],[],[],[],[],[],[],[],[],"['probs.size() == (2, 7, self.model.vocab.get_vocab_size())']",[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 2', 'tokens == [', 'ccg_categories == [', 'original_pos_tags == [', 'modified_pos_tags == [', 'predicate_arg_categories == [', 'len(instances) == 2', 'tokens == [', 'fields[].labels == expected_labels', 'tokens == [', 'fields[].labels == expected_labels', 'tokens == []', 'fields[].labels == expected_labels', 'tokens == []', 'fields[].labels == expected_labels', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}', 'output_dict[] < 50', 'first_choices == output_dict[]', 'set(lengths) == {5}', 'all(tag in {} for tag in tags_used)', 'len(tags) == 2', 'len(tags[0]) == 7', 'len(tags[1]) == 7', 'tag in {}']",['(ConfigurationError)'],[],[],[],[],[],"['(, (True, False))', '())', '(, (True, False))', '())']","['parametrize(, (True, False))', 'parametrize())', 'parametrize(, (True, False))', 'parametrize())']","['mark.parametrize(, (True, False))', 'mark.parametrize())', 'mark.parametrize(, (True, False))', 'mark.parametrize())']",[],[],"['import pytest', 'import pytest', 'import pytest']"
1952,John Giorgi,johnmgiorgi@gmail.com,2020-04-08 13:15:51-04:00,c497103542096037dc21c24466127bc6c820e75b,https://github.com/allenai/allennlp/commit/c497103542096037dc21c24466127bc6c820e75b,"Allow user to provide opt_level to load_archive (#4027)

* Allow user to provide opt_level to load_archive

* Moved .cuda call in merge, fix

* Revert argument order, update docstring

* More detailed warning logs

* Remove ensemble model

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1953,Dirk Groeneveld,dirkg@allenai.org,2020-04-10 18:19:41-07:00,051d2082641f6e38e9783de8bbfeeb187b7ad00c,https://github.com/allenai/allennlp/commit/051d2082641f6e38e9783de8bbfeeb187b7ad00c,"Moves NLI components (#4043)

* Correct `Optional` annotations

* Bring back ensemble

* Remove coref predictor that belongs into the models repo

* Remove unused test fixture

* Remove NLI configs that belong into the models repo

* Remove the ensemble class after all

* remove NLI models, update tests to use basic classifier

* black

* removing old fixtures

* fix dataset reader tests

* last one?

* Mode the Quora reader

* Move bimpm training config

* Makes the whitespace tokenizer visible again

Co-authored-by: Matt Gardner <mattg@allenai.org>",57,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,57,2,0,0,0,0,0,2,2,2,0,0,3,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],"['set(result.keys()) == {}', 'duplicate_reader.__name__ == ', 'tuple(original_weight.shape) == (213, 10)', 'tuple(extended_weight.shape) == (214, 10)', 'torch.all(original_weight == extended_weight[:213, :])', 'len(grads[][0]) == 5  # 9 words in hypothesis']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(result.keys()) == {}', 'duplicate_reader.__name__ == ', 'len(instances) == 3', '[t.text for t in fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 3', '[t.text for t in fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 3', '[t.text for t in fields[]', 'fields[]', 'in output_dict', 'in decode_output_dict', 'isinstance(model, DecomposableAttention)', 'tuple(original_weight.shape) == (24, 300)', 'tuple(extended_weight.shape) == (25, 300)', 'torch.all(original_weight == extended_weight[:24, :])', 'label_probs is not None', 'isinstance(label_probs, list)', 'len(label_probs) == 3', 'all(isinstance(x, float) for x in label_probs)', 'all(x >= 0 for x in label_probs)', 'sum(label_probs) == approx(1.0)', 'label_logits is not None', 'isinstance(label_logits, list)', 'len(label_logits) == 3', 'all(isinstance(x, float) for x in label_logits)', 'e / sumexps == approx(p)', 'len(results) == 2', 'label_probs is not None', 'isinstance(label_probs, list)', 'len(label_probs) == 3', 'all(isinstance(x, float) for x in label_probs)', 'all(x >= 0 for x in label_probs)', 'sum(label_probs) == approx(1.0)', 'label_logits is not None', 'isinstance(label_logits, list)', 'len(label_logits) == 3', 'all(isinstance(x, float) for x in label_logits)', 'e / sumexps == approx(p)', 'in new_instances[0].fields', 'in new_instances[0].fields', 'new_instances[0].fields[] is not None', 'new_instances[0].fields[] is not None', 'len(new_instances) == 1', 'in grads', 'grads[] is not None', 'len(grads[][0]) == 9  # 9 words in hypothesis', 'len(grads[][0]) == 5  # 5 words in premise']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],"['(, (True, False))', '(, (True, False))']","['parametrize(, (True, False))', 'parametrize(, (True, False))']","['mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))']",[],[],"['import pytest', 'import pytest', 'import pytest']"
1954,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-04-10 18:46:55-07:00,a8fa2d4b6925c5162109b6985e5ec1ce7c07c3e8,https://github.com/allenai/allennlp/commit/a8fa2d4b6925c5162109b6985e5ec1ce7c07c3e8,"Bump mkdocs-material from 4.6.3 to 5.0.1 (#4041)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 4.6.3 to 5.0.1.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/4.6.3...5.0.1)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1955,Wang Ran (),wrran@outlook.com,2020-04-14 01:42:25+08:00,f0f35e2c00bd5a890bac386189126858d28a650b,https://github.com/allenai/allennlp/commit/f0f35e2c00bd5a890bac386189126858d28a650b,Fix some typos in setup.py (#4063),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1956,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-04-13 18:08:45+00:00,108d9119758d01b6cf6299ad6243cbe8d694f2d7,https://github.com/allenai/allennlp/commit/108d9119758d01b6cf6299ad6243cbe8d694f2d7,Bump mkdocs-material from 5.0.1 to 5.1.0 (#4061),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1957,Dirk Groeneveld,dirkg@allenai.org,2020-04-14 14:37:12-07:00,cbebe90065d1814a3c02c73ec15369c85cd272c7,https://github.com/allenai/allennlp/commit/cbebe90065d1814a3c02c73ec15369c85cd272c7,Updates transformers library (#4067),1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1958,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-14 16:34:04-07:00,1791d71419bced2192f1d53875a9ed4c03e58094,https://github.com/allenai/allennlp/commit/1791d71419bced2192f1d53875a9ed4c03e58094,"move doc building logic to Makefile (#4066)

* move doc building to Makefile

* minor tweaks

* fix formatting

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1959,Tobias Rohde,tobiasr@uw.edu,2020-04-15 11:32:35-07:00,83792b69fcc8e3f148ef72b4119caab0c18df6b1,https://github.com/allenai/allennlp/commit/83792b69fcc8e3f148ef72b4119caab0c18df6b1,"Added method and test for sanitizing text that was tokenized with Sta (#4064)

* Added method and test for sanitizing text that was tokenized with Stanfords PTB tokenzier.

* Fixed inspection issues and fixed minor bug related to casing.
Added test case to ensure casing is preserved.

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['actual == expected'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1960,Dirk Groeneveld,dirkg@allenai.org,2020-04-15 13:54:51-07:00,dda76fd82e99ce21cba2e1345732fa859a20fc72,https://github.com/allenai/allennlp/commit/dda76fd82e99ce21cba2e1345732fa859a20fc72,"Some changes pulled from #3868 (#4068)

* Plan B for reading vocab

* Typos

* Disable fast tokenizers permanently

* Pick a less confusing kwarg

* Formatting

* Allow fast tokenizers with a warning

* Adds a test for use_fast

* Formatting",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1961,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-15 17:21:23-07:00,90e98e56c46bc466d4ad7712bab93566afe5d1d0,https://github.com/allenai/allennlp/commit/90e98e56c46bc466d4ad7712bab93566afe5d1d0,"Fix doc formatting and improve doc styling (#4072)

* switch to pydoc-markdown with custom processor

* add some extra css

* fixes

* fixes

* minor tweaks

* fixes

* add breadcrumbs

* fixes

* fix arg formatting

* fix

* fixes

* more fixes

* fix

* fix cross-refs within module

* fix dev requirements

* pin pydoc-markdown to latest commit

* small refactor and docstring fixes

* more small fixes",32,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1962,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-16 09:10:38-07:00,63f1dd6aefc338879111d33364cbf91a57532fc7,https://github.com/allenai/allennlp/commit/63f1dd6aefc338879111d33364cbf91a57532fc7,"ensure all API docs rebuilt when script changes, and always build from scratch in CI (#4074)

* ensure all API docs rebuilt when script changes

* better yet, force re-build from scratch

* build api docs at once, big speed up

* speed up more with multiprocessing

* improve script",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1963,Dirk Groeneveld,dirkg@allenai.org,2020-04-16 13:16:07-07:00,6056f1a12110990ae21fe4b62bf106d388e5d149,https://github.com/allenai/allennlp/commit/6056f1a12110990ae21fe4b62bf106d388e5d149,"Move sentiment analysis (#4073)

* Remove sentiment analysis

* Removing some unused test fixtures

* Removes some more unused fixtures

* Moves the graph parser

* No more docker config",29,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,29,10,0,0,0,0,0,1,1,1,0,0,2,[],[],[],[],[],[],[],[],[],[],[],[],[],"['def setUp(self):', 'def setUp(self):']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(instances) == 3', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 21', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 3', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'len(instances) == 2', '[t.text for t in fields[]', 'fields[]', '[t.text for t in fields[]', 'fields[]', 'reader._use_subtrees is True', 'reader._granularity == ', 'set(decode_output_dict.keys()) == {']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],"['import pytest', 'import pytest']"
1964,Santiago Castro,sacastro@umich.edu,2020-04-16 16:17:56-04:00,2a23f5a684e3af0870d5a2af2754043b4f60b464,https://github.com/allenai/allennlp/commit/2a23f5a684e3af0870d5a2af2754043b4f60b464,Fix typo in error message (#4077),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1965,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-16 15:05:36-07:00,25ba3a262ea32d18111549b6f394412305589842,https://github.com/allenai/allennlp/commit/25ba3a262ea32d18111549b6f394412305589842,Fix error message when top level config key missing (#4081),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1966,Dirk Groeneveld,dirkg@allenai.org,2020-04-16 15:22:37-07:00,25ed047d56b83bcd5eb456d344b469acd3413a9a,https://github.com/allenai/allennlp/commit/25ed047d56b83bcd5eb456d344b469acd3413a9a,Remove test that breaks with the release candidate,1,False,True,False,False,True,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],['class TestVersion(TestCase):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['version.prerelease == (,)', 'version.build == ()', 'version.prerelease == ()', 'version.build == ()', 'version.prerelease == (,)', 'version.build == (,)']",[],[],[],[],[],[],[],[],[],[],[],[]
1967,Dirk Groeneveld,dirkg@allenai.org,2020-04-16 15:30:09-07:00,59aca849f78eaf62b3b506027c9f72b2405195c1,https://github.com/allenai/allennlp/commit/59aca849f78eaf62b3b506027c9f72b2405195c1,bump version number to v1.0.0.rc1,7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1968,Dirk Groeneveld,dirkg@allenai.org,2020-04-16 15:58:00-07:00,3f5eabb2cb4d551c71e592c46e9617ddbddba98d,https://github.com/allenai/allennlp/commit/3f5eabb2cb4d551c71e592c46e9617ddbddba98d,Bump version numbers to v1.0.0.rc2-unreleased,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1969,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-17 13:39:44-07:00,51ef5b50fe6a9591014522d4885fa9a8fa373128,https://github.com/allenai/allennlp/commit/51ef5b50fe6a9591014522d4885fa9a8fa373128,improve sorting_key error message (#4083),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1970,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-17 15:04:09-07:00,1beddcdfb78a89eb44898882b8ecf5f91e104542,https://github.com/allenai/allennlp/commit/1beddcdfb78a89eb44898882b8ecf5f91e104542,a few more doc fixes (#4078),13,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1971,Dirk Groeneveld,dirkg@allenai.org,2020-04-17 18:09:48-07:00,b4e10dd198c9e7fa2ddf595dd4607336d4218b15,https://github.com/allenai/allennlp/commit/b4e10dd198c9e7fa2ddf595dd4607336d4218b15,Make sure the nightly build doesn't produce bogus version numbers,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1972,Dirk Groeneveld,dirkg@allenai.org,2020-04-20 11:40:21-07:00,6cb944c43cda33f3f870d8e253b424069ccdabe3,https://github.com/allenai/allennlp/commit/6cb944c43cda33f3f870d8e253b424069ccdabe3,"Correctly computes the number of training steps (#4099)

* Correctly computes the number of training steps

* Fixed expression

* Adds a test for counting the number of steps during training

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['batch_callback_counter == last_num_steps_per_epoch * number_of_epochs', 'batch_callback_counter == last_num_steps_per_epoch * number_of_epochs', 'normal_steps_per_epoch == math.ceil(last_num_steps_per_epoch / original_batch_size)', 'batch_callback_counter == last_num_steps_per_epoch * number_of_epochs', 'math.ceil(normal_steps_per_epoch / 3) == last_num_steps_per_epoch']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1973,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-20 16:36:17-07:00,24de9b170a360cb26f877299684f2c20e0ae4b46,https://github.com/allenai/allennlp/commit/24de9b170a360cb26f877299684f2c20e0ae4b46,"Add main CI workflow to GH Actions (#4097)

* add main CI workflow to GH Actions

* fix Makefile

* check large fiels

* fix

* try improve caching

* fix codecov

* fix

* try fix

* try fix path

* debug info

* try caching site-packages

* try caching

* cache whole python env

* check if cache works

* change pytest cmd

* add models tests

* fix

* fix

* add docs build

* ensure codecoverage computed correctly

* checkout v2 thx @bryant1410

* use codecov command to upload

* ensure wheel installed

* add test deployment step

* add docker job

* fix

* fix commit ref

* fix

* fix

* reorg and try docker direct

* only build docker on master

* clean up

* refactor

* finalize docker workflow

* add deployment step for docs

* add some comments",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1974,Annabelle Carrell,belle.carrell@gmail.com,2020-04-20 19:39:39-04:00,4eed5d4255c1c7c4a9f07a2d531f9e8e2a5d9889,https://github.com/allenai/allennlp/commit/4eed5d4255c1c7c4a9f07a2d531f9e8e2a5d9889,"Add custom 'logging.Logger' that has warn_once(), debug_once(), etc m (#4062)",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(f.readlines()) == 1', 'len(f.readlines()) == 1', 'len(f.readlines()) == 1', 'len(f.readlines()) == 1', 'len(f.readlines()) == 1', 'len(f.readlines()) == 1', 'len(self.logger._seen_msgs) == 1', 'isinstance(logger, AllenNlpLogger)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1975,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-20 16:55:18-07:00,c9b7cbd24ef9e2da31fbffff294b51b0f4cc15f9,https://github.com/allenai/allennlp/commit/c9b7cbd24ef9e2da31fbffff294b51b0f4cc15f9,Fixes for GitHub Actions (#4105),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1976,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-20 17:55:10-07:00,10fdf2744e3f7a8857a51ee90d7cf4a5938606fb,https://github.com/allenai/allennlp/commit/10fdf2744e3f7a8857a51ee90d7cf4a5938606fb,"More fixes to GitHub Actions (#4106)

* More fixes to GitHub Actions

* report code coverage from GH Actions

* add token

* try again

* add comment about codecov failures",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1977,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-21 07:43:53-07:00,15e6b031efb48db82c2dad19aa419fa543105852,https://github.com/allenai/allennlp/commit/15e6b031efb48db82c2dad19aa419fa543105852,"Fix docs workflow (#4107)

* fix docs build

* only run docker and docs in main repo",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1978,Michael Schmitz,MichaelS@allenai.org,2020-04-21 11:29:03-07:00,78325af19d7d417dcd83378793dbcd39684215d8,https://github.com/allenai/allennlp/commit/78325af19d7d417dcd83378793dbcd39684215d8,Update README.md (#4110),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1979,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-04-21 14:03:44-07:00,ece5c59df5ca2aece018caff3627318b58d1e3c6,https://github.com/allenai/allennlp/commit/ece5c59df5ca2aece018caff3627318b58d1e3c6,"Bump mkdocs-material from 5.1.0 to 5.1.1 (#4103)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.1.0 to 5.1.1.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.1.0...5.1.1)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1980,Santiago Castro,sacastro@umich.edu,2020-04-21 17:04:48-04:00,0638cbb249caff0174ee0b7a6f6c8c235443e798,https://github.com/allenai/allennlp/commit/0638cbb249caff0174ee0b7a6f6c8c235443e798,Fix param name in `GradientDescentTrainer` doc (#4091),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1981,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-21 14:31:19-07:00,b4c7d76cc1f1e9a039c2d27ad7ecbfd828a36ec2,https://github.com/allenai/allennlp/commit/b4c7d76cc1f1e9a039c2d27ad7ecbfd828a36ec2,"Adds release workflow, fixes logging test and docs workflow (#4112)",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1982,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-21 15:28:13-07:00,0056b9c16d8c200a88116abd51f3112d42f553fa,https://github.com/allenai/allennlp/commit/0056b9c16d8c200a88116abd51f3112d42f553fa,fix docs output directory (#4113),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1983,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-22 08:45:07-07:00,98a29533895dbf8ca27b3a252da1bdbb8409cb10,https://github.com/allenai/allennlp/commit/98a29533895dbf8ca27b3a252da1bdbb8409cb10,"Simplify pull request workflow (#4117)

* simplify pull request workflow

* tweak installation

* tweak job graph

* remove unneeded conditions",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1984,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-22 11:06:43-07:00,8be8e854c0da4fa36cb8c9af73655086722533d3,https://github.com/allenai/allennlp/commit/8be8e854c0da4fa36cb8c9af73655086722533d3,"Ensure all deps are up-to-date in CI (#4120)

* add flag to pip to ensure deps upgraded

* ensure apex installed last",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1985,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-22 11:43:55-07:00,f5a4f4ff67feeb5b53137c2cbb17a9ac5b33d642,https://github.com/allenai/allennlp/commit/f5a4f4ff67feeb5b53137c2cbb17a9ac5b33d642,"Update README with new CI links / badge (#4116)

* Update README with new CI links / badge

Also matches the formatting of the logo with what's in allennlp-models.

* Update for new workflow",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1986,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-22 17:39:56-07:00,5d58993943cb81d39acd35df79564e05a0423c29,https://github.com/allenai/allennlp/commit/5d58993943cb81d39acd35df79564e05a0423c29,add nightly release schedule (#4123),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1987,epwalsh,epwalsh10@gmail.com,2020-04-22 18:10:27-07:00,583ea41392d3c173b09bd9f0e2ee0ce2e6befc9e,https://github.com/allenai/allennlp/commit/583ea41392d3c173b09bd9f0e2ee0ce2e6befc9e,pypi release workflow HOT FIX,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1988,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-23 09:29:42-07:00,7b51c2220a0fb7f5a1a04be6b1979bb75b3804d4,https://github.com/allenai/allennlp/commit/7b51c2220a0fb7f5a1a04be6b1979bb75b3804d4,"Fix cron schedule (#4128)

This is what I originally intended",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1989,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-23 10:07:58-07:00,42b93872749e11447464cce5e68738fadaaef579,https://github.com/allenai/allennlp/commit/42b93872749e11447464cce5e68738fadaaef579,Simplify GitHub Actions job graph (#4129),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1990,Santiago Castro,santi.1410@hotmail.com,2020-04-23 14:42:02-04:00,fc824503a1fa37fcdadf178a86f174458f714896,https://github.com/allenai/allennlp/commit/fc824503a1fa37fcdadf178a86f174458f714896,Fix typo in `InitializerApplicator` docstring (#4100),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1991,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-04-23 12:37:49-07:00,66651d10a81cf754fefc82853d9821b1e4638be9,https://github.com/allenai/allennlp/commit/66651d10a81cf754fefc82853d9821b1e4638be9,"Bump pre-commit from 2.2.0 to 2.3.0 (#4127)

* Bump pre-commit from 2.2.0 to 2.3.0

Bumps [pre-commit](https://github.com/pre-commit/pre-commit) from 2.2.0 to 2.3.0.
- [Release notes](https://github.com/pre-commit/pre-commit/releases)
- [Changelog](https://github.com/pre-commit/pre-commit/blob/master/CHANGELOG.md)
- [Commits](https://github.com/pre-commit/pre-commit/compare/v2.2.0...v2.3.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* try pip issue work-around

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1992,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-23 12:54:04-07:00,8f8288bee9965a7f8929b701238565b66aeb8d99,https://github.com/allenai/allennlp/commit/8f8288bee9965a7f8929b701238565b66aeb8d99,"Fix version suffix in release job and make deps caching more robust (#4130)

* fix version suffix for releases

* ensure Python cached based on exact version",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1993,epwalsh,epwalsh10@gmail.com,2020-04-23 13:35:53-07:00,1dc05ddf67505e8a0b2e25d956c3cf4fb01b8ec4,https://github.com/allenai/allennlp/commit/1dc05ddf67505e8a0b2e25d956c3cf4fb01b8ec4,fix extract tag,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1994,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-24 08:31:59-07:00,b3fcf60054ef8d16017f0e97c6bda82079e695db,https://github.com/allenai/allennlp/commit/b3fcf60054ef8d16017f0e97c6bda82079e695db,"Push 'latest' tag versions of Docker images (#4134)

* improve Docker builds in CI

* hold off on caching",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1995,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-24 11:30:42-07:00,1384a70c8a231000ac114de2db4f45bfd04850f6,https://github.com/allenai/allennlp/commit/1384a70c8a231000ac114de2db4f45bfd04850f6,"document release process (#4133)

* document release process

* Format list.

* add more

* Update RELEASE_PROCESS.md

* Update RELEASE_PROCESS.md

Co-authored-by: Michael Schmitz <MichaelS@allenai.org>",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1996,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-24 12:03:06-07:00,2a063d0e6f28c34c4d18bc9d4a02ba3ffd5ddc63,https://github.com/allenai/allennlp/commit/2a063d0e6f28c34c4d18bc9d4a02ba3ffd5ddc63,"Remove unused Dockerfiles (#4137)

* Remove unused Dockerfiles

* fix comment typo

* make Docker image building process more clear

* move instructions to readme

* point docker tag in readme to latest",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1997,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-04-24 12:59:29-07:00,5e8b2ba5928de53cec72240bfcd3b1677a9575c4,https://github.com/allenai/allennlp/commit/5e8b2ba5928de53cec72240bfcd3b1677a9575c4,"Update torch requirement from <=1.4.0,>1.3.1 to >1.3.1,<1.6.0 (#4118)

* Update torch requirement from <=1.4.0,>1.3.1 to >1.3.1,<1.6.0

Updates the requirements on [torch](https://github.com/pytorch/pytorch) to permit the latest version.
- [Release notes](https://github.com/pytorch/pytorch/releases)
- [Commits](https://github.com/pytorch/pytorch/compare/v1.4.0a0...v1.5.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* try adding pip flag

* catch IndexError

* tighten torch pin

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1998,Dirk Groeneveld,dirkg@allenai.org,2020-04-24 14:40:03-07:00,4b8edc5e9b2f3c402550fd78e1d2d7f73c1ac760,https://github.com/allenai/allennlp/commit/4b8edc5e9b2f3c402550fd78e1d2d7f73c1ac760,Some tokenizers don's have padding tokens (#4131),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
1999,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-24 15:19:13-07:00,6ea6c5941162c347b81872b048a186254ab87b95,https://github.com/allenai/allennlp/commit/6ea6c5941162c347b81872b048a186254ab87b95,test logging errors work-around (#4139),1,False,True,False,False,True,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2000,Junlin Wang,junlinwang18@gmail.com,2020-04-24 17:27:57-07:00,d709e59ff3f54e137ea473d411056f68c197c266,https://github.com/allenai/allennlp/commit/d709e59ff3f54e137ea473d411056f68c197c266,"modified the make_output_human_readable method in basic_classifier for allennlp-demo (#4038)

* modified the make_output_human_readable method in basic_classifier, so that the outputdict can contain a tokens field for allennlp-demo. This fix is only for BERT and may not be compatiable to other models.

* added namespace to the constructer

* Formatting

* Fix tests

* Formatting

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(result.keys()) == {}', 'set(result.keys()) == {}', 'set(result.keys()) == {}', 'set(result.keys()) == {}', 'set(result.keys()) == {', 'set(result.keys()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(result.keys()) == {}', 'set(result.keys()) == {}', 'set(result.keys()) == {}', 'set(result.keys()) == {}', 'set(result.keys()) == {}', 'set(result.keys()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[]
2001,Bharat Raghunathan,bharatraghunthan9767@gmail.com,2020-04-27 20:52:49+05:18,c2e1be9ce1af83de8542f2aa26b6da69333b6f08,https://github.com/allenai/allennlp/commit/c2e1be9ce1af83de8542f2aa26b6da69333b6f08,Fix broken link pointing to GitHub Actions (#4144),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2002,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-27 10:49:17-07:00,b04d3171a67ff7d06659b8b41b4f118dd86f598e,https://github.com/allenai/allennlp/commit/b04d3171a67ff7d06659b8b41b4f118dd86f598e,"hard-code version (#4142)

* hard-code version

* fixes

* improve get_version script",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2003,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-27 12:08:07-07:00,24e11a870c31d7cfed448ae16b87856d3c7d85b0,https://github.com/allenai/allennlp/commit/24e11a870c31d7cfed448ae16b87856d3c7d85b0,"add shortcuts for 'stable' and 'latest' to docs (#4138)

* add shortcuts for 'stable' and 'latest' to docs

* fix

* handle stable and latest better

* only setup ssh and configure git in main repo

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2004,epwalsh,epwalsh10@gmail.com,2020-04-27 12:16:36-07:00,4720199fb2d831dac8bd68c79c3e03cc92fae87b,https://github.com/allenai/allennlp/commit/4720199fb2d831dac8bd68c79c3e03cc92fae87b,docs workflow quick fix,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2005,epwalsh,epwalsh10@gmail.com,2020-04-27 13:03:12-07:00,9766eb407e7d83a0bf2150ad054a7c8e2da4ae2b,https://github.com/allenai/allennlp/commit/9766eb407e7d83a0bf2150ad054a7c8e2da4ae2b,quick fix to docs job,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2006,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-27 13:29:28-07:00,bc2435d47c1235bf3bcc268de3a301c015d5d84e,https://github.com/allenai/allennlp/commit/bc2435d47c1235bf3bcc268de3a301c015d5d84e,Update RELEASE_PROCESS.md (#4151),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2007,Santiago Castro,santi.1410@hotmail.com,2020-04-27 20:12:00-04:00,27e374ac6e6aaae6565751970d5f592ff6b855de,https://github.com/allenai/allennlp/commit/27e374ac6e6aaae6565751970d5f592ff6b855de,"Fix `from_params` when the class has no registered impl (#4090)

* Add a test for from_params when the class has no registered impl

* Typo

* Inelegant fix for the problem of anonymous from_param classes

* more tests, better fix

* black, lint

* Register default checkpointer, add test for it

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Michael Schmitz <MichaelS@allenai.org>
Co-authored-by: Matt Gardner <mattg@allenai.org>",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError, match=)', '(ConfigurationError, match=)', '(ConfigurationError, match=)', '(ConfigurationError, match=)', '(ConfigurationError, match=)', '(ConfigurationError, match=)', '(ConfigurationError, match=)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2008,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-27 17:42:35-07:00,dfe8b1cea701ebfd28d8a4b4b35838a2eec51efc,https://github.com/allenai/allennlp/commit/dfe8b1cea701ebfd28d8a4b4b35838a2eec51efc,"clean up scripts dir (#4152)

* clean up scripts dir

* remove some more @matt-gardner",10,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2009,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-04-28 10:01:43-07:00,69e7511f261fc884cab962e9bef769958b8462ed,https://github.com/allenai/allennlp/commit/69e7511f261fc884cab962e9bef769958b8462ed,"Bump mkdocs-material from 5.1.1 to 5.1.3 (#4150)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.1.1 to 5.1.3.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.1.1...5.1.3)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2010,Dirk Groeneveld,dirkg@allenai.org,2020-04-28 11:02:49-07:00,0fe28393263864aa5d8b53b396af87de9ecb05ad,https://github.com/allenai/allennlp/commit/0fe28393263864aa5d8b53b396af87de9ecb05ad,"Fixes an error with pip (#4158)

* Fixes an error with pip

* Tabs vs. spaces

* Yes

* Kick GitHub",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2011,Dirk Groeneveld,dirkg@allenai.org,2020-04-28 11:26:22-07:00,b0c7ac76704b102f166d99d4f88ebea37b771d57,https://github.com/allenai/allennlp/commit/b0c7ac76704b102f166d99d4f88ebea37b771d57,Uninstall typing before running pip again (#4161),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2012,Dirk Groeneveld,dirkg@allenai.org,2020-04-28 11:32:45-07:00,9d8862a6ea50b28ff53a2d418b5500a0175cd471,https://github.com/allenai/allennlp/commit/9d8862a6ea50b28ff53a2d418b5500a0175cd471,"Move default predictors (#4154)

* Move DecomposableAttention test

* Move default predictors

* Fix test

* Productivity through formatting",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(self.outfile)', 'len(results) == 3', 'set(result.keys()) == {']",[],[],[],[],[],[],[],[],[],[],[],[],"['model_type not in DEFAULT_PREDICTORS', 'os.path.exists(self.outfile)', 'len(results) == 3', 'set(result.keys()) == {}']",[],[],[],[],[],[],[],[],[],[],[],[]
2013,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-28 13:23:02-07:00,d9dd5038eeaf5df203f54318e6816305ec0979db,https://github.com/allenai/allennlp/commit/d9dd5038eeaf5df203f54318e6816305ec0979db,ensure typing backport uninstalled first (#4162),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2014,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-28 14:29:09-07:00,af890b29dcaf82ae608913423c07176b71b68db8,https://github.com/allenai/allennlp/commit/af890b29dcaf82ae608913423c07176b71b68db8,add test for version convention (#4157),1,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['is_valid(version) is valid', 'is_valid(VERSION)']",[],[],[],[],[],[],[''],['parametrize('],['mark.parametrize('],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2015,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-28 14:35:47-07:00,11f4307d2c8a4d49e1bf8c89842b6e35719be373,https://github.com/allenai/allennlp/commit/11f4307d2c8a4d49e1bf8c89842b6e35719be373,"Reduce number of warnings seen after running tests (#4153)

* clean up a bunch of test warnings

* fix

* fix warnings from optimizers

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['tryfirst'],['mark.tryfirst'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2016,epwalsh,epwalsh10@gmail.com,2020-04-29 09:26:19-07:00,26e313b7d11eacf3a78c09c34608ad1bfd7db120,https://github.com/allenai/allennlp/commit/26e313b7d11eacf3a78c09c34608ad1bfd7db120,tick version to rc4 for nightly releases,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2017,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-29 15:26:35-07:00,4a6023b3ee692da50ff27126f331546e7c2f284a,https://github.com/allenai/allennlp/commit/4a6023b3ee692da50ff27126f331546e7c2f284a,"Fix logging (#4164)

* ensure error messages aren't duplicated in log streams

* attempt at fixing logging

* reorganize",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2018,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-29 16:48:43-07:00,08874e95026e1364dbe116752a7c0664af052965,https://github.com/allenai/allennlp/commit/08874e95026e1364dbe116752a7c0664af052965,remove elmo command (#4168),3,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,1,0,0,0,0,0,0,0,0,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(self.output_path)', 'set(h5py_file.keys()) == {}', 'embedding.shape == (3, len(sentence.split()), 32)', 'json.loads(h5py_file.get(}', 'os.path.exists(self.output_path)', 'set(h5py_file.keys()) == {}', 'embedding.shape == (len(sentence.split()), 32)', 'json.loads(h5py_file.get(}', 'os.path.exists(self.output_path)', 'set(h5py_file.keys()) == {}', 'embedding.shape == (len(sentence.split()), 32)', 'json.loads(h5py_file.get(}', 'os.path.exists(self.output_path)', 'set(h5py_file.keys()) == {}', 'h5py_file.get(sentence_id).shape == (3, len(sentence.split()), 32)', 'json.loads(h5py_file.get()[0]) == {', 'os.path.exists(self.output_path)', 'set(h5py_file.keys()) == set(sentences)', 'h5py_file.get(sentence).shape == (3, len(sentence.split()), 32)', 'os.path.exists(self.output_path)', 'set(h5py_file.keys()) == {}', 'h5py_file.get(sentence_id).shape == (3, len(sentence.split()), 32)', 'os.path.exists(self.output_path)', 'len(h5py_file.keys()) == 3', 'set(h5py_file.keys()) == {}', 'h5py_file.get(sentence_id).shape == (3, len(sentence.split()), 32)', 'len(loaded_sentences) == len(loaded_embeddings)', 'len(expected_embeddings) == len(sentences)', 'len(embeddings) == len(sentences)', 'embeddings.shape == (3, 0, 1024)', 'len(embeddings) == 2']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest']
2019,Dirk Groeneveld,dirkg@allenai.org,2020-04-29 23:15:06-07:00,52ae7928c364ccd79bf0697a51f8464d414dfbb3,https://github.com/allenai/allennlp/commit/52ae7928c364ccd79bf0697a51f8464d414dfbb3,Use new env var in the allennlp-models build (#4172),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2020,YKX-A,38134733+YKX-A@users.noreply.github.com,2020-04-30 23:03:26+08:00,82cae1b43060fa6f8382dc4bb7b68b5a00e171db,https://github.com/allenai/allennlp/commit/82cae1b43060fa6f8382dc4bb7b68b5a00e171db,add missing param `threshold_mode` (#4173),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2021,Bharat Raghunathan,bharatraghunthan9767@gmail.com,2020-04-30 20:41:07+05:18,706bf528e44d4177defd82758eb3f5132b4c1ce5,https://github.com/allenai/allennlp/commit/706bf528e44d4177defd82758eb3f5132b4c1ce5,"DOCS: Clean up the docs for commands (#4145)

* DOCS: Clean up the docs for commands

* DOCS: Fix some errors after building docs locally

* DOC: Fix linter warnings

* Resolve conflicts

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2022,YKX-A,38134733+YKX-A@users.noreply.github.com,2020-05-01 00:25:09+08:00,be53f07104be5220527c875278fbd01628a94d63,https://github.com/allenai/allennlp/commit/be53f07104be5220527c875278fbd01628a94d63,"add other missing param to ReduceOnPlateau LR Scheduler (#4177)

Co-authored-by: yk x <xyk1021355229@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2023,Mateusz Klimaszewski,mk.klimaszewski@gmail.com,2020-04-30 18:41:35+02:00,7cbeb6c281b8f4c3ac6193a49dd003129ef18c92,https://github.com/allenai/allennlp/commit/7cbeb6c281b8f4c3ac6193a49dd003129ef18c92,"Display activation functions as modules. (#4045)

* Display activations as modules.

* Fix tests and make changes in doc.

* Fix parameter type.

* Fix lambda based activation name displaying.

* Fix formatting.

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],"[('Equal', '(actual_text_representation, expected_text_representation)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2024,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-30 10:52:03-07:00,6038fd1a9d28c6686027953617c54a273a2f3a58,https://github.com/allenai/allennlp/commit/6038fd1a9d28c6686027953617c54a273a2f3a58,remove verbose mode of linters (#4176),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2025,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-30 11:06:28-07:00,ca9118f24875ca32b001b235be22cef752830572,https://github.com/allenai/allennlp/commit/ca9118f24875ca32b001b235be22cef752830572,ensure docs can build in PR workflow (#4178),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2026,Nick Walker,nick@nickwalker.us,2020-04-30 13:13:41-05:00,0f8346de9367cc38ba8c012c59413a4a750a8b39,https://github.com/allenai/allennlp/commit/0f8346de9367cc38ba8c012c59413a4a750a8b39,"Fix XLNet token type number (#4125)

The max type id is 2, but the number of ids is 3

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2027,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-04-30 11:38:50-07:00,74c840495cc2be2a4385fd6aae2bae12a42ca216,https://github.com/allenai/allennlp/commit/74c840495cc2be2a4385fd6aae2bae12a42ca216,"Bump mkdocs-material from 5.1.3 to 5.1.4 (#4174)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.1.3 to 5.1.4.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.1.3...5.1.4)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: ai2-bulldozer[bot] <47044978+ai2-bulldozer[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2028,Matt Gardner,mattg@allenai.org,2020-04-30 15:21:32-07:00,2544e598bcea3f30cd99047a49af301b02073d69,https://github.com/allenai/allennlp/commit/2544e598bcea3f30cd99047a49af301b02073d69,"Find the right embedding layer for mismatched cases (#4179)

* Find the right embedding layer for mismatched cases

* black",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2029,Evan Pete Walsh,epwalsh10@gmail.com,2020-04-30 17:30:09-07:00,cbe74586e7cb40f67db7483b6faf4da76b2c5a5e,https://github.com/allenai/allennlp/commit/cbe74586e7cb40f67db7483b6faf4da76b2c5a5e,"Add self-hosted runner for GPU checks (#4180)

* try again

* add again

* Trigger CI again

* try building image

* fix

* use 3.7 base image

* update

* fix

* fix

* register gpu mark

* add -v

* finalize

* Trigger CI again

* fix step name",9,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['gpu', 'gpu', 'gpu', 'gpu', 'gpu', 'gpu']","['mark.gpu', 'mark.gpu', 'mark.gpu', 'mark.gpu', 'mark.gpu', 'mark.gpu']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2030,Zhaofeng Wu,wuzhaofeng1997@gmail.com,2020-04-30 22:38:46-07:00,e56992bc5bb085cf7e2ddf76360ff10faf161555,https://github.com/allenai/allennlp/commit/e56992bc5bb085cf7e2ddf76360ff10faf161555,"Add failing from_archive test (#4156)

* Add failing from_archive test

* fix loading

* actual fix for the problem

Co-authored-by: Matt Gardner <mattg@allenai.org>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['not (parameters == base_model_params[name]).all()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2031,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-01 08:31:10-07:00,ab4218947059d4cbbdd767ebedce2fa5bfe7c00d,https://github.com/allenai/allennlp/commit/ab4218947059d4cbbdd767ebedce2fa5bfe7c00d,"update GPU checks CI (#4182)

Adds a condition to only run GPU checks on main repo and PRs to main repo so that the workflows will work for forks that have GitHub Actions enabled.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2032,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-01 11:22:20-07:00,e99de854af1ce07b9a48614c2dc9b14dc57583bb,https://github.com/allenai/allennlp/commit/e99de854af1ce07b9a48614c2dc9b14dc57583bb,"Improve Docker-based workflows (#4183)

* tweak docker builds

* only run docker flow on main repo

* fixes

* fixes

* test docker workflow

* revert",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2033,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-01 11:37:00-07:00,31616dec814822cae84d0fa19cd30227c37b11cf,https://github.com/allenai/allennlp/commit/31616dec814822cae84d0fa19cd30227c37b11cf,"tweak torch requirement (#4166)

* tweak torch requirement

* allow patches

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2034,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-01 13:42:51-07:00,2602c8ffb933b0e63c2ca6789689b42e7f8f4d51,https://github.com/allenai/allennlp/commit/2602c8ffb933b0e63c2ca6789689b42e7f8f4d51,"improve error message for Vocab.get_token_index (#4185)

* improve error message Vocab.get_token_index

* fix comments

* fix linting

* a little better wording",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab._token_to_index[]', 'vocab._token_to_index[]', 'vocab.get_token_index() == 1', 'vocab._token_to_index[]', 'vocab._token_to_index[]']","['(KeyError, match=rf)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2035,Matt Gardner,mattg@allenai.org,2020-05-01 14:12:07-07:00,d67e72139e45bccbc5d356a456f41cee8f72eb1c,https://github.com/allenai/allennlp/commit/d67e72139e45bccbc5d356a456f41cee8f72eb1c,Fix heuristic in util.get_token_ids_from_text_field_tensors (#4184),14,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'padded_tokens[].tolist() == expected_padded_tokens', 'indices[] == expected_indices', '{: []} == indexer.get_empty_token_list()', '(token_ids == expected_token_ids).all()']",[],[],[],[],[],[],[],[],[],[],[],[],"['indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'indices == {: [expected_indices]}', 'padded_tokens[].tolist() == expected_padded_tokens', 'indices[] == expected_indices', '{: []} == indexer.get_empty_token_list()']",[],[],[],[],[],[],[],[],[],[],[],[]
2036,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-01 14:32:56-07:00,42a4e638c96812ad6fcf76282162fd4caf2a2d3b,https://github.com/allenai/allennlp/commit/42a4e638c96812ad6fcf76282162fd4caf2a2d3b,"Adds links in readme to stable and latest docs (#4186)

* add finer documentation links

* add links to docs as well

* improve",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2037,Annabelle Carrell,belle.carrell@gmail.com,2020-05-01 19:30:32-04:00,c09833c3a2b2fe66f10ffd18761f90d0912c5ea2,https://github.com/allenai/allennlp/commit/c09833c3a2b2fe66f10ffd18761f90d0912c5ea2,"Remove allennlp sparse_clip_grad and replace with torch clip_grad_norm_. (#4159)

* Remove allennlp sparse_clip_grad and replace with torch clip_grad_norm_.

* Put test_sparse_clip_grad() back in trainer_test.

* upgrade torch to at least 1.5.0

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2038,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-04 08:57:33-07:00,967660a477c04d83be748f5bb8b0b9d862b85fc1,https://github.com/allenai/allennlp/commit/967660a477c04d83be748f5bb8b0b9d862b85fc1,remove namespace plugin mechanism (#4188),21,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,46,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,2,2,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],"[('SetEqual', '(set(), available_plugins)'), ('In', '(, subcommands_available)'), ('In', '(, output)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '('), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '('), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('NotIn', '(, subcommands_available)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('NotIn', '(, subcommands_available)'), ('SetEqual', '({}, available_plugins)'), ('NotIn', '(, subcommands_available)'), ('In', '(, subcommands_available)')]",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['()', '()']",[],[],[],[],"['skip()', 'skip()']","['mark.skip()', 'mark.skip()']",[],[],['import pytest']
2039,SARTHAK JAIN,successar@gmail.com,2020-05-04 19:16:52-04:00,c4583034f8b4e8b5714eab59d7757e28c3a663e2,https://github.com/allenai/allennlp/commit/c4583034f8b4e8b5714eab59d7757e28c3a663e2,Fix Bug in evaluate script (#4199),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2040,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-04 17:45:46-07:00,b6e0ba9699e3816883b10a0f48c068326e53f978,https://github.com/allenai/allennlp/commit/b6e0ba9699e3816883b10a0f48c068326e53f978,"attach allennlp cache to Docker images and fix apex test (#4197)

* attach allennlp cache to Docker images

* fix Apex tests",3,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['gpu'],['mark.gpu'],[],[],[],[],[],[],[],[],[],[],[],"['tryfirst', 'spawn']","['mark.tryfirst', 'mark.spawn']",[],[],['import pytest']
2041,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-05-05 15:44:25+00:00,1895743a29fdc2a937c603e39f9678a71f03a53e,https://github.com/allenai/allennlp/commit/1895743a29fdc2a937c603e39f9678a71f03a53e,Bump mkdocs-material from 5.1.4 to 5.1.5 (#4195),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2042,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-07 10:33:49-07:00,4e47894f0e741b22670aef210e57d91d05992ce1,https://github.com/allenai/allennlp/commit/4e47894f0e741b22670aef210e57d91d05992ce1,Add linke to allennlp-models in README (#4196),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2043,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-07 13:54:50-07:00,743d2d836f327a3adacc931eeab34777b46b963f,https://github.com/allenai/allennlp/commit/743d2d836f327a3adacc931eeab34777b46b963f,"Separate linting from formatting in CI, always run all steps of workflow (#4202)",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2044,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-07 14:05:25-07:00,82bf58ae9b33a27d7a53c0ab9c28dc6cd236f810,https://github.com/allenai/allennlp/commit/82bf58ae9b33a27d7a53c0ab9c28dc6cd236f810,"Switch to pytest style test classes, use plain asserts (#4204)

* switch to pytest style test classes

* fix failing test

* ensure multi_device tests are also gpu marked

* make flake8 happy

* temporarily point to different models branch

* matts comment

* fix

* revert temp models install patch",63,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,1,0,1,57,55,0,1,0,0,0,0,0,0,37,27,0,0,0,0,0,0,1,0,0,0,10,12,3,0,0,0,1,0,0,0,1,0,0,0,[],[],[],[],[],[],[],[],[],['from unittest import mock'],[],['class AllenNlpTestCase(TestCase):'],"[('Equal', '('), ('In', '('), ('AlmostEqual', '(metrics[], 8.0)'), ('AlmostEqual', '(metrics[], (70 + 18 + 12) / 13.5)'), ('Raises', '(SystemExit) as cm:'), ('Raises', '(SystemExit) as cm:'), ('Raises', '(SystemExit) as cm:'), ('SetEqual', '(set(), available_plugins)'), ('In', '(, subcommands_available)'), ('Raises', '(NotImplementedError):'), ('Raises', '(SystemExit) as cm:'), ('Raises', '(SystemExit) as cm:'), ('Raises', '(SystemExit) as cm:'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '(set(), available_plugins)'), ('SetEqual', '({}, available_plugins)'), ('In', '(, subcommands_available)'), ('SetEqual', '(expected_devices, actual_devices)'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Raises', '(span_utils.InvalidTagSequence):'), ('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '(logger=):'), ('Logs', '('), ('Logs', '(logger=):'), ('Raises', '('), ('Raises', '('), ('Raises', '('), ('Equal', '(lengths.tolist(), expected_lengths)'), ('True', '('), ('Raises', '(ValueError):'), ('Equal', '(actual_text_representation, expected_text_representation)'), ('Raises', '(ValueError):'), ('Raises', '(ValueError):'), ('Raises', '(ValueError):'), ('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError) as context:'), ('Raises', '(ConfigurationError):'), ('AlmostEqual', '(accuracy.get_metric(), 0.0)'), ('AlmostEqual', '(accuracy.get_metric(), 0.0)'), ('Raises', '(ConfigurationError, FBetaMeasure, beta=0.0)'), ('Raises', '(ConfigurationError, FBetaMeasure, average=)'), ('Raises', '(ConfigurationError, FBetaMeasure, labels=[])'), ('Raises', '(RuntimeError, fbeta.get_metric)'), ('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError):'), ('Raises', '(ConfigurationError):'), ('AlmostEqual', '(grad._values().norm(2.0).item(), 1.5, places=5)')]","['def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):', 'def setUp(self):']",[],['def tearDown(self):'],[],[],[],[],[],[],"['expected_output == actual_output, (', 'module_info.name in [parent_module.__name__ + ], (', 'metrics[] == pytest.approx(8.0)', 'metrics[] == pytest.approx((70 + 18 + 12) / 13.5)', 'cm.value.code == 2  # argparse code for incorrect usage', 'available_plugins == set()', 'in subcommands_available', 'cm.value.code == 2  # argparse code for incorrect usage', 'available_plugins == set()', 'available_plugins == set()', 'available_plugins == {}', 'in subcommands_available', 'expected_devices == actual_devices', 'not in LabelField._already_warned_namespaces', 'caplog.records', 'in LabelField._already_warned_namespaces', 'not caplog.records', 'not in LabelField._already_warned_namespaces', 'caplog.records', 'not in MultiLabelField._already_warned_namespaces', 'caplog.records', 'in MultiLabelField._already_warned_namespaces', 'not caplog.records', 'not in MultiLabelField._already_warned_namespaces', 'caplog', 'not in SequenceLabelField._already_warned_namespaces', 'caplog.records', 'in SequenceLabelField._already_warned_namespaces', 'not caplog.records', 'not in SequenceLabelField._already_warned_namespaces', 'caplog.records', 'lengths.tolist() == expected_lengths', 'numpy.allclose(', 'actual_text_representation == expected_text_representation', 'accuracy.get_metric() == pytest.approx(0.0)', 'accuracy.get_metric() == pytest.approx(0.0)', 'grad._values().norm(2.0).item() == pytest.approx(1.5, rel=1e-4)']","['(SystemExit)', '(SystemExit)', '(SystemExit)', '(NotImplementedError)', '(SystemExit)', '(SystemExit)', '(SystemExit)', '(span_utils.InvalidTagSequence)', '(span_utils.InvalidTagSequence)', '(span_utils.InvalidTagSequence)', '(span_utils.InvalidTagSequence)', '(span_utils.InvalidTagSequence)', '(span_utils.InvalidTagSequence)', '(span_utils.InvalidTagSequence)', '(ValueError)', '(ValueError)', '(ValueError)', '(ValueError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError, FBetaMeasure, beta=0.0)', '(ConfigurationError, FBetaMeasure, average=)', '(ConfigurationError, FBetaMeasure, labels=[])', '(RuntimeError, fbeta.get_metric)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],"['parametrize(, _available_devices)(pytest.mark.gpu(test_method))']",[],[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest']","['cm.exception.code == 2  # argparse code for incorrect usage', 'cm.exception.code == 2  # argparse code for incorrect usage', 'not in LabelField._already_warned_namespaces', 'in LabelField._already_warned_namespaces', 'not in LabelField._already_warned_namespaces', 'not in MultiLabelField._already_warned_namespaces', 'in MultiLabelField._already_warned_namespaces', 'not in MultiLabelField._already_warned_namespaces', 'not in SequenceLabelField._already_warned_namespaces', 'in SequenceLabelField._already_warned_namespaces', 'not in SequenceLabelField._already_warned_namespaces', 'in str(context.exception)']","['(AssertionError)', '(AssertionError)', '(AssertionError)']",[],[],[],['(autouse=True)'],[],[],[],['fixture(autouse=True)'],[],[],[]
2045,Daniel King,43149077+danielkingai2@users.noreply.github.com,2020-05-08 11:17:31-07:00,b916720b7e07f2a1aa0273b42309fc2fe5a2148f,https://github.com/allenai/allennlp/commit/b916720b7e07f2a1aa0273b42309fc2fe5a2148f,Add wordpiece_mask to default to bool tensor (#4206),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2046,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-08 14:44:02-07:00,edf91ac2885fed85b48449dc3313e180852327d9,https://github.com/allenai/allennlp/commit/edf91ac2885fed85b48449dc3313e180852327d9,"improve Docker workflows (#4210)

* improve Docker workflows

* clean up",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2047,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-08 14:57:40-07:00,72061b152250dec87fe9f4637381d759bc205cb9,https://github.com/allenai/allennlp/commit/72061b152250dec87fe9f4637381d759bc205cb9,ensure Docker images get the right name and tag (#4214),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2048,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-08 16:57:17-07:00,0bcab362d6977a281f61e05c4b5f3575faddec2c,https://github.com/allenai/allennlp/commit/0bcab362d6977a281f61e05c4b5f3575faddec2c,consolidate testing decorators (#4213),6,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,5,0,0,0,2,0,0,0,7,0,0,0,0,15,14,0,0,2,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['if(not torch.cuda.is_available(), reason=)', 'if(torch.cuda.device_count() < 2, reason=)']",[],[],[],[],"['parametrize(, _available_devices)(pytest.mark.gpu(test_method))', 'gpu(', 'skipif(not torch.cuda.is_available(), reason=)(', 'gpu(', 'skipif(torch.cuda.device_count() < 2, reason=)(']",[],[],[],"['import pytest', 'import pytest']",[],[],[],"['if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(not torch.cuda.is_available(), reason=)', 'if(not torch.cuda.is_available(), reason=)', 'if(torch.cuda.device_count() < 2, reason=)', 'if(not torch.cuda.is_available(), reason=)']",[],[],[],[],"['parametrize(, _available_devices)(pytest.mark.gpu(test_method))', 'gpu', 'skipif(torch.cuda.device_count() < 2, reason=)', 'gpu', 'skipif(torch.cuda.device_count() < 2, reason=)', 'gpu', 'skipif(torch.cuda.device_count() < 2, reason=)', 'gpu', 'skipif(not torch.cuda.is_available(), reason=)', 'gpu', 'skipif(not torch.cuda.is_available(), reason=)', 'gpu', 'skipif(torch.cuda.device_count() < 2, reason=)', 'gpu', 'skipif(not torch.cuda.is_available(), reason=)']","['mark.gpu', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.gpu', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.gpu', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.gpu', 'mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.gpu', 'mark.skipif(not torch.cuda.is_available(), reason=)', 'mark.gpu', 'mark.skipif(torch.cuda.device_count() < 2, reason=)', 'mark.gpu', 'mark.skipif(not torch.cuda.is_available(), reason=)']",[],[],"['import pytest', 'import pytest']"
2049,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-12 08:59:18-07:00,b461f3f300453bf50db14413de04f1f98d906566,https://github.com/allenai/allennlp/commit/b461f3f300453bf50db14413de04f1f98d906566,fix new linting errors (#4227),11,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['[layer.weight.size(-1) == 3 for layer in feedforward._linear_layers]'],[],[],[],[],[],[],[],[],[],[],[],[],['[l.weight.size(-1) == 3 for l in feedforward._linear_layers]'],[],[],[],[],[],[],[],[],[],[],[],[]
2050,Michael Schmitz,MichaelS@allenai.org,2020-05-12 09:07:17-07:00,89238d22dffe0a34bd19863bfd415050e6b5992a,https://github.com/allenai/allennlp/commit/89238d22dffe0a34bd19863bfd415050e6b5992a,"Remove unused path. (#4226)

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2051,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-12 10:06:25-07:00,7d9b72cda0b18df11ef1b31b2078c18061f1f7f2,https://github.com/allenai/allennlp/commit/7d9b72cda0b18df11ef1b31b2078c18061f1f7f2,remove unused path in test image (#4229),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2052,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-12 13:03:20-07:00,114751f7d82b98c4acb65b6d630f74e20812da90,https://github.com/allenai/allennlp/commit/114751f7d82b98c4acb65b6d630f74e20812da90,"Attach nltk and HF caches to docker containers in CI (#4232)

* attach docker volumes for nltk and HF caches

* fix

* formatting",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2053,Michael Schmitz,MichaelS@allenai.org,2020-05-12 15:14:08-07:00,592c65341891ccadec31a624c4e6f062e8455723,https://github.com/allenai/allennlp/commit/592c65341891ccadec31a624c4e6f062e8455723,"Add a more informative exception when there's no GPU available. (#4230)

* Add a more informative exception when there's no GPU available.

* Update allennlp/common/checks.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2054,Dirk Groeneveld,dirkg@allenai.org,2020-05-12 15:30:49-07:00,e3d72fcb1664caf9554ef4e611191c33a7a5cbbd,https://github.com/allenai/allennlp/commit/e3d72fcb1664caf9554ef4e611191c33a7a5cbbd,"Use the new tokenizers (#3868)

* Use the new tokenizers

* Fix various problems with the tests

* Matching implementation of intra_word_tokenize

* Update some of the tests

* Fix changed API

* Workaround for an API not implemented

* Fix some more tests, remove the tokenize_sentence_pair function

* Makes all the tests succeed when run against the latest HF master

* Depend on latest huggingface master

* Formatting

* Make the tokenizers work even when we don't get a fast one

* Fall back to the old method of calculating offsets

* Incredibly, this passes tests

* Depend on a released version of transformers

* Formatting

* Update allennlp/data/tokenizers/pretrained_transformer_tokenizer.py

Co-authored-by: Santiago Castro <bryant@montevideo.com.uy>

* Fix copy and paste error

* Be more flexible with the transformers version

* Productivity through formatting

* `token.text` is now the word piece again

* New way of doing pairs

* Formatting

* Slight refactoring

* Refactoring

* Formatting and mypy

Co-authored-by: Santiago Castro <bryant@montevideo.com.uy>",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['get_token_ids(tokenizer.sequence_pair_start_tokens) == [101]', 'get_token_ids(tokenizer.sequence_pair_mid_tokens) == [102]', 'get_token_ids(tokenizer.sequence_pair_end_tokens) == [102]', 'get_token_ids(tokenizer.single_sequence_start_tokens) == [101]', 'get_token_ids(tokenizer.single_sequence_end_tokens) == [102]', 'get_type_ids(tokenizer.sequence_pair_start_tokens) == [0]', 'tokenizer.sequence_pair_first_token_type_id == 0', 'get_type_ids(tokenizer.sequence_pair_mid_tokens) == [0]', 'tokenizer.sequence_pair_second_token_type_id == 1', 'get_type_ids(tokenizer.sequence_pair_end_tokens) == [1]', 'get_type_ids(tokenizer.single_sequence_start_tokens) == [0]', 'tokenizer.single_sequence_token_type_id == 0', 'get_type_ids(tokenizer.single_sequence_end_tokens) == [0]', 'get_token_ids(tokenizer.sequence_pair_start_tokens) == []', 'get_token_ids(tokenizer.sequence_pair_mid_tokens) == [4]', 'get_token_ids(tokenizer.sequence_pair_end_tokens) == [4, 3]', 'get_token_ids(tokenizer.single_sequence_start_tokens) == []', 'get_token_ids(tokenizer.single_sequence_end_tokens) == [4, 3]', 'get_type_ids(tokenizer.sequence_pair_start_tokens) == []', 'tokenizer.sequence_pair_first_token_type_id == 0', 'get_type_ids(tokenizer.sequence_pair_mid_tokens) == [0]', 'tokenizer.sequence_pair_second_token_type_id == 1', 'get_type_ids(tokenizer.sequence_pair_end_tokens) == [1, 2]', 'get_type_ids(tokenizer.single_sequence_start_tokens) == []', 'tokenizer.single_sequence_token_type_id == 0', 'get_type_ids(tokenizer.single_sequence_end_tokens) == [0, 2]']",[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == expected_tokens', 'tokens == expected_tokens', 'with_idx_time <= 2 * without_idx_time', 'tokens == expected_tokens', 'idxs == expected_idxs', '(', 'tokenizer._determine_num_special_tokens_added() == (1, 1, 1)', 'tokenizer._determine_num_special_tokens_added() == (0, 1, 2)', 'forced_lowercase_tokenizer._tokenizer_lowercases', 'tokenized == lowercase_tokens', 'not tokenizer._tokenizer_lowercases']",[],[],[],[],[],[],[],[],[],[],[],[]
2055,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-05-13 18:51:05+00:00,6701e5938c100d3470a6ade9e25b80ca83001f33,https://github.com/allenai/allennlp/commit/6701e5938c100d3470a6ade9e25b80ca83001f33,Bump mkdocs-material from 5.1.5 to 5.1.6 (#4221),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2056,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-13 12:47:34-07:00,522742020b5c5ddc7da3003b56a932c5431c511c,https://github.com/allenai/allennlp/commit/522742020b5c5ddc7da3003b56a932c5431c511c,remove pre-commit (#4236),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2057,Matt Gardner,mattg@allenai.org,2020-05-13 14:12:28-07:00,189624df866a12b738fd0e8d7d098c5ca12c776f,https://github.com/allenai/allennlp/commit/189624df866a12b738fd0e8d7d098c5ca12c776f,"Make some arguments to evaluate() optional, add docstring (#4237)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2058,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-13 14:46:38-07:00,3f193367a103f70405ef01061793f75fe26964dc,https://github.com/allenai/allennlp/commit/3f193367a103f70405ef01061793f75fe26964dc,gitignore evalb binary (#4235),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2059,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-14 11:52:31-07:00,99bf1ffb7dbb18c3378f6fdf067726fd97a14cd1,https://github.com/allenai/allennlp/commit/99bf1ffb7dbb18c3378f6fdf067726fd97a14cd1,ensure nightly builds don't run for forks (#4240),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2060,epwalsh,epwalsh10@gmail.com,2020-05-14 15:12:56-07:00,1b0d231dc7e6b6210d6bc0368d54dbe4989763ec,https://github.com/allenai/allennlp/commit/1b0d231dc7e6b6210d6bc0368d54dbe4989763ec,tick version to rc5,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2061,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-18 11:28:36-07:00,4de68a42a0df89df01a999ee48f361f24c8c19d4,https://github.com/allenai/allennlp/commit/4de68a42a0df89df01a999ee48f361f24c8c19d4,"Improves API docs and docstring consistency (#4244)

* refactor py2md

* improve py2md, warn if backticks missing

* ensure backticks consistent

* remove docstring help test

* fixes and handle more edge cases

* add failing test for pydoc-markdown bug

* update pydoc-markdown

* fix some links",112,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,1,0,0,0,0,0,2,2,2,0,0,1,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['captured.out.split()', 'param is not None', 'param.to_line() == line_out']",['(DocstringError)'],[],[],[],[],[],"['', '']","['parametrize(', 'parametrize(']","['mark.parametrize(', 'mark.parametrize(']",[],[],['import pytest'],"['expected_output == actual_output, (', 'module_info.name in [parent_module.__name__ + ], (']",[],[],[],[],[],[],[],[],[],[],[],[]
2062,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-18 12:17:10-07:00,fc810670a9cb30ffddaf5bbf4cd8060c8f5933a8,https://github.com/allenai/allennlp/commit/fc810670a9cb30ffddaf5bbf4cd8060c8f5933a8,move py2md back to scripts (#4251),9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],['def setUp(self):'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2063,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-18 16:23:57-07:00,7d71398b44636c52e811467a684c3099c64009ec,https://github.com/allenai/allennlp/commit/7d71398b44636c52e811467a684c3099c64009ec,"make 'cached_path' work offline (#4253)

* make 'cached_path' work offline

* add test case

* Update allennlp/common/file_utils.py

Co-authored-by: Michael Schmitz <michael@schmitztech.com>

* log some more info

* else clause

Co-authored-by: Michael Schmitz <michael@schmitztech.com>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,1,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['get_from_cache(url, cache_dir=self.TEST_DIR) == filenames[-1]', 'get_from_cache(url, cache_dir=self.TEST_DIR) == filename', '_split_s3_path()', '_split_s3_path()']",[],[],[],[],[],[],[],[],[],"['setattr(file_utils, , mocked_http_etag)']",[],[],"['split_s3_path()', 'split_s3_path()']",[],[],[],[],[],[],[],[],[],[],[],[]
2064,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-19 15:08:20-07:00,b41d44878d8a0890c879b682fa97503b0f44c155,https://github.com/allenai/allennlp/commit/b41d44878d8a0890c879b682fa97503b0f44c155,"Add a CHANGELOG (#4260)

* add CHANGELOG

* add CI check to ensure CHANGELOG updated

* update comments

* fix

* actually fix

* actually, actually fix

* dont need upstream

* try checkout v1

* update

* add comment

* Format a little prettier",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2065,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-19 15:36:14-07:00,88683d46f0a9d8712fe83e6fbb65e82b83a487f0,https://github.com/allenai/allennlp/commit/88683d46f0a9d8712fe83e6fbb65e82b83a487f0,"switch to tokenless codecov upload (#4261)

* switch to tokenless codecov upload

* forgot to add

* only run on pushes to master, not schedule or releases

* remove 'not sniff_test' from pytest command",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2066,Michael Schmitz,MichaelS@allenai.org,2020-05-19 16:06:48-07:00,65a146d20697ac431564ef1bedb18d61011e727e,https://github.com/allenai/allennlp/commit/65a146d20697ac431564ef1bedb18d61011e727e,Clean up the command to create a commit list. (#4263),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2067,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-20 11:30:27-07:00,9c51d6c89875b3a3a50cac165d6f3188d9941c5b,https://github.com/allenai/allennlp/commit/9c51d6c89875b3a3a50cac165d6f3188d9941c5b,"move test and fixtures to root level and simplify test-install command (#4264)

* simplify test-install command

* update CHANGELOG

* fix MANIFEST.in

* move tests and fixtures to root level

* fix archive fixture

* update coverage configs",259,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == [', 'arcs.indices == [', 'arcs.labels == [', 'tokens == [', 'arcs.indices == [', 'arcs.labels == [', 'os.path.exists(os.path.join(project_root, ))']",[],[],[],[],[],[],[],[],[],[],[],['import pytest']
2068,Dirk Groeneveld,dirkg@allenai.org,2020-05-21 10:43:42-07:00,7e683ddb7f92ea688658c9ebf78d67c0ec50d733,https://github.com/allenai/allennlp/commit/7e683ddb7f92ea688658c9ebf78d67c0ec50d733,"Workers in the distributed scenario need to see different instances (#4241)

* Let's use our own convenience functions

* Make sure a worker process only runs on what it needs to run on

* Formatting

Flake still sucks though. It doesn't like assigning lambdas.

* Fix documentation

* Try to make this work with lazy datasets

* So much code for so little effect

* Productivity through formatting

* Fixes the test for dataset sharding

* Fix another sharding test

* Sharded dataset reader should always disable the other sharding mechanism

* Revert ""Fix another sharding test""

This reverts commit 1d5492a23dbf0070279d8249531a3def3799f1bd.

* Revert ""Fixes the test for dataset sharding""

This reverts commit c67403e393c68e55f6c580b28ff6c34bc8cd40a9.

* Test the new sharding behavior

* Try to get the test to find the callback

* Update changelog

* Formatting

* Adds null callbacks for batch and epoch

* Formatting

* Fix the logging in the test

* Be verbose

* Fix test expectations

* Add a callback that gets called in workers

* Also call in_worker during validation

* Fix test

* Productivity through formatting

* More formatting

* Fix test after they were moved

* Silence mypy

* Set correct types

* Docs

* Less code, same result

* Fix another test

* Test both lazy and eager cases

* Remove leftover code from an earlier iteration",8,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'archive.model', 'tokens == {', 'train_complete in worker0_log', 'validation_complete in worker0_log', 'train_complete in worker1_log', 'validation_complete in worker1_log', 'first_word_counts == {']",[],[],[],[],[],[],"['(, [True, False])', '(, [True, False])']","['parametrize(, [True, False])', 'parametrize(, [True, False])']","['mark.parametrize(, [True, False])', 'mark.parametrize(, [True, False])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2069,Dirk Groeneveld,dirkg@allenai.org,2020-05-21 13:45:39-07:00,f27475aaeba87052e277df83beaadf002f4fd9da,https://github.com/allenai/allennlp/commit/f27475aaeba87052e277df83beaadf002f4fd9da,"Enable multi-process training on CPU (#4272)

* Use torch.device everywhere

* Update changelog

* Run distributed tests even on CPU

* Fix bug when running distributed tests on CPU

* Remove unused imports

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",10,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['gpu(test_method)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2070,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-21 15:07:51-07:00,dacbb7572928c6c2f54a8a7acdcb0aff151cf457,https://github.com/allenai/allennlp/commit/dacbb7572928c6c2f54a8a7acdcb0aff151cf457,"wait for non-master workers to finish reading vocab before master worker saves it (#4274)

* wait for non-master workers to finish reading

* update CHANGELOG

* typo",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2071,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-21 15:14:14-07:00,4ee2735a407eca786c68e18b7210bb91bd004252,https://github.com/allenai/allennlp/commit/4ee2735a407eca786c68e18b7210bb91bd004252,"update contribution guidelines (#4271)

* update contribution guidelines

* clean up

* matts comments",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2072,Matt Gardner,mattg@allenai.org,2020-05-21 15:36:56-07:00,5198a5cdedc57651bb885c8bdcd53ebd5b72cf43,https://github.com/allenai/allennlp/commit/5198a5cdedc57651bb885c8bdcd53ebd5b72cf43,"Document when parameters do not need an entry in a config file (#4275)

* Document when parameters do not need an entry in a config file

* black, actually make parameter optional...

* update changelog",19,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2073,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-05-21 16:44:00-07:00,f7d967304ca25e6da90e98dc3a7cade2b3e4409c,https://github.com/allenai/allennlp/commit/f7d967304ca25e6da90e98dc3a7cade2b3e4409c,"Bump mkdocs-material from 5.1.6 to 5.2.0 (#4257)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.1.6 to 5.2.0.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.1.6...5.2.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2074,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-05-21 16:44:13-07:00,24617c0201c74b3998f37640d3996b8e3d614aba,https://github.com/allenai/allennlp/commit/24617c0201c74b3998f37640d3996b8e3d614aba,"Bump overrides from 2.8.0 to 3.0.0 (#4249)

Bumps [overrides](https://github.com/mkorpela/overrides) from 2.8.0 to 3.0.0.
- [Release notes](https://github.com/mkorpela/overrides/releases)
- [Commits](https://github.com/mkorpela/overrides/commits)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2075,Matt Gardner,mattg@allenai.org,2020-05-21 21:40:15-07:00,6574823c20a09c2028ad39fd422223b34137bcc2,https://github.com/allenai/allennlp/commit/6574823c20a09c2028ad39fd422223b34137bcc2,"Make special token inference logic more robust (#4267)

* Make special token inference logic more robust

* update changelog

* remove prints

* fix typo",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['tokens == expected_tokens'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2076,Dirk Groeneveld,dirkg@allenai.org,2020-05-22 09:59:39-07:00,e52fea2801fefc07808ee2039a086a9abbf21a1e,https://github.com/allenai/allennlp/commit/e52fea2801fefc07808ee2039a086a9abbf21a1e,Makes the EpochCallback work the same way as the BatchCallback (#4277),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2077,Nicola De Cao,nicola.decao@uva.nl,2020-05-26 15:59:16+01:00,69fc5b4608ea6da566dac7aba87312fe9c27c717,https://github.com/allenai/allennlp/commit/69fc5b4608ea6da566dac7aba87312fe9c27c717,Update saliency_interpreter.py (#4286),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2078,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-05-26 12:58:38-07:00,a9be961c539700b4410d44710ef14d42ef0c8c7e,https://github.com/allenai/allennlp/commit/a9be961c539700b4410d44710ef14d42ef0c8c7e,"Bump mkdocs-material from 5.2.0 to 5.2.2 (#4288)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.2.0 to 5.2.2.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.2.0...5.2.2)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2079,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-26 13:49:10-07:00,f421e91161e33cec15126bea53dfe5996a3559b1,https://github.com/allenai/allennlp/commit/f421e91161e33cec15126bea53dfe5996a3559b1,"clean up dependencies (#4290)

* clean up dependencies

* revert CI change",3,False,False,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2080,Dirk Groeneveld,dirkg@allenai.org,2020-05-26 16:17:01-07:00,7dcc60becc4df4dc3fd2b0905034846cdc94eaf2,https://github.com/allenai/allennlp/commit/7dcc60becc4df4dc3fd2b0905034846cdc94eaf2,Update version for release v1.0.0rc5,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2081,Dirk Groeneveld,dirkg@allenai.org,2020-05-26 17:14:28-07:00,8ff47d34a5368fb85f27816aefa5739910a9e3e4,https://github.com/allenai/allennlp/commit/8ff47d34a5368fb85f27816aefa5739910a9e3e4,Set version to rc6,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2082,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-27 08:59:46-07:00,79999ec044789d8afcb823d1910a9e6b901737c7,https://github.com/allenai/allennlp/commit/79999ec044789d8afcb823d1910a9e6b901737c7,"Adds a ""duplicate()"" method on instances and fields (#4294)

* modify behavior of deepcopy on TextField

* update CHANGELOG

* make a little more robust

* add 'duplicate' method

* update CHANGELOG

* add a test",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['other == instance', 'not in other.fields', 'other != instance  # sanity check on the  method.']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2083,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-27 12:18:54-07:00,9526f00736bcda004ca2742add38f738d4e24a83,https://github.com/allenai/allennlp/commit/9526f00736bcda004ca2742add38f738d4e24a83,"Update issue templates (#4293)

* Update bug_report.md

* Update bug_report.md

* Update bug_report.md

* update

* remove 'question' issue template",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2084,epwalsh,epwalsh10@gmail.com,2020-05-27 12:22:34-07:00,58dc84ea42b1a0b3647213828c1318256e17b2b0,https://github.com/allenai/allennlp/commit/58dc84ea42b1a0b3647213828c1318256e17b2b0,add 'Feature request' label to template,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2085,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-28 13:27:17-07:00,25134f2bad0e1a953d65535c13c2d2b3aead5ea2,https://github.com/allenai/allennlp/commit/25134f2bad0e1a953d65535c13c2d2b3aead5ea2,"add lock file within caching and vocab saving/loading mechanisms (#4299)

* add file lock within caching mechanism

* update CHANGELOG

* add filelock to setup.py

* pin filelock to be safe

* add some more logging statements to complement lockfile's logging

* small cleanup and logging tweaks

* use lock file when saving and loading vocab

* fix tests

* remove unnecessary barrier from train command",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['set(vocab_files) == {', 'set(vocab_files) == {']",[],[],[],[],[],[],[],[],[],[],[],[],"['set(vocab_files) == {}', 'set(vocab_files) == {}']",[],[],[],[],[],[],[],[],[],[],[],[]
2086,Tobias Rohde,tobiasr@allenai.org,2020-05-28 17:06:55-07:00,5ad7a33a04d8829ad3439b5f9390bd136105f986,https://github.com/allenai/allennlp/commit/5ad7a33a04d8829ad3439b5f9390bd136105f986,"Support for bart in allennlp-models (#4169)

* Support for bart in allennlp-models

- Added option to PretrainedTransformerEmbedder to allow usage with
encoder-decoder models and created unit test.
- Added ROUGE-N metric. ROUGE-L will follow soon
- Added indices to tokens abstract method to TokenIndexer. Implemented
for PretrainedTransformerIndexer. This is useful for turning decoded
sequences in seq2seq models into text.
- added timestep parameter to step function in beamsearch
- other minor changes

* Implemented ROUGE-L, updated ROUGE-N, new tests
- Implemented ROUGE-L metric (F1 score)
- Implemented ROUGE-N recall, precision and F1 as metrics that can be
accessed separately
- Now computing overall ROUGE-N/L as average over scores of each
sequence pair, rather than summing counts across all pairs and then
computing the metric
- added tests for new padding behavior in get_text_field_mask
- added test for ROUGE-N/L
- stylistic improvements

* Polynomial lr scheduling, max tokens batch sampling, other small changes

- Implemented Polynomial learning rate scheduling, which is used in
BART. The implementeation is based on Fairseqs and tensorflows
implementation.

- Implementation an option to specify the number of maximum tokens per
batch, rather than specifiying a fixed batch size. This is also used for
fine-tuning BART. Added a unit test too.

- For indices_to_tokens, removed code that removes the cls/sep tokens
introduced by max length. Added a test to reflect this.

* Small stylistic changes

* Added documentation, separated max tokens sampler, fixed circular
important, memory tracking per batch, polynomical lr decay bug fix
- Added documentation for lazy_groups_of_max_size
- Some stylistic changes
- Made MaxTokensBatchSampler a subclass of BucketBatchSampler
- Annotated beam search with no grad
- fixed bug in poly decay related to lr of first batch
- fixed circular import, finally
- added gpu/cpu memory tracking for tensorboard for batches (previously
this was only possible for epochs)

* Fixed linting errors, fixed rouge test

- TODO: fix
`TestPretrainedTransformerEmbedder.test_encoder_decoder_model` and
TestPretrainedTransformerIndexer.test_indices_to_tokens. Both issues are
related to the new tokenizers

* Fixed issues with new tokenizers
- fixed issue with roberta based tokenizers in
pretrained_transformer_indexer
- temporary fix for incorrect types ids when using max length for
tokens_to_indices in PretrainedTransformerIndexer
- fixed indexer test to not compare idx and idx_end of Tokens

* Added max tokens batch sampler to __init__.py

* Fixed max tokens sampler to account for padding

* Fixed large batches due to short source sequences but long target
sequences in max tokens batch sampler

* Formatting

* Filled in the changelog

* Tests have moved

* Fix docs

* Adds a test for the max tokens sampler

* Adds warning when a single instance is too big

* More docs changes

* Formatting

* Docs

* Fix old models

* Fixed linting and type checking errors

* Fix docs build

* Fix circular imports

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",29,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,37,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['group in expected_groups', 'expected_groups == []', 'sampler.sorting_keys is None', 'sampler.sorting_keys == []', 'sampler.sorting_keys == sorting_keys', 'sampler.padding_noise == 0.1', 'sampler.max_tokens == 32', 'sampler.sorting_keys == sorting_keys', 'sampler.padding_noise == 0.5', 'sampler.max_tokens == 100', 'len(dataloader) == 3', 'set(candidate_instances) == set(expected_instances)', 'expected.text == actual.text', 'expected.text_id == actual.text_id', 'expected.type_id == actual.type_id', 'optimizer.param_groups[0][] == 0.5  # 1.0 * 1/2', 'optimizer.param_groups[0][] == 1.0  # 1.0 * 2/2', 'optimizer.param_groups[0][] == 0.60625  # (1.0 - 0.1) * (3/4) ** 2 + 0.1', 'optimizer.param_groups[0][] == 0.325  # (1.0 - 0.1) * (2/4) ** 2 + 0.1', 'optimizer.param_groups[0][] == 0.15625  # (1.0 - 0.1) * (1/4) ** 2 + 0.1', 'optimizer.param_groups[0][] == 0.1  # (1.0 - 0.1) * (0/4) ** 2 + 0.1', 'self.metric._total_sequence_count == 3', 'unigram_recall == 2 / 3 + 1 / 3 + 3 / 3', 'unigram_precision == 2 / 3 + 1 / 2 + 3 / 3', 'unigram_f1 == self.f1(2 / 3, 2 / 3) + self.f1(1 / 2, 1 / 3) + self.f1(3 / 3, 3 / 3)', 'metrics[] == unigram_recall / self.metric._total_sequence_count', 'metrics[] == unigram_precision / self.metric._total_sequence_count', 'metrics[] == unigram_f1 / self.metric._total_sequence_count', 'bigram_recall == 1 / 1 + 0 / 2 + 1 / 1', 'bigram_precision == 1 / 1 + 0 + 1 / 2', 'bigram_f1 == self.f1(1 / 1, 1 / 1) + self.f1(0, 0 / 2) + self.f1(1 / 2, 1 / 1)', 'metrics[] == bigram_recall / self.metric._total_sequence_count', 'metrics[] == bigram_precision / self.metric._total_sequence_count', 'metrics[] == bigram_f1 / self.metric._total_sequence_count', 'self.metric._total_rouge_l_f1 == self.f1(2 / 3, 2 / 3) + self.f1(', '(', 'score == 0.0']",[],[],[],[],[],[],[],[],[],[],[],[],['set(candidate_instances) == set(expected_instances)'],[],[],[],[],[],[],[],[],[],[],[],[]
2087,Evan Pete Walsh,epwalsh10@gmail.com,2020-05-29 08:47:35-07:00,91d0fa1a51485c4118e48426d76328acd8049587,https://github.com/allenai/allennlp/commit/91d0fa1a51485c4118e48426d76328acd8049587,remove setup.cfg (#4300),1,False,False,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2088,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-01 14:12:37-07:00,a7265c04078964ea2b80a78fc3967bde8d16072d,https://github.com/allenai/allennlp/commit/a7265c04078964ea2b80a78fc3967bde8d16072d,"move tensorboard memory logging to BatchCallback (#4306)

* move tensorboard memory logging to BatchCallback

* update CHANGELOG

* clean up",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2089,Michael Schmitz,MichaelS@allenai.org,2020-06-01 14:58:18-07:00,720ad434138179db2c2cb1133850df07a72a7cf0,https://github.com/allenai/allennlp/commit/720ad434138179db2c2cb1133850df07a72a7cf0,A few small fixes in the README.md (#4307),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2090,Michael Schmitz,MichaelS@allenai.org,2020-06-01 15:17:13-07:00,77b432f682c9ee3101b534ad6d4dac5a571601c9,https://github.com/allenai/allennlp/commit/77b432f682c9ee3101b534ad6d4dac5a571601c9,Update README.md (#4309),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2091,epwalsh,epwalsh10@gmail.com,2020-06-01 15:27:24-07:00,8c9421da29445c1e7372870c23984a7efabaa1af,https://github.com/allenai/allennlp/commit/8c9421da29445c1e7372870c23984a7efabaa1af,fix Makefile,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2092,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-01 16:00:31-07:00,d51ffa11bd2570aa456067b398344bf313db483c,https://github.com/allenai/allennlp/commit/d51ffa11bd2570aa456067b398344bf313db483c,"Update transformers requirement from <2.10,>=2.9 to >=2.9,<2.11 (#4282)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v2.9.0...v2.10.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2093,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-01 18:35:26-07:00,33a49454db239bfe3de6928229c405da056a8bf4,https://github.com/allenai/allennlp/commit/33a49454db239bfe3de6928229c405da056a8bf4,ensure CUDA available in GPU checks workflow (#4310),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2094,Joe Palermo,josephwpalermo@gmail.com,2020-06-02 13:28:10-04:00,32bccfbdaf97045f31861ab16bcfdefb8007c3f2,https://github.com/allenai/allennlp/commit/32bccfbdaf97045f31861ab16bcfdefb8007c3f2,Fix a bug where predictor.get_gradients() would return an empty...  (#4305),4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not embedding_layer.weight.requires_grad', 'bool(grads)', 'not embedding_layer.weight.requires_grad']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2095,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-02 13:32:01-07:00,11a08ae7e5045f8bd600d0c26a73fe7dd103a96b,https://github.com/allenai/allennlp/commit/11a08ae7e5045f8bd600d0c26a73fe7dd103a96b,"Making Token class a ""slots"" class (#4312)

* ensure linting and typechecking ran on all code

* make Token a __slots__ class

* add benchmarks

* update CHANGELOG

* fix test with custom token subclass

* Update allennlp/data/tokenizers/token.py

Co-authored-by: Matt Gardner <mattg@allenai.org>

Co-authored-by: Matt Gardner <mattg@allenai.org>",12,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2096,Dirk Groeneveld,dirkg@allenai.org,2020-06-02 17:04:22-07:00,fc47bf6ae5c0df6d473103d459b75fa7edbdd979,https://github.com/allenai/allennlp/commit/fc47bf6ae5c0df6d473103d459b75fa7edbdd979,"Deals with the case where a word doesn't have any word pieces assigned (#4301)

* Deals with the case where a word doesn't have any word pieces assigned

* Adds a test, and then fixes that test

* Productivity through formatting

* Adds changelog",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens[].tolist() == [', 'bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)', 'not torch.isnan(bert_vectors).any()', 'all(bert_vectors[0, 1] == 0)', 'all(bert_vectors[1, 1] == 0)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2097,Makoto Hiramatsu,himkt@klis.tsukuba.ac.jp,2020-06-03 10:26:56+09:00,345459e975f6f03d499af4e73fbfed40e9875db9,https://github.com/allenai/allennlp/commit/345459e975f6f03d499af4e73fbfed40e9875db9,"Stop calculating span-based F1 metric when `calculate_span_f1` is `False`. (#4302)

* Stop calculating span_f1 when calculate_span_f1 is False

* Update fixture

* Update CHANGELOG

* Make SimpleTagger consistent with CrfTagger

* Add test

* Change name to avoid name collision

* Set _f1_metric to None when calculate_span_f1 is False

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Also check self._f1_metric in SimpleTaggerSpanF1Test

* Remove test for the case calculate_span_f1=False

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['self.model.calculate_span_f1 and self.model._f1_metric is not None'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2098,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-03 09:16:50-07:00,a038c01a4d49bcdcb928738b25c6d56c6b370c99,https://github.com/allenai/allennlp/commit/a038c01a4d49bcdcb928738b25c6d56c6b370c99,"Update transformers requirement from <2.11,>=2.9 to >=2.9,<2.12 (#4315)

* Update transformers requirement from <2.11,>=2.9 to >=2.9,<2.12

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v2.9.0...v2.11.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* try fix

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2099,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-03 09:24:32-07:00,2b2d14136985e99be38b3ad18e8ebf7fe0fb090b,https://github.com/allenai/allennlp/commit/2b2d14136985e99be38b3ad18e8ebf7fe0fb090b,"Bump mypy from 0.770 to 0.780 (#4316)

* Bump mypy from 0.770 to 0.780

Bumps [mypy](https://github.com/python/mypy) from 0.770 to 0.780.
- [Release notes](https://github.com/python/mypy/releases)
- [Commits](https://github.com/python/mypy/compare/v0.770...v0.780)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* mypy upgrade work-arounds

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2100,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-04 10:49:27-07:00,06bac68b3bc7c9f7ca2b0ccf8086b881df79ebc7,https://github.com/allenai/allennlp/commit/06bac68b3bc7c9f7ca2b0ccf8086b881df79ebc7,"make Instance, Batch, and all field classes ""slots"" classes (#4313)

* make field classes slots classes

* update CHANGELOG

* make Instance a slot class as well

* make Batch a slots class

* add test and fix more Matt's edge case

* add comment

* handle case where sub field is not a slots class

* fix comment

* safely get slots

* clean up

* make more robust",18,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['SubField(1) == SubField(1)', 'SubField(1) != SubField(2)', 'SubSubField(1, 2) == SubSubField(1, 2)', 'SubSubField(1, 2) != SubSubField(1, 1)', 'SubSubField(1, 2) != SubSubField(2, 2)', 'SubSubSubField(1, 2, 3) == SubSubSubField(1, 2, 3)', 'SubSubSubField(1, 2, 3) != SubSubSubField(0, 2, 3)', 'SubField(1) == SubField(1)', 'SubField(1) != SubField(2)', 'SubField(1) == SubField(1)', 'SubField(1) != SubField(2)', 'SubSubField(1, 2) == SubSubField(1, 2)', 'SubSubField(1, 2) != SubSubField(1, 1)', 'SubSubField(1, 2) != SubSubField(2, 2)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2101,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-04 15:50:02-07:00,7d66b3e720cb3e1ffdd7a56e1b17ca23d91d03fd,https://github.com/allenai/allennlp/commit/7d66b3e720cb3e1ffdd7a56e1b17ca23d91d03fd,"report CPU memory usage for each worker (#4323)

* report CPU memory usage for each worker

* fix

* fix

* update docstring",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0']",[],[],[],[],[],[],[],[],[],[],[],[],"['in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0', 'in metrics', 'isinstance(metrics[], float)', 'metrics[] > 0']",[],[],[],[],[],[],[],[],[],[],[],[]
2102,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-05 14:06:12-07:00,11b57996e263050c435fc2eef1b8daebca65a7d0,https://github.com/allenai/allennlp/commit/11b57996e263050c435fc2eef1b8daebca65a7d0,log metrics in alphabetical order (#4327),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2103,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-05 14:47:46-07:00,902d36a520dd75fd82ebaa014799ed8fa6d02e2e,https://github.com/allenai/allennlp/commit/902d36a520dd75fd82ebaa014799ed8fa6d02e2e,"Fix bug with lazy data loading, un-implement __len__ on AllennlpLazyDataset (#4328)

* improve support for lazy data loading

* update changelog

* raise TypeError instead

* fix

* use num_steps_per_epoch=None with lazy",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2104,Matt Gardner,mattg@allenai.org,2020-06-05 16:38:00-07:00,7ab7551bad2c0988067001f4f4b7a20cdd142d75,https://github.com/allenai/allennlp/commit/7ab7551bad2c0988067001f4f4b7a20cdd142d75,"Removing old tutorials, pointing to the new guide in the README (#4334)",58,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2105,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-08 16:07:49+00:00,5c6cc3a2bdd0d90460c3583f1c09a7242bc1ec33,https://github.com/allenai/allennlp/commit/5c6cc3a2bdd0d90460c3583f1c09a7242bc1ec33,Bump mkdocs-material from 5.2.2 to 5.2.3 (#4341),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2106,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-08 09:24:09-07:00,8f68d69b55d5410c39552937e33fb93d0b346d84,https://github.com/allenai/allennlp/commit/8f68d69b55d5410c39552937e33fb93d0b346d84,"load plugins from Predictor.from_path (#4333)

* load plugins from Predictor.from_path

* update CHANGELOG

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2107,Dirk Groeneveld,dirkg@allenai.org,2020-06-08 18:32:56+02:00,2d03c413f83e7811cf79342570e63a2ae62928e4,https://github.com/allenai/allennlp/commit/2d03c413f83e7811cf79342570e63a2ae62928e4,Allow using pretrained transformers without fine-tuning them (#4338),5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,2,2,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['bert_vectors.requires_grad == train_parameters', 'bert_vectors.requires_grad == train_parameters']",[],[],[],[],[],[],"['(, [True, False])', '(, [True, False])']","['parametrize(, [True, False])', 'parametrize(, [True, False])']","['mark.parametrize(, [True, False])', 'mark.parametrize(, [True, False])']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2108,Dirk Groeneveld,dirkg@allenai.org,2020-06-08 19:07:55+02:00,73289bc8193e0d223a616d4f9e58ef918855391e,https://github.com/allenai/allennlp/commit/73289bc8193e0d223a616d4f9e58ef918855391e,Consistently use underscores in Predictor names (#4340),6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2109,Dirk Groeneveld,dirkg@allenai.org,2020-06-08 10:19:09-07:00,3d8ce44228e48f80b668f6bbfb0abf2059b439f1,https://github.com/allenai/allennlp/commit/3d8ce44228e48f80b668f6bbfb0abf2059b439f1,Fixes spelling in changelog,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2110,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-09 19:37:38-07:00,2012fea98bfbb1b60980cdd2760fdf56ae352006,https://github.com/allenai/allennlp/commit/2012fea98bfbb1b60980cdd2760fdf56ae352006,remove links to tutorials in API docs (#4346),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2111,Bruno,brataodream@gmail.com,2020-06-10 13:47:48-03:00,f4d330a25649e1976aed56c8f1a692c0f53e3383,https://github.com/allenai/allennlp/commit/f4d330a25649e1976aed56c8f1a692c0f53e3383,"Update vocabulary load to a system-agnostic newline (#4342)

* Update vocabulary load to a system-agnostic newline

Hello, 
I had a problem about training a model on a Linux machine and loading on a Windows machine.  The error was:
AssertionError: OOV token not found!

After some debugging I found out that during the vocabulary loading, it was splitting by '\n', where this can cause a difference between Linux and Windows. This PR change the split to OS agnostic method of new-line splitting.

* Use a regex because the splitlines algo split on tabulation chars

* Use a regex because the splitlines algo split on tabulation chars

* Added to changelog

* Added to changelog

* Use a pre-compiled regex

Co-authored-by: Bruno Cabral <bruno@potelo.com.br>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2112,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-10 12:35:58-07:00,33d0cd8cd86259fe144f40b433ce83782cb1ac81,https://github.com/allenai/allennlp/commit/33d0cd8cd86259fe144f40b433ce83782cb1ac81,fix file utils test (#4349),1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2113,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-11 14:37:45-07:00,d98d13b5656efb66a0ea227a101878a2ece4f4f1,https://github.com/allenai/allennlp/commit/d98d13b5656efb66a0ea227a101878a2ece4f4f1,"add 'allennlp_server' to default plugins (#4348)

* add 'allennlp_server' to default plugins

* update CHANGELOG",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2114,epwalsh,epwalsh10@gmail.com,2020-06-11 14:44:54-07:00,c3755d168fcfb5982e0939245ed319798967f7f0,https://github.com/allenai/allennlp/commit/c3755d168fcfb5982e0939245ed319798967f7f0,update CHANGELOG,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2115,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-12 12:36:10-07:00,87c23e4a7e25d81e91ba8234eef38b5395993c51,https://github.com/allenai/allennlp/commit/87c23e4a7e25d81e91ba8234eef38b5395993c51,"Fix handling of ""datasets_for_vocab_creation"" param (#4350)

* handle 'datasets_for_vocab_creation' properly

* another fix

* update CHANGELOG

* fixes

* fix CHANGELOG

* fix

* updaet CHANGELOG

* tests and improvements

* revert small change",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,2,0,0,0,1,0,1,1,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not in log_messages', 'not in log_messages', 'not in log_messages', 'not in log_messages', 'in log_messages', 'not in log_messages', 'not in log_messages', 'in log_messages', 'not in log_messages', 'not in log_messages', 'in log_messages', 'in log_messages', 'in log_messages', 'in log_messages', 'in log_messages', 'in log_messages', 'in log_messages', 'in log_messages', 'not in log_messages', 'in log_messages', 'in log_messages', 'not in log_messages', 'in log_messages']","['(ConfigurationError, match=)', '(ConfigurationError, match=)']",[],[],[],"['(scope=, autouse=True)']",[],[''],['parametrize('],"['fixture(scope=, autouse=True)', 'mark.parametrize(']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2116,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-13 17:36:55-07:00,6a124d80a1166169e5a740f5390f8e25780579e2,https://github.com/allenai/allennlp/commit/6a124d80a1166169e5a740f5390f8e25780579e2,"ensure 'from_files' vocab doesn't load instances (#4356)

* ensure 'from_files' vocab doesn't load instances

* clean up

* consolidate CUDA check in CI",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2117,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-15 09:40:59-07:00,884a6149ea0f4e9b53dabbf99263d46af5a1b9a8,https://github.com/allenai/allennlp/commit/884a6149ea0f4e9b53dabbf99263d46af5a1b9a8,"Bump mkdocs-material from 5.2.3 to 5.3.0 (#4359)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.2.3 to 5.3.0.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.2.3...5.3.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2118,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-15 11:03:25-07:00,b764bef5f3e6c42cea0800b9acf4eed9f316a7aa,https://github.com/allenai/allennlp/commit/b764bef5f3e6c42cea0800b9acf4eed9f316a7aa,"simplify dataset classes, fix multi-process lazy loading (#4344)

* simplify dataset classes, fix multi-process lazy loading

* remove unecessary overrides decorators

* warn about tokenizers deadlock

* clean up

* fix race conditions

* fix type hint

* remove outdated docstring

* fixes

* fix caching again

* issue warning when can't write to cache safely

* comments

* update CHANGELOG

* update docstring of _read

* revert generic type

* test and fix 'multi_worker_islice

* clean up

* no more tuples :(

* revert, revert, revert

* revert

* revert

* non-lazy locking

* add another test

* revert

* make mypy happy

* update CHANGELOG

* improvements

* fix comment

* doc fixes

* update CHANGELOG

* tweak docs

* improve caching system

* improve caching

* add test

* add another logging statement

* warnings

* add UserWarning about manual sharding",12,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,3,0,0,0,0,0,5,5,5,7,0,1,8,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not os.path.exists(handle.name)', 'not os.path.exists(cache_filename)', 'isinstance(instances, AllennlpLazyDataset)', 'len(first_pass_instances) > 2', 'first_pass_instances == second_pass_instances', 'not os.path.exists(cache_file)', '.join([rec.message for rec in caplog.records])', '.join([rec.message for rec in caplog.records])', 'in caplog.text', 'instances', 'not os.path.exists(cache_file)', 'os.path.exists(cache_file)', 'in caplog.text', 'instances', 'not os.path.exists(cache_file)', 'in caplog.text', 'not os.path.exists(cache_file)', 'instances', 'os.path.exists(cache_file)', 'len(instances) == len(new_instances)', 'len(instances) == 2', 'len(instances) == 2', 'not os.path.exists(cache_file)', 'len(instances) > 2', 'os.path.exists(cache_file)', 'len(instances) == 2', 'result == expected_result']","['(IOError, match=)', '(ConfigurationError, match=)', '(ConfigurationError, match=)']",[],[],[],[],[],"['(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (0, 1, 2))', '']","['parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (0, 1, 2))', 'parametrize(']","['mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (0, 1, 2))', 'mark.parametrize(']","['setattr(common_util, , lambda: True)', 'setattr(dist, , lambda: 0)', 'setattr(dist, , lambda: 1)', 'setattr(common_util, , lambda: True)', 'setattr(dist, , lambda: node_rank)', 'setattr(dist, , lambda: world_size)', 'setattr(']",[],['import pytest'],"['not os.path.exists(cache_file)', 'os.path.exists(cache_file)', 'len(instances) == len(cached_instances)', 'instance.fields == cached_instance.fields', 'isinstance(instances, _LazyInstances)', 'not os.path.exists(cache_file)', 'instance_count > 2', 'instance_count == 2']",[],[],[],[],[],[],[],[],[],[],[],[]
2119,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-16 09:47:21-07:00,c5549105cc11cf0a02a9295bcfdf2e8f7372bb98,https://github.com/allenai/allennlp/commit/c5549105cc11cf0a02a9295bcfdf2e8f7372bb98,quick doc fixes (#4364),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2120,epwalsh,epwalsh10@gmail.com,2020-06-16 10:01:57-07:00,d3ed6197de723c535e417ea058c028cee9da262b,https://github.com/allenai/allennlp/commit/d3ed6197de723c535e417ea058c028cee9da262b,fix Makefile,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2121,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-16 11:06:33-07:00,a8b840df93efa06890fcc214c8bbea5ea2be6bdd,https://github.com/allenai/allennlp/commit/a8b840df93efa06890fcc214c8bbea5ea2be6bdd,"fix some formatting issues in README (#4365)

* fix some formatting issues in README

* add link to repo from API docs",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2122,epwalsh,epwalsh10@gmail.com,2020-06-16 11:10:23-07:00,29f3b6c36cab1b3d9e347f4d985253e9c9c9e6de,https://github.com/allenai/allennlp/commit/29f3b6c36cab1b3d9e347f4d985253e9c9c9e6de,Prepare for release v1.0.0,3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2123,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-16 14:37:37-07:00,ef7c75b8c1358c5582a9d1a967f00d7af2b6f7f1,https://github.com/allenai/allennlp/commit/ef7c75b8c1358c5582a9d1a967f00d7af2b6f7f1,reduce amount of log messages produced by file_utils (#4366),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2124,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-17 18:03:01+00:00,63a5e15887333e814436b3d54dc5381c7bf89f03,https://github.com/allenai/allennlp/commit/63a5e15887333e814436b3d54dc5381c7bf89f03,"Update spacy requirement from <2.3,>=2.1.0 to >=2.1.0,<2.4 (#4370)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2125,epwalsh,epwalsh10@gmail.com,2020-06-17 16:52:49-07:00,4f70bc93d286a8bb6d563c17397573efe9257474,https://github.com/allenai/allennlp/commit/4f70bc93d286a8bb6d563c17397573efe9257474,tick version for nightly releases,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2126,Matt Gardner,mattg@allenai.org,2020-06-18 09:09:23-07:00,3e8a9ef606ed258295237d54f7cdae4a22382542,https://github.com/allenai/allennlp/commit/3e8a9ef606ed258295237d54f7cdae4a22382542,Add link to new template repo for config file development (#4372),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2127,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-18 16:21:50-07:00,e52b7518c2a957cf34812855db42658566be8484,https://github.com/allenai/allennlp/commit/e52b7518c2a957cf34812855db42658566be8484,"ensure transformer params are frozen at initialization when train_parameters is false (#4377)

* ensure transformer params are frozen at initialization

* update CHANGELOG

* removed un-needed member var",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2128,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-18 23:32:19+00:00,ebde6e8567b6e6f43aefefb8fbe8adc254e2a897,https://github.com/allenai/allennlp/commit/ebde6e8567b6e6f43aefefb8fbe8adc254e2a897,Bump overrides from 3.0.0 to 3.1.0 (#4375),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2129,Matt Gardner,mattg@allenai.org,2020-06-19 15:11:36-07:00,bf422d5648a6b9db7332252d786d52be5f2d11dc,https://github.com/allenai/allennlp/commit/bf422d5648a6b9db7332252d786d52be5f2d11dc,Add github template for using your own python run script (#4380),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2130,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-21 17:10:19-07:00,6852deff7a7e59f11af3f35fd0d71de34e74b98a,https://github.com/allenai/allennlp/commit/6852deff7a7e59f11af3f35fd0d71de34e74b98a,"pin some doc building requirements (#4386)

* pin some doc building requirements

* tweak",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2131,Matt Gardner,mattg@allenai.org,2020-06-21 20:15:44-07:00,c2ecb7a282eb8462d0557bbfed913b1dbe213a70,https://github.com/allenai/allennlp/commit/c2ecb7a282eb8462d0557bbfed913b1dbe213a70,"Add a method to ModelTestCase for use without config files (#4381)

* Add a method to ModelTestCase for use without config files

* Updated changelog

* add missing parameter to docstring",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metric_value is not None, f', 'metric_terminal_value is not None, ', 'abs(metric_value - metric_terminal_value) < metric_tolerance']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2132,Michael Schmitz,MichaelS@allenai.org,2020-06-22 01:28:40-07:00,85e531c240ec8df0979e01d2dc38c27b33550094,https://github.com/allenai/allennlp/commit/85e531c240ec8df0979e01d2dc38c27b33550094,"Update README.md (#4385)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2133,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-22 13:36:49+00:00,ba79f146874b35094d8380c6b1a8fcf5c4c2d4c3,https://github.com/allenai/allennlp/commit/ba79f146874b35094d8380c6b1a8fcf5c4c2d4c3,Bump mypy from 0.780 to 0.781 (#4390),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2134,Crissman Loomis,crissman@preferred.jp,2020-06-23 00:55:01+09:00,20afe6ce8a4457a4822aaf92e9925dd2c3f8dd29,https://github.com/allenai/allennlp/commit/20afe6ce8a4457a4822aaf92e9925dd2c3f8dd29,Add Optuna integrated badge to README.md (#4361),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2135,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-22 09:20:32-07:00,ffc51843ff76931f990f17877fad820281c898be,https://github.com/allenai/allennlp/commit/ffc51843ff76931f990f17877fad820281c898be,"ensure Vocab.from_files and ShardedDatasetReader can handle archives (#4371)

* ensure Vocab.from_files can handle archives

* handle archive with ShardedDatasetReader

* through helpful ConfigurationError

* update docstring",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.isdir(extracted)', 'os.path.exists(os.path.join(extracted, ))', 'os.path.exists(os.path.join(extracted, ))', 'os.path.basename(extracted) == ', 'os.path.basename(extracted) == ', 'extracted.endswith()', 'extracted.endswith()', 'vocab.get_token_from_index(3, namespace=', 'vocab.get_token_from_index(3, namespace=', 'vocab.get_token_from_index(3, namespace=']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2136,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-22 16:28:10+00:00,1d07cc75ade2eedda2dd681037aec9e133ba6755,https://github.com/allenai/allennlp/commit/1d07cc75ade2eedda2dd681037aec9e133ba6755,Bump mkdocs-material from 5.3.0 to 5.3.2 (#4389),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2137,epwalsh,epwalsh10@gmail.com,2020-06-22 16:40:49-07:00,b0ba2d4c76eb3c7081fa0a9eba52d864182554be,https://github.com/allenai/allennlp/commit/b0ba2d4c76eb3c7081fa0a9eba52d864182554be,update version,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2138,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-23 08:25:04-07:00,30e5dbfc2f806eb607600bf024b4f3118e46562a,https://github.com/allenai/allennlp/commit/30e5dbfc2f806eb607600bf024b4f3118e46562a,"Bump mypy from 0.781 to 0.782 (#4395)

Bumps [mypy](https://github.com/python/mypy) from 0.781 to 0.782.
- [Release notes](https://github.com/python/mypy/releases)
- [Commits](https://github.com/python/mypy/compare/v0.781...v0.782)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2139,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-23 16:12:50-07:00,b6fd6978b507ce6118023e23f3e4dbfa334d39b5,https://github.com/allenai/allennlp/commit/b6fd6978b507ce6118023e23f3e4dbfa334d39b5,"fix sharded dataset reader (#4396)

* fix sharded dataset reader

* update CHANGELOG

* fix",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2140,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-25 04:54:53-07:00,e104e4419157a7d41e91421db6fa8ce304082feb,https://github.com/allenai/allennlp/commit/e104e4419157a7d41e91421db6fa8ce304082feb,Add test to ensure data loader yields all instances when batches_per_epoch is set (#4394),1,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['epoch_batches == ['],[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2141,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-25 13:46:47-07:00,7fa7531c8c3e9cb4fd0f2807fbd22e70dab7600e,https://github.com/allenai/allennlp/commit/7fa7531c8c3e9cb4fd0f2807fbd22e70dab7600e,"fix __eq__ method of ArrayField (#4401)

* fix __eq__ method of ArrayField

* update CHANGELOG",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['array1 != array2', 'array1 != array3', 'array1 == array4']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2142,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-06-25 20:56:54+00:00,aa2943e50d8ee81ea86a907c72f5d56a83ddc2fc,https://github.com/allenai/allennlp/commit/aa2943e50d8ee81ea86a907c72f5d56a83ddc2fc,Bump mkdocs-material from 5.3.2 to 5.3.3 (#4398),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2143,Pengcheng YIN,pcyin@cs.cmu.edu,2020-06-26 22:23:44-04:00,eee15ca80ade6ec414162aa945aba61446698356,https://github.com/allenai/allennlp/commit/eee15ca80ade6ec414162aa945aba61446698356,Assign an empty mapping array to empty fields of `NamespaceSwappingField` (#4403),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2144,Dirk Groeneveld,dirkg@allenai.org,2020-06-29 14:47:55+02:00,96ff58514d84aeaf7e46f66756c202c713e1101c,https://github.com/allenai/allennlp/commit/96ff58514d84aeaf7e46f66756c202c713e1101c,"Changes from my multiple-choice work (#4368)

* Ability to ignore dimensions in the bert pooler

* File reading utilities

* Productivity through formatting

* More reasonable defaults for the Huggingface AdamW optimizer

* Changelog

* Adds a test for the BertPooler

* We can't run the new transformers lib yet

* Pin more recent transformer version

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Adds ability to override transformer weights

* Adds a transformer cache, and the ability to override weights

* Fix up this PR

* Fix comment

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",13,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['encoder.get_input_dim() == encoder.get_output_dim()', 'pooled1.size() == (8, encoder.get_input_dim())']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2145,Dirk Groeneveld,dirkg@allenai.org,2020-06-29 20:41:19+02:00,54c41fcc8f2a7ba366e848c88874199a4246385a,https://github.com/allenai/allennlp/commit/54c41fcc8f2a7ba366e848c88874199a4246385a,"Adds the ability to automatically detect whether we have a GPU (#4400)

* Adds the ability to automatically detect whether we have a GPU

* Make `None` the default

* Changelog

* Fix type annotations and defaults

* Actually test that the right device is used

* More tests

* The batches we see in the callback are never on the GPU

* We have many places where we initialize the trainer.",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(_seen_training_devices) == 1', 'seen_training_device.type == ', 'seen_training_device.type == ', 'len(_seen_training_devices) == 1', 'seen_training_device.type == ', 'len(_seen_training_devices) == 1', 'seen_training_device.type == ']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2146,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-29 15:30:14-07:00,84988b8149c2b69329136383c05ace2865adba17,https://github.com/allenai/allennlp/commit/84988b8149c2b69329136383c05ace2865adba17,"Log plugins discovered and filter out transformers ""PyTorch version ... available"" log message (#4414)

* filter out transformers pytorch log msg, log plugins

* update CHANGELOG

* make flake8 happy",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2147,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-30 00:28:22-07:00,9c4dfa544e85e00d636beb0026a08e40dcdb6404,https://github.com/allenai/allennlp/commit/9c4dfa544e85e00d636beb0026a08e40dcdb6404,small fix to pretrained transformer tokenizer (#4417),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2148,Evan Pete Walsh,epwalsh10@gmail.com,2020-06-30 07:52:36-07:00,637dbb159082999c546ac2fc64746b88e5c9d1b5,https://github.com/allenai/allennlp/commit/637dbb159082999c546ac2fc64746b88e5c9d1b5,"fix README, pin mkdocs, update mkdocs-material (#4412)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2149,Dirk Groeneveld,dirkg@allenai.org,2020-07-01 17:14:55+02:00,acd999526c56603d2ce388a762336f88df0483ee,https://github.com/allenai/allennlp/commit/acd999526c56603d2ce388a762336f88df0483ee,"Automatic file-friendly logging (#4383)

* Makes it possible to turn off redirecting stdout and stderr

* Changelog

* Log uncaught exceptions

* Simplified logging

* Remove tee

* Changelog

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,12,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files']",[],[],[],[],[],[],[],[],[],[],[],[],"['in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files']",[],[],[],[],[],[],[],[],[],[],[],[]
2150,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-01 08:28:21-07:00,6d0a4fd2bf5b1b0e8118a6ad8f8aaea7d5058893,https://github.com/allenai/allennlp/commit/6d0a4fd2bf5b1b0e8118a6ad8f8aaea7d5058893,"generalize DataLoader (#4416)

* generalize DataLoader

* update CHANGELOG

* fixes

* fix tests

* Update CHANGELOG.md

Co-authored-by: Matt Gardner <mattg@allenai.org>

Co-authored-by: Matt Gardner <mattg@allenai.org>",14,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2151,Dirk Groeneveld,dirkg@allenai.org,2020-07-01 17:39:30+02:00,23e549e4c98a31fd92e188c15034a3ddca8a3bfb,https://github.com/allenai/allennlp/commit/23e549e4c98a31fd92e188c15034a3ddca8a3bfb,More multiple-choice changes (#4415),7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['optimizer.param_groups[0][] == 0.5  # 1.0 * 1/2', 'optimizer.param_groups[0][] == 1.0  # 1.0 * 2/2', 'optimizer.param_groups[0][] == 0.75', 'optimizer.param_groups[0][] == 0.5', 'optimizer.param_groups[0][] == 0.25', 'optimizer.param_groups[0][] == 0.0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2152,Matt Gardner,mattg@allenai.org,2020-07-02 04:48:01-07:00,60deece9fca2da6b66bfcde44484384bdefa3fe7,https://github.com/allenai/allennlp/commit/60deece9fca2da6b66bfcde44484384bdefa3fe7,"Fix type hint in text_field.py (#4434)

Fixes #4433.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2153,Ryo Takahashi,reiyw.setuve@gmail.com,2020-07-06 23:15:49+09:00,8229aca3be784ae3af5cd4edec2749124e6b6cba,https://github.com/allenai/allennlp/commit/8229aca3be784ae3af5cd4edec2749124e6b6cba,"Fix pretrained model initialization (#4439)

* Add failing test

* Use copy_ instead of slicing

* Update CHANGELOG",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.equal(self.net1.scalar, self.net2.scalar)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2154,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-07-06 10:40:29-07:00,e46a578ea83b99223174c55f15cd9a935bc11cdf,https://github.com/allenai/allennlp/commit/e46a578ea83b99223174c55f15cd9a935bc11cdf,"Update transformers requirement from <2.11,>=2.10 to >=2.10,<2.12 (#4411)

* Update transformers requirement from <2.11,>=2.10 to >=2.10,<2.12

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v2.10.0...v2.11.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* change model name back to 'facebook/bart'

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2155,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-06 11:04:32-07:00,8482f022c281fafcb8bbc9c3eb63796d427304e2,https://github.com/allenai/allennlp/commit/8482f022c281fafcb8bbc9c3eb63796d427304e2,fix bug with SlantedTriangular LR scheduler (#4443),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2156,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-07 02:32:14-07:00,5b988d637d9d2fde405eb0d0bc22b3bdb4012ad2,https://github.com/allenai/allennlp/commit/5b988d637d9d2fde405eb0d0bc22b3bdb4012ad2,"ensure only rank 0 worker writes to terminal (#4445)

* ensure only rank 0 worker writes to terminal

* update CHANGELOG",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2157,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-08 08:29:14-07:00,8a05ad43f1ff66b81dc1386903976d607da29a99,https://github.com/allenai/allennlp/commit/8a05ad43f1ff66b81dc1386903976d607da29a99,Update CONTRIBUTING.md (#4447),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2158,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-08 11:17:27-07:00,c75a1ebdc305c359ad0f1244c67b636895a7c0fd,https://github.com/allenai/allennlp/commit/c75a1ebdc305c359ad0f1244c67b636895a7c0fd,ensure base reader of ShardedDatasetReader doesn't implement sharding itself (#4454),3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ValueError, match=)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2159,Yohei Tamura,tamuhey@gmail.com,2020-07-10 01:15:32+09:00,181ef5d2d6c931e229edb59ffdace6300483b6f4,https://github.com/allenai/allennlp/commit/181ef5d2d6c931e229edb59ffdace6300483b6f4,"pin boto3 to resolve some dependency issues (#4453)

* fix boto3 dependency for poetry

* fix boto3 version

* modified:   CHANGELOG.md

Co-authored-by: Michael Schmitz <MichaelS@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2160,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-07-09 11:50:12-07:00,b9a91646bd97942609b545794e889b16ba8e05a5,https://github.com/allenai/allennlp/commit/b9a91646bd97942609b545794e889b16ba8e05a5,"Update transformers requirement from <2.12,>=2.10 to >=2.10,<3.1 (#4446)

* Update transformers requirement from <2.12,>=2.10 to >=2.10,<3.1

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v2.10.0...v3.0.2)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* remove 'add_prefix_space' param

* Pin transformers to at least 3.0

* update tokenizer tests

* update token indexer tests

* update CHANGELOG

* patch models branch temporarily

* revert models CI patch

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['indexed['],[],[],[],[],[],[],[],[],[],[],[],[],['indexed[] == expected_ids'],[],[],[],[],[],[],[],[],[],[],[],[]
2161,Akshita Bhagia,akshita23bhagia@gmail.com,2020-07-10 12:23:46-04:00,8c32ddfda04a712f623d31e40b21b10d91f075dc,https://github.com/allenai/allennlp/commit/8c32ddfda04a712f623d31e40b21b10d91f075dc,Fixing bug in TextClassificationPredictor so that it passes tokenized inputs to the DatasetReader (#4456),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2162,Akshita Bhagia,akshita23bhagia@gmail.com,2020-07-10 13:28:24-04:00,6acf20582db29d9d92c83a8b2380173f912fff93,https://github.com/allenai/allennlp/commit/6acf20582db29d9d92c83a8b2380173f912fff93,"Fix regloss logging (#4449)

* hide reg_loss from display for models with no regularization penalty (#4436)

* Updating CHANGELOG

* hide reg_loss from display for models with no regularization penalty (#4436)

* Updating CHANGELOG

* Fixing the issue of inadvertently hiding other metrics

* hide reg_loss from display for models with no regularization penalty (#4436)

* Updating CHANGELOG

* Fixing the issue of inadvertently hiding other metrics

* reg_loss is only returned if regularization penalty is configured

* ensure that configured regularization penalty is a tensor

* Adding check to ensure that regularizer is not a non-zero float",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['penalty is None'],['(RuntimeError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],['penalty == 0'],[],[],[],[],[],[],[],[],[],[],[],[]
2163,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-10 12:02:37-07:00,d00ad66879006cefd50426a8a010602159caabbe,https://github.com/allenai/allennlp/commit/d00ad66879006cefd50426a8a010602159caabbe,"Minor tqdm and logging clean up (#4448)

* fix formatting

* set tqdm descriptions in various places

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2164,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-10 12:34:25-07:00,7a563a8fabfe333b64214cd89fdcf89c2fb672bb,https://github.com/allenai/allennlp/commit/7a563a8fabfe333b64214cd89fdcf89c2fb672bb,"add option to use scalar mix of all transformer layers (#4460)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,1,0,0,0,0,0,0,1,1,1,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['bert_vectors.requires_grad == (train_parameters or not last_layer_only)'],[],[],[],[],[],[],[''],['parametrize('],['mark.parametrize('],[],[],[],['bert_vectors.requires_grad == train_parameters'],[],[],[],[],[],[],"['(, [True, False])']","['parametrize(, [True, False])']","['mark.parametrize(, [True, False])']",[],[],[]
2165,Dirk Groeneveld,dirkg@allenai.org,2020-07-13 19:31:54+02:00,b9d011ef90709d7892000420e45e27d205a21c4a,https://github.com/allenai/allennlp/commit/b9d011ef90709d7892000420e45e27d205a21c4a,"More BART changes (#4468)

* Make cached_path work with files inside archives

* Performance gain

* Productivity through formatting

* Test for extracting files in cached_file()

* Changelog",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['f.read().startswith()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2166,John Giorgi,johnmgiorgi@gmail.com,2020-07-13 13:47:41-04:00,64db027d9178012f8286705369bf1dedfc663d22,https://github.com/allenai/allennlp/commit/64db027d9178012f8286705369bf1dedfc663d22,"Skip ETag check if OSError (#4469)

* Skip ETag check if OSError

* Update changelog with info about cached_path fix

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2167,Akshita Bhagia,akshita23bhagia@gmail.com,2020-07-13 16:54:54-04:00,7b188c93b5efe2f417fc541b61f6be29bc2e632f,https://github.com/allenai/allennlp/commit/7b188c93b5efe2f417fc541b61f6be29bc2e632f,fixed bug that erronously increased last label's false positive count (#4473),3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2168,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-14 03:02:26-07:00,69d2f03db6b1e3fec37a711a912df4c2181ffd13,https://github.com/allenai/allennlp/commit/69d2f03db6b1e3fec37a711a912df4c2181ffd13,"Clean up Tqdm bars when output is being piped or redirected (#4470)

* fix Tqdm formatting when output being redirected

* update changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2169,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-14 10:22:02-07:00,9c801a3ceb367bc6cbf5c2c3aa8629697f3bffeb,https://github.com/allenai/allennlp/commit/9c801a3ceb367bc6cbf5c2c3aa8629697f3bffeb,"add CHANGELOG to API docs, point to license on GitHub, improve API doc formatting (#4472)

* add CHANGELOG to API docs

* point to license directly on GitHub

* tweak renderer

* fix failing test

* improvements

* update CHANGELOG

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2170,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-14 13:51:10-07:00,f195440bf2f81b003be6e54b67428389b6c000da,https://github.com/allenai/allennlp/commit/f195440bf2f81b003be6e54b67428389b6c000da,"update 'Models' links in README (#4475)

* update 'Models' links in README

* tweak",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2171,epwalsh,epwalsh10@gmail.com,2020-07-14 13:54:17-07:00,4eb9795368861b543a1ab6b80b63cd662d982077,https://github.com/allenai/allennlp/commit/4eb9795368861b543a1ab6b80b63cd662d982077,Prepare for release v1.1.0rc1,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2172,epwalsh,epwalsh10@gmail.com,2020-07-14 14:16:30-07:00,5c970833c1551c26c0d5f7014e3b94d6abb1e22a,https://github.com/allenai/allennlp/commit/5c970833c1551c26c0d5f7014e3b94d6abb1e22a,fix release link in CHANGELOG and formatting in README,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2173,Akshita Bhagia,akshita23bhagia@gmail.com,2020-07-15 10:28:24-04:00,9144918dd48be314ff98f4b49b9af5c4199b765d,https://github.com/allenai/allennlp/commit/9144918dd48be314ff98f4b49b9af5c4199b765d,"Fix reported loss (#4477)

* fixed bug that erroneously increased last label's false positive count

* adding  to training metrics

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics[] == float(loss / num_batches)', 'metrics[] == loss', 'metrics[] == float(loss / num_batches)', 'not in metrics']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2174,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-15 09:48:11-07:00,2f878322a06e6e2c5aecbeedfb3680b0981ecbc7,https://github.com/allenai/allennlp/commit/2f878322a06e6e2c5aecbeedfb3680b0981ecbc7,"only show validation progress bar from main process (#4476)

* only show validation progress bar from main process

* fix",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2175,Dirk Groeneveld,dirkg@allenai.org,2020-07-15 19:44:34+02:00,d693cf1ca4b111ba38b35dacba6a45a8d673f439,https://github.com/allenai/allennlp/commit/d693cf1ca4b111ba38b35dacba6a45a8d673f439,"PathLike (#4479)

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2176,epwalsh,epwalsh10@gmail.com,2020-07-15 11:35:54-07:00,53eeec105fa0da91a7793e45c66b9cec14c45dff,https://github.com/allenai/allennlp/commit/53eeec105fa0da91a7793e45c66b9cec14c45dff,tick version for nightly releases,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2177,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-17 01:34:11-07:00,db20b1fbca7cb43b3521b4a13aa5315a80b4fee1,https://github.com/allenai/allennlp/commit/db20b1fbca7cb43b3521b4a13aa5315a80b4fee1,"use longer tqdm intervals when output being redirected (#4488)

* use longer tqdm intervals when output being redirected

* update CHANGELOG",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2178,Akshita Bhagia,akshita23bhagia@gmail.com,2020-07-17 04:44:52-04:00,714334ad35cc4517c2bc8802ba2d16abf2666b5f,https://github.com/allenai/allennlp/commit/714334ad35cc4517c2bc8802ba2d16abf2666b5f,"Fix reported loss: Bug fix in batch_loss (#4485)

* fixed bug that erronously increased last label's false positive count

* adding  to training metrics

* adding  to training metrics

* fixed bug that erronously increased last label's false positive count

* Bug fix in reported per-batch loss

* Update to CHANGELOG

* adding test case for reported batch loss

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['metrics[] == float(sum(trainer.batch_losses) / batches_per_epoch)', 'metrics[] == float(total_loss / num_batches)', 'metrics[] == batch_loss', 'metrics[] == float(total_loss / num_batches)']",[],[],[],[],[],[],[],[],[],[],[],[],"['metrics[] == float(loss / num_batches)', 'metrics[] == loss', 'metrics[] == float(loss / num_batches)']",[],[],[],[],[],[],[],[],[],[],[],[]
2179,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-17 08:49:02-07:00,478bf46cb676524ee9b74fb271ec0a592d1c4a48,https://github.com/allenai/allennlp/commit/478bf46cb676524ee9b74fb271ec0a592d1c4a48,"remove deadlock warning in DataLoader (#4487)

* remove deadlock warning

* fix CHANGELOG

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2180,wlhgtc,hgtcwl@foxmail.com,2020-07-21 23:14:36+08:00,1cab3bfef37ea25b9d019013e5259a1669b19faa,https://github.com/allenai/allennlp/commit/1cab3bfef37ea25b9d019013e5259a1669b19faa,"Update beam_search.py (#4462)

* Update beam_search.py

1. support for multi-layer decoders

* reformat code and fix bug in shape check

* Update CHANGELOG.md

* change shape check conditions

* add test case for diff shape state

* fix beam test bug

* fix gather bug

* adjust conditions for diff shape

* fix key error

* Update CHANGELOG.md

* fix batch_size name error

* recover blank line

* make code clearly

* fix varaible assign bug

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2181,Dirk Groeneveld,dirkg@allenai.org,2020-07-23 19:54:59+02:00,d73f8a91fc32d1a51235977fee2732aa61d7182c,https://github.com/allenai/allennlp/commit/d73f8a91fc32d1a51235977fee2732aa61d7182c,"More BART changes (#4500)

* Make it possible to test models that only return a loss when training

* Give the indexer one more chance to update the vocab

* Changelog",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['loaded_model_loss is not None'],[],[],[],[],[],[],[],[],[],[],[],[],['loaded_model_loss is not None'],[],[],[],[],[],[],[],[],[],[],[],[]
2182,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-07-24 08:53:29-07:00,6c848dfbb8f59d68e1e7d9f3b2de63c80f57c4ee,https://github.com/allenai/allennlp/commit/6c848dfbb8f59d68e1e7d9f3b2de63c80f57c4ee,"Bump mkdocs-material from 5.4.0 to 5.5.0 (#4507)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.4.0 to 5.5.0.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.4.0...5.5.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2183,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-24 13:35:48-07:00,18a4eb3495903a31d4fd7991b922854889d6c37f,https://github.com/allenai/allennlp/commit/18a4eb3495903a31d4fd7991b922854889d6c37f,"add a requires_grad option to param groups (#4502)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['all([param.requires_grad for param in self.model.text_field_embedder.parameters()])', 'not any(', 'len(param_groups[2][]) == 2']",[],[],[],[],[],[],[],[],[],[],[],[],['len(param_groups[2][]) == 3'],[],[],[],[],[],[],[],[],[],[],[],[]
2184,Dirk Groeneveld,dirkg@allenai.org,2020-07-24 22:45:05+02:00,14f63b771835fe7233bad947268869f3d90e1a7d,https://github.com/allenai/allennlp/commit/14f63b771835fe7233bad947268869f3d90e1a7d,"Make sure we have a bool tensor where we expect one (#4505)

Co-authored-by: ai2-bulldozer[bot] <47044978+ai2-bulldozer[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2185,Akshita Bhagia,akshita23bhagia@gmail.com,2020-07-27 11:21:00-04:00,e53d18580807dabff707f618f7e148c98d25da18,https://github.com/allenai/allennlp/commit/e53d18580807dabff707f618f7e148c98d25da18,"Bug fix for case when param type is Optional[Union...] (#4510)

* Bug fix for case when param type is Optional[Union...]

* Update CHANGELOG

* Adding test case",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2186,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-30 16:54:34-07:00,fa39d4988231f3e8dd082a2c991e24cb1dabb8a8,https://github.com/allenai/allennlp/commit/fa39d4988231f3e8dd082a2c991e24cb1dabb8a8,ensure __call__ methods are rendered in docs (#4522),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2187,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-31 09:16:14-07:00,54e5c83e2caa82adb580dcb7a83681a2eaf165b1,https://github.com/allenai/allennlp/commit/54e5c83e2caa82adb580dcb7a83681a2eaf165b1,closes #4494 (#4508),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2188,Evan Pete Walsh,epwalsh10@gmail.com,2020-07-31 09:16:42-07:00,2401282352b244ee8faa7d7bd52e7c09c1a76a2a,https://github.com/allenai/allennlp/commit/2401282352b244ee8faa7d7bd52e7c09c1a76a2a,add back file-friendly-logging flag (#4509),7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2189,Makoto Hiramatsu,himkt@cookpad.com,2020-08-01 01:17:32+09:00,146bd9eea014315068625ee26f464360708bcadf,https://github.com/allenai/allennlp/commit/146bd9eea014315068625ee26f464360708bcadf,"Remove link to self-attention modules. (#4512)

* Remove link to self-attention modules

* CHANGELOG

* Fix links to pytorch modules

* FeedfowardEncoder -> FeedForwardEncoder

* Add compose and gated-cnn

* Fix path to {PassThrough,FeedForward}Encoder

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Apply suggestions from code review

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Remove alternating_highway_lstm

* Add stacked_bidirectional_lstm

* Use internal links for {RNN,LSTM,GRU} encoders

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2190,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-07-31 09:36:31-07:00,9415350de27754c55dbdb26b4418c3e4b3af921c,https://github.com/allenai/allennlp/commit/9415350de27754c55dbdb26b4418c3e4b3af921c,"Update torch requirement from <1.6.0,>=1.5.0 to >=1.5.0,<1.7.0 (#4519)

* Update torch requirement from <1.6.0,>=1.5.0 to >=1.5.0,<1.7.0

Updates the requirements on [torch](https://github.com/pytorch/pytorch) to permit the latest version.
- [Release notes](https://github.com/pytorch/pytorch/releases)
- [Commits](https://github.com/pytorch/pytorch/compare/v1.5.0...v1.6.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* fix tensor division

* replace Apex with torch's native amp

* add another note to CHANGELOG

* use amp during validation as well

* change test name

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>
Co-authored-by: ai2-bulldozer[bot] <47044978+ai2-bulldozer[bot]@users.noreply.github.com>",9,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[''],['parametrize('],['mark.parametrize('],[],[],[],[],[],[],"['if(amp is None, reason=)']",[],[],[],[],"['skipif(amp is None, reason=)']","['mark.skipif(amp is None, reason=)']",[],[],[]
2191,epwalsh,epwalsh10@gmail.com,2020-07-31 09:56:01-07:00,73220d71cd5990f38747e50e64674a5166347e52,https://github.com/allenai/allennlp/commit/73220d71cd5990f38747e50e64674a5166347e52,Prepare for release v1.1.0rc2,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2192,epwalsh,epwalsh10@gmail.com,2020-07-31 10:11:08-07:00,e80d7687fd766217f0c53054ace8616939a845a2,https://github.com/allenai/allennlp/commit/e80d7687fd766217f0c53054ace8616939a845a2,pin torch >= 1.6,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2193,Santiago Castro,santiagoc@netflix.com,2020-08-03 12:56:02-04:00,5bc3b73208695499a12a8ae0e5ed860e4d964bcc,https://github.com/allenai/allennlp/commit/5bc3b73208695499a12a8ae0e5ed860e4d964bcc,"Fix typo in warning in file_utils (#4527)

* Fix typo in warning in file_utils

* Fix another typo in a comment in the same file",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2194,Alasdair Tran,alasdair.tran@gmail.com,2020-08-05 02:19:12+10:00,bfecdc3efdf5903d2f0cc7756bd1263e6fd4d213,https://github.com/allenai/allennlp/commit/bfecdc3efdf5903d2f0cc7756bd1263e6fd4d213,"Ensure len(self.evaluation_data_loader) is not called (#4531)

* Ensure len(self.evaluation_data_loader) is not called

* Update CHANGELOG.md",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2195,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-08-04 09:19:54-07:00,9209bc913f869256677a2806a22dd52e8698b55f,https://github.com/allenai/allennlp/commit/9209bc913f869256677a2806a22dd52e8698b55f,"Bump mkdocs-material from 5.5.0 to 5.5.3 (#4533)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.5.0 to 5.5.3.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.5.0...5.5.3)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2196,Nitish Gupta,gnnitish@gmail.com,2020-08-05 16:57:08-04:00,15e288f5c23dcfd45bc093e7ad27453996c7e566,https://github.com/allenai/allennlp/commit/15e288f5c23dcfd45bc093e7ad27453996c7e566,"EpochCallBack for tracking epoch (#4540)

* EpochCallback for tracking epoch in the model

* minor lint

* updated CHANGELOG

* added unit test for track epoch callback

* Update allennlp/training/trainer.py

Co-authored-by: Matt Gardner <mattg@allenai.org>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['trainer.model.epoch == num_epochs'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2197,Evan Pete Walsh,epwalsh10@gmail.com,2020-08-07 02:25:34-07:00,660fdaf2e189ea8748413d38311faafc9d62402c,https://github.com/allenai/allennlp/commit/660fdaf2e189ea8748413d38311faafc9d62402c,"Fix handling of max length with transformer tokenizers (#4534)

* explicity set 'truncation' param for transformer tokenizer

* update CHANGELOG

* add some tests

* clarify CHANGELOG

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(tokens) == 10', 'len(tokens) == 550']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2198,Santiago Castro,santiagoc@netflix.com,2020-08-07 12:33:10-04:00,f639336a2c721a2efc575397c009c958f02d9d91,https://github.com/allenai/allennlp/commit/f639336a2c721a2efc575397c009c958f02d9d91,"Fix logger being created twice (#4538)

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2199,ArneBinder,ArneBinder@users.noreply.github.com,2020-08-10 16:47:27+02:00,b32608e384009098efe7e208e2e2e880c22ccfbe,https://github.com/allenai/allennlp/commit/b32608e384009098efe7e208e2e2e880c22ccfbe,"add gradient checkpointing for transformer token embedders (#4544)

* add gradient checkpointing for transformer token embedders

* Adds test for gradient checkpointing

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2200,epwalsh,epwalsh10@gmail.com,2020-08-10 15:20:39-07:00,5b9778098f271106865cf75408a592b95453bfca,https://github.com/allenai/allennlp/commit/5b9778098f271106865cf75408a592b95453bfca,tick version for nightly releases,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2201,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-08-11 10:43:19-07:00,1d6196597ba259f1e67ae8bc7986cbbb8f7955b4,https://github.com/allenai/allennlp/commit/1d6196597ba259f1e67ae8bc7986cbbb8f7955b4,"Bump mkdocs-material from 5.5.3 to 5.5.5 (#4547)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.5.3 to 5.5.5.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.5.3...5.5.5)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2202,Akshita Bhagia,akshita23bhagia@gmail.com,2020-08-12 13:28:21-04:00,44d2847610944f56a06b7cfa54faadb66e130a83,https://github.com/allenai/allennlp/commit/44d2847610944f56a06b7cfa54faadb66e130a83,"Metrics in distributed setting (#4525)

* initial commit to ensure that metrics work correctly in distributed setting

* updating global_distributed_metric to take metric object

* adding distributed f1 score

* adding distributed attachment scores

* bug fix

* adding distributed boolean accuracy

* adding distributed entropy

* adding distributed evalb

* adding distributed mean_absolute_error

* adding distributed sequence accuracy

* adding distributed unigram recall

* making models compatible with distributed metrics

* adding distributed auc

* adding distributed bleu

* adding missing argument

* initial commit to ensure that metrics work correctly in distributed setting

* updating global_distributed_metric to take metric object

* adding distributed f1 score

* adding distributed attachment scores

* bug fix

* adding distributed boolean accuracy

* adding distributed entropy

* adding distributed evalb

* adding distributed mean_absolute_error

* adding distributed sequence accuracy

* adding distributed unigram recall

* making models compatible with distributed metrics

* adding distributed auc

* adding distributed bleu

* adding missing argument

* changing start method

* removing unnecessary argument

* adding remaining metrics, removing extra argument

* allowing float values

* bug fix

* more bug fixes

* changing average to return float

* adding timeout for distributed test

* testing unequal batches

* adding distributed auc

* adding distributed spearman correlation

* adding distributed covariance and pearson correlation

* changing distributed test to function, misc changes

* checking batch lengths explicitly to raise errors

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",41,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,2,0,0,0,0,0,0,0,0,0,0,1,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['world_size > 1', 'metric.get_metric()[] == 0.0', 'metric.get_metric()[] == 0.0', 'mae.get_metric()[] == 21.0 / 12.0', 'mae.get_metric()[] == (21.0 + 3.5) / (12.0 + 8.0)', 'mae.get_metric()[] == (21.0 + 3.5 + 32.0) / (12.0 + 8.0 + 12.0)', 'mae.get_metric()[] == 32.0 / 12.0', 'metrics[] == unigram_recall / metric._total_sequence_count', 'metrics[] == unigram_precision / metric._total_sequence_count', 'metrics[] == unigram_f1 / metric._total_sequence_count', 'metrics[] == bigram_recall / metric._total_sequence_count', 'metrics[] == bigram_precision / metric._total_sequence_count', 'metrics[] == bigram_f1 / metric._total_sequence_count', 'metrics[] == metric._total_rouge_l_f1 / metric._total_sequence_count']","['(Exception)', '(Exception)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],"['metric.get_metric() == 0.0', 'metric.get_metric() == 0.0', 'mae.get_metric() == 21.0 / 12.0', 'mae.get_metric() == (21.0 + 3.5) / (12.0 + 8.0)', 'mae.get_metric() == (21.0 + 3.5 + 32.0) / (12.0 + 8.0 + 12.0)', 'mae.get_metric() == 32.0 / 12.0']",[],[],[],[],[],[],[],[],[],[],[],[]
2203,epwalsh,epwalsh10@gmail.com,2020-08-12 13:13:08-07:00,3b86f58889d1420b8b2606fdfb0056bc0a4a81d4,https://github.com/allenai/allennlp/commit/3b86f58889d1420b8b2606fdfb0056bc0a4a81d4,Prepare for release v1.1.0rc3,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2204,epwalsh,epwalsh10@gmail.com,2020-08-12 13:15:24-07:00,0ac13a4f5f6ce8bffb9913b76d026b7d2bdf7a70,https://github.com/allenai/allennlp/commit/0ac13a4f5f6ce8bffb9913b76d026b7d2bdf7a70,fix CHANGELOG,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2205,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-08-13 11:00:43-07:00,351941f3faeb27ba5ecb24fc58f3e323a71cda0d,https://github.com/allenai/allennlp/commit/351941f3faeb27ba5ecb24fc58f3e323a71cda0d,"Only pin mkdocs-material to minor version, ignore specific patch version (#4556)

* Bump mkdocs-material from 5.5.5 to 5.5.6

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 5.5.5 to 5.5.6.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.5.5...5.5.6)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* Update dev-requirements.txt

* Update dev-requirements.txt

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2206,Dirk Groeneveld,dirkg@allenai.org,2020-08-17 18:04:33+02:00,5a07009b5ae88fe17aca2fcb48dcfede07da6e1b,https://github.com/allenai/allennlp/commit/5a07009b5ae88fe17aca2fcb48dcfede07da6e1b,"Fix RoBERTa SST (#4548)

* Fix RobertaSST

* Fix unrelated formatting issue

* Changelog

* Be slightly more flexible about tokens",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2207,davidatbu,52462475+davidatbu@users.noreply.github.com,2020-08-17 13:22:12-04:00,de41306576c380bb26a87b54f9c829a079929d86,https://github.com/allenai/allennlp/commit/de41306576c380bb26a87b54f9c829a079929d86,"Static type checking fixes (#4545)

* small type annotation fixes

* py.typed marker, and CHANGELOG.md updated regarding it

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2208,Evan Pete Walsh,epwalsh10@gmail.com,2020-08-17 13:02:57-07:00,85112746e81651e3c3cb14cbb428eb55064b2bab,https://github.com/allenai/allennlp/commit/85112746e81651e3c3cb14cbb428eb55064b2bab,"add actions workflow for closing stale issues (#4561)

* add actions workflow for closing stale issues

* fix cron

* fix

* update CHANGELOG

* fix name

* try fix token

* make sure to ignore PRs

* finalize

* add creation time criteria

* tweak cron schedule

* add job to ping inactive issue assignees

* update CHANGELOG",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2209,Elad Segal,eladsegal@users.noreply.github.com,2020-08-17 23:25:05+03:00,0a456a7582da2ab4271756d7775bba84a75c8c0d,https://github.com/allenai/allennlp/commit/0a456a7582da2ab4271756d7775bba84a75c8c0d,"Fix boolean and categorical accuracy for distributed (#4568)

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2210,Matt Gardner,mattg@allenai.org,2020-08-18 13:44:40-07:00,bd9ee6a41d6266fe4b878f38ad3bcf2962ddc8ec,https://github.com/allenai/allennlp/commit/bd9ee6a41d6266fe4b878f38ad3bcf2962ddc8ec,"Give better usage info for overrides parameter (#4575)

* Give better usage info for overrides parameter

* changelog",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2211,Evan Pete Walsh,epwalsh10@gmail.com,2020-08-19 08:19:13-07:00,71a9a90dbff767ba47ffb739f77e2a0cc04a9bb1,https://github.com/allenai/allennlp/commit/71a9a90dbff767ba47ffb739f77e2a0cc04a9bb1,upgrade actions to cache@v2 (#4573),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2212,Akshita Bhagia,akshita23bhagia@gmail.com,2020-08-19 17:52:53-04:00,87a61ad92a9e0129e5c81c242f0ea96d77e6b0af,https://github.com/allenai/allennlp/commit/87a61ad92a9e0129e5c81c242f0ea96d77e6b0af,"Bug fix in distributed metrics (#4570)

* bug fix in distributed metrics

* fixing test

* update changelog

* reorganizing

* Convert tensor to LongTensor to avoid potential overflow

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Revert ""Convert tensor to LongTensor to avoid potential overflow""

This reverts commit 9cf6fd249b69237a2c25ae75c2dea7e51cd2e176.

* Raising error in case of distributed setting for Covariance and Pearson

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",26,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['desired_values[key] == metrics[key]', 'desired_values == metric.get_metric()', 'desired_values == metric.get_metric()', 'desired_values[key] == metric_values[key]', 'desired_values[]', 'desired_values[]', 'desired_values[]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2213,Akshita Bhagia,akshita23bhagia@gmail.com,2020-08-20 14:43:39-04:00,3aedac976e942bfb1ef1b8e2b207af7803c7ecb0,https://github.com/allenai/allennlp/commit/3aedac976e942bfb1ef1b8e2b207af7803c7ecb0,Prepare for release v1.1.0rc4,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2214,Akshita Bhagia,akshita23bhagia@gmail.com,2020-08-21 11:46:40-04:00,d01cdff903de6ce7dde3ff1fb6bcd8742695ce72,https://github.com/allenai/allennlp/commit/d01cdff903de6ce7dde3ff1fb6bcd8742695ce72,"Update RELEASE_PROCESS.md to include allennlp-models (#4587)

* update release process to include models

* Update RELEASE_PROCESS.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2215,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-08-21 08:54:11-07:00,f464aa38629979ff3f4974bea0e625d4d3a28bc1,https://github.com/allenai/allennlp/commit/f464aa38629979ff3f4974bea0e625d4d3a28bc1,"Bump markdown-include from 0.5.1 to 0.6.0 (#4586)

Bumps [markdown-include](https://github.com/cmacmackin/markdown-include) from 0.5.1 to 0.6.0.
- [Release notes](https://github.com/cmacmackin/markdown-include/releases)
- [Commits](https://github.com/cmacmackin/markdown-include/compare/v0.5.1...v0.6.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2216,Yaroslav Emelianov,mojesty@users.noreply.github.com,2020-08-24 19:28:23+03:00,62f554ffc93c150df8aa7663d379a4e3825c82eb,https://github.com/allenai/allennlp/commit/62f554ffc93c150df8aa7663d379a4e3825c82eb,"specify module names by a regex in predictor.capture_model_internals() (#4585)

* implemented #4574, can now specify module names by a regex in predictor.capture_model_internals()

* conform to black

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(internals) == 10', 'len(internals) == 2', 'len(results) == 3']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2217,OhadRubin,ohadr@mail.tau.ac.il,2020-08-25 19:21:38+03:00,2dd335e4faad78a04c1028e6f048b65143399c40,https://github.com/allenai/allennlp/commit/2dd335e4faad78a04c1028e6f048b65143399c40,"batched_span_select now guarantees element order in each span (#4511)

* batched_span_select now guarantees element order in each span

* batched_span_select now guarantees element order in each span

* Update util.py

added 0<=raw_span_indices

* changed test to reflect order preserving of batched_span_select

* formatting

* updated comment

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Your Name <you@example.com>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2218,Evan Pete Walsh,epwalsh10@gmail.com,2020-08-26 09:33:57-07:00,2c54cf8b67f0d70f6c0f0374838a2ea6c1e6b41a,https://github.com/allenai/allennlp/commit/2c54cf8b67f0d70f6c0f0374838a2ea6c1e6b41a,"reformat for new version of black (#4605)

* reformat for new version of black

* pin black",30,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2219,OhadRubin,iohadrubin@gmail.com,2020-08-27 00:24:04+03:00,dbc3c3ffffe639157c719b971657f6e671047e6a,https://github.com/allenai/allennlp/commit/dbc3c3ffffe639157c719b971657f6e671047e6a,"Added batched versions of scatter and fill to util.py (#4598)

* added batched_index_fill

* added batched_index_scatter

* added batched_index_scatter..

* added batched_index_scatter..

* fixed util.  typo

* fixed test

* ran linter

* ran linter (again....)

* renamed methods and other small changes

* removed target.clone() and  changed from scatter_ to scatter

* Update allennlp/nn/util.py

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>

* ran black

Co-authored-by: Your Name <you@example.com>
Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2220,Santiago Castro,santiagoc@netflix.com,2020-08-27 12:00:24-04:00,e840a589afc4bfdac0165a8650145259a7603807,https://github.com/allenai/allennlp/commit/e840a589afc4bfdac0165a8650145259a7603807,"s/logging/logger/ (#4609)

* s/logging/logger

* Update vocabulary.py",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2221,Evan Pete Walsh,epwalsh10@gmail.com,2020-08-31 12:55:42-07:00,187b24e5dad348a11391b52599a0d5f3919a9d1d,https://github.com/allenai/allennlp/commit/187b24e5dad348a11391b52599a0d5f3919a9d1d,"add more tutorial links to README (#4613)

* add more tutorial links to README

* change link name

* fix",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2222,Matt Gardner,mattg@allenai.org,2020-08-31 12:57:53-07:00,be97943a42e55ac68c75794187a1c84be5f8d898,https://github.com/allenai/allennlp/commit/be97943a42e55ac68c75794187a1c84be5f8d898,"Improve handling of **kwargs in FromParams (#4616)

* Improve handling of **kwargs in FromParams

* new black version

* add one more test

* black",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['foo.a == 2', 'foo.b == ', 'foo.a == 2', 'foo.b == ', 'foo.c == {}', 'bar.a == 2', 'bar.b == ', 'bar.c == {}', 'bar.d == 0', 'foo.a == 2', 'foo.b == ', 'foo.c == ', 'foo.a == 2', 'foo.b == ', 'foo.a == 2', 'foo.b == ', 'foo.c == {}', 'foo.a == 2', 'foo.b == ', 'foo.c is None', 'foo.a == 2', 'foo.b == ', 'foo.c == {}']","['(TypeError, match=)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2223,David Wadden,dwadden@cs.washington.edu,2020-09-01 08:27:52-07:00,711afaa7720ebaba4a3739c1753c02568039993d,https://github.com/allenai/allennlp/commit/711afaa7720ebaba4a3739c1753c02568039993d,"Fix division by zero when there are zero-length spans in MismatchedEmbedder. (#4615)

* Implment MattG's fix for NaN gradients in MismatchedEmbedder.

Fix `clamp_min` on embeddings.

Implment MattG's fix for NaN gradients in MismatchedEmbedder.

* Fix NaN gradients caused by weird tokens in MismatchedEmbedder.

Fixed division by zero error when there are zero-length spans in the input to a
mismatched embedder.

* Add changelog message.

* Re-run `black` to get code formatting right.

* combine fixed sections after merging with master

Co-authored-by: Matt Gardner <mattg@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(grad is None) or (not torch.any(torch.isnan(grad)).item())'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2224,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-03 09:09:54-07:00,e1aa57cfd5c9ea12cae6923d9c889692d8688ab2,https://github.com/allenai/allennlp/commit/e1aa57cfd5c9ea12cae6923d9c889692d8688ab2,"improve robustness of cached_path when extracting archives (#4622)

* improve robustness of cache_path when extracting archives

* dirks comment",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2225,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-08 10:17:01-07:00,aa750becf439224df59f80eb57aef5737cf11337,https://github.com/allenai/allennlp/commit/aa750becf439224df59f80eb57aef5737cf11337,"fix Average metric (#4624)

* fix Average metric

* try spawn

* try again

* oops

* clean up, fix evalb too

* use different start method for GPU vs CPU tests

* add comment",7,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2226,epwalsh,epwalsh10@gmail.com,2020-09-08 10:51:09-07:00,dcc9cdc763a92bdd078128b760399a85449faea5,https://github.com/allenai/allennlp/commit/dcc9cdc763a92bdd078128b760399a85449faea5,Prepare for release v1.1.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2227,Dirk Groeneveld,dirkg@allenai.org,2020-09-08 13:38:19-07:00,bf3206a28cd504d91ccd4a8fdbd07cbf549e2f2f,https://github.com/allenai/allennlp/commit/bf3206a28cd504d91ccd4a8fdbd07cbf549e2f2f,Workaround for Python not finding imports in spawned processes (#4630),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2228,Elad Segal,eladsegal@users.noreply.github.com,2020-09-10 19:27:48+03:00,6d480aaeeda0b035e593b15b81c8ea2a49fa342e,https://github.com/allenai/allennlp/commit/6d480aaeeda0b035e593b15b81c8ea2a49fa342e,"Improve handling of **kwargs in FromParams (#4629)

* Improve handling of **kwargs in FromParams

* remove duplicated line

* improved handling of *args and *kwargs in FromParams

* changelog

* **kwargs is needed

* Revert ""**kwargs is needed""

This reverts commit c74a94cdf142c720262431f29da9f61a11a4b5cd.

* revert FromParams changes

* ignore *args

* change optimizers' inheritance order

* add bare constructor to ForParams

* Revert ""add bare constructor to ForParams""

This reverts commit 4afe072d8dd4529b79d439a4f08f66528386035f.

* Revert ""change optimizers' inheritance order""

This reverts commit d9fe03634730b5a567b147202156cc4ecbfe491f.

* remove comment",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['bar.a == 2', 'foo.a == 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2229,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-09-11 13:34:59-07:00,2df364ff5f95f2ad44c699e066c8e371b1d7959b,https://github.com/allenai/allennlp/commit/2df364ff5f95f2ad44c699e066c8e371b1d7959b,"Update transformers requirement from <3.1,>=3.0 to >=3.0,<3.2 (#4621)

* Update transformers requirement from <3.1,>=3.0 to >=3.0,<3.2

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v3.0.0...v3.1.0)

Signed-off-by: dependabot-preview[bot] <support@dependabot.com>

* update CHANGELOG

* exclude 3.0, patch models in tests

* handle missing position_ids in transformer state dicts

* fix

* oops, fix again

* Undo models version patch

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2230,Dirk Groeneveld,dirkg@allenai.org,2020-09-11 14:44:11-07:00,0e33b0bac5282f2f1ac64bf36bc58ff94902a851,https://github.com/allenai/allennlp/commit/0e33b0bac5282f2f1ac64bf36bc58ff94902a851,"Return consistent types from metrics (#4632)

* Return consistent types from metrics

* Changelog

* Remove unused import",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2231,dependabot-preview[bot],27856297+dependabot-preview[bot]@users.noreply.github.com,2020-09-14 09:11:22-07:00,f0e7a78ce54c295dd4b5f729c6d6adcb20d15745,https://github.com/allenai/allennlp/commit/f0e7a78ce54c295dd4b5f729c6d6adcb20d15745,"Create Dependabot config file (#4635)

Co-authored-by: dependabot-preview[bot] <27856297+dependabot-preview[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2232,John Giorgi,johnmgiorgi@gmail.com,2020-09-14 13:02:56-04:00,e4fd5a0c1afb324c0de2451fb0c84241c136b270,https://github.com/allenai/allennlp/commit/e4fd5a0c1afb324c0de2451fb0c84241c136b270,"Multi-label F-beta metric (#4562)

* Add multi-label Fbeta metric

* Add tests for multi-label fbeta measure

* Import FBetaMeasureMultiLabel from metrics module

* Fix typo in import statement

* Add multi-label Fbeta metric

* Add tests for multi-label fbeta measure

* Import FBetaMeasureMultiLabel from metrics module

* Fix typo in import statement

* Handle all edge cases beside true negatives

* Add tests for edge cases besides true negatives

* Fix bug breaking GPU tests

* Rename FBetaMultiLabelMeasure everywhere

* Properly compute _true_negative_sum

* Adds an F1MultiLabel measure

* Remove redunant code in __init__

* Replace torch.where with ge check

* Add note about FBetaMultiLabelMeasure to CHANGELOG

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,4,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(precisions, List)', 'isinstance(recalls, List)', 'isinstance(fscores, List)', 'isinstance(precisions, float)', 'isinstance(recalls, float)', 'isinstance(fscores, float)']","['(ConfigurationError, FBetaMultiLabelMeasure, beta=0.0)', '(ConfigurationError, FBetaMultiLabelMeasure, average=)', '(ConfigurationError, FBetaMultiLabelMeasure, labels=[])', '(RuntimeError, fbeta.get_metric)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2233,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-16 11:15:08-07:00,e8e89d5acffb16b65e48688fb4b3ad369cba0510,https://github.com/allenai/allennlp/commit/e8e89d5acffb16b65e48688fb4b3ad369cba0510,"add flag for saving predictions to 'evaluate' command (#4637)

* add flag for saving predictions to 'evaluate' command

* Apply suggestions from code review

* format",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['in prediction'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2234,Nelson Liu,nelson-liu@users.noreply.github.com,2020-09-16 11:57:17-07:00,de5d68bc93c70440ad447b07d6f8ab6953186d3f,https://github.com/allenai/allennlp/commit/de5d68bc93c70440ad447b07d6f8ab6953186d3f,"Fix tensor.nonzero() function overload warning (#4644)

* Fix tensor.nonzero() function overload warning

* Update changelog",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2235,Matt Mulholland,mulhodm@gmail.com,2020-09-17 11:39:09-04:00,c7b7c0085d946bdfec010c614f3545d6bab7a35c,https://github.com/allenai/allennlp/commit/c7b7c0085d946bdfec010c614f3545d6bab7a35c,"Feature/prevent temp directory retention (#4643)

* Remove extracted archive directory in load_archive instead of at exit

* Update CHANGELOG",3,False,True,False,False,False,False,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['from unittest import mock'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2236,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-17 13:43:52-07:00,824f97d457bff15955a6793535092e334e761515,https://github.com/allenai/allennlp/commit/824f97d457bff15955a6793535092e334e761515,"smooth out release process (#4648)

* smooth out release process

* fix wording

* another small fix",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2237,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-17 15:33:36-07:00,2d5f24bd94ba229741a1a17e09b540a374447c77,https://github.com/allenai/allennlp/commit/2d5f24bd94ba229741a1a17e09b540a374447c77,"improve how cached_path extracts archives (#4645)

* improve archive extraction

* fixes

* Update CHANGELOG.md

* make _resource_to_filename() private

* use different lock file for extraction

* formatting",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['_resource_to_filename(baseurl + )', 'filename == os.path.join(self.TEST_DIR, _resource_to_filename(url, etag=))', 'filename3 == os.path.join(self.TEST_DIR, _resource_to_filename(url, etag=))', 'filename == os.path.join(self.TEST_DIR, _resource_to_filename(url, etag=))', 'pathlib.Path(extracted).parent == self.TEST_DIR']",[],[],[],[],[],[],[],[],[],[],[],[],"['url_to_filename(baseurl + )', 'filename == os.path.join(self.TEST_DIR, url_to_filename(url, etag=))', 'filename3 == os.path.join(self.TEST_DIR, url_to_filename(url, etag=))', 'filename == os.path.join(self.TEST_DIR, url_to_filename(url, etag=))', 'os.path.basename(extracted) == ', 'os.path.basename(extracted) == ']",[],[],[],[],[],[],[],[],[],[],[],[]
2238,epwalsh,epwalsh10@gmail.com,2020-09-19 15:19:57-07:00,fbd2ccca1dd767e919a62d344c6b6569fc38227a,https://github.com/allenai/allennlp/commit/fbd2ccca1dd767e919a62d344c6b6569fc38227a,fix numbering in RELEASE_GUIDE,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2239,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-22 09:24:24-07:00,175c76beda1d4d68011e1405fcd647dc77f4b212,https://github.com/allenai/allennlp/commit/175c76beda1d4d68011e1405fcd647dc77f4b212,fix confusing distributed logging info (#4654),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2240,Matt Mulholland,mulhodm@gmail.com,2020-09-22 13:39:11-04:00,d7c06fe7e78a2f23fb569944ce1b273541d85dee,https://github.com/allenai/allennlp/commit/d7c06fe7e78a2f23fb569944ce1b273541d85dee,"Expose from_pretrained keyword arguments (#4651)

* Add ability to pass through transformers cache-related kwargs such as cache_dir and local_files_only

* Add a couple tests for cached_transformers

* Update CHANGELOG

* Fix formatting

* Apply suggestions

* Add/fix tokenizers_kwargs/transformer_kwargs in a few places; add documentation wherever it occurs

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update bert_pooler.py transformer_kwargs documentation

* Apply suggestions from code review

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Remove test_from_pretrained_kwargs_local_files_only_missing_from_cache test

* Use AllenNlpTestCase in cached_transformers_test.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",9,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['str(execinfo.value) == (', 'str(execinfo.value) == (']","['(ValueError)', '(ValueError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2241,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-22 14:50:30-07:00,b833f9059b7c203f8c79dcfeaefbe25458cb1282,https://github.com/allenai/allennlp/commit/b833f9059b7c203f8c79dcfeaefbe25458cb1282,fix multi-line links in docs (#4660),4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2242,epwalsh,epwalsh10@gmail.com,2020-09-22 14:52:10-07:00,e5e3d0207cfba70d062b8d5fca0e57a702be6f9b,https://github.com/allenai/allennlp/commit/e5e3d0207cfba70d062b8d5fca0e57a702be6f9b,tick version for nightly releases,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2243,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2020-09-23 09:06:08-07:00,c9f376bf71ddc01f0b49458ef335a198d8d045cb,https://github.com/allenai/allennlp/commit/c9f376bf71ddc01f0b49458ef335a198d8d045cb,"Update transformers requirement from <3.2,>=3.1 to >=3.1,<3.3 (#4663)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v3.1.0...v3.2.0)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2244,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-23 13:02:46-07:00,97fe88d2a58d239d94bede033a2039d9ba22ff2d,https://github.com/allenai/allennlp/commit/97fe88d2a58d239d94bede033a2039d9ba22ff2d,"Cached path command (#4652)

* add cached-path command

* clean up tests

* bug fixes

* add more comments

* add more tests

* fix

* accept globs

* update wording

* test bad usage

* add more tests

* implement removal functionality

* add more tests

* calc size of directories

* clean up

* clarify print statement

* improve size formatting

* ignore duplicate hard linked files

* fix up

* NamedTuple

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,3,0,0,0,0,0,2,2,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in captured.out', 'in captured.out', 'in captured.out', 'in captured.out', 'os.path.exists(filename + )', 'meta.resource == url', 'meta.resource == url', 'meta.etag == etag', 'meta.creation_time is not None', 'meta.size == len(self.glove_bytes)', 'in captured.out', 'in captured.out', 'in captured.out', 'in captured.out', 'in captured.out', 'not in captured.out', 'reclaimed_space == 3 * len(self.glove_bytes)', 'size_left == 2 * len(self.glove_bytes)', 'len(entries_left) == 1', 'len(entry_left[0]) == 1', 'len(entry_left[1]) == 1', 'len(os.listdir(self.TEST_DIR)) == 0', 'os.path.exists(extracted + )', 'format_size(size) == result', 'format_timedelta(td) == result']","['(RuntimeError, match=)', '(RuntimeError, match=)', '(RuntimeError, match=)']",[],[],[],[],[],"['', '']","['parametrize(', 'parametrize(']","['mark.parametrize(', 'mark.parametrize(']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2245,Matt Gardner,mattg@allenai.org,2020-09-25 09:36:54-07:00,11def8eaa3e89d3d953cfc0c95bfdff0c3752cfe,https://github.com/allenai/allennlp/commit/11def8eaa3e89d3d953cfc0c95bfdff0c3752cfe,Update bug_report.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2246,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-25 10:18:09-07:00,1e381bb086edfa6f7c30428b64eccb1e64881ebc,https://github.com/allenai/allennlp/commit/1e381bb086edfa6f7c30428b64eccb1e64881ebc,"Clean up the documentation for beam search (#4664)

* clean up docs for beam search

* clean up

* test both step function types

* oops, fix",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(, [take_step_with_timestep, take_step_no_timestep])']","['parametrize(, [take_step_with_timestep, take_step_no_timestep])']","['mark.parametrize(, [take_step_with_timestep, take_step_no_timestep])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2247,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-25 13:27:23-07:00,97db5387e846350285c25bf7e39be7b64102baa7,https://github.com/allenai/allennlp/commit/97db5387e846350285c25bf7e39be7b64102baa7,"official support for Python 3.8  (#4671)

* support Python 3.8

* make flake8 happy

* drop 3.6 in CI

* clean up docs",9,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['base_class.by_name() == FakeAlternate2'],[],[],[],[],[],[],[],[],[],[],[],[],['base_class.by_name() == FakeAlternate'],[],[],[],[],[],[],[],[],[],[],[],[]
2248,epwalsh,epwalsh10@gmail.com,2020-09-25 13:31:12-07:00,990c9c17522ea238cd06947ffc830f9a1c7817eb,https://github.com/allenai/allennlp/commit/990c9c17522ea238cd06947ffc830f9a1c7817eb,clarify conda Python version in README.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2249,Dirk Groeneveld,dirkg@allenai.org,2020-09-25 14:18:38-07:00,55cfb47b5a0c84fa9ae97b792f82805919a0149a,https://github.com/allenai/allennlp/commit/55cfb47b5a0c84fa9ae97b792f82805919a0149a,"The truncation setting doesn't do anything anymore (#4672)

* The truncation setting doesn't do anything anymore

* Changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2250,Matt Mulholland,mulhodm@gmail.com,2020-09-28 12:49:11-04:00,9ac6c76c2cc0e567a9e0aa9e6cd7a1b5596e3b10,https://github.com/allenai/allennlp/commit/9ac6c76c2cc0e567a9e0aa9e6cd7a1b5596e3b10,Allow overrides to be JSON string or dict (#4680),6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(, [dict, str])']","['parametrize(, [dict, str])']","['mark.parametrize(, [dict, str])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2251,Matt Mulholland,mulhodm@gmail.com,2020-09-28 13:02:38-04:00,9dabf3fa848550db3c89dbb18265d5e4d85e545f,https://github.com/allenai/allennlp/commit/9dabf3fa848550db3c89dbb18265d5e4d85e545f,"Add missing tokenizer/transformer kwargs (#4682)

* Add tokenizer_kwargs in PretrainedTransformerMismatchedIndexer and tokenizer_kwargs/transformer_kwargs in PretrainedTransformerMismatchedEmbedder

* Update allennlp/data/token_indexers/pretrained_transformer_mismatched_indexer.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2252,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-28 10:09:53-07:00,c3b5ed74eabbed9ce92e56d907781a387c40739f,https://github.com/allenai/allennlp/commit/c3b5ed74eabbed9ce92e56d907781a387c40739f,zero grad optimization (#4673),5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2253,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2020-09-28 10:17:37-07:00,ce604f1f85a201dd911e1b578b44ac01efcedce9,https://github.com/allenai/allennlp/commit/ce604f1f85a201dd911e1b578b44ac01efcedce9,"Update mkdocs-material requirement from <5.6.0,>=5.5.0 to >=5.5.0,<6.1.0 (#4679)

Updates the requirements on [mkdocs-material](https://github.com/squidfunk/mkdocs-material) to permit the latest version.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.5.0...6.0.1)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: ai2-bulldozer[bot] <47044978+ai2-bulldozer[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2254,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-28 10:17:54-07:00,d9bdaa952b455916973c9d1fa72e321c8cab2e86,https://github.com/allenai/allennlp/commit/d9bdaa952b455916973c9d1fa72e321c8cab2e86,"add build-vocab command (#4655)

* add build-vocab command

* print helpful note at the end

* use CacheFile context manager

* improve help message",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['os.path.exists(output_path)'],"['(RuntimeError, match=)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2255,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2020-09-29 19:55:41+00:00,b9a9284221a2ba6fad198d488b863512060aa172,https://github.com/allenai/allennlp/commit/b9a9284221a2ba6fad198d488b863512060aa172,"Update transformers requirement from <3.3,>=3.1 to >=3.1,<3.4 (#4684)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v3.1.0...v3.3.0)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2256,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-30 12:03:33-07:00,e0b2e26579ab68da6e0bdcec996996c1177f3975,https://github.com/allenai/allennlp/commit/e0b2e26579ab68da6e0bdcec996996c1177f3975,display class decorators in API docs (#4685),4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2257,Evan Pete Walsh,epwalsh10@gmail.com,2020-09-30 12:32:00-07:00,17c3b84b3233d118796e0d492fd558f00f336fb6,https://github.com/allenai/allennlp/commit/17c3b84b3233d118796e0d492fd558f00f336fb6,Fix small typo (#4686),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2258,Michael Schmitz,MichaelS@allenai.org,2020-10-02 15:27:12-07:00,eb7f2568037029508aa402ceac7097f9d289d527,https://github.com/allenai/allennlp/commit/eb7f2568037029508aa402ceac7097f9d289d527,Add StackOverflow link to README (#4694),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2259,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-03 10:11:07-07:00,3506e3fd2d4a4bc205123f41767b2d005f3c79dc,https://github.com/allenai/allennlp/commit/3506e3fd2d4a4bc205123f41767b2d005f3c79dc,ensure parameters that are actual dictionaries get logged (#4697),3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2260,Elad Segal,eladsegal@users.noreply.github.com,2020-10-06 02:39:45+03:00,edcb6d3466d2c4263f1e6a5731c6ace5358f47e8,https://github.com/allenai/allennlp/commit/edcb6d3466d2c4263f1e6a5731c6ace5358f47e8,"Fix a bug in saving vocab during distributed training (#4705)

* is_master bug fix

* changelog

* remove is_master

* changelog",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2261,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-06 11:15:42-07:00,39ddb523060d34f20c718f4d62d87893a51752a0,https://github.com/allenai/allennlp/commit/39ddb523060d34f20c718f4d62d87893a51752a0,"CLI improvements (#4692)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2262,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-06 16:20:53-07:00,90f003799e9fd6f786f54027441600ac6e871d20,https://github.com/allenai/allennlp/commit/90f003799e9fd6f786f54027441600ac6e871d20,fix reported batch_loss (#4706),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2263,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-06 16:48:43-07:00,327188b882b2739855abbc0b2cfd8ea4943297a1,https://github.com/allenai/allennlp/commit/327188b882b2739855abbc0b2cfd8ea4943297a1,"improve memory helper functions (#4699)

* improve memory helper functions

* fixes

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",10,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,2,2,2,0,0,0,3,0,0,0,0,0,0,2,2,2,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in serialized_files', 'metrics[] > 0', 'metrics[] > 0', 'metrics[] > 0', 'metrics[] > 0', 'util.format_size(size) == result', 'util.format_timedelta(td) == result', 'isinstance(metrics[], float)']",[],[],[],[],[],[],"['', '']","['parametrize(', 'parametrize(']","['mark.parametrize(', 'mark.parametrize(']",[],[],[],"['format_size(size) == result', 'format_timedelta(td) == result', 'isinstance(metrics[], int)']",[],[],[],[],[],[],"['', '']","['parametrize(', 'parametrize(']","['mark.parametrize(', 'mark.parametrize(']",[],[],[]
2264,Elad Segal,eladsegal@users.noreply.github.com,2020-10-07 19:38:35+03:00,40bb47adcc62b5414ba2166b3ae0bd70cc4dbd42,https://github.com/allenai/allennlp/commit/40bb47adcc62b5414ba2166b3ae0bd70cc4dbd42,"Load weights to cpu with PretrainedModelInitializer (#4712)

* load weights to cpu with PretrainedModelInitializer

* changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2265,Elad Segal,eladsegal@users.noreply.github.com,2020-10-07 19:58:28+03:00,c14ea40e8fb700a15b2dc875c3a522295e1a8bed,https://github.com/allenai/allennlp/commit/c14ea40e8fb700a15b2dc875c3a522295e1a8bed,"Save checkpoint before running evaluation (#4704)

* save model weights before evaluation

* Update CHANGELOG.md

* black

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2266,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-07 09:59:26-07:00,001e1f76edfa6ff463a6edb1007e3f92f7c01a56,https://github.com/allenai/allennlp/commit/001e1f76edfa6ff463a6edb1007e3f92f7c01a56,"new way of setting env variables in GH Actions (#4700)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2267,Will Merrill,vikingarnir.will@gmail.com,2020-10-07 13:09:59-04:00,321d4f48f6c14a559386afa4d19ae96b829fd025,https://github.com/allenai/allennlp/commit/321d4f48f6c14a559386afa4d19ae96b829fd025,"TrainerCallback with batch/epoch/end hooks (#4708)

* Wrote tests and stuff. But can't test on PC..

* Added TrainerCallback with metaclass that automatically creates Batch/Epoch callbacks wrapping it.

* Reformatting.

* Changelog

* Added type: ignore's

* Updated with docstrings.

* Refactored _make_callback_type into metaclass.

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['trainer.end_callback_calls == expected_calls', 'trainer.batch_callback_calls == expected_batch_calls', 'trainer.epoch_callback_calls == expected_epoch_calls', 'trainer.end_callback_calls == expected_end_calls']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2268,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-07 11:14:34-07:00,ae7cf85b8f755f086341a087aeca1ba7c1df3769,https://github.com/allenai/allennlp/commit/ae7cf85b8f755f086341a087aeca1ba7c1df3769,"automatically find local open port in distributed training (#4696)

* auto find open port

* fixes

* only do on localhost

* fix spelling

* fix comment

* fix

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2269,Vikash,v9balasu@uwaterloo.ca,2020-10-08 01:22:19-04:00,bc6f15accc2392c42d97e2bdee7bcb47a664f597,https://github.com/allenai/allennlp/commit/bc6f15accc2392c42d97e2bdee7bcb47a664f597,"Fixes rouge metric calculation corrected for distributed training (#4717)

* Fixes #4715 : Rouge metric calculation corrected for distributed training

* CHANGELOG",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2270,jvstokes,40584422+jvstokes@users.noreply.github.com,2020-10-08 11:25:09-07:00,b099b69c72489a0bc25382e3a0009a5f0bb394c8,https://github.com/allenai/allennlp/commit/b099b69c72489a0bc25382e3a0009a5f0bb394c8,"Add top_k and top_p sampling to BeamSearch (#4695)

* Draft of top_k and top_p sampling for beam search

* Fixed indexing issue in samplers

* small fix for top-k sampler

* Beam search passing all tests

* Cleaned up beam search PR

* remove prints

* remove prints in test

* merge master in and fix lint

* make beam search registrable

* Made BeamSearch Registrable

* fix documentation in BeamSearch and Samplers

* Update allennlp/nn/beam_search.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* pushing again

* Apply suggestions from code review

Co-authored-by: Jackson Stokes <jacksons@Jacksons-MacBook-Pro.local>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,2,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(top_p.size())[:-1] == [batch_size, beam_size]', '((0 <= top_p) & (top_p <= 5)).all()', 'list(log_probs.size()) == [batch_size, beam_size]', 'list(top_k.size())[:-1] == [batch_size, beam_size]', '((0 <= top_k) & (top_k <= 5)).all()', 'list(log_probs.size()) == [batch_size, beam_size]', 'list(predictions.size()) == [2, 1, 1]', 'list(log_probs.size()) == [2, 1]', '(predictions == self.end_index).all()', '(log_probs == 0).all()', 'list(predictions.size()) == [2, 1, 1]', 'list(log_probs.size()) == [2, 1]', '(predictions == self.end_index).all()', '(log_probs == 0).all()', 'beam_search.beam_size == 2', 'beam_search._end_index == 7', 'beam_search.sampler is None', 'beam_search.beam_size == 2', 'beam_search._end_index == 7', 'beam_search.sampler is not None', 'beam_search.beam_size == 2', 'beam_search._end_index == 7', 'beam_search.sampler is not None']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],"['', '']","['parametrize(', 'parametrize(']","['mark.parametrize(', 'mark.parametrize(']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2271,Elad Segal,eladsegal@users.noreply.github.com,2020-10-09 02:03:32+03:00,1ff0658c510abe525c8136eadc62b43968a0c3d6,https://github.com/allenai/allennlp/commit/1ff0658c510abe525c8136eadc62b43968a0c3d6,"Added logging for the main process when running in distributed mode (#4710)

* Log main process as well when running in distributed mode

* changelog

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2272,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-08 17:11:11-07:00,3a85e3595b71c05fbd9acb014e3d76b5b7dd0bc4,https://github.com/allenai/allennlp/commit/3a85e3595b71c05fbd9acb014e3d76b5b7dd0bc4,add reasonable timeout to gpu checks job (#4719),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2273,Nicola Sahar,39612300+nicolasahar@users.noreply.github.com,2020-10-12 13:06:59-04:00,cccad29addf269d121fe7a5c3c2f202f4cfe867d,https://github.com/allenai/allennlp/commit/cccad29addf269d121fe7a5c3c2f202f4cfe867d,"Updated AllenNlpTestCase docstring (#4722)

* Updated AllenNlpTestCase docstring

* Updated CHANGELOG.md",2,False,True,False,False,True,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2274,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2020-10-12 10:20:50-07:00,d3c69f757e73492e6ef13028f208a13264ae26a6,https://github.com/allenai/allennlp/commit/d3c69f757e73492e6ef13028f208a13264ae26a6,"Bump mypy from 0.782 to 0.790 (#4723)

* Bump mypy from 0.782 to 0.790

Bumps [mypy](https://github.com/python/mypy) from 0.782 to 0.790.
- [Release notes](https://github.com/python/mypy/releases)
- [Commits](https://github.com/python/mypy/compare/v0.782...v0.790)

Signed-off-by: dependabot[bot] <support@github.com>

* make mypy happy

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2275,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-13 14:58:18-07:00,24519fd964a469e9443d050d87ace3680135a0f5,https://github.com/allenai/allennlp/commit/24519fd964a469e9443d050d87ace3680135a0f5,fix typehint on checkpointer method (#4726),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2276,tpanza,19810086+tpanza@users.noreply.github.com,2020-10-14 18:48:50-07:00,c14a056dfc2a3e4dbf7ad6798b1b50cd281170fc,https://github.com/allenai/allennlp/commit/c14a056dfc2a3e4dbf7ad6798b1b50cd281170fc,"avoid defaulting to CPU device in add_sentence_boundary_token_ids() (#4727)

* avoid defaulting to CPU device in add_sentence_boundary_token_ids()

* 2D input will use scalars, so do not use detach() and no need to be concerned about device of tensor

* update CHANGELOG

* move to device and detach outside the loop

Co-authored-by: Anthony P Panza <anthony.p.panza@boeing.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2277,Elad Segal,eladsegal@users.noreply.github.com,2020-10-16 03:50:34+03:00,ce14bdc09c32067d90910bbeaa02d40ebd703112,https://github.com/allenai/allennlp/commit/ce14bdc09c32067d90910bbeaa02d40ebd703112,"Allow usage of .tar.gz with PretrainedModelInitializer (#4709)

* Allow usage of .tar.gz with PretrainedModelInitializer

* changelog

* typing

* simplify code with contextmanager

* make the code cleaner

* fix

* change cleanup

* fix

* fix

* fix typing

* fix according to review

* black and typing

* fix

* load dataset readers in `load_archive`

* black

* lint

* review fixes

* fix

* fix

* remove unused condition

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(', 'isinstance(', 'params2.as_dict() == params_dict_copy', 'params2.as_dict() == params_dict_copy', 'initializer.weights', 'initializer.parameter_name_overrides == {}', 'torch.equal(parameter, initializer.weights[name])']",[],[],[],[],[],[],[],[],[],[],[],[],"['params2.as_dict() == params_copy', 'params2.as_dict() == params_copy']",[],[],[],[],[],[],[],[],[],[],[],[]
2278,Elad Segal,eladsegal@users.noreply.github.com,2020-10-16 04:27:37+03:00,006bab483426363f2dc1c3bde67bcecab2575b82,https://github.com/allenai/allennlp/commit/006bab483426363f2dc1c3bde67bcecab2575b82,"Don't use PretrainedModelInitializer when loading a model (#4711)

* Don't use PretrainedModelInitializer when loading a model

* fix according to review

* empty

* remove unused condition

* changelog

* fix test

* Adds a function for backwards compatibility

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['params[', 'params[] == 80', ']', ']', 'not in params']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2279,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-16 15:00:14-07:00,0e64b4d3281808fac0fe00cc5b56e5378dbb7615,https://github.com/allenai/allennlp/commit/0e64b4d3281808fac0fe00cc5b56e5378dbb7615,fix docstring for PyTorchSeq2VecWrapper (#4734),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2280,Luke Gessler,lukegessler@gmail.com,2020-10-19 12:31:08-04:00,10c11ceaa4782b70f8a6a1cf03d9ca67bc78a158,https://github.com/allenai/allennlp/commit/10c11ceaa4782b70f8a6a1cf03d9ca67bc78a158,Fix typo in PretrainedTransformerMismatchedEmbedder docstring (#4737),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2281,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2020-10-19 10:45:51-07:00,3f23938b51e0cd1649f9ca85d1e67613d0f569a6,https://github.com/allenai/allennlp/commit/3f23938b51e0cd1649f9ca85d1e67613d0f569a6,"Update mkdocs-material requirement from <6.1.0,>=5.5.0 to >=5.5.0,<6.2.0 (#4738)

Updates the requirements on [mkdocs-material](https://github.com/squidfunk/mkdocs-material) to permit the latest version.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.5.0...6.1.0)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2282,Dirk Groeneveld,dirkg@allenai.org,2020-10-19 11:32:05-07:00,00bb6c59b3ac8fdc78dfe8d5b9b645ce8ed085c0,https://github.com/allenai/allennlp/commit/00bb6c59b3ac8fdc78dfe8d5b9b645ce8ed085c0,"Be sure to close the TensorBoard writer (#4731)

* Be sure to close the tensorboard writer

* Changelog

* unindent

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2283,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-20 09:13:53-07:00,6bb9ce9a188631eeeb49d4e73dccf5860549e42d,https://github.com/allenai/allennlp/commit/6bb9ce9a188631eeeb49d4e73dccf5860549e42d,"warn about batches_per_epoch with validation loader (#4735)

* warn about batches_per_epoch with validation loader

* line length",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2284,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2020-10-21 12:01:40-07:00,1f29f35271341be17ca029b049d3bdecde7fabc2,https://github.com/allenai/allennlp/commit/1f29f35271341be17ca029b049d3bdecde7fabc2,"Update transformers requirement from <3.4,>=3.1 to >=3.1,<3.5 (#4741)

* Update transformers requirement from <3.4,>=3.1 to >=3.1,<3.5

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v3.1.0...v3.4.0)

Signed-off-by: dependabot[bot] <support@github.com>

* update `make install` target

* parametrize vocab size test

* fixes for new version of transformers

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['vocab.get_vocab_size(namespace=namespace) == tokenizer.vocab_size'],[],[],[],[],[],[],['(])'],['parametrize(])'],['mark.parametrize(])'],[],[],['import pytest'],['vocab.get_vocab_size(namespace=namespace) == tokenizer.vocab_size'],[],[],[],[],[],[],[],[],[],[],[],[]
2285,Elad Segal,eladsegal@users.noreply.github.com,2020-10-22 02:10:55+03:00,01644caf4de31710a6614fb96a9d4ea291353486,https://github.com/allenai/allennlp/commit/01644caf4de31710a6614fb96a9d4ea291353486,"Pass serialization_dir to Model, DatasetReader, and support `include_in_archive` (#4713)

* Allow usage of .tar.gz with PretrainedModelInitializer

* changelog

* typing

* simplify code with contextmanager

* make the code cleaner

* fix

* change cleanup

* fix

* fix

* fix typing

* fix according to review

* black and typing

* fix

* load dataset readers in `load_archive`

* black

* fix

* lint

* remove redundant test

* fix

* black

* empty commit

* review changes

* change `include_in_archive` to be a top-level param

* Update CHANGELOG.md

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Elad Segal <eldsegal@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",9,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.isfile(os.path.join(tempdir, ))', 'os.path.isfile(os.path.join(tempdir, ))', 'not os.path.isfile(os.path.join(tempdir, ))', 'in str(exc.value)']",['(ConfigurationError)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2286,Akshita Bhagia,akshita23bhagia@gmail.com,2020-10-22 14:43:40-07:00,7c10fd26d0833e6f97f8559576ad759f4366a234,https://github.com/allenai/allennlp/commit/7c10fd26d0833e6f97f8559576ad759f4366a234,Prepare for release v1.2.0rc1,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2287,wlhgtc,hgtcwl@foxmail.com,2020-10-24 03:02:07+08:00,b792c834b5f70122c7c296ded7c97ac974cda6f4,https://github.com/allenai/allennlp/commit/b792c834b5f70122c7c296ded7c97ac974cda6f4,"Fix device mismatch bug for categorical accuracy metric in distributed training (#4744)

* refix bug in distributed metrics

* update change log

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2288,Jacob Danovitch,jacob.danovitch@mila.quebec,2020-10-26 14:44:22-04:00,27edfbf8e084371f2b3adeece97d119e09a8b96d,https://github.com/allenai/allennlp/commit/27edfbf8e084371f2b3adeece97d119e09a8b96d,"Add end+trainer callbacks to Trainer.from_partial_objects (#4751)

* add end+trainer callbacks to Trainer.from_partial_objects

* Update changelog

* Update changelog part 2",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2289,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-26 15:05:34-07:00,71a98c2a5fd014867188b8d81a05129cbc64268d,https://github.com/allenai/allennlp/commit/71a98c2a5fd014867188b8d81a05129cbc64268d,"stricter typing for Optional[T] types, improve handling of Lazy params (#4743)

* stricter typing for Optional[T] types

* fix linting error

* fix checkpointer test

* fix add_field method

* fix '_extract_token_and_type_ids' method

* fix typing on Lazy

* improve Lazy API

* add notes about Lazy to CHANGELOG

* fix CHANGELOG",55,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model is not None', 'test1.lazy1.a == 1', 'test1.lazy2.a == 2', 'test1.lazy3 is None', 'test1.lazy4 is not None', 'test2.lazy1.a == 1', 'test2.lazy2.a == 3', 'test2.lazy3 is None', 'test2.lazy4 is not None', 'test3.lazy1.a == 1', 'test3.lazy2.a == 2', 'test3.lazy3 is not None', 'test3.lazy3.a == 3', 'test3.lazy4 is None']","['(ConfigurationError, match=)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2290,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-26 16:26:04-07:00,0ad228d4cf7dee4bb782026de272866819d44654,https://github.com/allenai/allennlp/commit/0ad228d4cf7dee4bb782026de272866819d44654,"a few small doc fixes (#4752)

* a few small doc fixes

* update CHANGELOG",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2291,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2020-10-27 13:27:11-07:00,5d6670ce3d8ad0d03830046657d8da50446ecf7c,https://github.com/allenai/allennlp/commit/5d6670ce3d8ad0d03830046657d8da50446ecf7c,"Update torch requirement from <1.7.0,>=1.6.0 to >=1.6.0,<1.8.0 (#4753)

* Update torch requirement from <1.7.0,>=1.6.0 to >=1.6.0,<1.8.0

Updates the requirements on [torch](https://github.com/pytorch/pytorch) to permit the latest version.
- [Release notes](https://github.com/pytorch/pytorch/releases)
- [Commits](https://github.com/pytorch/pytorch/compare/v1.6.0...v1.7.0)

Signed-off-by: dependabot[bot] <support@github.com>

* update CHANGELOG

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2292,Mateusz Klimaszewski,mk.klimaszewski@gmail.com,2020-10-28 17:26:14+01:00,baca7545252196245f8288b35de8fa78e381e086,https://github.com/allenai/allennlp/commit/baca7545252196245f8288b35de8fa78e381e086,"Make returning token type id default in transformers intra word tokenization. (#4758)

* Make returning token type id default in transformers intra word tokenization.

* Add information about intra word tokenization fix in changelog.",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2293,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-28 16:00:40-07:00,aeb6d362820694ddf6e9b9fb3761ee4f867e5790,https://github.com/allenai/allennlp/commit/aeb6d362820694ddf6e9b9fb3761ee4f867e5790,revert samplers and fix bug when max_steps=1 (#4760),6,False,True,False,False,False,True,False,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,2,0,0,0,0,0,2,2,2,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(top_p.size())[:-1] == [batch_size, beam_size]', '((0 <= top_p) & (top_p <= 5)).all()', 'list(log_probs.size()) == [batch_size, beam_size]', 'list(top_k.size())[:-1] == [batch_size, beam_size]', '((0 <= top_k) & (top_k <= 5)).all()', 'list(log_probs.size()) == [batch_size, beam_size]', 'list(predictions.size()) == [2, 1, 1]', 'list(log_probs.size()) == [2, 1]', '(predictions == self.end_index).all()', '(log_probs == 0).all()', 'list(predictions.size()) == [2, 1, 1]', 'list(log_probs.size()) == [2, 1]', '(predictions == self.end_index).all()', '(log_probs == 0).all()', 'beam_search.sampler is None', 'beam_search.beam_size == 2', 'beam_search._end_index == 7', 'beam_search.sampler is not None', 'beam_search.beam_size == 2', 'beam_search._end_index == 7', 'beam_search.sampler is not None']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],"['', '']","['parametrize(', 'parametrize(']","['mark.parametrize(', 'mark.parametrize(']",[],[],[]
2294,Matt Gardner,mattg@allenai.org,2020-10-29 11:36:14-07:00,812ac5709f5575bf06d87c68a32671a3d5ca8074,https://github.com/allenai/allennlp/commit/812ac5709f5575bf06d87c68a32671a3d5ca8074,"Fix hotflip bug where vocab items were not re-encoded correctly (#4759)

* Fix hotflip bug where vocab items were not re-encoded correctly

* changelog

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2295,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-29 12:25:06-07:00,cc9ac0f270b67eacf3b3c33c8221fbf5f3bfe382,https://github.com/allenai/allennlp/commit/cc9ac0f270b67eacf3b3c33c8221fbf5f3bfe382,"ensure dataclasses not installed in CI (#4754)

* ensure dataclasses not installed

* fix tabs

* add test-install job to PRs

* fix

* fix

* fixes

* clean up

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2296,Evan Pete Walsh,epwalsh10@gmail.com,2020-10-29 14:06:14-07:00,7f85c74e69cbfccd92600a4e8c21b0470121d1c0,https://github.com/allenai/allennlp/commit/7f85c74e69cbfccd92600a4e8c21b0470121d1c0,fix docker build (#4762),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2297,Akshita Bhagia,akshita23bhagia@gmail.com,2020-10-29 14:31:41-07:00,5e510e4b2cb4353321e4ac7686c1697290c12db7,https://github.com/allenai/allennlp/commit/5e510e4b2cb4353321e4ac7686c1697290c12db7,Prepare for release v1.2.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2298,tpanza,19810086+tpanza@users.noreply.github.com,2020-11-02 12:04:06-08:00,9759b15fb7096b0d3a5d89b4b7c5e1e10e183baf,https://github.com/allenai/allennlp/commit/9759b15fb7096b0d3a5d89b4b7c5e1e10e183baf,"allow TextFieldEmbedder to have EmptyEmbedder that may not be in input (#4761)

* allow TextFieldEmbedder to have EmptyEmbedder that may not be in input

* Fix linting error. Update CHANGELOG.

Co-authored-by: Anthony P Panza <anthony.p.panza@boeing.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2299,Matt Gardner,mattg@allenai.org,2020-11-02 14:21:23-08:00,b7cec515448f46daec9a76551d0a3342ef51b27b,https://github.com/allenai/allennlp/commit/b7cec515448f46daec9a76551d0a3342ef51b27b,"Made Interpret code handle mismatched cases better (#4733)

* Made Interpret code handle mismatched cases better

* Add albert to find_embedding_layer heuristics

* changelog

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2300,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-04 11:47:47-08:00,b4f1a7abfbd7c74ea903debae1315f919abbe04f,https://github.com/allenai/allennlp/commit/b4f1a7abfbd7c74ea903debae1315f919abbe04f,add seed option to ModelTestCase.set_up_model (#4769),2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2301,Michal Malyska,malyskamichal@gmail.com,2020-11-05 18:50:03-05:00,23f0a8a65007670d07d99a2f666c52fbf881bd07,https://github.com/allenai/allennlp/commit/23f0a8a65007670d07d99a2f666c52fbf881bd07,"Ensure cnn_encoder respects masking (#4746)

* Create additive masks for filters involving pad tokens

* Add test on respecting masking

* Reformat

* Add to changelog

* Add Replacing all-pad activations picked up my maxpool with 0s

* Update allennlp/modules/seq2vec_encoders/cnn_encoder.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/modules/seq2vec_encoders/cnn_encoder.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/modules/seq2vec_encoders/cnn_encoder.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/modules/seq2vec_encoders/cnn_encoder.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/modules/seq2vec_encoders/cnn_encoder.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Black formatting

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2302,Dirk Groeneveld,dirkg@allenai.org,2020-11-06 16:06:19-08:00,92a844a7b1d99839428f4e3e3302f27c2f06bc7f,https://github.com/allenai/allennlp/commit/92a844a7b1d99839428f4e3e3302f27c2f06bc7f,"RoBERTa embeddings are no longer a type of BERT embeddings (#4771)

* RoBERTa embeddings are no longer a type of BERT embeddings

* Changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2303,Dirk Groeneveld,dirkg@allenai.org,2020-11-09 12:02:40-08:00,b89320cda5c79c232d21b599ffd088b8918b7ed1,https://github.com/allenai/allennlp/commit/b89320cda5c79c232d21b599ffd088b8918b7ed1,"Set the device for an auto-created mask (#4774)

* Set the device for an auto-created mask

* Changelog

* One more missing device",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2304,Kentaro,cfiken@gmail.com,2020-11-10 06:55:24+09:00,fcc3a70ba39e6b016c4089ad3dba2ed5ce6d24cf,https://github.com/allenai/allennlp/commit/fcc3a70ba39e6b016c4089ad3dba2ed5ce6d24cf,"Fix: typo in metric, rogue -> rouge (#4777)

* Fix: typo rogue -> rouge

* fix changelog

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2305,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-09 23:13:59-08:00,dc3a4f67808b274a6979ec9fe79b1af54962218b,https://github.com/allenai/allennlp/commit/dc3a4f67808b274a6979ec9fe79b1af54962218b,clean up forward hooks on exception (#4778),4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2306,Elad Segal,eladsegal@users.noreply.github.com,2020-11-10 19:44:07+02:00,764bbe2e772e64e901265a73bf5421a70a870e18,https://github.com/allenai/allennlp/commit/764bbe2e772e64e901265a73bf5421a70a870e18,"Pass batch metrics to `BatchCallback` (#4764)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2307,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-10 13:36:34-08:00,f6fe8c6d2faf19f20944ec59c61be98aea88f27d,https://github.com/allenai/allennlp/commit/f6fe8c6d2faf19f20944ec59c61be98aea88f27d,pin urllib3 in dev reqs for responses (#4780),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2308,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-10 16:00:49-08:00,9f7cc2487eed838d046df7e05c95abbf59da1dc6,https://github.com/allenai/allennlp/commit/9f7cc2487eed838d046df7e05c95abbf59da1dc6,"Add sampling strategies to beam search (#4768)

* add node and beam samplers

* refactor

* get stochastic beam search working

* Add MultiomialSampler, TopPSampler, TopKSampler to beam_search.py, and tests for those samplers and stochastic_beam_search

* Update changelog and finalize documentation

* set default to without replacement

* Updated TopPSampler to remove loop, with testing and bugfix. Cleaned up documentation and sampeler code.

* added p sampler test

* Better error messages

* Update allennlp/nn/beam_search.py

* lint

* default to top-k if insufficient examples when top-p sampling

* formatting

* minor clean up

* fix CHANGELOG

Co-authored-by: Jackson Stokes <jacksons@Jacksons-MacBook-Pro.local>",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,34,2,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['list(top_p.size())[:-1] == [batch_size, beam_size]', '((0 <= top_p) & (top_p <= 5)).all()', 'list(log_probs.size()) == [batch_size, beam_size]', 'list(top_k.size())[:-1] == [batch_size, beam_size]', '((0 <= top_k) & (top_k <= 5)).all()', 'list(log_probs.size()) == [batch_size, beam_size]', 'list(top_k.size())[:-1] == [batch_size, beam_size]', '((0 <= top_k) & (top_k <= 5)).all()', 'list(log_probs.size()) == [batch_size, beam_size]', 'token == self.end_index', 'beam_search.beam_size == 2', 'beam_search._end_index == 7', 'beam_search.sampler is not None', 'beam_search.beam_size == 2', 'beam_search._end_index == 7', 'beam_search.sampler is not None', 'probabilities.size() == classes.size()', 'classes.size() == (2, 3)', 'all([x < 4 for x in classes[0]])', 'all([x > 1 for x in classes[1]])', 'probabilities.size() == classes.size()', 'classes.size() == (2, 3)', 'all([x > 0 and x < 4 for x in classes[0]])', 'all([x > 1 and x < 5 for x in classes[1]])', 'probabilities.size() == classes.size()', 'classes.size() == (2, 3)', 'all([x > 0 and x < 4 for x in classes[0]])', 'all([x > 1 and x < 5 for x in classes[1]])', 'all([x == 2 or x == 3 or x == 1 for x in classes[0]])', 'all([x == 2 or x == 3 for x in classes[1]])', 'probabilities.size() == classes.size()', 'classes.size() == (2, 3)', 'all([x >= 0 and x < 4 for x in classes[0]])', 'all([x > 1 and x <= 5 for x in classes[1]])']","['(ValueError)', '(ValueError)']",[],[],[],[],[],"['()])', '(, [-1, 0])']","['parametrize()])', 'parametrize(, [-1, 0])']","['mark.parametrize()])', 'mark.parametrize(, [-1, 0])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2309,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-10 16:12:05-08:00,04247faad640762f623883ba012ebf6bcec5faf2,https://github.com/allenai/allennlp/commit/04247faad640762f623883ba012ebf6bcec5faf2,"support global plugins file, improve plugins docs (#4779)

* support global plugins file, improve plugins docs

* fix type hints

* make links relative

* fix

* comments

* fix

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2310,epwalsh,epwalsh10@gmail.com,2020-11-10 16:21:02-08:00,e3171b0099afef786901e19d9d11399366a6c21c,https://github.com/allenai/allennlp/commit/e3171b0099afef786901e19d9d11399366a6c21c,Prepare for release v1.2.1,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2311,Dirk Groeneveld,dirkg@allenai.org,2020-11-10 16:44:05-08:00,f27ef38b3074ec89a964d9b2d8de110ed75e7cd1,https://github.com/allenai/allennlp/commit/f27ef38b3074ec89a964d9b2d8de110ed75e7cd1,"Fixes pretrained embeddings for transformers that don't have end tokens (#4732)

* Fixes pretrained embeddings for transformers that don't have end tokens

* Changelog

* Adds a failing test

* Attempt to paper over a failing test

* Use the token_id hack on both places where it's needed

* Fix the test for T5

* We now need a newer transformer for make T5 work

* Fixes for new transformer version

* Can't pickle lambdas",7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in tokens1] == expected_tokens1', '[t.text for t in tokens2] == expected_tokens2', 'tokens[].shape == (2, max_length)', 'tokens[].tolist() == [', 'bert_vectors.size() == (2, 8, 64)', 'bert_vectors.requires_grad == (train_parameters or not last_layer_only)']",[],[],[],[],[],[],[''],['parametrize('],['mark.parametrize('],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2312,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2020-11-11 14:00:39-08:00,1e7492d7f36bf1848c6c8d6d76fa9de20c355c2c,https://github.com/allenai/allennlp/commit/1e7492d7f36bf1848c6c8d6d76fa9de20c355c2c,"Update transformers requirement from <3.5,>=3.4 to >=3.4,<3.6 (#4784)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v3.4.0...v3.5.0)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2313,Dirk Groeneveld,dirkg@allenai.org,2020-11-11 16:17:21-08:00,9fe8d900647763900f50a78bc11c6d090d5d18c0,https://github.com/allenai/allennlp/commit/9fe8d900647763900f50a78bc11c6d090d5d18c0,"Makes the transformer cache work with custom kwargs (#4781)

* Makes the transformer cache work with custom kwargs

* Changelog

* Use hashlib instead of mmh3",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2314,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-11 22:19:20-08:00,d99f7f8a4a59bf7f3370ec29c9c9cabf7b44040a,https://github.com/allenai/allennlp/commit/d99f7f8a4a59bf7f3370ec29c9c9cabf7b44040a,ensure Gumbel sorts beams by true log prob (#4786),3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['log_probs.size() == indices.size()', 'indices.size() == (2, 3)', '(sorted_indices == torch.arange(3).unsqueeze(0)).all()', 'all([x >= 0 and x < 4 for x in indices[0]])', 'all([x > 1 and x <= 5 for x in indices[1]])']",[],[],[],[],[],[],[],[],[],[],[],[],"['probabilities.size() == classes.size()', 'classes.size() == (2, 3)', 'all([x >= 0 and x < 4 for x in classes[0]])', 'all([x > 1 and x <= 5 for x in classes[1]])']",[],[],[],[],[],[],[],[],[],[],[],[]
2315,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-13 09:43:12-08:00,e4cc95ce3c4460721fa21ffade82283215d1712b,https://github.com/allenai/allennlp/commit/e4cc95ce3c4460721fa21ffade82283215d1712b,"improve plugin section in README (#4789)

* improve plugin section in README

* add semparse to default plugins

* clean up",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2316,epwalsh,epwalsh10@gmail.com,2020-11-13 11:10:56-08:00,0d8873cfef628eaf0457bee02422bbf8dae475a2,https://github.com/allenai/allennlp/commit/0d8873cfef628eaf0457bee02422bbf8dae475a2,doc link quickfix,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2317,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-16 15:59:13-08:00,ec37dd46b0435222ddee6701aa91997bb232ec63,https://github.com/allenai/allennlp/commit/ec37dd46b0435222ddee6701aa91997bb232ec63,"Docker builds for other CUDA versions, improve CI (#4796)

* Docker builds for other CUDA versions

* merge PR and master workflows

* build for different CUDA versions

* fix

* fix

* fix

* fix

* clean up

* clean up

* add CHANGELOG check back in",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2318,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-16 16:12:24-08:00,efde092db74a78580d9396696ac3f15070260a3e,https://github.com/allenai/allennlp/commit/efde092db74a78580d9396696ac3f15070260a3e,"upgrade ssh-agent action (#4797)

* upgrade ssh-agent action

* fix badge",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2319,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-16 16:13:07-08:00,3cad5b416b865dd440ce2cf5b042aec0908fd44b,https://github.com/allenai/allennlp/commit/3cad5b416b865dd440ce2cf5b042aec0908fd44b,fix AUC test (#4795),1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2320,epwalsh,epwalsh10@gmail.com,2020-11-17 08:34:11-08:00,7b0826c128925d67bb4f0a89f9ffc555bdbdb131,https://github.com/allenai/allennlp/commit/7b0826c128925d67bb4f0a89f9ffc555bdbdb131,push commit images for both CUDA versions,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2321,epwalsh,epwalsh10@gmail.com,2020-11-17 10:12:48-08:00,023d9bcc70f25dd29c504aab2a507000fbc677a6,https://github.com/allenai/allennlp/commit/023d9bcc70f25dd29c504aab2a507000fbc677a6,Prepare for release v1.2.2,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2322,epwalsh,epwalsh10@gmail.com,2020-11-17 10:22:55-08:00,d823a2591e94912a6315e429d0fe0ee2efb4b3ee,https://github.com/allenai/allennlp/commit/d823a2591e94912a6315e429d0fe0ee2efb4b3ee,GH Actions quickfix,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2323,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-17 17:02:29-08:00,ad8e8a09b1ed7fcdb4392afd3be0fa2681294a54,https://github.com/allenai/allennlp/commit/ad8e8a09b1ed7fcdb4392afd3be0fa2681294a54,no ssh setup on PRs (#4801),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2324,Akshita Bhagia,akshita23bhagia@gmail.com,2020-11-18 10:29:28-08:00,0a832713a1221803670c2eba134e2aea3ea29a44,https://github.com/allenai/allennlp/commit/0a832713a1221803670c2eba134e2aea3ea29a44,No Docker auth on PRs (#4802),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2325,Evan Pete Walsh,epwalsh10@gmail.com,2020-11-20 13:03:35-08:00,f353c6ce326affc07a7ea359611c22b103934144,https://github.com/allenai/allennlp/commit/f353c6ce326affc07a7ea359611c22b103934144,"add link to source code in docs (#4807)

* add link to source code in docs

* fix test",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2326,IINemo,ArtemShelmanov@gmail.com,2020-11-23 05:34:51+03:00,5b30658514a00e11000e648fec23be11a998bd92,https://github.com/allenai/allennlp/commit/5b30658514a00e11000e648fec23be11a998bd92,"Fix bug in GradientDescentTrainer when validation data is absent (#4811)

* Fix issue in GradientDescentTrainer, when validation data is absent

* Prevent an error when GradientDescentTrainer is constructed with
validation_data_loader=None and learning_rate_scheduler!=None

* Update CHANGELOG.md

* Fix issue with formatting",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2327,Tianshu Wang,13161779+tshu-w@users.noreply.github.com,2020-12-02 12:00:36+08:00,458c4c2baa85798d50b435bed31c7a00e18531d5,https://github.com/allenai/allennlp/commit/458c4c2baa85798d50b435bed31c7a00e18531d5,fix the way handlers are removed from the root logger (#4829),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2328,Alessandro Suglia,alessandro.suglia@gmail.com,2020-12-02 04:02:38+00:00,3e6236589bb18777ba966cad5d1c2d56f25b2aee,https://github.com/allenai/allennlp/commit/3e6236589bb18777ba966cad5d1c2d56f25b2aee,"Bugfix for attribute inheritance in ShardedDatasetReader (#4830)

* Bugfix for issue https://github.com/allenai/allennlp/issues/4825

Implemented automatic parameters inheritance from base_reader in ShardedDatasetReader.

* Updated CHANGELOG.md

* Constrained the parameters that can be inherited from the base reader

* Simplified logic for setting only `lazy` parameters

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(', '(']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2329,Tom Sherborne,tr.sherborne@gmail.com,2020-12-02 04:04:04+00:00,48a4865281c9fcbb3a5f3a99f2392332470d0475,https://github.com/allenai/allennlp/commit/48a4865281c9fcbb3a5f3a99f2392332470d0475,"Add GELU activation (#4828)

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2330,Evan Pete Walsh,epwalsh10@gmail.com,2020-12-02 14:24:05-08:00,cec92098641d3f4c395cd51d84ba93b691d1cdf3,https://github.com/allenai/allennlp/commit/cec92098641d3f4c395cd51d84ba93b691d1cdf3,"Several micro optimizations (#4833)

* benchmark transfers

* create tensors directl on device when possible

* fix",20,False,False,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2331,Evan Pete Walsh,epwalsh10@gmail.com,2020-12-04 22:48:56-08:00,6c3238ec8e714960174171decc47f9c34d1941f2,https://github.com/allenai/allennlp/commit/6c3238ec8e714960174171decc47f9c34d1941f2,rename token.py -> token_class.py (#4842),24,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2332,Evan Pete Walsh,epwalsh10@gmail.com,2020-12-04 22:52:37-08:00,63b6d163133fedc2ac1f2dde60e112c2b28abd0c,https://github.com/allenai/allennlp/commit/63b6d163133fedc2ac1f2dde60e112c2b28abd0c,"fix FromParams bug (#4841)

* fix FromParams bug

* simplify

* fix",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in kwargs', 'b.lazy is True', 'baz.b is None', 'baz.b == ']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2333,Elad Segal,eladsegal@users.noreply.github.com,2020-12-06 20:04:49+02:00,41c52245e4893ffae4934f3942730b8ac3b4ce3f,https://github.com/allenai/allennlp/commit/41c52245e4893ffae4934f3942730b8ac3b4ce3f,"Improve the band-aid solution for seg faults and the static TLS error (#4846)

* another fix attempt for static TLS

* changelog

* changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2334,Akshita Bhagia,akshita23bhagia@gmail.com,2020-12-10 11:44:03-08:00,fdad31aa764a3373d74ef23cdf67e7d364290881,https://github.com/allenai/allennlp/commit/fdad31aa764a3373d74ef23cdf67e7d364290881,"Add ability to specify the embedding layer if the model does not use `TextFieldEmbedder` (#4836)

* add ability to specify custom embedding layer

* update changelog

* changing function names",11,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['attack is not None', 'in attack', 'in attack', 'in attack', 'len(attack[][0]) == len(', 'interpretation is not None', 'in interpretation', ']', 'len(grad_input_1) == 7  # 7 words in input', 'interpretation is not None', 'in interpretation', ']', 'len(grad_input_1) == 7  # 7 words in input', 'interpretation is not None', 'in interpretation', ']', 'len(grad_input_1) == 7  # 7 words in input']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2335,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2020-12-11 15:24:51-08:00,84a36a06e28894fe3fbf582186fd71a3eb25cd6f,https://github.com/allenai/allennlp/commit/84a36a06e28894fe3fbf582186fd71a3eb25cd6f,"Update transformers requirement from <3.6,>=3.4 to >=4.0,<4.1 (#4831)

* Update transformers requirement from <3.6,>=3.4 to >=3.4,<4.1

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v3.4.0...v4.0.0)

Signed-off-by: dependabot[bot] <support@github.com>

* updates for transformers==4.0.1

* update changelog

* adding sentencepiece as dependency

* Update setup.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2336,Dirk Groeneveld,dirkg@allenai.org,2020-12-11 17:51:19-08:00,f2a53310383cb9c17e7c9d8e1bcca4ae3ed8b387,https://github.com/allenai/allennlp/commit/f2a53310383cb9c17e7c9d8e1bcca4ae3ed8b387,"Adds a safety check for tar files (#4858)

* Adds a safety check for tar files

* Changelog

* Adds test for dangerous tar file

* Formatting",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(ValueError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2337,Evan Pete Walsh,epwalsh10@gmail.com,2020-12-15 12:28:40-08:00,d408f4169ea95ef6fd84477e48768299edbef553,https://github.com/allenai/allennlp/commit/d408f4169ea95ef6fd84477e48768299edbef553,log import errors for default plugins (#4866),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2338,Akshita Bhagia,akshita23bhagia@gmail.com,2020-12-15 14:04:55-08:00,1ca478ab674dd412447b2f11c820ca5664737cc2,https://github.com/allenai/allennlp/commit/1ca478ab674dd412447b2f11c820ca5664737cc2,Prepare for release v1.3.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2339,David Fidalgo,david@recogn.ai,2020-12-16 03:09:44+01:00,832901e8cb00ab0f415649bb2e52ffbab4a5ae5d,https://github.com/allenai/allennlp/commit/832901e8cb00ab0f415649bb2e52ffbab4a5ae5d,"Turn superfluous warning to info when extending the vocab in the embedding matrix (#4854)

* fix: use module logger instead of root logger

* split warning in warning and info

* Update CHANGELOG.md

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2340,Evan Pete Walsh,epwalsh10@gmail.com,2020-12-16 12:12:28-08:00,a3732d00a3e7dae3bff54bff19ece7b8b6eaca88,https://github.com/allenai/allennlp/commit/a3732d00a3e7dae3bff54bff19ece7b8b6eaca88,"Fix cache volume (#4869)

* fix

* only attach cache/huggingface, not whole cache",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2341,Evan Pete Walsh,epwalsh10@gmail.com,2020-12-18 19:26:29-08:00,6a8d425f43713ff0ee7fad885d1c609588669b2e,https://github.com/allenai/allennlp/commit/6a8d425f43713ff0ee7fad885d1c609588669b2e,"add CombinedLearningRateScheduler (#4871)

* add CombinedLearningRateScheduler

* update",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(scheduler, CombinedLearningRateScheduler)', 'isinstance(scheduler._current_scheduler, PolynomialDecay)', 'self.optimizer.param_groups[0][] == 0.0', 'scheduler._current_scheduler is None', 'scheduler._current_scheduler is not None', 'scheduler._current_scheduler.total_steps == 50', 'scheduler._current_scheduler.base_values[0] == 0.5', 'scheduler._current_scheduler is not None', 'scheduler._current_scheduler.total_steps == 20', 'scheduler._current_scheduler.base_values[0] == 1.0', 'epoch_end_lrs[0] == 1.0', 'epoch_end_lrs[1] == 0.5', 'epoch_end_lrs[6] == 0.1', 'epoch_end_lrs[6] == 0.1', 'scheduler.last_epoch == 2', 'scheduler._current_scheduler is not None', 'scheduler._current_scheduler.total_steps == 50', 'scheduler._current_scheduler.base_values[0] == 0.5', 'new_scheduler.last_epoch == 2', 'new_scheduler._current_scheduler is not None', 'new_scheduler._current_scheduler.total_steps == 50', 'new_scheduler._current_scheduler.base_values[0] == 0.5, state_dict']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2342,Hicham EL BOUKKOURI,helboukkouri.dev@gmail.com,2020-12-21 18:38:50+01:00,d2aea979f49aaa73d7c88d666acd1b5fc6e7eeea,https://github.com/allenai/allennlp/commit/d2aea979f49aaa73d7c88d666acd1b5fc6e7eeea,"Fix typo in __str__ (#4874)

* Fix typo in __str__

* Update CHANGELOG.md

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2343,Evan Pete Walsh,epwalsh10@gmail.com,2020-12-21 13:50:21-08:00,1fff7cae9e157d2936ec7bfc82662a62ef5faebc,https://github.com/allenai/allennlp/commit/1fff7cae9e157d2936ec7bfc82662a62ef5faebc,"Update docker torch version (#4873)

* bump torch version in Docker builds

* update CHANGELOG",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2344,Akshita Bhagia,akshita23bhagia@gmail.com,2020-12-22 14:00:00-08:00,d1f032d82bb3a3cde21db1d9efe19a3367024f38,https://github.com/allenai/allennlp/commit/d1f032d82bb3a3cde21db1d9efe19a3367024f38,"Moving modelcard and taskcard abstractions to main repo (#4881)

* moving modelcard and taskcard abstractions to main repo

* CHANGELOG.md

* fix changelog",5,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['model_card.id == ', 'model_card.display_name == ', 'model_card.archive_file == ModelCard._storage_location + ', 'model_card.model_details.description == ', 'model_card.display_name == ', 'model_card.model_details.description == ', 'model_card.display_name == ', 'model_card.model_details.description == ', '(', 'model_card.display_name == ', 'key in model_card_dict', 'key not in model_card_dict', 'task_card.id == ', 'task_card.name == ', 'task_card.expected_inputs == ']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2345,Tim Gates,tim.gates@iress.com,2020-12-23 10:26:09+11:00,d0a07fb32811c649185ee99d71373cc7cab8791e,https://github.com/allenai/allennlp/commit/d0a07fb32811c649185ee99d71373cc7cab8791e,"docs: fix simple typo, multplication -> multiplication (#4883)

There is a small typo in allennlp/modules/elmo.py.

Should read `multiplication` rather than `multplication`.

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2346,Evan Pete Walsh,epwalsh10@gmail.com,2020-12-23 10:34:54-08:00,9635af827f8d6a4d8723f3a4ed47469f8e0afe27,https://github.com/allenai/allennlp/commit/9635af827f8d6a4d8723f3a4ed47469f8e0afe27,"rename 'master' -> 'main' (#4887)

* rename 'master' -> 'main'

* fix",11,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2347,epwalsh,epwalsh10@gmail.com,2020-12-23 10:51:13-08:00,9cf41b2f782f2be3076f247f42ed53f56e344a90,https://github.com/allenai/allennlp/commit/9cf41b2f782f2be3076f247f42ed53f56e344a90,fix navbar link,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2348,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-04 17:28:29-08:00,ec197c3b9e1fafa9deea30b86b40efc19ad2ad56,https://github.com/allenai/allennlp/commit/ec197c3b9e1fafa9deea30b86b40efc19ad2ad56,Create pull_request_template.md (#4891),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2349,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-05 13:57:53-08:00,1d21c759e289751754b7f82fd68b7c9951b34e60,https://github.com/allenai/allennlp/commit/1d21c759e289751754b7f82fd68b7c9951b34e60,"issue warning instead of failing when lock can't be acquired on a resource that exists in a read-only file system (#4867)

* allow FileLock to work on read-only file-system

* catch OSError too

* narrow-down the OSError

* fix",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(Timeout)', '(PermissionError)', '(PermissionError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2350,Karen Hambardzumyan,mahnerak@gmail.com,2021-01-07 20:10:51+04:00,2623c4bfb24d917ac36454dc202d1ddfd536b36b,https://github.com/allenai/allennlp/commit/2623c4bfb24d917ac36454dc202d1ddfd536b36b,"Making TrackEpochCallback an EpochCallback (#4893)

* Making TrackEpochCallback a EpochCallback

* Updated CHANGELOG

* Update CHANGELOG.md",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2351,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-08 07:29:19-08:00,54e85eee96983afd2a602fc642e45d59e048f686,https://github.com/allenai/allennlp/commit/54e85eee96983afd2a602fc642e45d59e048f686,"disable codecov annotations (#4902)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2352,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-01-14 11:02:36-08:00,4183a49c9ca7469fe877eb39a67a448f6509eb15,https://github.com/allenai/allennlp/commit/4183a49c9ca7469fe877eb39a67a448f6509eb15,"Update mkdocs-material requirement from <6.2.0,>=5.5.0 to >=5.5.0,<6.3.0 (#4880)

Updates the requirements on [mkdocs-material](https://github.com/squidfunk/mkdocs-material) to permit the latest version.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.5.0...6.2.1)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2353,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-01-20 13:08:32-08:00,d82287e5c06873759e9cd1997b4b8f18ca858613,https://github.com/allenai/allennlp/commit/d82287e5c06873759e9cd1997b4b8f18ca858613,"Update transformers requirement from <4.1,>=4.0 to >=4.0,<4.2 (#4872)

* Update transformers requirement from <4.1,>=4.0 to >=4.0,<4.2

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v4.0.0...v4.1.1)

Signed-off-by: dependabot[bot] <support@github.com>

* Include patch

* oops, fix

* pin >=4.1

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2354,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-20 14:58:27-08:00,9ab2bf0391e43f05d310b77262aafa7422f681f3,https://github.com/allenai/allennlp/commit/9ab2bf0391e43f05d310b77262aafa7422f681f3,add CUDA 10.1 Docker image (#4921),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2355,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-20 15:42:49-08:00,ed322ebaf136955b8f9f060d8fc49a6c252a0bba,https://github.com/allenai/allennlp/commit/ed322ebaf136955b8f9f060d8fc49a6c252a0bba,"A helper for distributed reductions (#4920)

* add dist_reduce helper

* fixes

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2356,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-22 09:24:34-08:00,a74453572cc80825de9e0a1815019d4e89d386b9,https://github.com/allenai/allennlp/commit/a74453572cc80825de9e0a1815019d4e89d386b9,fix mkdocs config (#4923),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2357,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-01-22 13:30:34-08:00,65e50b3061600e93b7fb342b192c55daeaf52f6b,https://github.com/allenai/allennlp/commit/65e50b3061600e93b7fb342b192c55daeaf52f6b,"Bump mypy from 0.790 to 0.800 (#4927)

* Bump mypy from 0.790 to 0.800

Bumps [mypy](https://github.com/python/mypy) from 0.790 to 0.800.
- [Release notes](https://github.com/python/mypy/releases)
- [Commits](https://github.com/python/mypy/compare/v0.790...v0.800)

Signed-off-by: dependabot[bot] <support@github.com>

* tell mypy to settle down

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2358,Dirk Groeneveld,dirkg@allenai.org,2021-01-26 11:12:56-08:00,67fa291cb72ce92a1e88a56974ba54168c1a8b15,https://github.com/allenai/allennlp/commit/67fa291cb72ce92a1e88a56974ba54168c1a8b15,"Merging vision into main (#4800)

* An initial VilBERT model for NLVR2 (#4423)

* Some initial work; lots left to do

* Initial test mostly passing, though things are still a bit of a mess

* tests are passing with small fixtures

* remove prints

* Test more stuff

* PathLike

* Make vilbert pass tests

* PR comments

* call float before log

* add CI

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* Initializing a VilBERT model from a pre-trained transformer (#4495)

* saving state

* Code is running, though it is returning zero gradients (but not None)

* initial test passing, still working on albert

* albert works, but bert-base-uncased still gives zero gradients

* Loading of weights should now work

* black, flake, mypy

* remove drop and mask functionality from reader

* make comment better

* fix tests

* flake

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* new data loading (#4497)

* first implementation

* update docstrings

* fixes

* fix sharding logic

* clean up DatasetReader

* fix samplers

* fixes

* fixes

* patch models for now

* more fixes

* fix linting error

* fix model test case

* some fixes

* fix linting err

* updates

* rename dataloader -> data_loader

* fixes

* more JoinableQueue

* set daemon=True

* fixes

* fix

* fixes

* fix

* update shuffle logic

* load instances right away when not lazy

* add tqdm when num_workers <= 0

* apply_token_indexers

* fix bug causing high mem usage

* address some of @dirkgr's comments

* fix lazy

* use sensible default for max_batches_in_mem

* ensure workers terminated on err

* fix

* start adding some tests

* more tests

* add some more tests

* address most of Matt's comments

* update PyTorchDataLoader test

* get rid of lazy option

* fix linting

* update docs, change max_batches_per_epoch to max_instances_per_epcoh

* update CHANGELOG

* fix drop_last validation

* fix py2md test fixture

* handle drop_last

* update docs

* implement sharding for most readers

* fix worker init fn

* limit tqdm output

* fixes

* ensure vision CI runs on each commit (#4582)

* ensure vision CI runs on each commit

* fix

* try fix CHANGELOG check

* ensure models check runs on right branch

* Formatting updates for new version of black (#4607)

* reformat for new version of black (#4605)

* reformat for new version of black

* pin black

* reformat for black

* fix

* rename 'node_rank' to 'global_rank' in dataset reader 'DistributedInfo' (#4608)

* rename 'node_rank' to 'global_rank'

* Clarify doc comments

* fix line length

* remove duplicate padding calculations in collate fn (#4617)

* fix len calculation for new data loader (#4618)

* fix len calculation for new data loader

* add test

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* make existing readers work with multi-process loading (#4597)

* make existing readers work with multi-process loading

* add 'overrides' decorator

* call apply_token_indexers in predictor

* clean up

* fix tests

* Add MultiTaskModel (#4601)

* Initial design of the multi-task model

* PR comments, more implementation

* changelog and docs fix

* More tests, and fixes for those tests

* mypy and make test less flaky

* Update allennlp/models/multitask.py

* Update allennlp/models/multitask.py

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>

* Update allennlp/models/multitask.py

Co-authored-by: James Barry <james.barry26@mail.dcu.ie>

* respect active heads in get_metrics

* Clean up changelog

* black (apparently github UI doesn't add newlines?)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>
Co-authored-by: James Barry <james.barry26@mail.dcu.ie>

* Detectron NLVR2 (#4481)

* Passes a batch of detectron images to the model in the correct format

* Loads a model and runs inference on it

* Some initial work; lots left to do

* Initial test mostly passing, though things are still a bit of a mess

* tests are passing with small fixtures

* remove prints

* More configurable reader

* add image_root and feature extraction to detectron model

* Use general detectron cfg functions

* Adds TensorField

* Fix detectron dependency

* Adds a detectron processor that we can use in dataset readers

* Test more stuff

* PathLike

* Make vilbert pass tests

* PR comments

* call float before log

* add CI

* PathLike

* Adds another NLVR2 reader

* add region feature and grid feature configuration json and attrtibute to cfg file

* change detectron_utils based on https://github.com/vedanuj/grid-feats-vqa/blob/master/extract_feature.py

* add bottom up and top down roi head into detectron2 based on allennlp/models/detectron.py

* Fix padding in TensorField

* Fix field construction

* Adds ability to read an arbitrary file

* More type annotations

* Remove old reader, add test for new one

* Use the right kind of field

* Run Jiasen's configs as tests

* We don't need this field

* Removes detectron reader

* Remove detectron reader and field

* Unify ArrayField and TensorField

* Making sure that no merge will go cleanly from now on

* Clean up the new output from the detectron processor a bit

* Fix Detectron2 version as v0.2

* saving state

* Code is running, though it is returning zero gradients (but not None)

* initial test passing, still working on albert

* albert works, but bert-base-uncased still gives zero gradients

* Note

* Formatting

* Adds Registrable base classes for image operations

* Adds a real example of a image2image module

* Run the new code (without implementation) in the nlvr2 reader

* Solve some issue involving circular imports

* add new modules for vilbert

* add parameters for detectron image loader.

* push current code on implementing proposal generator.

* push current progress on proposal generator

* Update FasterRCNNProposalGenerator & Merge Detectron2 config

* Loading of weights should now work

* black, flake, mypy

* Run detectron pipeline pieces one at a time

This is unfinished and will not run this way.

* Fix the data format for the backbone

* Handle image sizes separately

* remove drop and mask functionality from reader

* make comment better

* remove proposal_embedder, and finish proposal generator

* working on grid embedder

* added simple test for resnet backbone, which passes

* Got proposal generator test passing

* Change default number of detections per image: 100 => 36

* Fix detectron config hierarchy: test_detectron_per_image

* Make number of detections configurable & Add test

* rename ProposalGenerator to RegionDetector

* try to fix makefile

* another attempt at makefile

* quotes in the pip command...

* added a simple test for the dataset reader, made it pass

* add feature caching to the dataset reader

* another try with the makefile

* a better temporary fix for installing detectron

* writing files before committing is good...

* fix tests

* fix (at least part of) the vilbert tests

* ok, this makefile change should actually work

* add torchvision, try to remove eager import of detectron code

* flake

* cleanup

* more cleanup

* mypy, flake

* add back code I shouldn't have removed

* black

* test and flake fixes

* fix region_detector for multiple images and add feature and coords padding

* fix imports

* restore null grid embedder

* add back (todo) null region detector

* Bring back import changes, to fix circular imports caused by NLVR2
reader

* region detector test passing

* model test finally passing

* update torchvision version

* add vqav2 dataset

* add gpu support for detectron feature extraction

* add lmdbCache to cache feature into lmdb database

* fix typo

* update vqa jsonnet

* fix url adding by cat

* Fixes type annotation

* Fixes borked error message

* New feature cache

* Formatting

* Fix the tensor cache

* Be explicit about our dependencies

* Use the new tensor cache

* Adds a test using the tensor cache

* Run NLVR dataprep on GPU

* Tqdm when finding images

* Fixes padding in array field

* Adjust max_length when truncating in PretrainedTransformerTokenizer

* Fewer print statements

* remove VQA from this branch and copy default vilbert parameters.

* Sanjay's vision features cache script (#4633)

* Use LMDB cache in NLVR2 dataset reader; fix a few typos

* Standalone script for caching image features

* Removing reference to LMDB cache in NLVR2 dataset reader

* Adding back asterisk in nlvr2 dataset reader

* Fixing one variable name mistake

* Decreasing batch size and making a few cuda-related changes

* Loading images in batches to avoid GPU OOM error

* Pedantic changes for consistency

* Run the pre-processing with the models and not the data loading

* Filter out paths of images already cached

* Add image extensions other than png

* Fixes import error

* Makes the vision features script work alongside other scripts or training runs

Co-authored-by: sanjays <sanjays@ip-10-0-0-157.us-west-2.compute.internal>
Co-authored-by: sanjays <sanjays@ip-10-1-10-157.us-west-2.compute.internal>
Co-authored-by: Sanjay Subramanian <sanjays@allennlp-server1.corp.ai2>
Co-authored-by: Sanjay Subramanian <sanjays_ssubramanian@hotmail.com>

* Adds missing imports

* Makes TensorCache into a real MutableMapping

* Formatting

* Changelog

* Fix typecheck

* Makes the NLVR2 reader work with Pete's new code

* Fix type annotation

* Formatting

* Backwards compatibility

* Fix tests

* Fix broken config

* Update grid embedder test

* Fix vilbert_from_huggingface configuration

* Don't run the vilbert_from_huggingface test anymore

* Remove unused test fixtures

* Fix the region detector test

* Fix vilbert-from-huggingface and bring it back

* Fuck the linter

* Run the region detector test on GPU

* Run more stuff on GPU

The CPU test runner doesn't have enough memory.

* Depend on newer version of Detectron

* Reinstall Detectron before running tests

* Just force CUDA to be on, instead of reinstalling Detecton2

* Detectron needs CUDA_HOME to be set during install

At least this thing fails quickly.

* Try a different way of wrangling the detectron installer

* Bring back amp

* Trying to make tests faster, and passing

* use two regions, to make tests pass

* black

* Documentation for TensorCache

* Documentation for the NLVR2 dataset reader

* Rename ArrayField to TensorField

Co-authored-by: Matt Gardner <mattg@allenai.org>
Co-authored-by: jiasenlu <jiasenlu@gatech.edu>
Co-authored-by: Jaemin Cho <heythisischo@gmail.com>
Co-authored-by: jiasenlu <echosenm@gmail.com>
Co-authored-by: sanjays <sanjays@ip-10-0-0-157.us-west-2.compute.internal>
Co-authored-by: sanjays <sanjays@ip-10-1-10-157.us-west-2.compute.internal>
Co-authored-by: Sanjay Subramanian <sanjays@allennlp-server1.corp.ai2>
Co-authored-by: Sanjay Subramanian <sanjays_ssubramanian@hotmail.com>

* This should have been part of the previously merged PR

* Transformer toolkit (#4577)

* transformer toolkit: BertEmbeddings

* transformer toolkit: BertSelfAttention

* transformer toolkit: BertSelfOutput

* transformer toolkit: BertAttention

* transformer toolkit: BertIntermediate

* transformer toolkit: BertOutput

* transformer toolkit: BertLayer

* transformer toolkit: BertBiAttention

* transformer toolkit: BertEmbeddings

* transformer toolkit: BertSelfAttention

* transformer toolkit: BertSelfOutput

* transformer toolkit: BertAttention

* transformer toolkit: BertIntermediate

* transformer toolkit: BertOutput

* transformer toolkit: BertLayer

* transformer toolkit: BertBiAttention

* Attention scoring functions

* merging output and self output

* utility to replicate layers, further cleanup

* adding sinusoidal positional encoding

* adding activation layer

* adding base class for generic loading of pretrained weights

* further generalizing, adding tests

* updates

* adding bimodal encoder, kwargs in from_pretrained_module

* vilbert using transformer toolkit

* fixing test function

* changing to torch.allclose

* fixing attention score api

* bug fix in bimodal output

* changing to older attention modules

* _construct_default_mapping returns mapping

* adding kwargs to _get_input_arguments, adding examples

* using cached_transformers

* making transformer_encoder more general

* added get_relevant_module, loading by name

* fixing constructor name

* undoing failure after merge

* misc minor changes

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* Transformer toolkit: BiModalEncoder now has separate `num_attention_heads` for both modalities (#4728)

* separate num_attention_heads for both modalities, default arguments

* adding tests for toolkit examples

* debug statements for failing test

* removing debug statements, reordering

* Let's be more tolerant

* removing commented code

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* separating TransformerPooler as a new module (#4730)

* separating TransformerPooler as a new module

* adding size check

* fix failing tests

* Generalizing self attention (#4756)

* generalizing SelfAttention

* typecheck changes

* adding shape information to docstring

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* Multitask data loading and scheduling (#4625)

* Some initial work, still a bunch left to do

* Adds a utility function that can shuffle iterables

* remove shuffle

* Getting close; saving state before fixing lint and adding tests

* mypy and flake

* put in some initial schedulers and samplers; just need to write tests

* added some tests

* changelog

* add more-itertools to setup.py

* finish docstring

* some PR comments addressed

* mypy

* use homogeneous scheduler by default, not the non-homogeneous one

* add option to not shuffle

* normalize dataset proportions

* Update allennlp/data/data_loaders/multitask_data_loader.py

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* improve independence of vision components (#4793)

* improve independence of vision components

* fix install

* fix failing test

* haha, actually fix

* include torchvision exception too

* fix torchvision install

* remove vision push trigger

* VQAv2 (#4639)

* albert works, but bert-base-uncased still gives zero gradients

* Note

* Formatting

* Adds Registrable base classes for image operations

* Adds a real example of a image2image module

* Run the new code (without implementation) in the nlvr2 reader

* Solve some issue involving circular imports

* add new modules for vilbert

* add parameters for detectron image loader.

* push current code on implementing proposal generator.

* push current progress on proposal generator

* Update FasterRCNNProposalGenerator & Merge Detectron2 config

* Loading of weights should now work

* black, flake, mypy

* Run detectron pipeline pieces one at a time

This is unfinished and will not run this way.

* Fix the data format for the backbone

* Handle image sizes separately

* remove drop and mask functionality from reader

* make comment better

* remove proposal_embedder, and finish proposal generator

* working on grid embedder

* added simple test for resnet backbone, which passes

* Got proposal generator test passing

* Change default number of detections per image: 100 => 36

* Fix detectron config hierarchy: test_detectron_per_image

* Make number of detections configurable & Add test

* rename ProposalGenerator to RegionDetector

* try to fix makefile

* another attempt at makefile

* quotes in the pip command...

* added a simple test for the dataset reader, made it pass

* add feature caching to the dataset reader

* another try with the makefile

* a better temporary fix for installing detectron

* writing files before committing is good...

* fix tests

* fix (at least part of) the vilbert tests

* ok, this makefile change should actually work

* add torchvision, try to remove eager import of detectron code

* flake

* cleanup

* more cleanup

* mypy, flake

* add back code I shouldn't have removed

* black

* test and flake fixes

* fix region_detector for multiple images and add feature and coords padding

* fix imports

* restore null grid embedder

* add back (todo) null region detector

* Bring back import changes, to fix circular imports caused by NLVR2
reader

* region detector test passing

* model test finally passing

* update torchvision version

* add vqav2 dataset

* add gpu support for detectron feature extraction

* add lmdbCache to cache feature into lmdb database

* fix typo

* update vqa jsonnet

* fix url adding by cat

* Fixes type annotation

* Fixes borked error message

* New feature cache

* Formatting

* Fix the tensor cache

* Be explicit about our dependencies

* Use the new tensor cache

* Adds a test using the tensor cache

* Run NLVR dataprep on GPU

* Tqdm when finding images

* Fixes padding in array field

* Adjust max_length when truncating in PretrainedTransformerTokenizer

* Fewer print statements

* remove VQA from this branch and copy default vilbert parameters.

* add VQAv2 dataset

* Added dataset reader and model tests, which are now passing

* Sanjay's vision features cache script (#4633)

* Use LMDB cache in NLVR2 dataset reader; fix a few typos

* Standalone script for caching image features

* Removing reference to LMDB cache in NLVR2 dataset reader

* Adding back asterisk in nlvr2 dataset reader

* Fixing one variable name mistake

* Decreasing batch size and making a few cuda-related changes

* Loading images in batches to avoid GPU OOM error

* Pedantic changes for consistency

* Run the pre-processing with the models and not the data loading

* Filter out paths of images already cached

* Add image extensions other than png

* Fixes import error

* Makes the vision features script work alongside other scripts or training runs

Co-authored-by: sanjays <sanjays@ip-10-0-0-157.us-west-2.compute.internal>
Co-authored-by: sanjays <sanjays@ip-10-1-10-157.us-west-2.compute.internal>
Co-authored-by: Sanjay Subramanian <sanjays@allennlp-server1.corp.ai2>
Co-authored-by: Sanjay Subramanian <sanjays_ssubramanian@hotmail.com>

* Adds missing imports

* Makes TensorCache into a real MutableMapping

* Formatting

* Changelog

* Fix typecheck

* Makes the NLVR2 reader work with Pete's new code

* Fix type annotation

* Formatting

* Backwards compatibility

* Restore NLVR to former glory

* Types and multi-process reading for VQAv2

* Formatting

* Fix tests

* Fix broken config

* Update grid embedder test

* Fix vilbert_from_huggingface configuration

* Don't run the vilbert_from_huggingface test anymore

* Remove unused test fixtures

* Fix the region detector test

* Fix vilbert-from-huggingface and bring it back

* Fuck the linter

* Fix for VQA test

* Why was this metric disabled?

* Black and flake

* Re-add VQA reader

* Image featurizers now need to be called with sizes

* Run the region detector test on GPU

* Run more stuff on GPU

The CPU test runner doesn't have enough memory.

* Depend on newer version of Detectron

* Reinstall Detectron before running tests

* Just force CUDA to be on, instead of reinstalling Detecton2

* Fixes VQA2 DatasetReader

* Fix documentation

* Detectron needs CUDA_HOME to be set during install

At least this thing fails quickly.

* Try a different way of wrangling the detectron installer

* Try a different way of wrangling the detectron installer

* Bring back amp

* Refactored VQA reader

* More training paths

* Remove debug code

* Don't check in debug code

* Auto-detect GPU to use

* Apply indexers later

* Fix typo

* Register the model

* Fields live on CPU. Only batches get GPUs.

* black

* black, flake

* mypy

* more flake

* More realistic training config

* Adds a basic Predictor for VQAv2

* Make vilbert output human-readable

* Forgot to enumerate

* Use the right namspace

* Trying to make tests faster, and passing

* add image prefix when loading coco image

* fix vqav2 dataset reader and config file

* use two regions, to make tests pass

* black

* Output probabilities in addition to logits

* Make it possible to turn off the cache

* Turn off the cache in the predictor

* Fix the VQA predictor

* change the experiment to the defualt vilbert hyperparams.

* add default experiment_from_huggingface.json

* fix typos in vqa reader

* Proper probabilities

* Formatting

* Remove unused variable

* Make mypy happy

* Fixed loss function, metric, and got tests to pass

* Updates the big training config

* Put real settings into the vilbert_vqa config

* Strings are lists in Python

* Make mypy happy

* Formatting

* Unsatisfying mypy

* Config changes to make this run

* Fix dimensionality of embeddings

* clean the code and add the image_num_heads and combine_num_heads

* fix answer vocab and add save and load from pre-extracted vocab

* fix loss and update save_answer_vocab script

* Typo

* Fixed fusion method

* Tweaking the VQA config some more

* Moved the from_huggingface config

* 20 epochs

* Set up the learning rate properly

* Simplify

* Hardcoded answer vocab

* Don't be lazy

* Steps per epoch cannot be None

* Let's chase the right score

* Fixing some parameter names

* Fields are stored on CPUs

* Bigger batch size, easier distributed training

* Don't run the debug code by default

* VQA with the Transformer Toolkit (#4729)

* transformer toolkit: BertEmbeddings

* transformer toolkit: BertSelfAttention

* transformer toolkit: BertSelfOutput

* transformer toolkit: BertAttention

* transformer toolkit: BertIntermediate

* transformer toolkit: BertOutput

* transformer toolkit: BertLayer

* transformer toolkit: BertBiAttention

* transformer toolkit: BertEmbeddings

* transformer toolkit: BertSelfAttention

* transformer toolkit: BertSelfOutput

* transformer toolkit: BertAttention

* transformer toolkit: BertIntermediate

* transformer toolkit: BertOutput

* transformer toolkit: BertLayer

* transformer toolkit: BertBiAttention

* Attention scoring functions

* merging output and self output

* utility to replicate layers, further cleanup

* adding sinusoidal positional encoding

* adding activation layer

* adding base class for generic loading of pretrained weights

* further generalizing, adding tests

* updates

* adding bimodal encoder, kwargs in from_pretrained_module

* vilbert using transformer toolkit

* fixing test function

* changing to torch.allclose

* fixing attention score api

* bug fix in bimodal output

* changing to older attention modules

* _construct_default_mapping returns mapping

* adding kwargs to _get_input_arguments, adding examples

* using cached_transformers

* making transformer_encoder more general

* added get_relevant_module, loading by name

* fixing constructor name

* undoing failure after merge

* misc minor changes

* Transformer toolkit (#4577)

* transformer toolkit: BertEmbeddings

* transformer toolkit: BertSelfAttention

* transformer toolkit: BertSelfOutput

* transformer toolkit: BertAttention

* transformer toolkit: BertIntermediate

* transformer toolkit: BertOutput

* transformer toolkit: BertLayer

* transformer toolkit: BertBiAttention

* transformer toolkit: BertEmbeddings

* transformer toolkit: BertSelfAttention

* transformer toolkit: BertSelfOutput

* transformer toolkit: BertAttention

* transformer toolkit: BertIntermediate

* transformer toolkit: BertOutput

* transformer toolkit: BertLayer

* transformer toolkit: BertBiAttention

* Attention scoring functions

* merging output and self output

* utility to replicate layers, further cleanup

* adding sinusoidal positional encoding

* adding activation layer

* adding base class for generic loading of pretrained weights

* further generalizing, adding tests

* updates

* adding bimodal encoder, kwargs in from_pretrained_module

* vilbert using transformer toolkit

* fixing test function

* changing to torch.allclose

* fixing attention score api

* bug fix in bimodal output

* changing to older attention modules

* _construct_default_mapping returns mapping

* adding kwargs to _get_input_arguments, adding examples

* using cached_transformers

* making transformer_encoder more general

* added get_relevant_module, loading by name

* fixing constructor name

* undoing failure after merge

* misc minor changes

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* separate num_attention_heads for both modalities, default arguments

* adding tests for toolkit examples

* debug statements for failing test

* removing debug statements, reordering

* Typo

* Some compatibility with the transformer toolkit

* Reorganize the image inputs

* More transformer toolkit compatibility

* Debug settings

* Let's be more tolerant

* Fix how VilBERT runs

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>

* Make the region detector and region embedder lazy

* Fix references to the model

* Make various automated tests pass

* Formatting

* More logging

* One more logging statement

* Read answer vocab from vocab file instead of determining it automatically

* Don't keep the files open so long

* Use most of the validation set for training as well

* Get ready to be lazy

* Upgrade paths

* Be lazy

* Keep unanswerable questions only during test time

* Fix the from_huggingface config

* Fixes the VQA score

* VQA specific metric

* Fixes some tests

* Tests pass!

* Formatting

* Use the correct directory

* Use the region detector that's meant for testing

* Read the test split properly

* Be a little more verbose while discovering images

* Modernize Vilbert VQA

* Update NLVR, but it still doesn't run

* Formatting

* Remove NLVR

* Fix the last test

* Formatting

* Conditionally export the VilbertVqaPredictor

* ModuleNotFoundError is a type of ImportError

* Fix test-install

* Try the broken test with a fixed seed

* Try a bunch of seeds

* Smaller model to get bigger magnitudes

* Now that the test works, we don't need to specify the seeds anymore

Co-authored-by: Matt Gardner <mattg@allenai.org>
Co-authored-by: jiasenlu <jiasenlu@gatech.edu>
Co-authored-by: Jaemin Cho <heythisischo@gmail.com>
Co-authored-by: jiasenlu <echosenm@gmail.com>
Co-authored-by: sanjays <sanjays@ip-10-0-0-157.us-west-2.compute.internal>
Co-authored-by: sanjays <sanjays@ip-10-1-10-157.us-west-2.compute.internal>
Co-authored-by: Sanjay Subramanian <sanjays@allennlp-server1.corp.ai2>
Co-authored-by: Sanjay Subramanian <sanjays_ssubramanian@hotmail.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* SNLI_VE dataset reader (#4799)

* adding VE reader

* removing jsonlines

* blackify

* intial VE model

* adding VisionReader for common vision components

* fix test file

* fix doc

* temporarily removing VE model

* bug fix

* cleanup

* removing unnecessary check

* simplify

* Visual entailment model code (#4822)

* VE model code

* adding VE model

* misc minor updates

* update changelog

* Added GQA reader (#4832)

* Adds reader for GQA dataset. Will download questions from https://cs.stanford.edu/people/dorarad/gqa/download.html.

* Cleaned up GQA reader tests

* Other VQA datasets (#4834)

* Make the VQA reader work for the other datasets

* Also find pngs

* Really support pngs

* Remove debug code

* More logging

* Unexpected formatting

* Respect the device

* This is how your replace things in named tuples.

* Remove unused import

* This is how you override a method properly.

* This is how you set parameters in detectron.

* Also set the device for the region detector

* Training configs for all three datasets contained in VQA

* Bigger batches

* Bigger batches for image processing

* Fix vilbert-from-huggingface config

* Make the config switch modes for constructing vocab

* More vocab, more docs, better way of deriving vocab

* Modernize the from_huggingface config

* More updates to the from_huggingface config

* Better hyperparameters stolen from another project

* Fix for inverted parameter

* Formatting

* Throw a meaningful error message when we don't have images

* Add a warning that includes instructions for how to fix things

* Remove unused script

* Merge issue

* adding multilabel option (#4843)

* Generalizing transformer layers (#4776)

* adding HF tests, docstrings for AttentionLayer, TransformerLayer, TransformerBlock

* temp change to check if tests pass

* undoing temp change

* ci update

* more ci updates

* changing test run

* update makefile

* temp change

* isolating failing case

* further debugging

* fail check

* reverting to older CI

* test with reduced batch size

* cleanup

* more cleanup

* oops, fix

* gqa reader fixes during vilbert training (#4851)

* Refactored shared code

* typecheck fix

* rebase

* Refactored shared code

* typecheck fix

* rebase

* Cleaned up GQA reader tests

* Modify instance format for vilbert-vqa model

* update for vision branch bump

Co-authored-by: Jackson Stokes <jacksons@Jacksons-MacBook-Pro.local>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* Toolkit: Adding documentation and small changes for `BiModalAttention` (#4859)

* adding documentation for bimodal attn, small fixes

* changing the way mask is applied

* using large value rather than inf

* Update comment

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>

* moving apply_mask to util

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>

* Make tests work again (#4865)

* New import paths

* Duplicate entries

* Dataset readers can't be lazy anymore

* Switch to torchvision for vision components , simplify and improve MultiProcessDataLoader (#4821)

* implement TorchImageLoader

* implement ResnetBackbone

* add resize + normalize to image loader

* finalize FasterRcnnRegionDetector

* pin torchvision

* fix VQAv2Reader

* add box mask field

* dataset reader fixes

* fix model tests

* doc fixes

* add threshold parameters to FasterRcnnRegionDetector

* address @dirkgr comments

* mask fixes

* shape comments

* add some more comments

* cache answers_by_question_id

* implement LocalCacheResource

* fix

* add read-only option to cache

* fix

* simplify data loader

* make featurizer and detector optional in readers

* Cache in memory

* back pressure is important I guess

* merge

* Updated configs

* Fixes the way we apply masks

* Use more of Jiasen's real settings

* Upgrade the from_huggingface config

* Switch back to the images on corpnet

* Fix random seeds

* Bigger model needs smaller batch size

* Adds ability to selectively ignore one input

* address some comments

* format + lint

* fixes

* Bring back bert-base configs

* fix error handling

* fix test

* fix typo

* use lock when possible

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* doc fixes

* Only cache, no featurizing (#4870)

* implement TorchImageLoader

* implement ResnetBackbone

* add resize + normalize to image loader

* finalize FasterRcnnRegionDetector

* pin torchvision

* fix VQAv2Reader

* add box mask field

* dataset reader fixes

* fix model tests

* doc fixes

* add threshold parameters to FasterRcnnRegionDetector

* address @dirkgr comments

* mask fixes

* shape comments

* add some more comments

* cache answers_by_question_id

* implement LocalCacheResource

* fix

* add read-only option to cache

* fix

* simplify data loader

* make featurizer and detector optional in readers

* Cache in memory

* back pressure is important I guess

* merge

* Updated configs

* Fixes the way we apply masks

* Use more of Jiasen's real settings

* Upgrade the from_huggingface config

* Switch back to the images on corpnet

* Fix random seeds

* Bigger model needs smaller batch size

* Adds ability to selectively ignore one input

* address some comments

* format + lint

* fixes

* Bring back bert-base configs

* fix error handling

* fix test

* Adds the ability to read from a feature cache, but not run any featurization

* Update tests

* Let's stick with ""feature_cache""

As long as we're consistent ...

* More epochs, more random

* Use the new parameters

* Fix initialization

* Make tests work, add some documentation

* Remove the read_from_cache parameter

* Cleanup of training configs

* Typecheck

* Building docs right

* Better settings for VQA

* Leave the image_feature_dim at 1024

Co-authored-by: epwalsh <epwalsh10@gmail.com>

* Make images easier to find for Visual Entailment (#4878)

* implement TorchImageLoader

* implement ResnetBackbone

* add resize + normalize to image loader

* finalize FasterRcnnRegionDetector

* pin torchvision

* fix VQAv2Reader

* add box mask field

* dataset reader fixes

* fix model tests

* doc fixes

* add threshold parameters to FasterRcnnRegionDetector

* address @dirkgr comments

* mask fixes

* shape comments

* add some more comments

* cache answers_by_question_id

* implement LocalCacheResource

* fix

* add read-only option to cache

* fix

* simplify data loader

* make featurizer and detector optional in readers

* Cache in memory

* back pressure is important I guess

* merge

* Updated configs

* Fixes the way we apply masks

* Use more of Jiasen's real settings

* Upgrade the from_huggingface config

* Switch back to the images on corpnet

* Fix random seeds

* Bigger model needs smaller batch size

* Adds ability to selectively ignore one input

* address some comments

* format + lint

* fixes

* Bring back bert-base configs

* fix error handling

* fix test

* Adds the ability to read from a feature cache, but not run any featurization

* Update tests

* Let's stick with ""feature_cache""

As long as we're consistent ...

* More epochs, more random

* Use the new parameters

* Fix initialization

* Make tests work, add some documentation

* Remove the read_from_cache parameter

* Cleanup of training configs

* Typecheck

* Building docs right

* Better settings for VQA

* Open cached paths when reading json lines

* By default, autodetect GPUs when training

* Switch to torchvision

* Download training data from the web

* This needs to stay at 1024 until we get the new featurization model

* Have a more descriptive error message when images are missing

* Update vilbert_ve_from_huggingface.jsonnet

Co-authored-by: epwalsh <epwalsh10@gmail.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>

* Adding f1 score (#4890)

* adding f1 score

* updated config

* import MultiTaskDataLoader to data_loaders/__init__.py (#4885)

* Make GQA work (#4884)

* Refactored shared code

* typecheck fix

* rebase

* Refactored shared code

* typecheck fix

* rebase

* Cleaned up GQA reader tests

* Modify instance format for vilbert-vqa model

* update for vision branch bump

* Adding training config for GQA

* Unnamed variable

* Various GQA fixes

* Temporary extra configs needed to make vocab

* Remove unused file

* Optimize VQA score instead of F-Score

* Use our newly created vocab

* Remove temporary configs

* Don't fail when we don't need to create a directory

* Make a config that works on the servers as well

* Update comment

* A new command to count instances

* Temporary config to count instances

* Undo temporary changes

* Put in the correct number of steps per epoch

* Remove this number from the config because it's almost certainly wrong

* Don't put Fields in Tuples

* Formatting

* More informative error message when batches are heterogeneous

* Formatting

* Not my type

* Generate the fields properly when answers are missing

* Properly discard instances with missing answers

* Changelog

* Update number of steps per epoch

* Adds a config for balanced GQA

* fix file_utils extract with directory

* fix Batch._check_types

* Fill in URL

Co-authored-by: Jackson Stokes <jacksons@Jacksons-MacBook-Pro.local>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Toolkit: Cleaning up TransformerEmbeddings (#4900)

* fixing issue of non-deterministic dropout

* updating TransformerEmbeddings

* ImageFeatureEmbeddings is now a subclass of Embeddings

* allowing for no token type embeddings

* fixing kwargs for loading pretrained module

* Data loading cuda device (#4879)

* add test with tensor fields

* improve nn.util.move_to_device

* ensure start_method is 'spawn' when using lazy and mem pin

* add 'non_blocking' arg to 'move_to_device'

* fix fake test tensor

* fix sampler test

* lint

* fix 'move_to_device'

* fix condition check

* add device to data loader

* clean up doc string

* rename 'device' arg to 'cuda_device'

* pinning is very slow, revert

* DataLoaders load to CUDA device

* fix evaluate test

* rename 'multi_process_*' -> 'multiprocess' for consistency (#4906)

* MultiProcessDataLoader takes PathLike data_path (#4908)

* remove PyTorchDataLoader, add SimpleDataLoader for testing (#4907)

* remove PyTorchDataLoader, add SimpleDataLoader for testing

* fix test

* comments

* improve data loading docs (#4909)

* improve data loading docs

* document best practices, add 'get_batch_size' method to samplers

* try fix annoying unrelated test

* revert that

* clarify handling of 'max_instances_in_memory'

* fix imports in file_utils

* rename 'master' -> 'primary' for distributed training (#4910)

* improve worker error handling in MultiProcessDataLoader (#4912)

* improve worker error handling

* rename test file

* Toolkit decoder (#4914)

* adding cross_attention, renaming block -> stack

* stack can be initialized with layer too

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* resolve _read type (#4916)

* resolve _read type

* fix sharded reader

* fix data loader arg

* Multitask example (#4898)

* Make the VQA reader work for the other datasets

* Also find pngs

* Really support pngs

* Remove debug code

* More logging

* Unexpected formatting

* Respect the device

* This is how your replace things in named tuples.

* Remove unused import

* This is how you override a method properly.

* This is how you set parameters in detectron.

* Also set the device for the region detector

* Training configs for all three datasets contained in VQA

* Bigger batches

* Bigger batches for image processing

* Fix vilbert-from-huggingface config

* Make the config switch modes for constructing vocab

* More vocab, more docs, better way of deriving vocab

* Modernize the from_huggingface config

* More updates to the from_huggingface config

* Better hyperparameters stolen from another project

* Fix for inverted parameter

* Formatting

* Throw a meaningful error message when we don't have images

* Add a warning that includes instructions for how to fix things

* Remove unused script

* Merge issue

* Adds named splits to the SNLI-VE reader

* Make the multitask data loader discoverable

* Formatting

* More flexible inputs to the dataset readers

* Prototype config for the multitask training job

* json_lines_from_file() already calls cached_path()

* Visual entailment should track accuracy

* Switching to torch

* Fixing VE image paths

* Formatting

* Experimentally use threaded_generator to read instances from readers simultaneously

* Vilbert backbone

* Fixed paths

* Formatting

* Adds heads

* Revert ""Experimentally use threaded_generator to read instances from readers simultaneously""

This reverts commit a633e67134cf82f103071eba8ee560825f258c7b.

* Multitask trains now!

* Remove useless parameter from GQA reader

* Updated multitask config

* Schedulers produce batches, not instances

* Track multiple metrics

* Make mypy happy

* Formatting

* Keep better track of which heads have been called

* Fix the merge

* We have more than strings for input

* Remove unused imports

* -1 is CPU

* Go back to tracking instances per epoch so that the samplers can work

* Better error message

* A useful sampler to have

* We haven't indexed until we've indexed

* Makes tests pass

* Formatting

* Fine-tuning the metric tracker

* Update model configs for my changes

* Fixing model configs for Akshita's changes

* Implement VisionTextModel in terms of VilbertBackbone

* Formatting

* Fix stale comment

* Use the server paths by default, not Dirk's desktop

* Fix tests

* Formatting again

* Removed data loader parameters that don't exist anymore

* Clarified comment

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Moves vision models to allennlp-models (#4918)

* Moves vision models to allennlp-models

* Also move test fixtures

* Don't return so many instances if we're cutting them out later anyways

* We actually need this image

* Formatting

* Fixing more paths

* Prepare for release v2.0.0rc1

* Make releasing work with the renamed master branch, and with the vision branch

* Debugging the release process in the slowest way possible

* Another attempt at fixing the release process

* Generic Callbacks (#4917)

* Better Callbacks

* Reformatting

* Fixes

* Tests for updated TrainerCallback

* Formatting and Type-Checking fixes

* Consistent metric tracker (#4928)

* Makes the metric tracker more consistent

* Turns out we need best_epoch_metrics after all.

* Backwards compatibility

* Formatting

* Remove old script

* Changes CI since we won't have a `vision` branch anymore

* fix up CHANGELOG

Co-authored-by: Matt Gardner <mattg@allenai.org>
Co-authored-by: epwalsh <epwalsh10@gmail.com>
Co-authored-by: James Barry <james.barry26@mail.dcu.ie>
Co-authored-by: jiasenlu <jiasenlu@gatech.edu>
Co-authored-by: Jaemin Cho <heythisischo@gmail.com>
Co-authored-by: jiasenlu <echosenm@gmail.com>
Co-authored-by: sanjays <sanjays@ip-10-0-0-157.us-west-2.compute.internal>
Co-authored-by: sanjays <sanjays@ip-10-1-10-157.us-west-2.compute.internal>
Co-authored-by: Sanjay Subramanian <sanjays@allennlp-server1.corp.ai2>
Co-authored-by: Sanjay Subramanian <sanjays_ssubramanian@hotmail.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: jvstokes <40584422+jvstokes@users.noreply.github.com>
Co-authored-by: Jackson Stokes <jacksons@Jacksons-MacBook-Pro.local>
Co-authored-by: Karen Hambardzumyan <mahnerak@gmail.com>",164,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,186,9,0,0,0,0,0,19,19,19,6,0,8,78,3,0,0,0,0,0,16,16,16,7,0,3,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.allclose(old_parameters[name], parameter)', 'not cache.cached()', 'cache.cached()', 'data[] == 1', 'not cache.read_only', 'cache.read_only', 'cache[].shape == (3,)', 'cache.read_only', 'data_loader.batch_size == 2', 'reader.max_instances == 50', 'cycle_iterator_function_calls == 0', 'values == [1, 2, 1, 2, 1]', 'cycle_iterator_function_calls == 3', 'loader._instances', 'not isinstance(instances, (list, tuple))', 'len(instances) == MockDatasetReader.NUM_INSTANCES', 'len(indices) == len(set(indices)), indices', 'len(indices) == MockDatasetReader.NUM_INSTANCES, epoch', 'len(list(loader.iter_instances())) == MockDatasetReader.NUM_INSTANCES', 'MockDatasetReader.NUM_INSTANCES == 100', 'len(batch[]) == 16', 'len(batches) == 6', 'len(loader) == 10', 'len(list(loader)) == 10', 'batch[)', 'torch.all(batch[] == torch.IntTensor([0, 1, 0, 1]))', 'torch.all(batch[] == torch.IntTensor([0, 1, 0, 1]))', 'torch.all(batch[] == torch.IntTensor([0, 1, 0, 1]))', 'torch.all(batch[] == torch.IntTensor([0, 1, 1, 1]))', 'torch.all(batch[] == torch.IntTensor([1]))', 'list(batches) == [[1, 2, 1, 2], [1, 2, 1, 1]]', 'list(flattened) == [', 'minimum_expected_result_size <= len(result)', 'len(result) <= maximum_expected_result_size', 'len(union) == total == (max_instances or TOTAL_INSTANCES)', 'empty_field.tensor.dtype == array_field2.tensor.dtype', 'image.shape == (3, 480, 640)', 'images.device == torch_device', 'sizes.device == torch_device', 'images.shape[0] == 2', 'images.shape[1] == 3', 'sizes.shape == (2, 2)', 'list(sizes[0]) == [7, 15]', 'list(sizes[1]) == [9, 12]', 'images.shape[2] == 9', 'images.shape[3] == 15', 'images.shape[2] >= 9', 'images.shape[3] >= 15', '(images.shape[2] / loader.size_divisibility) % 1 == 0', 'image.device == torch_device', 'size.device == torch_device', 'len(image.shape) == 3', 'list(size) == [7, 15]', 'image.device == torch_device', 'size.device == torch_device', 'image.shape[1] == 800', 'loaded_image.shape == transformed_raw_image.tensors.shape', 'len(data_loader) == 3', 'len(data_loader) == 2', 'len(data_loader) == 3', 'in outputs', 'in outputs', 'in outputs', 'in outputs', 'in outputs', 'in outputs', 'not in outputs', 'in outputs', 'not in outputs  # no loss because we have no labels', 'in outputs  # but we can compute logits', 'in outputs', 'in outputs', 'in outputs', 'in outputs', 'in outputs', 'in outputs', 'abs(outputs[].item() - combined_loss) <= 1e-6', 'not torch.allclose(', 'torch.allclose(', 'activation_layer.dense.in_features == self.params_dict[]', 'activation_layer.dense.out_features == self.params_dict[]', 'biattention.num_attention_heads == self.params_dict[]', 'biattention.attention_head_size == int(', '(', 'biattention.query1.in_features == self.params_dict[]', 'biattention.key1.in_features == self.params_dict[]', 'biattention.value1.in_features == self.params_dict[]', 'biattention.dropout1.p == self.params_dict[]', 'biattention.query2.in_features == self.params_dict[]', 'biattention.key2.in_features == self.params_dict[]', 'biattention.value2.in_features == self.params_dict[]', 'biattention.dropout2.p == self.params_dict[]', 'len(modules[]', 'len(modules[]', 'output_layer.dense.in_features == self.params_dict[]', 'output_layer.dense.out_features == self.params_dict[]', 'output_layer.layer_norm.normalized_shape[0] == self.params_dict[]', 'output_layer.dropout.p == self.params_dict[]', 'self.positional_encoding.min_timescale == self.params_dict[]', 'self.positional_encoding.max_timescale == self.params_dict[]', 'self.self_attention.num_attention_heads == self.params_dict[]', 'self.self_attention.attention_head_size == int(', '(', 'self.self_attention.query.in_features == self.params_dict[]', 'self.self_attention.key.in_features == self.params_dict[]', 'self.self_attention.value.in_features == self.params_dict[]', 'self.self_attention.dropout.p == self.params_dict[]', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output)', 'len(small.transformer.layers) == 4', '(len(medium.separate_transformer.layers)) == 8', '(len(medium.combined_transformer.layers)) == 4', 'len(almost.transformer.layers) == 12', 'isinstance(almost.embeddings, AlbertEmbeddings)', '(', '(', '(', '(', '(', '(', '(', '(', 'self.transformer_embeddings.dropout.p == self.params_dict[]', 'output.shape[-1] == 7', 'len(module.embeddings) == 2', 'len(missing) == 0', 'torch.allclose(output, hf_output)', '(', '(', '(', 'self.img_embeddings.dropout.p == self.params_dict[]', 'attention_layer.self.num_attention_heads == self.params_dict[]', 'attention_layer.self.attention_head_size == int(', '(', 'attention_layer.self.query.in_features == self.params_dict[]', 'attention_layer.self.key.in_features == self.params_dict[]', 'attention_layer.self.value.in_features == self.params_dict[]', 'attention_layer.self.dropout.p == self.params_dict[]', 'attention_layer.output.dense.in_features == self.params_dict[]', 'attention_layer.output.dense.out_features == self.params_dict[]', '(', 'attention_layer.output.dropout.p == self.params_dict[]', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output, atol=1e-04)', '(', 'transformer_layer.attention.self.attention_head_size == int(', '(', 'transformer_layer.attention.self.query.in_features == self.params_dict[]', 'transformer_layer.attention.self.key.in_features == self.params_dict[]', 'transformer_layer.attention.self.value.in_features == self.params_dict[]', 'transformer_layer.attention.self.dropout.p == self.params_dict[]', '(', '(', '(', 'transformer_layer.attention.output.dropout.p == self.params_dict[]', 'transformer_layer.intermediate.dense.in_features == self.params_dict[]', '(', 'transformer_layer.output.dense.in_features == self.params_dict[]', 'transformer_layer.output.dense.out_features == self.params_dict[]', '(', 'transformer_layer.output.dropout.p == self.params_dict[]', 'hasattr(transformer_layer, )', 'hasattr(transformer_layer_new, )', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output, atol=1e-04)', 'self.pooler.dense.in_features == self.params_dict[]', 'self.pooler.dense.out_features == self.params_dict[]', 'out.size() == (2, 3)', 'len(modules[]', 'torch.allclose(layer_output[0], params_output[0])', 'hasattr(modules[)', 'hasattr(new_modules[)', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output)', 'tuple(result.keys()) == backbone.get_feature_names()', 'len(detections.features) == 2', 'len(detections.boxes) == 2', 'len(detections.class_probs) == 2', 'len(detections.class_labels) == 2', 'detections.features[0].shape[0] >= 1', 'detections.features[0].shape[1] == 1024', '(', '(result[0][] == detections.class_labels[0]).all()', '(result[0][] == detections.class_probs[0]).all()', 'trainer._batch_num_total == num_epochs * 3', 'trainer.start_callback_is_fired_first']","['(ValueError, match=)', '(WorkerError, match=)', '(ValueError, match=)', '(StopIteration)', '(StopIteration)', '(IndexError)', '(ValueError, match=)', '(AssertionError)', '(AssertionError)']",[],[],[],[],[],"['(, [None, 10])', '(, [None, 10])', '(, (None, 10))', '', '', '(, [False, True])', '', '', '(])', '(, get_modules(PARAMS_DICT).items())', '', '', '(, get_modules(PARAMS_DICT).items())', '', '', '(, get_layer_modules(LAYER_PARAMS_DICT).items())', '', '(, get_modules(PARAMS_DICT).items())', '']","['parametrize(, [None, 10])', 'parametrize(, [None, 10])', 'parametrize(, (None, 10))', 'parametrize(', 'parametrize(', 'parametrize(, [False, True])', 'parametrize(', 'parametrize(', 'parametrize(])', 'parametrize(, get_modules(PARAMS_DICT).items())', 'parametrize(', 'parametrize(', 'parametrize(, get_modules(PARAMS_DICT).items())', 'parametrize(', 'parametrize(', 'parametrize(, get_layer_modules(LAYER_PARAMS_DICT).items())', 'parametrize(', 'parametrize(, get_modules(PARAMS_DICT).items())', 'parametrize(']","['mark.parametrize(, [None, 10])', 'mark.parametrize(, [None, 10])', 'mark.parametrize(, (None, 10))', 'mark.parametrize(', 'mark.parametrize(', 'mark.parametrize(, [False, True])', 'mark.parametrize(', 'mark.parametrize(', 'mark.parametrize(])', 'mark.parametrize(, get_modules(PARAMS_DICT).items())', 'mark.parametrize(', 'mark.parametrize(', 'mark.parametrize(, get_modules(PARAMS_DICT).items())', 'mark.parametrize(', 'mark.parametrize(', 'mark.parametrize(, get_layer_modules(LAYER_PARAMS_DICT).items())', 'mark.parametrize(', 'mark.parametrize(, get_modules(PARAMS_DICT).items())', 'mark.parametrize(']","['setattr(common_util, , lambda: True)', 'setattr(dist, , lambda: global_rank)', 'setattr(dist, , lambda: world_size)', 'setattr(common_util, , lambda: True)', 'setattr(dist, , lambda: global_rank)', 'setattr(dist, , lambda: world_size)']",[],"['import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest', 'import pytest']","['data_loader.batch_sampler.sampler.__class__.__name__ == ', 'data_loader.batch_sampler.sampler.data_source is dataset', 'reader.lazy is True', 'str(reader._cache_directory) == ', 'Sampler.by_name(', 'Sampler.by_name(', 'BatchSampler.by_name(', 'epoch_batches == [', 'isinstance(instances, AllennlpLazyDataset)', 'len(first_pass_instances) > 2', 'first_pass_instances == second_pass_instances', 'os.path.exists(cache_file)', 'cache_contents == final_cache_contents', 'not os.path.exists(cache_file)', '.join([rec.message for rec in caplog.records])', 'os.path.exists(cache_file)', '.join([rec.message for rec in caplog.records])', 'len(first_pass_instances) == len(second_pass_instances)', 'instance.fields == cached_instance.fields', 'len(first_pass_instances) == len(cached_instances)', 'instance.fields == cached_instance.fields', 'in caplog.text', 'instances', 'not os.path.exists(cache_file)', 'os.path.exists(cache_file)', 'in caplog.text', 'instances', 'not os.path.exists(cache_file)', 'in caplog.text', 'not os.path.exists(cache_file)', 'instances', 'os.path.exists(cache_file)', 'len(instances) == len(new_instances)', 'instance_count == 2', 'len(instances) == 2', 'len(instances) == 2', 'not os.path.exists(cache_file)', 'len(instances) > 2', 'os.path.exists(cache_file)', 'len(instances) == 2', 'result == expected_result', 'reader.num_reads == 0', 'ensure_list(_instances) == self.instances', 'reader.num_reads == 10', 'reader.num_reads == 0', 'ensure_list(_instances) == self.instances', 'reader.num_reads == 1', '(', '(', 'empty_field.dtype == array_field2.dtype', 'len(dataloader) == 3', 'len(dataloader) == 2', 'sampler.sorting_keys == sorting_keys', 'sampler.padding_noise == 0.1', 'sampler.max_tokens == 32', 'sampler.sorting_keys == sorting_keys', 'sampler.padding_noise == 0.5', 'sampler.max_tokens == 100', 'len(dataloader) == 3', 'not torch.allclose(', 'torch.allclose(', 'has_tensor([, 10, tensor])', 'not has_tensor([, 10])', 'has_tensor((, 10, tensor))', 'not has_tensor((, 10))', 'has_tensor({: 1})', 'not has_tensor({: 1})', 'has_tensor(tensor)', 'not has_tensor(3)', 'has_tensor({: [3, [10, tensor]]}}]})', 'trainer._batch_num_total == num_epochs * batches_per_epoch', 'next_epoch == 3', 'best_epoch == 1', 'trainer._metric_tracker._best_so_far == 0.1', 'trainer._metric_tracker._epochs_with_no_improvement == 1', 'trainer.batch_callback_calls == expected_calls', 'trainer.epoch_callback_calls == expected_calls', 'trainer.end_callback_calls == expected_calls']","['(ConfigurationError, match=)', '(ConfigurationError, match=)', '(ValueError, match=)']",[],[],[],[],[],"['(, [True, False])', '(, [True, False])', '(, (True, False))', '', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (0, 1, 2))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(, (True, False))', '(])']","['parametrize(, [True, False])', 'parametrize(, [True, False])', 'parametrize(, (True, False))', 'parametrize(', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (0, 1, 2))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(, (True, False))', 'parametrize(])']","['mark.parametrize(, [True, False])', 'mark.parametrize(, [True, False])', 'mark.parametrize(, (True, False))', 'mark.parametrize(', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (0, 1, 2))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(, (True, False))', 'mark.parametrize(])']","['setattr(common_util, , lambda: True)', 'setattr(dist, , lambda: 0)', 'setattr(dist, , lambda: 1)', 'setattr(common_util, , lambda: True)', 'setattr(dist, , lambda: node_rank)', 'setattr(dist, , lambda: world_size)', 'setattr(']",[],"['import pytest', 'import pytest', 'import pytest']"
2359,epwalsh,epwalsh10@gmail.com,2021-01-26 12:06:26-08:00,00e3ff27b312b121aa2b4b199acbffa31ebf3e07,https://github.com/allenai/allennlp/commit/00e3ff27b312b121aa2b4b199acbffa31ebf3e07,tick version for nightly release,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2360,Dirk Groeneveld,dirkg@allenai.org,2021-01-26 12:08:34-08:00,7364da0329b46dc2ab59fedc6ebabe4967120e1f,https://github.com/allenai/allennlp/commit/7364da0329b46dc2ab59fedc6ebabe4967120e1f,Fix parameter name in the documentation,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2361,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-26 15:15:49-08:00,fa1dc7b8a3899ee9ec1f51146251dccb378e1f5e,https://github.com/allenai/allennlp/commit/fa1dc7b8a3899ee9ec1f51146251dccb378e1f5e,"Add link to upgrade guide to README (#4934)

Also removes the link to discourse",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2362,epwalsh,epwalsh10@gmail.com,2021-01-27 09:38:50-08:00,8b95316bc8d7c717dccc2d72fb19d27870ee3fcf,https://github.com/allenai/allennlp/commit/8b95316bc8d7c717dccc2d72fb19d27870ee3fcf,ci quick fix,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2363,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-27 13:44:20-08:00,15300823d64acedf83d8ad0fdd87fac471b529f9,https://github.com/allenai/allennlp/commit/15300823d64acedf83d8ad0fdd87fac471b529f9,"Log to TensorBoard through a TrainerCallback in GradientDescentTrainer (#4913)

* make TensorboardWriter optional in GradientDescentTrainer

* fix

* implement tensorboard logging as a callback

* fixes

* fix param_updates logic",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2364,Dirk Groeneveld,dirkg@allenai.org,2021-01-27 15:10:00-08:00,b2a639c6a3ea6969a1a0eb2591078fea8fbba0a1,https://github.com/allenai/allennlp/commit/b2a639c6a3ea6969a1a0eb2591078fea8fbba0a1,Prepare for release v2.0.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2365,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-28 13:40:25-08:00,96ea4839bec51c1ac6363b9a462aa5eacec232c1,https://github.com/allenai/allennlp/commit/96ea4839bec51c1ac6363b9a462aa5eacec232c1,"Add missing ""Unreleased"" section to CHANGELOG",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2366,Pedro Vitor Quinta de Castro,pvcastro@gmail.com,2021-01-28 19:46:41-03:00,fa625ec0a8dd0b98004ca4aca6d585a2dbad1d63,https://github.com/allenai/allennlp/commit/fa625ec0a8dd0b98004ca4aca6d585a2dbad1d63,"Adding missing transformer_kwargs arg that was recently added to PretrainedTransformerEmbedder (#4941)

* Adding missing  arg to  that was recently added to

* Updating changelog

* Updating changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2367,Akshita Bhagia,akshita23bhagia@gmail.com,2021-01-28 15:16:20-08:00,501b0ab43c1b5fca35e99fc788885b19cf08f29e,https://github.com/allenai/allennlp/commit/501b0ab43c1b5fca35e99fc788885b19cf08f29e,"Fixing papers and datasets (#4919)

* fixing papers and datasets

* update keys

* renaming classes",2,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(model_card.model_details.paper, Paper)', 'model_card.model_details.paper.url == ', 'model_card.training_data.dataset.name == ']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2368,Pedro Vitor Quinta de Castro,pvcastro@gmail.com,2021-01-29 14:31:19-03:00,f0ae9f3c8c27e429047e04d1ae2f9d14dabed2e4,https://github.com/allenai/allennlp/commit/f0ae9f3c8c27e429047e04d1ae2f9d14dabed2e4,Adding tokenizer_kwargs argument to PretrainedTransformerBackbone constructor. (#4944),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2369,Evan Pete Walsh,epwalsh10@gmail.com,2021-01-29 09:53:41-08:00,cd96d953d34853f64f4bdac116f67ae922abe5ec,https://github.com/allenai/allennlp/commit/cd96d953d34853f64f4bdac116f67ae922abe5ec,"Sanitize set (#4945)

* ensure sets are sanitized to lists

* update CHANGELOG",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(x, list)', 'len(x) == 3']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2370,Makoto Hiramatsu,himkt@cookpad.com,2021-01-30 06:31:16+09:00,caa497f30061f9d9843a73bab4d71eb3b2770387,https://github.com/allenai/allennlp/commit/caa497f30061f9d9843a73bab4d71eb3b2770387,"Update `GradientDescentTrainer` to automatically create directory for `serialization_dir` (#4940)

* Automatically create serialization_dir when GradientDescent is instantiated

* Update CHANGELOG

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Move to unreleased

* Update CHANGELOG.md

* Update trainer.py

* Fix

* Update CHANGELOG.md

* Fix whitespace

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2371,epwalsh,epwalsh10@gmail.com,2021-01-29 13:46:12-08:00,fcfa41736bda07c1e302d21bd7e1fddaabddba0f,https://github.com/allenai/allennlp/commit/fcfa41736bda07c1e302d21bd7e1fddaabddba0f,Prepare for release v2.0.1,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2372,epwalsh,epwalsh10@gmail.com,2021-01-29 15:07:31-08:00,2731db12b2e129a0beffa304ab208ad45bc2b86e,https://github.com/allenai/allennlp/commit/2731db12b2e129a0beffa304ab208ad45bc2b86e,tick version for nightly release,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2373,Dirk Groeneveld,dirkg@allenai.org,2021-02-01 23:47:56-08:00,6f222919aba1799f320ef507b08bce8a84e4af3f,https://github.com/allenai/allennlp/commit/6f222919aba1799f320ef507b08bce8a84e4af3f,"Allows specifying extra arguments for predictors (#4947)

* Allows specifying extra arguments for predictors

* Changelog",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.exists(self.outfile)', 'len(results) == 2', 'set(result.keys()) == {', 'result[']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2374,Evan Pete Walsh,epwalsh10@gmail.com,2021-02-02 17:39:20-08:00,1ace4bbbf285a8400984e4ad7d9c1d39abd78de8,https://github.com/allenai/allennlp/commit/1ace4bbbf285a8400984e4ad7d9c1d39abd78de8,fix bug with MultiProcessDataLoader (#4956),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2375,Akshita Bhagia,akshita23bhagia@gmail.com,2021-02-03 11:08:36-08:00,4535f5c84462ee1bc673df60a1afc35c7913cf55,https://github.com/allenai/allennlp/commit/4535f5c84462ee1bc673df60a1afc35c7913cf55,"adding ModelUsage, rearranging fields (#4952)",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['model_card.model_usage.archive_file == ModelUsage._storage_location + '],[],[],[],[],[],[],[],[],[],[],[],[],['model_card.archive_file == ModelCard._storage_location + '],[],[],[],[],[],[],[],[],[],[],[],[]
2376,Dirk Groeneveld,dirkg@allenai.org,2021-02-04 10:40:59-08:00,c418f84be4fef12ab4e5be23ea3da99118db90a0,https://github.com/allenai/allennlp/commit/c418f84be4fef12ab4e5be23ea3da99118db90a0,"Fixes recording validation metrics for learning rate schedulers that rely on it (#4959)

* Fixes recording validation metrics for learning rate schedulers that rely on it

* Test for learning rate schedulers that take metrics

* Changelog

* Make mypy happy",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['all([value != 0 for value in lr_scheduler.recordings])'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2377,Makoto Hiramatsu,himkt@klis.tsukuba.ac.jp,2021-02-06 03:14:49+09:00,52c23dd23385b468ff0596adf2977503ed173372,https://github.com/allenai/allennlp/commit/52c23dd23385b468ff0596adf2977503ed173372,"Introduce `convert_to_coding_scheme` and make `coding_scheme` deprecated in CoNLL2003DatasetReader (#4960)

* Update CHANGELOG

* Restore conll2003_test.py

* Deprecate `coding_scheme` and introduce `convert_to_coding_scheme`

* Update docstring

* Update docstring to add assumption about coding scheme

* Update allennlp/data/dataset_readers/conll2003.py

* Apply suggestions from code review

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,1,0,0,0,0,0,2,3,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens == []', 'fields[].labels == expected_labels', 'tokens == []', 'fields[].labels == expected_labels', 'tokens == []', 'fields[].labels == expected_labels', 'tokens == []', 'fields[].labels == expected_labels']",['(ConfigurationError)'],[],[],[],[],[],"['())', '())']","['filterwarnings()', 'parametrize())', 'parametrize())']","['mark.filterwarnings()', 'mark.parametrize())', 'mark.parametrize())']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2378,Pedro Vitor Quinta de Castro,pvcastro@gmail.com,2021-02-05 20:10:10-03:00,9267ce7cefed6456d7e0431aa235582c00996851,https://github.com/allenai/allennlp/commit/9267ce7cefed6456d7e0431aa235582c00996851,"Resize transformers word embeddings layer for additional_special_tokens (#4946)

* Adding a mechanism to resize the word embeddings layer from transformers models in case additional special tokens are provided in tokenizer_kwargs.

* Updating changelog

* Reformatting test file with black

* Fixing failed test for transformer model that don't implement get_input_embeddings()

* Adding message to warn user about the transformer model being unable to resize it's embeddings layer when additional tokens are provided

* Reformatting with black

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(', '(']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2379,wlhgtc,hgtcwl@foxmail.com,2021-02-09 13:08:52+08:00,bf8eeafebecdf0537c38070af72f745ab8a024a7,https://github.com/allenai/allennlp/commit/bf8eeafebecdf0537c38070af72f745ab8a024a7,"Add method to vocab to instantiate from a pretrained transformer (#4958)

* ADD: add from_pretrained method for vocab

* MOD: test format

* MOD: format file

* MOD: update changelog

* MOD: fix bug

* MOD: fix bug

* MOD: fix typo

* MOD: make the mothod in class

* MOD: fix bug

* MOD: change to instance method

* MOD: fix typo

* MOD: fix bug

* MOD: change oov to avoid bug

* Update allennlp/data/vocabulary.py

* Update allennlp/data/vocabulary.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/vocabulary.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/vocabulary.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* MOD: fix formate

* MOD: add test case

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab._token_to_index[namespace] == tokenizer.get_vocab()', 'vocab1._token_to_index[namespace] == tokenizer.get_vocab()']",[],[],[],[],[],[],['(])'],['parametrize(])'],['mark.parametrize(])'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2380,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-02-09 09:34:47-08:00,d2ae540d489336ba05f15479d3c55530b0bd6949,https://github.com/allenai/allennlp/commit/d2ae540d489336ba05f15479d3c55530b0bd6949,"Update transformers requirement from <4.3,>=4.1 to >=4.1,<4.4 (#4967)

* Update transformers requirement from <4.3,>=4.1 to >=4.1,<4.4

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v4.1.0...v4.3.1)

Signed-off-by: dependabot[bot] <support@github.com>

* fix test

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",2,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in str(execinfo.value)', 'in str(execinfo.value)']","['(OSError)', '(OSError)']",[],[],[],[],[],[],[],[],[],[],[],"['str(execinfo.value) == (', 'str(execinfo.value) == (']","['(ValueError)', '(ValueError)']",[],[],[],[],[],[],[],[],[],[],[]
2381,Dirk Groeneveld,dirkg@allenai.org,2021-02-12 10:37:27-08:00,d4926f5eaa33dc6ca89ac54bdaa104ca5ff86252,https://github.com/allenai/allennlp/commit/d4926f5eaa33dc6ca89ac54bdaa104ca5ff86252,"Inputs to the FBetaMultiLabel metric were copied and pasted wrong (#4975)

* Fixes docs and assumption checker

* Microscopic performance improvement

* Changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2382,Evan Pete Walsh,epwalsh10@gmail.com,2021-02-15 15:46:47-08:00,da4dba150d91c6863580912f71cbb62fc2a02d99,https://github.com/allenai/allennlp/commit/da4dba150d91c6863580912f71cbb62fc2a02d99,raise on HTTP errors in cached_path (#4984),3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(HTTPError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2383,Will Frey,jfrey89@gmail.com,2021-02-17 12:46:03-05:00,7961b8b790b412f72558d2a975d1037016fccd7c,https://github.com/allenai/allennlp/commit/7961b8b790b412f72558d2a975d1037016fccd7c,"Ensure mean absolute error metric returns a float (#4983)

*  MeanAbsoluteError.get_metric() returns a float

*  Update MeanAbsoluteError tests

*  Remove unused import

*  Remove assert statement

*  Update CHANGELOG.md

*  Update CHANGELOG.md",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(actual_mae_value, float)', 'actual_mae_value == 21.0 / 12.0', 'isinstance(actual_mae_value, float)', 'actual_mae_value == (21.0 + 3.5) / (12.0 + 8.0)', 'isinstance(actual_mae_value, float)', 'actual_mae_value == (21.0 + 3.5 + 32.0) / (12.0 + 8.0 + 12.0)', 'isinstance(actual_mae_value, float)', 'actual_mae_value == 32.0 / 12.0']",[],[],[],[],[],[],[],[],[],[],[],[],"['mae.get_metric()[] == 21.0 / 12.0', 'mae.get_metric()[] == (21.0 + 3.5) / (12.0 + 8.0)', 'mae.get_metric()[] == (21.0 + 3.5 + 32.0) / (12.0 + 8.0 + 12.0)', 'mae.get_metric()[] == 32.0 / 12.0']",[],[],[],[],[],[],[],[],[],[],[],[]
2384,John Giorgi,johnmgiorgi@gmail.com,2021-02-17 16:33:57-05:00,f8b38075fcb63dfec7c2a4f3fd7e294069815c5e,https://github.com/allenai/allennlp/commit/f8b38075fcb63dfec7c2a4f3fd7e294069815c5e,"Add ListField example to apply token indexers (#4987)

* Add ListField example to API docs

* Update changelog

* Add example with TextField by itself

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2385,Evan Pete Walsh,epwalsh10@gmail.com,2021-02-18 16:29:28-08:00,1cff6ad97fe8304d03923ddfaedb5e05bb67bee5,https://github.com/allenai/allennlp/commit/1cff6ad97fe8304d03923ddfaedb5e05bb67bee5,update README (#4993),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2386,Evan Pete Walsh,epwalsh10@gmail.com,2021-02-19 08:10:25-08:00,828ee101f30116b3508e7ef452e2fd47a6f4450d,https://github.com/allenai/allennlp/commit/828ee101f30116b3508e7ef452e2fd47a6f4450d,Update CHANGELOG.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2387,Evan Pete Walsh,epwalsh10@gmail.com,2021-02-19 08:10:42-08:00,be9537f6e49e70b02fe9f3c66a01500a254c2b11,https://github.com/allenai/allennlp/commit/be9537f6e49e70b02fe9f3c66a01500a254c2b11,Update CHANGELOG.md,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2388,Bruno,brataodream@gmail.com,2021-02-19 20:57:57-03:00,0078c595ac06a4bd302b455b0985803921d38626,https://github.com/allenai/allennlp/commit/0078c595ac06a4bd302b455b0985803921d38626,"Update spaCy to 3.0 (#4953)

* Update spaCy to 3.0

* Bump version

* Fix splitter

* Fix tests

* temp patch allennlp-models branch

* Update .github/workflows/ci.yml

* Update CHANGELOG.md

Co-authored-by: Bruno Cabral <bruno@potelo.com.br>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['[t.text for t in fields[]', '[t.text for t in fields[]']",[],[],[],[],[],[],[],[],[],[],[],[],['[t.text for t in fields[]'],[],[],[],[],[],[],[],[],[],[],[],[]
2389,Evan Pete Walsh,epwalsh10@gmail.com,2021-02-22 16:55:23-08:00,a02f67da036f8f7df4c9bdbd59870686d55bf4c2,https://github.com/allenai/allennlp/commit/a02f67da036f8f7df4c9bdbd59870686d55bf4c2,"drop support for Python 3.6 (#5012)

* drop support for Python 3.6

* fix README",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2390,RyujiTamaki,e44119rt@gmail.com,2021-02-24 02:47:53+09:00,c5c9edf0977d1ed483b3e108a0c57b08ee6a8670,https://github.com/allenai/allennlp/commit/c5c9edf0977d1ed483b3e108a0c57b08ee6a8670,"Add text_key and label_key to TextClassificationJsonReader (#5005)

* Add text_key and label_key to TextClassificationJsonReader

* Update CHANGELOG.md

* Remove unnecessary test

* Apply suggestions from code review

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2391,Evan Pete Walsh,epwalsh10@gmail.com,2021-02-23 11:09:17-08:00,b8cfb95c5fce0f165ec29c04f07e63331f18d974,https://github.com/allenai/allennlp/commit/b8cfb95c5fce0f165ec29c04f07e63331f18d974,re-write docs commit history on releases (#4968),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2392,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-02-23 11:43:56-08:00,099786cf70ac434e9b6e0f7b21189d038d95d180,https://github.com/allenai/allennlp/commit/099786cf70ac434e9b6e0f7b21189d038d95d180,"Update responses requirement, remove pin on urllib3 (#4783)

* Update urllib3 requirement from <1.26.0 to <1.27.0

Updates the requirements on [urllib3](https://github.com/urllib3/urllib3) to permit the latest version.
- [Release notes](https://github.com/urllib3/urllib3/releases)
- [Changelog](https://github.com/urllib3/urllib3/blob/master/CHANGES.rst)
- [Commits](https://github.com/urllib3/urllib3/compare/0.3...1.26.0)

Signed-off-by: dependabot[bot] <support@github.com>

* remove urllib3, update responses

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2393,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-02-23 12:07:27-08:00,d535de67dc60bb0f8a9a1b2a8069b6a22e33db4c,https://github.com/allenai/allennlp/commit/d535de67dc60bb0f8a9a1b2a8069b6a22e33db4c,"Bump mypy from 0.800 to 0.812 (#5007)

Bumps [mypy](https://github.com/python/mypy) from 0.800 to 0.812.
- [Release notes](https://github.com/python/mypy/releases)
- [Commits](https://github.com/python/mypy/compare/v0.800...v0.812)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2394,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-02-23 20:39:30+00:00,bdb0e20a3b8eafa6e68214f9cfefbae80ae2f46f,https://github.com/allenai/allennlp/commit/bdb0e20a3b8eafa6e68214f9cfefbae80ae2f46f,"Update mkdocs-material requirement from <6.3.0,>=5.5.0 to >=5.5.0,<7.1.0 (#5015)

* Update mkdocs-material requirement from <6.3.0,>=5.5.0 to >=5.5.0,<7.1.0

Updates the requirements on [mkdocs-material](https://github.com/squidfunk/mkdocs-material) to permit the latest version.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.5.0...7.0.0)

Signed-off-by: dependabot[bot] <support@github.com>

* fix readme

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2395,Evan Pete Walsh,epwalsh10@gmail.com,2021-02-23 13:18:29-08:00,5974f54e9388fa2e8ea363c3865e505b2bab0c45,https://github.com/allenai/allennlp/commit/5974f54e9388fa2e8ea363c3865e505b2bab0c45,"Revert ""drop support for Python 3.6 (#5012)"" (#5016)

This reverts commit a02f67da036f8f7df4c9bdbd59870686d55bf4c2.",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2396,Evan Pete Walsh,epwalsh10@gmail.com,2021-02-23 16:23:07-08:00,f091cb9cd92e767f55659b2b59f0ffb75bc613be,https://github.com/allenai/allennlp/commit/f091cb9cd92e767f55659b2b59f0ffb75bc613be,"fix error when torch.distributed not available (#5011)

* fix dist error

* fix

* fix

* fixes for rollback on 3.6

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2397,James Barry,james.barry26@mail.dcu.ie,2021-02-24 00:58:04+00:00,4b5fad463d83bcf5c8d28399b4b11e4d8ba5bec0,https://github.com/allenai/allennlp/commit/4b5fad463d83bcf5c8d28399b4b11e4d8ba5bec0,"Regex optimizer (#4981)

* Check for empty parameter list and support a parameter_groups value of None

* Update RegexOptimizer docstrings and add optimizer options test

* Update RegexOptimizer tests

* Refactor RegexOptimizer so optimizer groups are created following the order in parameter_groups

* Refactor _populate_optimizer_groups and add default optimizer kwargs to default group

* Update RegexOptimizer docstrings and tests

* Better error message

* Makes RegexOptimizer use Lazy to create inner optimizers

* typo

* Copy more default parameters

* Changelog

* Transformers changed what they throw when it can't find a file

* Fix comment

* We need the empty default group after all

* Renames RegexOptimizer to MultiOptimizer

* The old and the new error message are too different to catch with a single regex

* Moves the import statement to where Pete wants it

* Apparently there are three versions of this exception 

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",5,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,2,0,0,0,0,0,0,0,0,0,0,0,2,2,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(', '(', 'id(parameter) in parameters_in_optimizer', '(', 'len(param_groups) == 1 + 1  # one extra for the empty default group', '(', 'param_groups[0][] == (0.9, 0.98)', 'param_groups[0][] == 2', 'param_groups[0][] == 0.01', '(', 'len(param_groups) == 2 + 1  # one extra for the empty default group', '(', 'param_group[] == 0.001', 'param_group[] == 0.002', '(', 'len(param_groups) == 2', 'lr > 0', 'param.sum() == 0, ', 'regex_optimizer_params == regex_optimizer_grouped_optimizer_params']","['((OSError, ValueError))', '((OSError, ValueError))']",[],[],[],[],[],[],[],[],[],[],[],"['in str(execinfo.value)', 'in str(execinfo.value)']","['(OSError)', '(OSError)']",[],[],[],[],[],[],[],[],[],[],[]
2398,Will Frey,jfrey89@gmail.com,2021-02-23 20:37:28-05:00,678518a09cd4ce8688c92292d483cd4503f107e4,https://github.com/allenai/allennlp/commit/678518a09cd4ce8688c92292d483cd4503f107e4,"Less opaque registrable annotations (#5010)

*  Update CHANGELOG.md

*  Update registrable.py annotations

*  Fix CHANGELOG.md formatting

*  Clean up _registry annotation

*  Move the change to ### Fixed

*  Fix _SubclassRegistry annotation typo

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2399,Dirk Groeneveld,dirkg@allenai.org,2021-02-23 19:15:32-08:00,9d88f8c5d5f5eb638d94241fcbb88f7273674be4,https://github.com/allenai/allennlp/commit/9d88f8c5d5f5eb638d94241fcbb88f7273674be4,"Fixes predictors in the multitask case (#4991)

* Formatting

* Remove obsolete imports

* This function never worked

* Adds multitask predictor

* Make batch predictions work

* Changelog

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/predictors/multitask.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Better type limits

* Improved documentation

* Moves imports

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",7,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2400,wlhgtc,hgtcwl@foxmail.com,2021-02-25 03:55:52+08:00,7c6adeff545a220255bdf68d23e6a56b188ed73f,https://github.com/allenai/allennlp/commit/7c6adeff545a220255bdf68d23e6a56b188ed73f,"Fix worker_info bug when num_workers > 0 (#5013)

* ADD: add from_pretrained method for vocab

* MOD: test format

* MOD: format file

* MOD: update changelog

* MOD: fix bug

* MOD: fix bug

* MOD: fix typo

* MOD: make the mothod in class

* MOD: fix bug

* MOD: change to instance method

* MOD: fix typo

* MOD: fix bug

* MOD: change oov to avoid bug

* Update allennlp/data/vocabulary.py

* Update allennlp/data/vocabulary.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/vocabulary.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/vocabulary.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* MOD: fix formate

* MOD: add test case

* Update CHANGELOG.md

* MOD: fix worker info bug

* ADD: update changelog

* MOD: fix format

* Update allennlp/data/data_loaders/multitask_data_loader.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2401,Dirk Groeneveld,dirkg@allenai.org,2021-02-24 13:00:32-08:00,8fbc9728e99a85483b8a061b246c6547bab15e40,https://github.com/allenai/allennlp/commit/8fbc9728e99a85483b8a061b246c6547bab15e40,Prepare for release v2.1.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2402,Akshita Bhagia,akshita23bhagia@gmail.com,2021-02-25 15:52:55-08:00,a0edfae9ca571ed7d43749974bb842167201c2da,https://github.com/allenai/allennlp/commit/a0edfae9ca571ed7d43749974bb842167201c2da,"Add options to log inputs in trainer (#4970)

* add options to log inputs

* removing debug line

* adding LogWriter, ConsoleWriter, ConsoleLogCallback

* renaming function

* histogram -> distribution

* minor changes

* fixing docs

* removing ConsoleWriter

* misc changes

* fixing weird tensor print

* fix changelog, remove memory logging

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",6,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2403,Dirk Groeneveld,dirkg@allenai.org,2021-03-01 09:53:40-08:00,a8b800697ca8a63f25bf532635895c4393144ae0,https://github.com/allenai/allennlp/commit/a8b800697ca8a63f25bf532635895c4393144ae0,"Makes sure serialized tensors live on CPUs (#5026)

* Makes sure serialized tensors live on CPUs

* Changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2404,Leo Liu,zeyul@allenai.org,2021-03-02 10:34:43-08:00,d2bf35d1f63d27e00448dd3e0e7dedf87f185d1b,https://github.com/allenai/allennlp/commit/d2bf35d1f63d27e00448dd3e0e7dedf87f185d1b,"Add methods for human readable representation of fields and instances (#4986)

* creating a new functionality  to fields and instances to support outputing instnaces to json files

* creating tests for the new functionality

* fixing docs

* Delete __init__.py

* Delete influence_interpreter.py

* Delete use_if.py

* Delete simple_influence_test.py

* fixing docs

* changing to_json() to human_readable_dict()

* formatting

* add more docs and specify output type

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/fields/field.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/fields/tensor_field.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* adding new readable method to Field and Instance; along with test

* Update allennlp/data/fields/field.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* forget to import properly

* fixing a bug in output type

* Update allennlp/data/fields/field.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* add human_readable_repr() for other fields

* add human_readable_repr() for other fields

* add human_readable_repr() for other fields

* fix error in typecheck

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/fields/tensor_field.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/fields/tensor_field.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* fix error in test

* fix error in test

* fix error in test

* fix format error in test

* update changelog

* update small change in tensor_field, along with tests

* Update allennlp/data/fields/field.py

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",29,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['adjacency_field.human_readable_repr() == {]}', 'flag.human_readable_repr() is True', 'index_field1.human_readable_repr() == 4', 'label.human_readable_repr() == ', 'list_field.human_readable_repr() == [', 'field.human_readable_repr() == {: [0]}', 'field.human_readable_repr() == []', 'sequence_label_field.human_readable_repr() == tags', 'span_field.human_readable_repr() == (2, 3)', 'array.human_readable_repr() == ans', 'field.human_readable_repr() == []', 'type(instance1.human_readable_dict()) is dict', 'instance1.human_readable_dict() == {: 1}', 'instance1_human_readable_dict == instance2.human_readable_dict()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2405,Evan Pete Walsh,epwalsh10@gmail.com,2021-03-03 10:00:02-08:00,0c36019cd840ef2839dd1053480b9620e6283859,https://github.com/allenai/allennlp/commit/0c36019cd840ef2839dd1053480b9620e6283859,clean up (#5034),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2406,John Giorgi,johnmgiorgi@gmail.com,2021-03-03 20:12:52-05:00,96415b2bab6d8c70a0fa80ca4a8b9d1dc988720e,https://github.com/allenai/allennlp/commit/96415b2bab6d8c70a0fa80ca4a8b9d1dc988720e,"Use HF Transformers output types (#5035)

* Use HF Transformers output types

* Update changelog

* Remove a comment that is no longer relevant",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2407,Nelson Liu,nelson-liu@users.noreply.github.com,2021-03-05 11:52:06-08:00,7f609901bcc58ba0050bb9a941c1fd7697614cdc,https://github.com/allenai/allennlp/commit/7f609901bcc58ba0050bb9a941c1fd7697614cdc,"Update torch requirement from <1.8.0,>=1.6.0 to >=1.6.0,<1.9.0 (#5037)

* Update torch requirement from <1.8.0,>=1.6.0 to >=1.6.0,<1.9.0

* Remove dataclasses uninstall from CI, w/ torch 1.80 upstream fix

* Update Docker check PyTorch and CUDA versions

* Fix typo in torchvision version

* Empty commit to rerun CI, seems like a spurious network issue",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2408,Nelson Liu,nelson-liu@users.noreply.github.com,2021-03-05 19:56:05-08:00,ce71901a8acce158905d739328998d3dc143139e,https://github.com/allenai/allennlp/commit/ce71901a8acce158905d739328998d3dc143139e,"Update torchvision requirement from <0.9.0,>=0.8.1 to >=0.8.1,<0.10.0 (#5041)

* Update torchvision requirement from <0.9.0,>=0.8.1 to >=0.8.1,<0.10.0

* Fix in-place op on leaf-tensor view

* Make the test less strict

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2409,Akshita Bhagia,akshita23bhagia@gmail.com,2021-03-09 17:33:16+05:18,5b57be292c7d193419d7c8436441aff907068d5e,https://github.com/allenai/allennlp/commit/5b57be292c7d193419d7c8436441aff907068d5e,"Adding normalization bias verification (#4990)

* adding batchnorm verification

* Adding trainer callback

* updating changelog

* renaming class

* detailed message for sanity check

* run sanity checks by default

* fix normalization bias issue in image embeddings

* update docstring

* fix test

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",12,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['verification.check(inputs=self.dataset.as_tensor_dict())', 'not self.valid_with_bias', 'self.valid_without_bias', 'len(detected_pairs) == 1', 'detected_pairs[0] == ()', 'len(self.verification_with_bias._hook_handles) == 3', 'module._forward_hooks', 'len(self.verification_with_bias._hook_handles) == 0', 'not module._forward_hooks']","['(AssertionError)', '(AssertionError)']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2410,Evan Pete Walsh,epwalsh10@gmail.com,2021-03-10 13:47:22-08:00,91e4af94ce257f926d36069b436a50f9921807b8,https://github.com/allenai/allennlp/commit/91e4af94ce257f926d36069b436a50f9921807b8,fix pickle bug for Lazy FromParams (#5049),4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2411,Evan Pete Walsh,epwalsh10@gmail.com,2021-03-12 07:40:02-08:00,b897e57c940588101ceec8b5bfa400fd6aeeb69a,https://github.com/allenai/allennlp/commit/b897e57c940588101ceec8b5bfa400fd6aeeb69a,ensure ROUGE metric can be pickled (#5051),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2412,XinzheL,43598514+XinzheL@users.noreply.github.com,2021-03-13 04:39:26+11:00,3aafb927dda66f8efbf38e263e352df48bbad6b6,https://github.com/allenai/allennlp/commit/3aafb927dda66f8efbf38e263e352df48bbad6b6,"clarify how  `predictions_to_labeled_instances` work for targeted or non-targeted hotflip attack (#4957)

* clarify how  work for targeted or non-targeted hotflip attack

* Fix typo

* run black to fix minor formatting issues

* Update CHANGELOG.md

* fix formatting

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2413,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-03-17 15:38:37-07:00,15b532fbee5ddc26ed293554678b0409aa54fd78,https://github.com/allenai/allennlp/commit/15b532fbee5ddc26ed293554678b0409aa54fd78,"Update transformers requirement from <4.4,>=4.1 to >=4.1,<4.5 (#5057)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v4.1.0...v4.4.1)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2414,Leo Liu,zeyul@allenai.org,2021-03-24 15:28:31-07:00,385124ad5971e8922a1c6bc5e88a865ee7f27512,https://github.com/allenai/allennlp/commit/385124ad5971e8922a1c6bc5e88a865ee7f27512,"Keep Spacy PoS tagger on by default (#5066)

* changing function signature of get_spacy_model

* add changelog

* format files

* fix SpacyTokenizer

* modify the change log

* change the function signature back (made a mistake)

* formatting

* change the function signature back (made a mistake)

* Delete tbd.py

* Update allennlp/common/util.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* change the function signature back (made a mistake)

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2415,Evan Pete Walsh,epwalsh10@gmail.com,2021-03-25 14:23:29-07:00,c5c9df584f98d71b34fb68cd46fa3c2257c8a7b5,https://github.com/allenai/allennlp/commit/c5c9df584f98d71b34fb68cd46fa3c2257c8a7b5,"refactor LogWriter, add W&B integration (#5061)

* refactor LogWriter, add W&B integration

* Update setup.py

* fix for backwards compat

* log moving average of batch loss

* fixes

* fix mean batch size

* ignore memory metrics

* underscores

* improve file saving

* refactor

* default callbacks

* fix

* fix

* enable_default_callbacks

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",18,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2416,epwalsh,epwalsh10@gmail.com,2021-03-26 10:00:15-07:00,b180d5759f58aa98108b8725d27e926887d67856,https://github.com/allenai/allennlp/commit/b180d5759f58aa98108b8725d27e926887d67856,Prepare for release v2.2.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2417,epwalsh,epwalsh10@gmail.com,2021-03-26 10:26:37-07:00,bb77bd10bdb4e8422d0d0cebae7ed389279de257,https://github.com/allenai/allennlp/commit/bb77bd10bdb4e8422d0d0cebae7ed389279de257,fix date in CHANGELOG,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2418,epwalsh,epwalsh10@gmail.com,2021-03-26 11:17:53-07:00,3daa0bafb8217cbfa5c099215669fa2204fc8765,https://github.com/allenai/allennlp/commit/3daa0bafb8217cbfa5c099215669fa2204fc8765,tick version for nightly,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2419,Dirk Groeneveld,dirkg@allenai.org,2021-03-26 14:12:19-07:00,59b92106443ff6ce26776beef5259dee3a422b40,https://github.com/allenai/allennlp/commit/59b92106443ff6ce26776beef5259dee3a422b40,"Allow example categories to be ordered (#5059)

* Allow example categories to be ordered

* Changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2420,ArjunSubramonian,arjun.subramonian@gmail.com,2021-03-30 16:02:24-07:00,4baf19ab7b3aeae9f1c47700d4ac71616af0316e,https://github.com/allenai/allennlp/commit/4baf19ab7b3aeae9f1c47700d4ac71616af0316e,"Arjuns/softmax loss documentation update (#5075)

* minor documentation update to SoftmaxLoss

* Updated CHANGELOG

* added the expected shapes of the input and output tensors of forward

* fixed doc string issues

* Update allennlp/modules/softmax_loss.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* minor changes to doc string and CHANGELOG

Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-114.us-west-2.compute.internal>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2421,nadgeri14,abhishek22596@gmail.com,2021-03-31 22:17:11+05:18,bf8e71e974c88473b8402a99e80fe8a03105209d,https://github.com/allenai/allennlp/commit/bf8e71e974c88473b8402a99e80fe8a03105209d,"compare namespace in counter and min_count (#3644)

* compare namespace in counter and min_count

* added fix vocabulary test, resolved typechecking issues and counter None check bug

* updated CHANGELOG

* minor CHANGELOG update

Co-authored-by: Abhishek Nadgeri <abhisheknadgeri@Abhisheks-MacBook-Air.local>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-114.us-west-2.compute.internal>
Co-authored-by: ArjunSubramonian <arjun.subramonian@gmail.com>",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfigurationError)', '(ConfigurationError)']",[],[],['()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2422,Dirk Groeneveld,dirkg@allenai.org,2021-03-31 10:21:42-07:00,542ce5d9137840e8197ef5781cd12f02f1c86f79,https://github.com/allenai/allennlp/commit/542ce5d9137840e8197ef5781cd12f02f1c86f79,"Move coref prep script (#5078)

* Removed data prep script for coref. It now lives in allennlp-models.

* Changelof",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2423,ArjunSubramonian,arjun.subramonian@gmail.com,2021-03-31 13:33:08-07:00,63a3b48993c5921232853d2de2e09492acd3418a,https://github.com/allenai/allennlp/commit/63a3b48993c5921232853d2de2e09492acd3418a,"set transformer to evaluation mode (#5073)

* set transformer to evaluation mode

* minor docstring update

* Updated CHANGELOG

* added test case to ensure that PretrainedTrransformerEmbedder's transformer model remains in eval mode even when module that instantiates it is switched to training mode

* Update tests/modules/token_embedders/pretrained_transformer_embedder_test.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* simplified eval mode logic

* made eval mode logic more robust

* fixed minor bug

* Incorporated Pete's solution

* Update allennlp/modules/token_embedders/pretrained_transformer_embedder.py

Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-115.us-west-2.compute.internal>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-114.us-west-2.compute.internal>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-117.us-west-2.compute.internal>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['token_embedder.training and not token_embedder.transformer_model.training', '(', 'not trainable.fixed_module.transformer_model.training']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2424,ArjunSubramonian,arjun.subramonian@gmail.com,2021-03-31 14:01:20-07:00,87504c42b34e31a0da8568be712a7d832b3bd3b9,https://github.com/allenai/allennlp/commit/87504c42b34e31a0da8568be712a7d832b3bd3b9,"Ported Huggingface LambdaLR-based schedulers (#5082)

Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-117.us-west-2.compute.internal>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['lrs == pytest.approx('],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2425,Evan Pete Walsh,epwalsh10@gmail.com,2021-03-31 14:14:55-07:00,bb703494bdaafcd0acba30958cd5c497288bea8d,https://github.com/allenai/allennlp/commit/bb703494bdaafcd0acba30958cd5c497288bea8d,"Replace master references with main in issue template (#5084)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2426,Evan Pete Walsh,epwalsh10@gmail.com,2021-03-31 14:26:37-07:00,f82d3f11d18dd99bbf24802b9c947491c927e5ff,https://github.com/allenai/allennlp/commit/f82d3f11d18dd99bbf24802b9c947491c927e5ff,"remove lambdas from activations (#5083)

* remove lambdas from activations

* fix

* fix test

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2427,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-04-01 16:30:54-07:00,913fb8a4806893fb15f69b44ffa89d36be84d9d4,https://github.com/allenai/allennlp/commit/913fb8a4806893fb15f69b44ffa89d36be84d9d4,"Update mkdocs-material requirement from <7.1.0,>=5.5.0 to >=5.5.0,<7.2.0 (#5074)

Updates the requirements on [mkdocs-material](https://github.com/squidfunk/mkdocs-material) to permit the latest version.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.5.0...7.1.0)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2428,Evan Pete Walsh,epwalsh10@gmail.com,2021-04-02 13:05:15-07:00,decb875b4129ee9e6e286c9eea5f51b3f453c944,https://github.com/allenai/allennlp/commit/decb875b4129ee9e6e286c9eea5f51b3f453c944,"Bring back `run_sanity_checks` parameter (#5091)

* add back 'run_sanity_checks' trainer param

* CHANGELOG

* doc fixes

* fix

* type fixes",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2429,Evan Pete Walsh,epwalsh10@gmail.com,2021-04-05 09:27:16-07:00,c3fb97eba95e648a63a0454a0869f4f73e226b63,https://github.com/allenai/allennlp/commit/c3fb97eba95e648a63a0454a0869f4f73e226b63,"add SanityCheckError class (#5092)

* add SanityCheckError class

* fix",3,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(SanityCheckError)', '(SanityCheckError)']",[],[],[],[],[],[],[],[],[],[],[],[],"['(AssertionError)', '(AssertionError)']",[],[],[],[],[],[],[],[],[],[],[]
2430,ArjunSubramonian,arjun.subramonian@gmail.com,2021-04-05 11:59:21-07:00,6021f7d4773aef93499c82f1241a85b56611671b,https://github.com/allenai/allennlp/commit/6021f7d4773aef93499c82f1241a85b56611671b,"Avoid from_pretrained download of model weights (#5085)

* Only downloads config of pretrained transformer

* updated CHANGELOG

* Only downloads config of pretrained transformer

* Major updates to test

* Another major update to test

* Update tests/common/cached_transformers_test.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Uses smaller model for test and includes better explanation of weights loading

* fixed linting error

Co-authored-by: Arjun Subramonian <arjuns@Arjuns-MacBook-Pro.local>
Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(os.listdir(str(self.TEST_DIR))) == 0', 'len(json_fnames) == 1', '(', 'set(os.listdir(str(self.TEST_DIR))) == set(', 'p1.data.ne(p2.data).sum() == 0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2431,prajaktakini-vmware,81632721+prajaktakini-vmware@users.noreply.github.com,2021-04-06 04:27:33+05:18,29f00ee22b34c159c973b1572183794462f0a9c9,https://github.com/allenai/allennlp/commit/29f00ee22b34c159c973b1572183794462f0a9c9,"Added new parameter 'sub_token_mode' to 'pretrained_transformer_mismatched_embedder' class to support first sub-token embedding (#4363) (#5087)

* Added new parameter 'sub_token_mode' to 'pretrained_transformer_mismatched_embedder' class to support first sub-token embedding (#4363)

If 'sub_token_mode' is set to 'first', return first sub-token representation as word-level representation
If 'sub_token_mode' is set to 'avg', return average of all the sub-tokens representation as word-level representation
If 'sub_token_mode' is not specified it defaults to 'avg'
If invalid 'sub_token_mode' is provided, throw 'ValueError'

Signed-off-by: Prajakta Kini (VMware) <pkini@vmware.com>

* Added new parameter 'sub_token_mode' to 'pretrained_transformer_mismatched_embedder' class to support first sub-token embedding (#4363)

If 'sub_token_mode' is set to 'first', return first sub-token representation as word-level representation
If 'sub_token_mode' is set to 'avg', return average of all the sub-tokens representation as word-level representation
If 'sub_token_mode' is not specified it defaults to 'avg'
If invalid 'sub_token_mode' is provided, throw 'ConfigurationError'

Signed-off-by: Prajakta Kini (VMware) <pkini@vmware.com>",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,1,0,0,0,0,0,2,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tokens[].tolist() == [', 'tokens[].tolist() == [', 'bert_vectors.size() == (2, max(len(sentence1), len(sentence2)), 768)', 'not torch.isnan(bert_vectors).any()']",['(ConfigurationError)'],[],[],[],[],[],"['())', '(])']","['parametrize())', 'parametrize(])']","['mark.parametrize())', 'mark.parametrize(])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2432,Evan Pete Walsh,epwalsh10@gmail.com,2021-04-06 09:58:52-07:00,99da3156851404fd042bb52489dd2f6219514ba5,https://github.com/allenai/allennlp/commit/99da3156851404fd042bb52489dd2f6219514ba5,fix __str__ method of ModelCardInfo (#5096),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2433,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-04-07 11:03:17-07:00,d906175d953bebcc177567ec0157220c3bd1b9ad,https://github.com/allenai/allennlp/commit/d906175d953bebcc177567ec0157220c3bd1b9ad,"Update transformers requirement from <4.5,>=4.1 to >=4.1,<4.6 (#5102)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v4.1.0...v4.5.0)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2434,Evan Pete Walsh,petew@allenai.org,2021-04-07 15:03:46-07:00,fe2d6e5a1a02d815fc1a1855341cda3ae1f9742f,https://github.com/allenai/allennlp/commit/fe2d6e5a1a02d815fc1a1855341cda3ae1f9742f,"vocab fix (#5099)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2435,Dirk Groeneveld,dirkg@allenai.org,2021-04-07 18:57:35-07:00,de611008a50b5fe9c0947b8e244d33bed7d14178,https://github.com/allenai/allennlp/commit/de611008a50b5fe9c0947b8e244d33bed7d14178,"Distributed training with gradient accumulation (#5100)

* Fixes distributed training with gradient accumulation

* Fix in case we don't do anything in a batch group

* Test for the problematic condition

* Formatting

* More formatting

* Changelog

* Fix another test

* Fix even more tests

* Fixes one more test

* I can fix these tests all day.",8,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,0,0,3,3,3,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in serialized_files', 'in serialized_files', 'in serialized_files', 'in serialized_files', 'metrics[] > 0', 'metrics[] > 0', 'metrics[] > 0', 'metrics[] > 0', 'load_archive(out_dir).model', 'tokens == [']",[],[],[],[],[],[],"['(, [1, 2, 3, 4, None])', '(, [None, 2])', '(, [1, 2, 3])']","['parametrize(, [1, 2, 3, 4, None])', 'parametrize(, [None, 2])', 'parametrize(, [1, 2, 3])']","['mark.parametrize(, [1, 2, 3, 4, None])', 'mark.parametrize(, [None, 2])', 'mark.parametrize(, [1, 2, 3])']",[],[],[],['tokens == []'],[],[],[],[],[],[],[],[],[],[],[],[]
2436,Evan Pete Walsh,petew@allenai.org,2021-04-08 09:36:32-07:00,2e8c3e2f14dfbde21a9addda0bd1e3365aaaf164,https://github.com/allenai/allennlp/commit/2e8c3e2f14dfbde21a9addda0bd1e3365aaaf164,"Add link to gallery and demo in README (#5103)

* Add link to gallery in README

* Update README.md

* try emojis

Is this overkill?",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2437,Jacob Morrison,jacob1morrison@gmail.com,2021-04-08 10:51:03-07:00,6ee1212366f34d7a70c0d03b151a8cb1b8afd71e,https://github.com/allenai/allennlp/commit/6ee1212366f34d7a70c0d03b151a8cb1b8afd71e,"Adding a metadata field to the basic classifier (#5104)

* Adding metadata parameter to BasicClassifier

* Fix

* Updating the changelog

* reformatting

* updating parameter type

* fixing import

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2438,Evan Pete Walsh,petew@allenai.org,2021-04-12 14:26:42-07:00,99415e364447fb890e372c39a8d5f15fb1f283b3,https://github.com/allenai/allennlp/commit/99415e364447fb890e372c39a8d5f15fb1f283b3,"additional W&B params (#5114)

* additional W&B params

* add wandb_kwargs

* fix

* fix docs",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2439,Nelson Liu,nelson-liu@users.noreply.github.com,2021-04-13 09:08:15-07:00,0ddd3d352fc801c001a6dbbb472852ca12d49c80,https://github.com/allenai/allennlp/commit/0ddd3d352fc801c001a6dbbb472852ca12d49c80,"Add eval_mode argument to pretrained transformer embedder (#5111)

* Add eval_mode argument to pretrained transformer embedder

* Edit changelog entry

* Lint

* Update allennlp/modules/token_embedders/pretrained_transformer_embedder.py

* Apply suggestions from code review

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Evan Pete Walsh <petew@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2440,Evan Pete Walsh,petew@allenai.org,2021-04-13 15:52:24-07:00,b34df73e1b3ccba123d03fd5d14708597204b786,https://github.com/allenai/allennlp/commit/b34df73e1b3ccba123d03fd5d14708597204b786,"specify 'truncation' to avoid transformers warning (#5120)

* specify 'truncation' to avoid transformers warning

* Update docs

* Remove `stride` param

* Update CHANGELOG.md

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2441,Dirk Groeneveld,dirkg@allenai.org,2021-04-13 17:54:11-07:00,6e1f34cb39be3df0cf27a9731ea91f1d3b194e93,https://github.com/allenai/allennlp/commit/6e1f34cb39be3df0cf27a9731ea91f1d3b194e93,"Predicting with a dataset reader on a multitask model (#5115)

* Create a way to use allennlp predict with a dataset and a multitask model

* Fix type ignoration

* Changelog

* Fix to the predictor",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2442,Evan Pete Walsh,petew@allenai.org,2021-04-13 17:57:19-07:00,5fdce9adae1205e85d07c80fc7c5bf22d4d5814a,https://github.com/allenai/allennlp/commit/5fdce9adae1205e85d07c80fc7c5bf22d4d5814a,"fix bug with interleaving dataset reader (#5122)

* fix bug with interleaving dataset reader

* more tests

* Update allennlp/data/dataset_readers/interleaving_dataset_reader.py

* Update allennlp/data/dataset_readers/interleaving_dataset_reader.py",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(, (True, False))']","['parametrize(, (True, False))']","['mark.parametrize(, (True, False))']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2443,Evan Pete Walsh,petew@allenai.org,2021-04-13 18:09:49-07:00,059a64fc8c89db1e053af927d96d687cb0fad6be,https://github.com/allenai/allennlp/commit/059a64fc8c89db1e053af927d96d687cb0fad6be,"remove jsonpickle from dependencies (#5121)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2444,Akshita Bhagia,akshita23bhagia@gmail.com,2021-04-14 14:51:23-07:00,aca16237ad521a7cd9bad4e3bd04e781b662f948,https://github.com/allenai/allennlp/commit/aca16237ad521a7cd9bad4e3bd04e781b662f948,Update docstring for basic_classifier (#5124),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2445,Evan Pete Walsh,petew@allenai.org,2021-04-14 15:33:30-07:00,c80e1751593987956b801fb9d61688cfb8425944,https://github.com/allenai/allennlp/commit/c80e1751593987956b801fb9d61688cfb8425944,"improve error message from Registrable class (#5125)

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['in str(exc.value)'],['(ConfigurationError)'],[],[],[],[],[],[''],['parametrize('],['mark.parametrize('],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2446,Akshita Bhagia,akshita23bhagia@gmail.com,2021-04-14 15:48:29-07:00,98334a503d8c4a4668861c4d2641c7f18ef2f89a,https://github.com/allenai/allennlp/commit/98334a503d8c4a4668861c4d2641c7f18ef2f89a,Prepare for release v2.3.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2447,epwalsh,epwalsh10@gmail.com,2021-04-14 15:59:08-07:00,8be3828f994bc1da6549863eb6c6fe0450c2f3f5,https://github.com/allenai/allennlp/commit/8be3828f994bc1da6549863eb6c6fe0450c2f3f5,fix docs CI,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2448,Dirk Groeneveld,dirkg@allenai.org,2021-04-14 17:30:01-07:00,0c7d60bcf008ef963a61ee6829420aec9ecf4372,https://github.com/allenai/allennlp/commit/0c7d60bcf008ef963a61ee6829420aec9ecf4372,"Take the number of runs in the test for distributed metrics (#5127)

* Take the number of runs in the test for distributed metrics

* Changelog",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['desired_values == metric.get_metric()'],[],[],[],[],[],[],[],[],[],[],[],[]
2449,Leo Liu,zeyuliu2@uw.edu,2021-04-19 16:03:36-07:00,c2ffb1011d2d25be384e240dc65e413c13ad2770,https://github.com/allenai/allennlp/commit/c2ffb1011d2d25be384e240dc65e413c13ad2770,"Add influence functions to interpret module (#4988)

* creating a new functionality  to fields and instances to support outputing instnaces to json files

* creating tests for the new functionality

* fixing docs

* Delete __init__.py

* Delete influence_interpreter.py

* Delete use_if.py

* Delete simple_influence_test.py

* fixing docs

* finishing up SimpleInfluence

* passing lint

* passing format

* making small progress in coding

* Delete fast_influence.py

Submit to the wrong branch

* Delete faiss_utils.py

wrong branch

* Delete gpt2_bug.py

not sure why it's included

* Delete text_class.py

not sure why it's included

* adding test file

* adding testing files

* deleted unwanted files

* deleted unwanted files and rearrange test files

* small bug

* adjust function call to save instance in json

* Update allennlp/interpret/influence_interpreters/influence_interpreter.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/interpret/influence_interpreters/influence_interpreter.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/interpret/influence_interpreters/influence_interpreter.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* move some documentation of parameters to base class

* delete one comment

* delete one deprecated abstract method

* changing interface

* formatting

* formatting err

* passing mypy

* passing mypy

* passing mypy

* passing mypy

* passing integration test

* passing integration test

* adding a new option to the do-all function

* modifying the callable function to the interface

* update API, fixes

* doc fixes

* add `from_path` and `from_archive` methods

* fix docs, improve logging

* add test

* address @matt-gardner's comments

* fixes to documentation

* update docs

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Evan Pete Walsh <petew@allenai.org>",12,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.equal(hessian_vector_product, expected_answer)', 'torch.equal(flatten_grad, ans)', 'torch.equal(inverse_hvp, ans)', 'len(results) == 3', 'len(result.top_k) == 1']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2450,ArjunSubramonian,arjun.subramonian@gmail.com,2021-04-19 19:14:32-07:00,2526674ff158ecce031f1eff7e4df9e024eb25cf,https://github.com/allenai/allennlp/commit/2526674ff158ecce031f1eff7e4df9e024eb25cf,"Update CONTRIBUTING.md (#5133)

* Update CONTRIBUTING.md

* updated changelog

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-106.us-west-2.compute.internal>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2451,Evan Pete Walsh,petew@allenai.org,2021-04-20 09:17:13-07:00,24ec7db4c0c6e460f14ab1b5a6e56149e73524f2,https://github.com/allenai/allennlp/commit/24ec7db4c0c6e460f14ab1b5a6e56149e73524f2,fix #5132 (#5134),3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2452,Lysandre Debut,lysandre@huggingface.co,2021-04-20 17:07:55-04:00,a84b9b1aa7077419b92dd88446ab73235be1acb7,https://github.com/allenai/allennlp/commit/a84b9b1aa7077419b92dd88446ab73235be1acb7,"Add cached_path support for HF hub (#5052)

* Load from HF hub



ELMO example


Cleanup


ok


Version is necessary


Prettier


env

* Tests

* Remove erroneous addition

* Add dependency to huggingface_hub

* Update changelog

* Address review comments

* Update changelog

* Update allennlp/common/file_utils.py

Co-authored-by: Julien Chaumond <chaumond@gmail.com>

* Style

* Fix style and tests

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Julien Chaumond <chaumond@gmail.com>",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['isinstance(', '(', 'predictor._dataset_reader._token_indexers[']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2453,epwalsh,epwalsh10@gmail.com,2021-04-20 14:44:19-07:00,f732b415f9ab9afad87f736da0768185243b3062,https://github.com/allenai/allennlp/commit/f732b415f9ab9afad87f736da0768185243b3062,Prepare for release v2.3.1,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2454,ArjunSubramonian,arjun.subramonian@gmail.com,2021-04-20 15:34:51-07:00,f877fdc30d18178b88c335fbd92722fb77c42d93,https://github.com/allenai/allennlp/commit/f877fdc30d18178b88c335fbd92722fb77c42d93,"Fairness Metrics (#5093)

* Added three definitions of fairness

* Updated CHANGELOG

* Added DemographicParityWithoutGroundTruth and finished tests

* finished refactoring Independence, Separation, and Sufficiency to accumulate

* added distributed functionality to Independence, Sufficiency, and Separation

* Finished aggregate and distributed functionality for DemographicParityWithoutGroundTruth

* fixed GPU and doc issues

* fixed GPU and doc issues

* fixed GPU and doc issues

* fixed GPU issues

* fixed GPU issues

* added init file

* fixed typo

* minor docstring changes

* minor changes to docstring

* Added simple explanations of fairness metrics to docstrings

* Further vectorized all metric implementations

* Fixed device issue

Co-authored-by: Arjun Subramonian <arjuns@Arjuns-MacBook-Pro.local>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,8,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['expected_kl_divs == pytest.approx(test_kl_divs, abs=1e-3)', 'expected_kl_divs == pytest.approx(test_kl_divs, abs=1e-3)', 'test_kl_divs == {0: np.nan, 1: np.nan}', 'expected_kl_divs == test_kl_divs', 'expected_kl_divs == test_kl_divs', 'test_kl_divs == {0: {0: np.nan, 1: np.nan}, 1: {0: np.nan, 1: np.nan}}', 'len(expected_kl_divs) == len(test_kl_divs)', 'expected_kl_divs[0] == pytest.approx(test_kl_divs[0], abs=1e-3)', 'expected_kl_divs[1] == test_kl_divs[1]', 'len(expected_kl_divs) == len(test_kl_divs)', 'expected_kl_divs[0] == pytest.approx(test_kl_divs[0], abs=1e-3)', 'expected_kl_divs[1] == test_kl_divs[1]', 'len(expected_kl_divs) == len(test_kl_divs)', 'test_kl_divs == {0: {0: np.nan, 1: np.nan}, 1: {0: np.nan, 1: np.nan}}', 'expected_ova_pmi_gaps == test_ova_pmi_gaps', 'expected_ova_pmi_gaps == test_ova_pmi_gaps', 'test_ova_pmi_gaps == {0: [np.nan, np.nan], 1: [np.nan, np.nan]}', 'expected_pairwise_pmi_gaps == test_pairwise_pmi_gaps', 'expected_pairwise_pmi_gaps == test_pairwise_pmi_gaps', 'test_pairwise_pmi_gaps == {', 'expected_ova_pmisq_gaps == test_ova_pmisq_gaps', 'expected_pairwise_pmisq_gaps == test_pairwise_pmisq_gaps']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2455,Evan Pete Walsh,petew@allenai.org,2021-04-22 09:34:20-07:00,7fc5a91ff769870ae99a20003ff1ed43d180272e,https://github.com/allenai/allennlp/commit/7fc5a91ff769870ae99a20003ff1ed43d180272e,"fix cached_path for hub downloads (#5141)

* fix cached_path for hub downloads

* fix test name

* fix type hint

* Update allennlp/common/file_utils.py

Co-authored-by: Lysandre Debut <lysandre@huggingface.co>

Co-authored-by: Lysandre Debut <lysandre@huggingface.co>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['os.path.isfile(path)', 'pathlib.Path(os.path.dirname(path)) == self.TEST_DIR', 'os.path.isfile(path + )', 'meta.etag is not None', 'meta.resource == ', 'os.path.isdir(path)', 'pathlib.Path(os.path.dirname(path)) == self.TEST_DIR', 'os.path.isfile(path + )', 'meta.resource == ']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2456,Dirk Groeneveld,dirkg@allenai.org,2021-04-22 12:11:44-07:00,4e862a54ddd2323c3fb5d30f70d05dcd19b8768b,https://github.com/allenai/allennlp/commit/4e862a54ddd2323c3fb5d30f70d05dcd19b8768b,"T5 (#4969)

* Formatting

* New activation functions

* Makes position embeddings optional in the transformer embeddings

* Adds T5

* Various fixes to make this start up

* Share weights

* Adds one test that passes, and one test that fails

* use min_value_of_dtype in apply_mask

* fixes, add beam search

* encoder fixes

* fix

* fix beam search

* fix tests

* rename to just 'T5'

* fix initialization from pretrained

* add Model, DatasetReader, and Predictor

* remove useless dataset reader

* move high-level peices to allennlp-models

* revert predictor changes

* remove unneeded hidden_size

* remove stray comment

* bool masks

* CHANGELOG

* fix test file name

* revert other change

* revert other change

* Distributed training with gradient accumulation (#5100)

* Fixes distributed training with gradient accumulation

* Fix in case we don't do anything in a batch group

* Test for the problematic condition

* Formatting

* More formatting

* Changelog

* Fix another test

* Fix even more tests

* Fixes one more test

* I can fix these tests all day.

* Add link to gallery and demo in README (#5103)

* Add link to gallery in README

* Update README.md

* try emojis

Is this overkill?

* Adding a metadata field to the basic classifier (#5104)

* Adding metadata parameter to BasicClassifier

* Fix

* Updating the changelog

* reformatting

* updating parameter type

* fixing import

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* additional W&B params (#5114)

* additional W&B params

* add wandb_kwargs

* fix

* fix docs

* Add eval_mode argument to pretrained transformer embedder (#5111)

* Add eval_mode argument to pretrained transformer embedder

* Edit changelog entry

* Lint

* Update allennlp/modules/token_embedders/pretrained_transformer_embedder.py

* Apply suggestions from code review

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Evan Pete Walsh <petew@allenai.org>

* specify 'truncation' to avoid transformers warning (#5120)

* specify 'truncation' to avoid transformers warning

* Update docs

* Remove `stride` param

* Update CHANGELOG.md

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* Predicting with a dataset reader on a multitask model (#5115)

* Create a way to use allennlp predict with a dataset and a multitask model

* Fix type ignoration

* Changelog

* Fix to the predictor

* fix bug with interleaving dataset reader (#5122)

* fix bug with interleaving dataset reader

* more tests

* Update allennlp/data/dataset_readers/interleaving_dataset_reader.py

* Update allennlp/data/dataset_readers/interleaving_dataset_reader.py

* remove jsonpickle from dependencies (#5121)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* Update docstring for basic_classifier (#5124)

* improve error message from Registrable class (#5125)

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>

* Prepare for release v2.3.0

* fix docs CI

* Take the number of runs in the test for distributed metrics (#5127)

* Take the number of runs in the test for distributed metrics

* Changelog

* Add influence functions to interpret module (#4988)

* creating a new functionality  to fields and instances to support outputing instnaces to json files

* creating tests for the new functionality

* fixing docs

* Delete __init__.py

* Delete influence_interpreter.py

* Delete use_if.py

* Delete simple_influence_test.py

* fixing docs

* finishing up SimpleInfluence

* passing lint

* passing format

* making small progress in coding

* Delete fast_influence.py

Submit to the wrong branch

* Delete faiss_utils.py

wrong branch

* Delete gpt2_bug.py

not sure why it's included

* Delete text_class.py

not sure why it's included

* adding test file

* adding testing files

* deleted unwanted files

* deleted unwanted files and rearrange test files

* small bug

* adjust function call to save instance in json

* Update allennlp/interpret/influence_interpreters/influence_interpreter.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/interpret/influence_interpreters/influence_interpreter.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/interpret/influence_interpreters/influence_interpreter.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* move some documentation of parameters to base class

* delete one comment

* delete one deprecated abstract method

* changing interface

* formatting

* formatting err

* passing mypy

* passing mypy

* passing mypy

* passing mypy

* passing integration test

* passing integration test

* adding a new option to the do-all function

* modifying the callable function to the interface

* update API, fixes

* doc fixes

* add `from_path` and `from_archive` methods

* fix docs, improve logging

* add test

* address @matt-gardner's comments

* fixes to documentation

* update docs

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Evan Pete Walsh <petew@allenai.org>

* Update CONTRIBUTING.md (#5133)

* Update CONTRIBUTING.md

* updated changelog

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-106.us-west-2.compute.internal>

* fix #5132 (#5134)

* fix

* Prepare for release v2.3.1

* Fairness Metrics (#5093)

* Added three definitions of fairness

* Updated CHANGELOG

* Added DemographicParityWithoutGroundTruth and finished tests

* finished refactoring Independence, Separation, and Sufficiency to accumulate

* added distributed functionality to Independence, Sufficiency, and Separation

* Finished aggregate and distributed functionality for DemographicParityWithoutGroundTruth

* fixed GPU and doc issues

* fixed GPU and doc issues

* fixed GPU and doc issues

* fixed GPU issues

* fixed GPU issues

* added init file

* fixed typo

* minor docstring changes

* minor changes to docstring

* Added simple explanations of fairness metrics to docstrings

* Further vectorized all metric implementations

* Fixed device issue

Co-authored-by: Arjun Subramonian <arjuns@Arjuns-MacBook-Pro.local>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

* fix cached_path for hub downloads (#5141)

* fix cached_path for hub downloads

* fix test name

* fix type hint

* Update allennlp/common/file_utils.py

Co-authored-by: Lysandre Debut <lysandre@huggingface.co>

Co-authored-by: Lysandre Debut <lysandre@huggingface.co>

* fix

* fix

Co-authored-by: epwalsh <epwalsh10@gmail.com>
Co-authored-by: Evan Pete Walsh <petew@allenai.org>
Co-authored-by: Jacob Morrison <jacob1morrison@gmail.com>
Co-authored-by: Nelson Liu <nelson-liu@users.noreply.github.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Leo Liu <zeyuliu2@uw.edu>
Co-authored-by: ArjunSubramonian <arjun.subramonian@gmail.com>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-106.us-west-2.compute.internal>
Co-authored-by: Arjun Subramonian <arjuns@Arjuns-MacBook-Pro.local>
Co-authored-by: Lysandre Debut <lysandre@huggingface.co>",9,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,0,0,0,0,4,0,1,1,5,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['input_ids.tolist() == [', 'labels.tolist() == [', 'outputs.loss == hf_outputs.loss', '(outputs.logits == hf_outputs.logits).all()', 's1_pred == []', 's1_prob == [0.5645]', 's2_pred == []', 's2_prob == [0.3992]', 'combined_preds == s1_pred + s2_pred', 'combined_probs == s1_prob + s2_prob']",[],[],[],[],"['(scope=)', '(scope=)', '(scope=)', '(scope=)']",[],[''],['parametrize('],"['mark.parametrize(', 'fixture(scope=)', 'fixture(scope=)', 'fixture(scope=)', 'fixture(scope=)']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2457,Evan Pete Walsh,petew@allenai.org,2021-04-22 14:41:14-07:00,6ec64596b38b72a561b2f74648f619b52b77d0ff,https://github.com/allenai/allennlp/commit/6ec64596b38b72a561b2f74648f619b52b77d0ff,allow W&B anon mode (#5110),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2458,Dirk Groeneveld,dirkg@allenai.org,2021-04-22 17:09:31-07:00,7c5cc98a9308cbc65bd5c2e4553c18820c7d786a,https://github.com/allenai/allennlp/commit/7c5cc98a9308cbc65bd5c2e4553c18820c7d786a,"Don't orphan checkpoints when we run out of patience (#5142)

* Don't orphan checkpoints when we run out of patience

* Changelog

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2459,Dirk Groeneveld,dirkg@allenai.org,2021-04-22 17:14:32-07:00,357691546bf65fc464bd0b564749bfa97e6db9aa,https://github.com/allenai/allennlp/commit/357691546bf65fc464bd0b564749bfa97e6db9aa,Prepare for release v2.4.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2460,TomBourgeade,54402915+TomBourgeade@users.noreply.github.com,2021-04-23 19:30:18+02:00,9184fbcb149f90171d9a5d93d4ca754c96642e5a,https://github.com/allenai/allennlp/commit/9184fbcb149f90171d9a5d93d4ca754c96642e5a,"Fixes Backbone / Model MRO inconsistency (#5148)

The ordering of parent classes in Backbone is backwards from Model's, which leads to inconsistent MRO issues if one wants to implement their Backbone by multi-inheriting from an existing Model.",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2461,Akshita Bhagia,akshita23bhagia@gmail.com,2021-04-23 16:22:42-07:00,d11359ed3fae160a37fb354bfabc3d2d719bcfaa,https://github.com/allenai/allennlp/commit/d11359ed3fae160a37fb354bfabc3d2d719bcfaa,make dist_reduce_sum work for tensors (#5147),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['ret_value == 23', '(ret_value == value).all().item()', '(output == desired_values).all().item()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2462,Akshita Bhagia,akshita23bhagia@gmail.com,2021-04-24 16:37:25-07:00,10400e029611b5e7a92f33021b557f93672ab05e,https://github.com/allenai/allennlp/commit/10400e029611b5e7a92f33021b557f93672ab05e,"Run checklist suites in AllenNLP (#5065)

* run checklist suites from command line

* specify output file

* separate task from checklist suite

* qa task

* adding describe, misc updates

* fix docs, TE suite

* update changelog

* bug fix

* adding default tests

* qa defaults

* typing, docs, minor updates

* more updates

* set add_default_tests to True

* remove commented lines

* capitalizing help strings

* does this work

* adding start_method to test

* skipping test

* oops, actually fix

* temp fix to check memory issues

* Skip more memory hungry tests

* fix

* fixing professions

* Update setup.py

Co-authored-by: Pete <petew@allenai.org>

* Update CHANGELOG.md

Co-authored-by: Pete <petew@allenai.org>

* Update allennlp/sanity_checks/task_checklists/task_suite.py

Co-authored-by: Pete <petew@allenai.org>

* formatting functions

Co-authored-by: Evan Pete Walsh <petew@allenai.org>",21,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,2,0,3,0,0,0,0,3,3,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['args.func.__name__ == ', 'args.archive_file == ', 'args.task == ', 'args.output_file == ', 'args.cuda_device == 0', 'len(task_suite.suite.tests) == 1', 'task_suite._fake_arg1 is None', 'task_suite._fake_arg2 is None', 'len(task_suite.suite.tests) == 1', 'task_suite._fake_arg1 == ', 'in task_suite.suite.tests', 'in task_suite.suite.tests', 'in task_suite.suite.tests', 'in task_suite.suite.tests', 'in task_suite.suite.tests', 'not in task_suite.suite.tests', 'perturbed[0] == ', 'perturbed[0] == ']","['(ConfigurationError)', '(NotImplementedError)']",[],"['()', '()', '()']",[],[],[],[],"['skip()', 'skip()', 'skip()']","['mark.skip()', 'mark.skip()', 'mark.skip()']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2463,Dirk Groeneveld,dirkg@allenai.org,2021-04-26 16:02:02-07:00,90915800d645c0e5a17e01e56f1fd4d02c5f4e43,https://github.com/allenai/allennlp/commit/90915800d645c0e5a17e01e56f1fd4d02c5f4e43,"Fixes token type ids for folded sequences (#5149)

* Fixes token type ids for folded sequences

* Changelog

* Save memory on the GitHub test runners

* Tensors have to be on the same device",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['min(indexed[]) == 0', 'max(indexed[]) == 1']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2464,Pete,petew@allenai.org,2021-04-27 12:24:01-07:00,12f5b0f5906f42a8b29aecee3efc22d080d04548,https://github.com/allenai/allennlp/commit/12f5b0f5906f42a8b29aecee3efc22d080d04548,"Run some slow tests on the self-hosted runner (#5161)

* make checklist test run faster

* mark some more tests as GPU

* move t5 download",4,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['pathlib.Path(os.path.dirname(path)) == self.TEST_DIR'],[],[],[],[],[],[],[],[],[],[],[],[]
2465,Akshita Bhagia,akshita23bhagia@gmail.com,2021-04-27 13:08:23-07:00,530dae43bb5e08e3b3fcb6591b1aa2d1e851f27a,https://github.com/allenai/allennlp/commit/530dae43bb5e08e3b3fcb6591b1aa2d1e851f27a,"Simplify metrics (#5154)

* use dist_reduce_sum

* simplify metrics using dist_reduce_sum",14,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2466,Pete,petew@allenai.org,2021-04-27 15:34:10-07:00,c71bb460c20c0a1d2cfb6bad864b1c5726f61a99,https://github.com/allenai/allennlp/commit/c71bb460c20c0a1d2cfb6bad864b1c5726f61a99,"improve err msg for PolynomialDecay LR scheduler (#5143)

* improve err msg for PolynomialDecay LR scheduler

* Update CHANGELOG.md

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2467,Pete,petew@allenai.org,2021-05-02 14:51:42-07:00,a463e0e74f4908950ccdfe35198d13f38de6ae1b,https://github.com/allenai/allennlp/commit/a463e0e74f4908950ccdfe35198d13f38de6ae1b,"Add way of skipping pretrained weights download (#5172)

* add way of skipping pretrained weights download

* clarify docstring

* add link to PR in CHANGELOG",8,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(os.listdir(str(self.TEST_DIR))) == 0', 'len(json_fnames) == 1', '(', 'set(os.listdir(str(self.TEST_DIR))) == set(', 'os.listdir(str(self.TEST_DIR)) == []']",[],[],[],[],[],[],[],[],[],[],[],[],['len(os.listdir(str(self.TEST_DIR))) == 0'],[],[],[],[],[],[],[],[],[],[],[],[]
2468,Pete,petew@allenai.org,2021-05-03 09:51:33-07:00,55efa683e432984bbd1d53154773e06ac0f3e61c,https://github.com/allenai/allennlp/commit/55efa683e432984bbd1d53154773e06ac0f3e61c,"fix dataclasses import (#5169)

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2469,ArjunSubramonian,arjun.subramonian@gmail.com,2021-05-03 10:07:06-07:00,eb2ae30ed049d54f893292ea68dc2c9eeca02af3,https://github.com/allenai/allennlp/commit/eb2ae30ed049d54f893292ea68dc2c9eeca02af3,Update README.md (#5165),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2470,Jennifer Melot,jtmelot@gmail.com,2021-05-03 13:53:48-04:00,01b232fbf04627b558add628461e0afc8192497c,https://github.com/allenai/allennlp/commit/01b232fbf04627b558add628461e0afc8192497c,"Allow google cloud storage locations for cached_path (#5173)

* Allow google cloud storage locations for cached_path

* Update changelog

* Add missing quotes

* Apply suggestions from code review

Co-authored-by: Pete <petew@allenai.org>
Co-authored-by: Pete <epwalsh10@gmail.com>",4,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['_split_gcs_path()', '_split_gcs_path()']",['(ValueError)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2471,Xin Zhang,izhx404@gmail.com,2021-05-04 02:43:50+08:00,b533733a6d4662fe3898406b4dfd1e8887b45400,https://github.com/allenai/allennlp/commit/b533733a6d4662fe3898406b4dfd1e8887b45400,"Refactor span extractors and unify forward. (#5160)

* Refactor span extractors

* add SpanExtractorWithSpanWidthEmbedding

* update changelog

* fix blank lines

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",6,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['extractor.get_output_dim() == 10  # input_dim + span_width_embedding_dim', 'extractor.get_output_dim() == output_dim', 'extractor.get_input_dim() == input_dim', 'list(span_representations.size()) == [2, 3, output_dim]']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2472,Dirk Groeneveld,dirkg@allenai.org,2021-05-03 16:26:35-07:00,3335700cd814b132e2b510395c3d5a3f53cf6ab9,https://github.com/allenai/allennlp/commit/3335700cd814b132e2b510395c3d5a3f53cf6ab9,"Default print first batch (#5175)

* By default, print the first batch

* Changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2473,Akshita Bhagia,akshita23bhagia@gmail.com,2021-05-06 12:42:25-07:00,0bf590df2a8494ec47e9f6460aa0addab7c26161,https://github.com/allenai/allennlp/commit/0bf590df2a8494ec47e9f6460aa0addab7c26161,Update Makefile (#5183),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2474,Pete,petew@allenai.org,2021-05-07 10:21:55-07:00,7a260da9c4ba40d2838db28dc8b1c90197932f7f,https://github.com/allenai/allennlp/commit/7a260da9c4ba40d2838db28dc8b1c90197932f7f,fix cuda_device docs (#5188),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2475,Pete,petew@allenai.org,2021-05-07 12:42:14-07:00,b1b455a218c23eebeed20fb528c3fad5ebe4395a,https://github.com/allenai/allennlp/commit/b1b455a218c23eebeed20fb528c3fad5ebe4395a,"improve contributing guide / PR template (#5185)

* improve contributing guide / PR template

* update coverage config

* update template",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2476,Pete,petew@allenai.org,2021-05-07 13:45:49-07:00,96c3caf9531875855f6580e45bffdc43184aedb2,https://github.com/allenai/allennlp/commit/96c3caf9531875855f6580e45bffdc43184aedb2,fix nltk downloads in install (#5189),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2477,Pete,petew@allenai.org,2021-05-07 14:46:53-07:00,d85c5c3ac158e7d26d43bbf25462717c78d2a28c,https://github.com/allenai/allennlp/commit/d85c5c3ac158e7d26d43bbf25462717c78d2a28c,"Explicitly pass serialization directory and local rank to trainer in train command (#5180)

* fix bug with local_rank

* fix up

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['torch.distributed.get_rank() == 0'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2478,Pete,petew@allenai.org,2021-05-07 16:07:30-07:00,74737373d443bae676c7c872f7724f2a000b7beb,https://github.com/allenai/allennlp/commit/74737373d443bae676c7c872f7724f2a000b7beb,"add diff command (#5109)

* add diff command

* fix docs

* no silly geese

* update CHANGELOG

* move 'load_state_dict' to nn.util

* normalize by size

* handle different checkpoint types

* add integration tests

* add 'scale' and 'threshold' params

* HuggingFace Hub support

* support '_/' as well, add test

* revert some changes

* fix

* Update CHANGELOG.md

* Update codecov.yml

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",8,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(', '(', '(', '(', '(']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2479,ArjunSubramonian,arjun.subramonian@gmail.com,2021-05-11 10:44:41-07:00,d9b19b69ad82b30cc5115ebfe269c7d214ef6130,https://github.com/allenai/allennlp/commit/d9b19b69ad82b30cc5115ebfe269c7d214ef6130,"Bias Mitigation and Direction Methods (#5130)

* added linear and hard debiasers

* worked on documentation

* committing changes before branch switch

* committing changes before switching branch

* finished bias direction, linear and hard debiasers, need to write tests

* finished bias direction test

* Commiting changes before switching branch

* finished hard and linear debiasers

* finished OSCaR

* bias mitigators tests and bias metrics remaining

* added bias mitigator tests

* added bias mitigator tests

* finished tests for bias mitigation methods

* fixed gpu issues

* fixed gpu issues

* fixed gpu issues

* resolve issue with count_nonzero not being differentiable

* added more references

* responded to Akshita's comments

Co-authored-by: Arjun Subramonian <arjuns@Arjuns-MacBook-Pro.local>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-106.us-west-2.compute.internal>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-108.us-west-2.compute.internal>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-1-108.us-west-2.compute.internal>
Co-authored-by: Michael Schmitz <MichaelS@allenai.org>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,43,24,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['k[0].item() == pytest.approx(k[1].item())', 'seed_embeddings.grad is None', 'seed_embeddings.grad is None', 'seed_embeddings.grad is not None', 'k[0].item() == pytest.approx(k[1].item())', 'seed_embeddings1.grad is None', 'seed_embeddings2.grad is None', 'seed_embeddings1.grad is None', 'seed_embeddings2.grad is None', 'seed_embeddings1.grad is not None', 'seed_embeddings2.grad is not None', 'allclose(expected_bias_direction, test_bias_direction, equal_nan=True)', 'seed_embeddings1.grad is None', 'seed_embeddings2.grad is None', 'seed_embeddings1.grad is None', 'seed_embeddings2.grad is None', 'seed_embeddings1.grad is not None', 'seed_embeddings2.grad is not None', '(', 'seed_embeddings1.grad is None', 'seed_embeddings2.grad is None', 'allclose(', 'self.bias_direction.grad is None', 'self.evaluation_embeddings.grad is None', 'self.bias_direction.grad is not None', 'self.evaluation_embeddings.grad is not None', 'allclose(', 'self.bias_direction.grad is None', 'self.evaluation_embeddings.grad is None', 'self.equalize_embeddings1.grad is None', 'self.equalize_embeddings2.grad is None', 'self.bias_direction.grad is not None', 'self.evaluation_embeddings.grad is not None', 'self.equalize_embeddings1.grad is not None', 'self.equalize_embeddings2.grad is not None', 'allclose(', 'allclose(', 'self.bias_direction1.grad is None', 'self.bias_direction2.grad is None', 'self.evaluation_embeddings.grad is None', 'self.bias_direction1.grad is not None', 'self.bias_direction2.grad is not None', 'self.evaluation_embeddings.grad is not None']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],"['import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
2480,ArjunSubramonian,arjun.subramonian@gmail.com,2021-05-12 18:06:36-07:00,fd5c9e4ce521dbb3a73d5bedd8d5666cfcf0e58d,https://github.com/allenai/allennlp/commit/fd5c9e4ce521dbb3a73d5bedd8d5666cfcf0e58d,"Bias Metrics (#5139)

* finished WEAT

* finished bias metrics

* updated CHANGELOG

* fixed gpu issu

* fixed gpu issue

* expanded NLI to include more NLI scores and work in batched and distributed settings

* removed evaluate bias mitigation command from this PR

Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-108.us-west-2.compute.internal>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-1-108.us-west-2.compute.internal>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-106.us-west-2.compute.internal>",6,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,12,0,0,0,0,0,0,0,0,0,0,1,8,2,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['test_weat_score.item() == pytest.approx(1.872, rel=1e-4)', 'test_ect_score.item() == pytest.approx(0.800, rel=1e-4)', 'nli.get_metric(reset=True) == pytest.approx(expected_scores)', 'all([v == 0.0 for k, v in nli.get_metric().items()])', 'expected_ova_pmi_gaps == test_ova_pmi_gaps', 'expected_ova_pmi_gaps == test_ova_pmi_gaps', 'test_ova_pmi_gaps == {0: [np.nan, np.nan], 1: [np.nan, np.nan]}', 'expected_pairwise_pmi_gaps == test_pairwise_pmi_gaps', 'expected_pairwise_pmi_gaps == test_pairwise_pmi_gaps', 'test_pairwise_pmi_gaps == {', 'expected_ova_pmisq_gaps == test_ova_pmisq_gaps', 'expected_pairwise_pmisq_gaps == test_pairwise_pmisq_gaps']","['(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],['import pytest'],"['expected_ova_pmi_gaps == test_ova_pmi_gaps', 'expected_ova_pmi_gaps == test_ova_pmi_gaps', 'test_ova_pmi_gaps == {0: [np.nan, np.nan], 1: [np.nan, np.nan]}', 'expected_pairwise_pmi_gaps == test_pairwise_pmi_gaps', 'expected_pairwise_pmi_gaps == test_pairwise_pmi_gaps', 'test_pairwise_pmi_gaps == {', 'expected_ova_pmisq_gaps == test_ova_pmisq_gaps', 'expected_pairwise_pmisq_gaps == test_pairwise_pmisq_gaps']","['(ConfigurationError)', '(ConfigurationError)']",[],[],[],[],[],[],[],[],[],[],[]
2481,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-05-13 17:20:21-07:00,db8ff675caf360333cca8af8701168c02b2cf998,https://github.com/allenai/allennlp/commit/db8ff675caf360333cca8af8701168c02b2cf998,"Update transformers requirement from <4.6,>=4.1 to >=4.1,<4.7 (#5199)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v4.1.0...v4.6.0)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2482,Akshita Bhagia,akshita23bhagia@gmail.com,2021-05-14 13:50:34-07:00,cccb35de94b8b678f496322f5e22d79dd0450174,https://github.com/allenai/allennlp/commit/cccb35de94b8b678f496322f5e22d79dd0450174,"Rename sanity_checks to confidence_checks (#5201)

* renaming sanity_checks to confidence_checks

* update changelog

* docs fix

* clean up",25,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['(ConfidenceCheckError)', '(ConfidenceCheckError)']",[],[],[],[],[],[],[],[],[],[],[],[],"['(SanityCheckError)', '(SanityCheckError)']",[],[],[],[],[],[],[],[],[],[],[]
2483,Pete,petew@allenai.org,2021-05-17 12:25:42-07:00,cf113d705b9054d329c67cf9bb29cbc3f191015d,https://github.com/allenai/allennlp/commit/cf113d705b9054d329c67cf9bb29cbc3f191015d,"Changes and improvements to how we initialize transformer modules from pretrained models (#5200)

* updates

* rename 'load_state_dict' -> 'read_state_dict'

* fix TransformerStack

* more fixes

* fix embeddings

* fix toolkit tests

* fix self attention

* fix bimodal encoder tests

* fix more tests

* fix T5!

* fixes

* fix backbone

* fix

* fixes

* fix

* doc fixes

* name changes

* patch models branch temporarily

* update CHANGELOG

* change default dist loading strategy to 'MEM_EFFICIENT' for T5

* fix distilbert test

* always use memory efficient distributed loading strategy

* Update .github/workflows/ci.yml

Co-authored-by: Pete <petew@allenai.org>

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",31,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,2,0,0,0,21,0,10,10,31,0,0,4,81,2,0,3,0,0,0,10,13,13,0,0,1,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['activation_layer.dense.in_features == params_dict[]', 'activation_layer.dense.out_features == params_dict[]', 'biattention.num_attention_heads == params_dict[]', 'biattention.attention_head_size == int(', '(', 'biattention.query1.in_features == params_dict[]', 'biattention.key1.in_features == params_dict[]', 'biattention.value1.in_features == params_dict[]', 'biattention.dropout1.p == params_dict[]', 'biattention.query2.in_features == params_dict[]', 'biattention.key2.in_features == params_dict[]', 'biattention.value2.in_features == params_dict[]', 'biattention.dropout2.p == params_dict[]', 'len(modules[]', 'len(modules[]', 'self_attention.num_attention_heads == params_dict[]', 'self_attention.attention_head_size == int(', '(', 'self_attention.query.in_features == params_dict[]', 'self_attention.key.in_features == params_dict[]', 'self_attention.value.in_features == params_dict[]', 'self_attention.dropout.p == params_dict[]', 'torch.allclose(output, hf_output)', 'embeddings.word_embeddings.num_embeddings == params_dict[]', 'embeddings.word_embeddings.embedding_dim == params_dict[]', 'embeddings.word_embeddings.padding_idx == params_dict[]', 'embeddings.position_embeddings.num_embeddings == params_dict[]', 'embeddings.position_embeddings.embedding_dim == params_dict[]', 'embeddings.token_type_embeddings.num_embeddings == params_dict[]', 'embeddings.token_type_embeddings.embedding_dim == params_dict[]', 'transformer_embeddings.layer_norm.normalized_shape[0] == params_dict[]', 'transformer_embeddings.dropout.p == params_dict[]', 'output.shape[-1] == 7', 'len(module.embeddings) == 2', 'torch.allclose(output, hf_output)', '(', '(', '(', 'image_embeddings.dropout.p == image_params_dict[]', 'attention_layer.self.num_attention_heads == attention_params[]', 'attention_layer.self.attention_head_size == int(', '(', 'attention_layer.self.query.in_features == attention_params[]', 'attention_layer.self.key.in_features == attention_params[]', 'attention_layer.self.value.in_features == attention_params[]', 'attention_layer.self.dropout.p == attention_params[]', 'attention_layer.output.dense.in_features == attention_params[]', 'attention_layer.output.dense.out_features == attention_params[]', 'attention_layer.output.layer_norm.normalized_shape[0] == attention_params[]', 'attention_layer.output.dropout.p == attention_params[]', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output, atol=1e-04)', '(', 'transformer_layer.attention.self.attention_head_size == int(', '(', 'transformer_layer.attention.self.query.in_features == layer_params[]', 'transformer_layer.attention.self.key.in_features == layer_params[]', 'transformer_layer.attention.self.value.in_features == layer_params[]', 'transformer_layer.attention.self.dropout.p == layer_params[]', 'transformer_layer.attention.output.dense.in_features == layer_params[]', 'transformer_layer.attention.output.dense.out_features == layer_params[]', '(', 'transformer_layer.attention.output.dropout.p == layer_params[]', 'transformer_layer.intermediate.dense.in_features == layer_params[]', 'transformer_layer.intermediate.dense.out_features == layer_params[]', 'transformer_layer.output.dense.in_features == layer_params[]', 'transformer_layer.output.dense.out_features == layer_params[]', 'transformer_layer.output.layer_norm.normalized_shape[0] == layer_params[]', 'transformer_layer.output.dropout.p == layer_params[]', 'hasattr(transformer_layer, )', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output, atol=1e-04)', 'set(state_dict_new.keys()) == set(', 'len(modules[]', 'torch.allclose(from_layer_output[0], output[0])', 'hasattr(modules[)', 'torch.allclose(output[0], hf_output[0])', 'not missing_keys', 'not unexpected_keys', 'set(missing_keys) == set(_missing_keys)', 'set(unexpected_keys) == set(_unexpected_keys)']","['(AssertionError)', '(AssertionError)']",[],[],[],"['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']",[],"['', '', '(, get_modules())', '(, get_attention_modules())', '', '(, get_layer_modules())', '', '(, [_load_pretrained])', '(])', '(, [_dist_load_ok, _dist_load_with_errors])']","['parametrize(', 'parametrize(', 'parametrize(, get_modules())', 'parametrize(, get_attention_modules())', 'parametrize(', 'parametrize(, get_layer_modules())', 'parametrize(', 'parametrize(, [_load_pretrained])', 'parametrize(])', 'parametrize(, [_dist_load_ok, _dist_load_with_errors])']","['fixture', 'fixture', 'fixture', 'fixture', 'fixture', 'fixture', 'fixture', 'fixture', 'fixture', 'fixture', 'fixture', 'fixture', 'mark.parametrize(', 'fixture', 'fixture', 'fixture', 'mark.parametrize(', 'mark.parametrize(, get_modules())', 'fixture', 'fixture', 'fixture', 'fixture', 'mark.parametrize(, get_attention_modules())', 'mark.parametrize(', 'fixture', 'mark.parametrize(, get_layer_modules())', 'mark.parametrize(', 'mark.parametrize(, [_load_pretrained])', 'fixture', 'mark.parametrize(])', 'mark.parametrize(, [_dist_load_ok, _dist_load_with_errors])']",[],[],"['import pytest', 'import pytest', 'import pytest', 'import pytest']","['activation_layer.dense.in_features == self.params_dict[]', 'activation_layer.dense.out_features == self.params_dict[]', 'biattention.num_attention_heads == self.params_dict[]', 'biattention.attention_head_size == int(', '(', 'biattention.query1.in_features == self.params_dict[]', 'biattention.key1.in_features == self.params_dict[]', 'biattention.value1.in_features == self.params_dict[]', 'biattention.dropout1.p == self.params_dict[]', 'biattention.query2.in_features == self.params_dict[]', 'biattention.key2.in_features == self.params_dict[]', 'biattention.value2.in_features == self.params_dict[]', 'biattention.dropout2.p == self.params_dict[]', 'len(modules[]', 'len(modules[]', 'self.self_attention.num_attention_heads == self.params_dict[]', 'self.self_attention.attention_head_size == int(', '(', 'self.self_attention.query.in_features == self.params_dict[]', 'self.self_attention.key.in_features == self.params_dict[]', 'self.self_attention.value.in_features == self.params_dict[]', 'self.self_attention.dropout.p == self.params_dict[]', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output)', '(', '(', '(', '(', '(', '(', '(', '(', 'self.transformer_embeddings.dropout.p == self.params_dict[]', 'output.shape[-1] == 7', 'len(module.embeddings) == 2', 'len(missing) == 0', 'torch.allclose(output, hf_output)', '(', '(', '(', 'self.img_embeddings.dropout.p == self.params_dict[]', 'attention_layer.self.num_attention_heads == self.params_dict[]', 'attention_layer.self.attention_head_size == int(', '(', 'attention_layer.self.query.in_features == self.params_dict[]', 'attention_layer.self.key.in_features == self.params_dict[]', 'attention_layer.self.value.in_features == self.params_dict[]', 'attention_layer.self.dropout.p == self.params_dict[]', 'attention_layer.output.dense.in_features == self.params_dict[]', 'attention_layer.output.dense.out_features == self.params_dict[]', '(', 'attention_layer.output.dropout.p == self.params_dict[]', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output, atol=1e-04)', '(', 'transformer_layer.attention.self.attention_head_size == int(', '(', 'transformer_layer.attention.self.query.in_features == self.params_dict[]', 'transformer_layer.attention.self.key.in_features == self.params_dict[]', 'transformer_layer.attention.self.value.in_features == self.params_dict[]', 'transformer_layer.attention.self.dropout.p == self.params_dict[]', '(', '(', '(', 'transformer_layer.attention.output.dropout.p == self.params_dict[]', 'transformer_layer.intermediate.dense.in_features == self.params_dict[]', '(', 'transformer_layer.output.dense.in_features == self.params_dict[]', 'transformer_layer.output.dense.out_features == self.params_dict[]', '(', 'transformer_layer.output.dropout.p == self.params_dict[]', 'hasattr(transformer_layer, )', 'hasattr(transformer_layer_new, )', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output, atol=1e-04)', 'len(modules[]', 'torch.allclose(layer_output[0], params_output[0])', 'hasattr(modules[)', 'hasattr(new_modules[)', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(output, hf_output)']","['(AssertionError)', '(AssertionError)']",[],"['()', '()', '()']",[],[],[],"['(, get_modules(PARAMS_DICT).items())', '', '', '(, get_modules(PARAMS_DICT).items())', '', '', '(, get_layer_modules(LAYER_PARAMS_DICT).items())', '', '(, get_modules(PARAMS_DICT).items())', '']","['skip()', 'parametrize(, get_modules(PARAMS_DICT).items())', 'skip()', 'parametrize(', 'parametrize(', 'parametrize(, get_modules(PARAMS_DICT).items())', 'parametrize(', 'parametrize(', 'parametrize(, get_layer_modules(LAYER_PARAMS_DICT).items())', 'parametrize(', 'skip()', 'parametrize(, get_modules(PARAMS_DICT).items())', 'parametrize(']","['mark.skip()', 'mark.parametrize(, get_modules(PARAMS_DICT).items())', 'mark.skip()', 'mark.parametrize(', 'mark.parametrize(', 'mark.parametrize(, get_modules(PARAMS_DICT).items())', 'mark.parametrize(', 'mark.parametrize(', 'mark.parametrize(, get_layer_modules(LAYER_PARAMS_DICT).items())', 'mark.parametrize(', 'mark.skip()', 'mark.parametrize(, get_modules(PARAMS_DICT).items())', 'mark.parametrize(']",[],[],['import pytest']
2484,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2021-05-17 17:26:39-04:00,79d16af1f9d719934a1aa4a3506482c05e24aae6,https://github.com/allenai/allennlp/commit/79d16af1f9d719934a1aa4a3506482c05e24aae6,"Add a `min_steps` parameter to `BeamSearch` (#5207)

* Implementing minimum number of decoding steps

* Adding unit tests

* Reformatting

* Adding entry to changelog

* Adding end token comment

* Adding start token comment

* Changing param to optional

Co-authored-by: Pete <petew@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2485,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2021-05-18 12:28:51-04:00,3585c9fe77d8ff2af561c96a996e175f605de0f4,https://github.com/allenai/allennlp/commit/3585c9fe77d8ff2af561c96a996e175f605de0f4,"Implementing abstraction to score final sequences in `BeamSearch` (#5208)

* Implementing FinalSequenceScorer in BeamSearch

* Including the end token in the normalization

* Reformating

* Apply suggestions from code review

Co-authored-by: Pete <epwalsh10@gmail.com>

* Sorting the sequences by the final scores

Co-authored-by: Pete <petew@allenai.org>
Co-authored-by: Pete <epwalsh10@gmail.com>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2486,ArjunSubramonian,arjun.subramonian@gmail.com,2021-05-19 12:18:59-07:00,bd941c6f6280d9ed0a3b88fe38f73f9008a730aa,https://github.com/allenai/allennlp/commit/bd941c6f6280d9ed0a3b88fe38f73f9008a730aa,"added shuffle disable option in BucketBatchSampler (#5212)

* added shuffle disable option in BucketBatchSampler

* Update allennlp/data/samplers/bucket_batch_sampler.py

Co-authored-by: Pete <petew@allenai.org>

Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-106.us-west-2.compute.internal>
Co-authored-by: Pete <petew@allenai.org>",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['group == expected_groups[idx]'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2487,Pete,petew@allenai.org,2021-05-19 13:34:00-07:00,d2840cba86d2898d38c351b4b8815b9d195a8d7a,https://github.com/allenai/allennlp/commit/d2840cba86d2898d38c351b4b8815b9d195a8d7a,"save meta data with model archives (#5209)

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",7,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['archive.meta is not None', 'archive.meta.version == VERSION']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2488,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-05-26 03:07:58+05:18,3e1b553b9611c145d8dbbe5d015f08af8d7517b4,https://github.com/allenai/allennlp/commit/3e1b553b9611c145d8dbbe5d015f08af8d7517b4,"Bump black from 20.8b1 to 21.5b1 (#5195)

* Bump black from 20.8b1 to 21.5b1

Bumps [black](https://github.com/psf/black) from 20.8b1 to 21.5b1.
- [Release notes](https://github.com/psf/black/releases)
- [Changelog](https://github.com/psf/black/blob/main/CHANGES.md)
- [Commits](https://github.com/psf/black/commits)

Signed-off-by: dependabot[bot] <support@github.com>

* formatting changes

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2489,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-05-26 04:26:59+05:18,59df2ad3a803f85d35f1c63c8cbf6230a972fcee,https://github.com/allenai/allennlp/commit/59df2ad3a803f85d35f1c63c8cbf6230a972fcee,"Update nr-interface requirement from <0.0.4 to <0.0.6 (#5213)

Updates the requirements on [nr-interface](https://git.niklasrosenstein.com/NiklasRosenstein/nr) to permit the latest version.

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2490,Pete,petew@allenai.org,2021-05-25 21:58:34-07:00,2d8f39045acc805d5a230a6034a2400ed6ae2b88,https://github.com/allenai/allennlp/commit/2d8f39045acc805d5a230a6034a2400ed6ae2b88,"Fix W&B callback for distributed training (#5223)

* fix wandb callback for distributed training

* fix

* close out

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2491,Pete,petew@allenai.org,2021-05-26 12:01:39-07:00,d662977251bb8cb297a88959d88b1b883441c70a,https://github.com/allenai/allennlp/commit/d662977251bb8cb297a88959d88b1b883441c70a,"cancel redundant GH Actions workflows (#5226)

* cancel redundant GH Actions workflows

* trigger CI

* fix job conditions

* run docker jobs on any self-hosted",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2492,Pete,petew@allenai.org,2021-05-27 10:06:55-07:00,12155c40540d77b3d7aea5ff93475c5c4039d9e1,https://github.com/allenai/allennlp/commit/12155c40540d77b3d7aea5ff93475c5c4039d9e1,"fix race condition when extracting files with cached_path (#5227)

* fix race condition when extracting files with cached_path

* add warning when directory already exists",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2493,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-05-27 10:40:39-07:00,d97ed4016ad54012ecc3a50788892fa62c040972,https://github.com/allenai/allennlp/commit/d97ed4016ad54012ecc3a50788892fa62c040972,"Bump checklist from 0.0.10 to 0.0.11 (#5222)

Bumps [checklist](https://github.com/marcotcr/checklist) from 0.0.10 to 0.0.11.
- [Release notes](https://github.com/marcotcr/checklist/releases)
- [Commits](https://github.com/marcotcr/checklist/commits)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2494,wlhgtc,hgtcwl@foxmail.com,2021-05-28 02:37:10+08:00,babc450d8a03f6e2c92715d2d4e58a49a05f4b56,https://github.com/allenai/allennlp/commit/babc450d8a03f6e2c92715d2d4e58a49a05f4b56,"Added `DataCollator` for dynamic operations for each batch. (#5221)

* ADD: add from_pretrained method for vocab

* MOD: test format

* MOD: format file

* MOD: update changelog

* MOD: fix bug

* MOD: fix bug

* MOD: fix typo

* MOD: make the mothod in class

* MOD: fix bug

* MOD: change to instance method

* MOD: fix typo

* MOD: fix bug

* MOD: change oov to avoid bug

* Update allennlp/data/vocabulary.py

* Update allennlp/data/vocabulary.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/vocabulary.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update allennlp/data/vocabulary.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* MOD: fix formate

* MOD: add test case

* Update CHANGELOG.md

* MOD: fix worker info bug

* ADD: update changelog

* MOD: fix format

* Update allennlp/data/data_loaders/multitask_data_loader.py

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* Update CHANGELOG.md

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>

* MOD: add demo code

* MOD: align code

* MOD: fix bug

* MOD: fix bug

* MOD: fix bug

* MOD: formate code

* Update allennlp/data/data_loaders/data_collator.py

Co-authored-by: Pete <epwalsh10@gmail.com>

* fix error

* MOD: add test code

* mod: change tokenizer

* mod: fix tokenizer

* MOD: fix bug

* MOD: fix bug

* MOD: fix bug

* Update allennlp/data/data_loaders/data_collator.py

Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>

* MOD: update changelog

* MOD: update change log

* Update allennlp/data/data_loaders/data_collator.py

We should be using underscores for everything.

* Formatting

Co-authored-by: Evan Pete Walsh <epwalsh10@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>
Co-authored-by: Dirk Groeneveld <groeneveld@gmail.com>",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.where(mlm_labels != -100, mlm_labels, mlm_inputs).tolist() == norm_inputs.tolist()']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2495,Jacob Morrison,jacob1morrison@gmail.com,2021-05-28 15:36:56-07:00,3d5799d8784592d648fa2531bd26bb24e5831b0c,https://github.com/allenai/allennlp/commit/3d5799d8784592d648fa2531bd26bb24e5831b0c,"Roll backbone (#5229)

Adding support for inputs to the backbone with more than 3 dimensions",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2496,Dirk Groeneveld,dirkg@allenai.org,2021-05-28 19:18:27-07:00,c5bff8ba0d835eb03931f10f4f427ffe936cf796,https://github.com/allenai/allennlp/commit/c5bff8ba0d835eb03931f10f4f427ffe936cf796,"Fixes Checkpointing (#5220)

* Removes unused variable

* Formatting

* Make sure we always restore the model's weights properly

* Give TrainerCallbacks the ability to save and load state dicts

* Give MovingAverage the ability to save and load state dicts

* Do not set gradients to None

* Typo

* Remove unused variable

* Typo

* Entirely new checkpointing code

* Formatting

* Make mypy happy

lol

* Makes the no-op trainer work with the new checkpointer

* Mark epochs as completed when they're skipped

* Changelog

* Fixes how we get the best weights after a training run

* Mypy is annoying

* Callback fixes

* Fix the no op trainer

* Simplify

* Assorted checkpointer fixes

* Mypy is now happy

* Fixed all the tests except for one

* Removed unused variable

* Fix trainer restore logic

* Fix test for trainer restore logic

* Check the Checkpointing branch of the models repo

* Help mypy along

* Fixed finalizing logic

* More mypy stuff

* Update allennlp/training/checkpointer.py

Co-authored-by: Pete <petew@allenai.org>

* Make weaker claims

Co-authored-by: Pete <petew@allenai.org>",21,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,0,0,0,0,0,0,1,1,1,0,0,0,23,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not any( in x for x in files)', 'not any( in x for x in files)', 'trainer._total_batches_completed == 0', 'trainer._total_batches_completed == num_epochs * 2', 'trainer._total_batches_completed == 0', 'trainer._total_batches_completed == num_epochs * 3', 'trainer._total_batches_completed == 0', 'trainer._total_batches_completed == num_epochs * batches_per_epoch', 'trainer._total_batches_completed == 0', 'trainer._total_batches_completed == num_epochs * batches_per_epoch', 'trainer._total_batches_completed == 0', 'trainer._total_batches_completed == num_epochs * batches_per_epoch', 'new_trainer._start_after_epochs_completed == 1', 'new_trainer._start_after_epochs_completed == 1', 'new_trainer._start_after_epochs_completed == 2', 'sorted(epochs) == expected', 'sorted(epochs) == expected', 'sorted(epochs) == expected', 'sorted(epochs) == expected', 'checkpoints == expected', 'original_metrics[]']",[],[],[],[],[],[],"['(, range(20))']","['parametrize(, range(20))']","['mark.parametrize(, range(20))']",[],[],[],"['not in files', 'not in files', 'trainer._batch_num_total == 0', 'trainer._batch_num_total == num_epochs * 2', 'trainer._batch_num_total == 0', 'trainer._batch_num_total == num_epochs * 3', 'trainer._batch_num_total == 0', 'trainer._batch_num_total == num_epochs * batches_per_epoch', 'trainer._batch_num_total == 0', 'trainer._batch_num_total == num_epochs * batches_per_epoch', 'trainer._batch_num_total == 0', 'trainer._batch_num_total == num_epochs * batches_per_epoch', 'epoch == 1', 'epoch == 1', 'epoch == 4', 'epoch == 2', 'sorted(epochs) == [2, 3, 4]', 'sorted(epochs) == [1, 3, 4, 5]', 'len(epochs) == 4', 'epochs[3] == ', 'in epochs[0]', 'epoch == 2', 'restore_trainer._batch_num_total == 2']",[],[],[],[],[],[],[],[],[],[],[],[]
2497,Dirk Groeneveld,dirkg@allenai.org,2021-05-28 19:51:16-07:00,98dae7f4a3b18a1521fdec8a10197d259cdf785b,https://github.com/allenai/allennlp/commit/98dae7f4a3b18a1521fdec8a10197d259cdf785b,Emergency fix. I forgot to take this out.,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2498,Daniel Deutsch,danieldeutsch@users.noreply.github.com,2021-06-01 13:42:05-04:00,c014232005c1817917015ebecb45eca7f244ce7c,https://github.com/allenai/allennlp/commit/c014232005c1817917015ebecb45eca7f244ce7c,"Add constraints to beam search (#5216)

* Implementing blocking repeated ngrams

* Adding comment

* Adding unit tests for the end to end beam search

* Renaming class

* Adding comment about  function

* Simplifying indexing to variable

* Refactoring the state copying into the  class

* Reformatting

* Editing changelog

* fix line too long

* comments

* doc updates

Co-authored-by: Pete <petew@allenai.org>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",4,False,True,False,False,False,True,True,True,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(state) == batch_size', 'len(beam_states) == 1', 'len(beam_state.keys()) == 2', 'len(beam_state[]) == 0', 'len(beam_state[]) == 0', 'len(disallowed_locations) == 4', '[0, 1, 4] in disallowed_locations', '[1, 1, 0] in disallowed_locations', '[1, 1, 1] in disallowed_locations', '[1, 1, 2] in disallowed_locations', 'updated_state == expected_state']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2499,John Giorgi,johnmgiorgi@gmail.com,2021-06-01 13:59:41-04:00,39d7e5ae06551fe371d3e16f4d93162e55ec5dcc,https://github.com/allenai/allennlp/commit/39d7e5ae06551fe371d3e16f4d93162e55ec5dcc,"Make BeamSearch Registrable (#5231)

* Make BeamSearch Registrable

* Update changelog

* Remove unused import

* Update CHANGELOG.md

Co-authored-by: Pete <petew@allenai.org>
Co-authored-by: Pete <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2500,epwalsh,epwalsh10@gmail.com,2021-06-02 11:46:43-07:00,5b111d082fff46c757efc0f8f5dcd01c7729762a,https://github.com/allenai/allennlp/commit/5b111d082fff46c757efc0f8f5dcd01c7729762a,tick version for nightly release,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2501,Akshita Bhagia,akshita23bhagia@gmail.com,2021-06-02 14:24:57-07:00,b0aa1d45b6f103d26529629195929fd9591b3b31,https://github.com/allenai/allennlp/commit/b0aa1d45b6f103d26529629195929fd9591b3b31,"Generalize T5 modules (#5166)

* initial commit

* general self attn

* fixing bugs, adding tests, adding docs

* updating other modules

* refactor

* bug fix

* update changelog

* fix shape

* fix format

* address feedback

* small doc fix

* Update allennlp/modules/transformer/transformer_stack.py

Co-authored-by: Pete <petew@allenai.org>

* remove old file

Co-authored-by: epwalsh <epwalsh10@gmail.com>
Co-authored-by: Pete <petew@allenai.org>",13,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,0,0,0,0,3,0,1,1,4,0,0,1,7,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['self_attention.dropout == params_dict[]', 't5_attention.num_attention_heads == params_dict[]', 't5_attention.attention_head_size == params_dict[]', '(', 't5_attention.query.in_features == params_dict[]', 't5_attention.key.in_features == params_dict[]', 't5_attention.value.in_features == params_dict[]', 't5_attention.output.in_features == params_dict[]', 't5_attention.dropout == params_dict[]', 'torch.allclose(hs, hf_output[0])', 'torch.allclose(output, hf_output)', 'attention_layer.self.dropout == attention_params[]', 'torch.allclose(output.hidden_states, hf_output[0])', 'transformer_layer.attention.self.dropout == layer_params[]', 'torch.allclose(output.hidden_states, hf_output[0])', 'torch.allclose(from_layer_output.final_hidden_states, output.final_hidden_states)', 'torch.allclose(output.final_hidden_states, hf_output[0])']",[],[],[],[],"['', '', '']",[],[''],['parametrize('],"['fixture', 'fixture', 'fixture', 'mark.parametrize(']",[],[],['import pytest'],"['self_attention.dropout.p == params_dict[]', 'attention_layer.self.dropout.p == attention_params[]', 'torch.allclose(output[0], hf_output[0])', 'transformer_layer.attention.self.dropout.p == layer_params[]', 'torch.allclose(output[0], hf_output[0])', 'torch.allclose(from_layer_output[0], output[0])', 'torch.allclose(output[0], hf_output[0])']",[],[],[],[],[],[],[],[],[],[],[],[]
2502,Kuo Liao,MagiaSN@yeah.net,2021-06-03 05:44:43+08:00,620679735958131a3b13b68473a04fda6b78b879,https://github.com/allenai/allennlp/commit/620679735958131a3b13b68473a04fda6b78b879,"Fix tqdm logging into multiple files with allennlp-optuna (#5235)

* Fix tqdm logging into multiple files with allennlp-optuna

* Update changelog

* Add unittest for resetting tqdm logger handlers

Co-authored-by: Pete <petew@allenai.org>",3,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(f.readlines()) == 0', 'len(f.readlines()) == 2']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2503,Akshita Bhagia,akshita23bhagia@gmail.com,2021-06-02 15:01:59-07:00,aa52a9a06532b389c05e7fcb004dc91fbc2c0ac9,https://github.com/allenai/allennlp/commit/aa52a9a06532b389c05e7fcb004dc91fbc2c0ac9,"Checklist fixes (#5239)

* bug fix

* common lexicons

* update changelog

* Update CHANGELOG.md",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2504,ArjunSubramonian,arjun.subramonian@gmail.com,2021-06-02 16:14:01-07:00,b92fd9a7cd3b9c295f94bf7df6edd228172e91a9,https://github.com/allenai/allennlp/commit/b92fd9a7cd3b9c295f94bf7df6edd228172e91a9,"Contextualized bias mitigation (#5176)

* added linear and hard debiasers

* worked on documentation

* committing changes before branch switch

* committing changes before switching branch

* finished bias direction, linear and hard debiasers, need to write tests

* finished bias direction test

* Commiting changes before switching branch

* finished hard and linear debiasers

* finished OSCaR

* bias mitigators tests and bias metrics remaining

* added bias mitigator tests

* added bias mitigator tests

* finished tests for bias mitigation methods

* fixed gpu issues

* fixed gpu issues

* fixed gpu issues

* resolve issue with count_nonzero not being differentiable

* added more references

* fairness during finetuning

* finished bias mitigator wrapper

* added reference

* updated CHANGELOG and fixed minor docs issues

* move id tensors to embedding device

* fixed to use predetermined bias direction

* fixed minor doc errors

* snli reader registration issue

* fixed _pretrained from params issue

* fixed device issues

* evaluate bias mitigation initial commit

* finished evaluate bias mitigation

* handles multiline prediction files

* fixed minor bugs

* fixed minor bugs

* improved prediction diff JSON format

* forgot to resolve a conflict

* Refactored evaluate bias mitigation to use NLI metric

* Added SNLIPredictionsDiff class

* ensured dataloader is same for bias mitigated and baseline models

* finished evaluate bias mitigation

* Update CHANGELOG.md

* Replaced local data files with github raw content links

* Update allennlp/fairness/bias_mitigator_applicator.py

Co-authored-by: Pete <petew@allenai.org>

* deleted evaluate_bias_mitigation from git tracking

* removed evaluate-bias-mitigation instances from rest of repo

* addressed Akshita's comments

* moved bias mitigator applicator test to allennlp-models

* removed unnecessary files

Co-authored-by: Arjun Subramonian <arjuns@Arjuns-MacBook-Pro.local>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-106.us-west-2.compute.internal>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-0-108.us-west-2.compute.internal>
Co-authored-by: Arjun Subramonian <arjuns@ip-192-168-1-108.us-west-2.compute.internal>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Pete <petew@allenai.org>",12,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.equal(', 'torch.equal(', 'torch.equal(']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2505,epwalsh,epwalsh10@gmail.com,2021-06-03 09:58:53-07:00,1e365b12ef1d4f64b4f96f6ac26fd30d2585a84a,https://github.com/allenai/allennlp/commit/1e365b12ef1d4f64b4f96f6ac26fd30d2585a84a,Prepare for release v2.5.0,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2506,epwalsh,epwalsh10@gmail.com,2021-06-03 10:47:30-07:00,7a5106d541006a5b7f544284aeedb03ba2b480d5,https://github.com/allenai/allennlp/commit/7a5106d541006a5b7f544284aeedb03ba2b480d5,tick version for nightly release,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2507,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-06-04 16:52:48+00:00,154f75d7b0e75b29a360ccc589304bc482221856,https://github.com/allenai/allennlp/commit/154f75d7b0e75b29a360ccc589304bc482221856,"Bump black from 21.5b1 to 21.5b2 (#5236)

Bumps [black](https://github.com/psf/black) from 21.5b1 to 21.5b2.
- [Release notes](https://github.com/psf/black/releases)
- [Changelog](https://github.com/psf/black/blob/main/CHANGES.md)
- [Commits](https://github.com/psf/black/commits)

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2508,Bhadresh Savani,bhadreshpsavani@gmail.com,2021-06-07 23:20:44+05:18,57df0e37194cf3dc688c2175707dbf52a29f1210,https://github.com/allenai/allennlp/commit/57df0e37194cf3dc688c2175707dbf52a29f1210,"[Docs] Fixes broken link in Fairness_Metrics (#5245)

* fixed broken link",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2509,Pete,petew@allenai.org,2021-06-07 14:55:56-07:00,8db45e87098df6f92720718eaff9bc5f605c1faf,https://github.com/allenai/allennlp/commit/8db45e87098df6f92720718eaff9bc5f605c1faf,"Ensure all relevant allennlp submodules are imported with `import_plugins()` (#5246)

* ensure allennlp is a default plugin

* fix logging issue

* fixes

* actually fix",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2510,ArjunSubramonian,arjun.subramonian@gmail.com,2021-06-10 17:04:35-07:00,a6cfb1221520fca7a5cc55bef001c6a79a6a3e2f,https://github.com/allenai/allennlp/commit/a6cfb1221520fca7a5cc55bef001c6a79a6a3e2f,"added `on_backward` trainer callback (#5249)

* added BackwardCallback

* finished tests

* fixed linting issue

* revised design per Dirk's suggestion

* added OnBackwardException, changed loss to batch_ouputs, etc.

Co-authored-by: Arjun Subramonian <arjuns@Arjuns-MacBook-Pro.local>",6,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['torch.equal(weights[name], param.data)']",['(OnBackwardException)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2511,Pete,petew@allenai.org,2021-06-15 15:49:18-07:00,5da5b5ba35075d387aad9ca5242889957646a94d,https://github.com/allenai/allennlp/commit/5da5b5ba35075d387aad9ca5242889957646a94d,"Upload code coverage reports from different jobs, other CI improvements (#5257)

* add new job to upload coverage

* checkout code to get coverage config

* fix

* write coverage from GPU test

* print some debug info

* try debug

* fix test image

* fix

* fix

* debugging

* update

* fixes

* upload GPU checks coverage

* fix codecov action config

* move linting and style checks to separate jobs

* update CONTRIBUTING

* update coverage artifact names and paths

* remove bulldozer config

* save coverage from model tests

* upload coverage from model tests

* fix

* use Make command in models to run tests

* fix

* update 'multi_device' decorator

* rename, clean up

* fix

* Update allennlp/common/testing/__init__.py

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>

* address comments

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2512,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-06-16 06:47:12-07:00,b37686f663e675237a05c5c75c809d3555a38b26,https://github.com/allenai/allennlp/commit/b37686f663e675237a05c5c75c809d3555a38b26,"Update torch requirement from <1.9.0,>=1.6.0 to >=1.6.0,<1.10.0 (#5267)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2513,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-06-16 14:19:37+00:00,e5468d964eeec090762da7e6c55d1692fec65855,https://github.com/allenai/allennlp/commit/e5468d964eeec090762da7e6c55d1692fec65855,Bump black from 21.5b2 to 21.6b0 (#5255),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2514,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-06-17 08:50:33-07:00,a1d36e67ab757b3b8db5eaac42efadc7b237cfdb,https://github.com/allenai/allennlp/commit/a1d36e67ab757b3b8db5eaac42efadc7b237cfdb,"Update torchvision requirement from <0.10.0,>=0.8.1 to >=0.8.1,<0.11.0 (#5266)

* Update torchvision requirement from <0.10.0,>=0.8.1 to >=0.8.1,<0.11.0

Updates the requirements on [torchvision](https://github.com/pytorch/vision) to permit the latest version.
- [Release notes](https://github.com/pytorch/vision/releases)
- [Commits](https://github.com/pytorch/vision/compare/v0.8.1...v0.10.0)

---
updated-dependencies:
- dependency-name: torchvision
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

* set timeout limits, clear transformer cache in some tests

* update torch versions in tests

* try skipping the test in question

* fix

* fixes

* fix I think

* run more with spawn

* ugh

* Apply suggestions from code review

* fix

* revert comment change

* patch models version

* Update .github/workflows/ci.yml

* update Makefile

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Pete <petew@allenai.org>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",7,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2515,Dirk Groeneveld,dirkg@allenai.org,2021-06-17 10:32:00-07:00,af101d67cdbfae80d2d232c5ed5162ff8b8ef123,https://github.com/allenai/allennlp/commit/af101d67cdbfae80d2d232c5ed5162ff8b8ef123,"Removes confusing zero mask from VilBERT (#5264)

* Remove confusing zero mask

* Changelog

* More coattention mask cleanup",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2516,ArjunSubramonian,arjun.subramonian@gmail.com,2021-06-17 11:03:10-07:00,f1f51fc9997fdca24763463db411d30cc8e88f09,https://github.com/allenai/allennlp/commit/f1f51fc9997fdca24763463db411d30cc8e88f09,"Adversarial bias mitigation (#5269)

* started adversarial bias mitigator wrapper

* initial commit

* finished adversarial bias mitigation; need to write tests

* manually checked for bugs

* debugged through testing

* updated CHANGELOG

* Update CHANGELOG.md

* minor fixes to docstrings and addressed Dirk's feedback

Co-authored-by: Arjun Subramonian <arjuns@Arjuns-MacBook-Pro.local>
Co-authored-by: Arjun Subramonian <arjuns@arjuns-mbp.home>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2517,Pete,petew@allenai.org,2021-06-21 09:14:59-07:00,6af9069de264df5b97354fc3b20347a3800bd99a,https://github.com/allenai/allennlp/commit/6af9069de264df5b97354fc3b20347a3800bd99a,"update Python environment setup in GitHub Actions (#5272)

* update Python environment setup

* fix

* fix

* fix again

* fix again

* fix

* more fixes

* skip install on cache hit

* fix

* fix

* change name of step

* set cache prefix at global env level

* use restore keys

* rename torch env vars

* use torch env vars in Docker build job

* clear cache weekly

* change cache prefix

* trigger CI

* make sure nltk packages are downloaded first",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2518,Dirk Groeneveld,dirkg@allenai.org,2021-06-21 10:28:40-07:00,c8b8ed3605cc9f8b1ecf1e1190bcc3d4fb94ef1c,https://github.com/allenai/allennlp/commit/c8b8ed3605cc9f8b1ecf1e1190bcc3d4fb94ef1c,"Transformer toolkit updates (#5270)

* Fix duplicate line

* Easy access to the output dimension of an activation layer

* Take an ignore an attention mask in TransformerEmbeddings

* Make it so a pooler can be derived from a huggingface module

* Pooler that can load from a transformer module

* Changelog

* Update transformer_embeddings.py

* Productivity through formatting

* Don't break positional arguments

* Some mode module names

* Remove _get_input_arguments()

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2519,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-06-21 18:25:33+00:00,8ad562e47b95b10dd18abc0490ae038242ab03d3,https://github.com/allenai/allennlp/commit/8ad562e47b95b10dd18abc0490ae038242ab03d3,"Update transformers requirement from <4.7,>=4.1 to >=4.1,<4.8 (#5273)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v4.1.0...v4.7.0)

---
updated-dependencies:
- dependency-name: transformers
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Pete <petew@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2520,Pete,petew@allenai.org,2021-06-21 16:20:05-07:00,5a7844b5986178298fa1c2b649866acf3e476e68,https://github.com/allenai/allennlp/commit/5a7844b5986178298fa1c2b649866acf3e476e68,add kwargs to Predictor.from_path() (#5275),2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2521,Jacob Morrison,jacob1morrison@gmail.com,2021-06-22 16:34:16-07:00,86504e6b57b26bb2bb362e33c0edc3e49c0760fe,https://github.com/allenai/allennlp/commit/86504e6b57b26bb2bb362e33c0edc3e49c0760fe,Making model test case consistently random (#5278),2,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2522,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-06-24 11:46:17-07:00,e8f816ddd31a4952840e28557d5aa8558da65bde,https://github.com/allenai/allennlp/commit/e8f816ddd31a4952840e28557d5aa8558da65bde,"Update google-cloud-storage requirement (#5277)

Updates the requirements on [google-cloud-storage](https://github.com/googleapis/python-storage) to permit the latest version.
- [Release notes](https://github.com/googleapis/python-storage/releases)
- [Changelog](https://github.com/googleapis/python-storage/blob/master/CHANGELOG.md)
- [Commits](https://github.com/googleapis/python-storage/compare/v1.38.0...v1.39.0)

---
updated-dependencies:
- dependency-name: google-cloud-storage
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2523,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-06-24 11:48:27-07:00,c936da9f067b2e03694fc56be0b468e4c96e3335,https://github.com/allenai/allennlp/commit/c936da9f067b2e03694fc56be0b468e4c96e3335,"Update transformers requirement from <4.8,>=4.1 to >=4.1,<4.9 (#5281)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v4.1.0...v4.8.0)

---
updated-dependencies:
- dependency-name: transformers
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2524,Pete,petew@allenai.org,2021-06-24 11:49:05-07:00,82053a98e43638f0171716c9d1f32fed97768327,https://github.com/allenai/allennlp/commit/82053a98e43638f0171716c9d1f32fed97768327,"Improve weight tying logic in transformer module (#5282)

* improve weight-tying logic

* fix",5,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['id(model.token_embeddings.weight) == id(model.lm_head.weight)'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2525,Dirk Groeneveld,dirkg@allenai.org,2021-06-24 14:31:43-07:00,a246e2772006602ccb58cd54ea118487012b4092,https://github.com/allenai/allennlp/commit/a246e2772006602ccb58cd54ea118487012b4092,"TransformerTextField (#5280)

* Adds TransformerTextField

* Changelog

* Export TransformerTextField

* Rescue the padding id

* Tests

* Documentation

* Update allennlp/data/fields/transformer_text_field.py

Improve human readability

Co-authored-by: Pete <petew@allenai.org>

Co-authored-by: Pete <petew@allenai.org>",4,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['in field_as_tensor', 'in field_as_tensor', 'torch.all(field_as_tensor[] == torch.BoolTensor([True, True, True]))', 'torch.all(field_as_tensor[] == torch.IntTensor([1, 2, 3]))', 'isinstance(field, TransformerTextField) and field.padding_token_id == 9', 'in field_as_tensor', 'in field_as_tensor', 'torch.all(field_as_tensor[] == torch.BoolTensor([]))', 'torch.all(field_as_tensor[] == torch.IntTensor([]))', 'tensors[].shape == (3, 4)', 'tensors[][0, -1] == 0', 'tensors[][0, -1] == torch.Tensor([False])', 'torch.all(tensors[][-1] == 0)', 'torch.all(tensors[][-1] == torch.tensor([False]))']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2526,Luke Gessler,lukegessler@gmail.com,2021-06-24 23:02:04-04:00,42d96dfa3eee46b7ad6f043e6d313b0127e390fd,https://github.com/allenai/allennlp/commit/42d96dfa3eee46b7ad6f043e6d313b0127e390fd,"typo: missing ""if"" in `drop_last` doc (#5284)",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2527,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-06-25 08:49:16+05:18,ad54d48f12e1a02c60746d7e54a570745386dc1c,https://github.com/allenai/allennlp/commit/ad54d48f12e1a02c60746d7e54a570745386dc1c,"Bump mypy from 0.812 to 0.910 (#5283)

Bumps [mypy](https://github.com/python/mypy) from 0.812 to 0.910.
- [Release notes](https://github.com/python/mypy/releases)
- [Commits](https://github.com/python/mypy/compare/v0.812...v0.910)

---
updated-dependencies:
- dependency-name: mypy
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2528,epwalsh,epwalsh10@gmail.com,2021-06-25 08:41:43-07:00,c6865d795666f9d3532a50d802db7d9a0d4fa91e,https://github.com/allenai/allennlp/commit/c6865d795666f9d3532a50d802db7d9a0d4fa91e,use smaller snapshot for HFHub integration test,1,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['meta.resource == f'],[],[],[],[],[],[],[],[],[],[],[],[],['meta.resource == '],[],[],[],[],[],[],[],[],[],[],[],[]
2529,Pete,petew@allenai.org,2021-06-25 14:24:30-07:00,672485fbc130edb9fb5980d0e0156b2f63c129e5,https://github.com/allenai/allennlp/commit/672485fbc130edb9fb5980d0e0156b2f63c129e5,only run CHANGELOG check when source files are modified (#5287),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2530,Akshita Bhagia,akshita23bhagia@gmail.com,2021-06-29 09:14:18-07:00,3f307ee3a5142acdf12fa0ad9a60e79822ece644,https://github.com/allenai/allennlp/commit/3f307ee3a5142acdf12fa0ad9a60e79822ece644,Update README.md (#5288),1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2531,Pete,petew@allenai.org,2021-06-30 16:57:42-07:00,7428155a69a2096b508dfb941e9f0dd1034bf71a,https://github.com/allenai/allennlp/commit/7428155a69a2096b508dfb941e9f0dd1034bf71a,"ensure torch always up-to-date in CI (#5286)

* ensure torch always up-to-date in CI

* refactor

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2532,Dirk Groeneveld,dirkg@allenai.org,2021-07-01 10:50:03-07:00,5378533fe4a91f9e5e460057fdaae474a7a78f03,https://github.com/allenai/allennlp/commit/5378533fe4a91f9e5e460057fdaae474a7a78f03,"Fixes recovering when the model expects metrics to be ready (#5293)

* Fixes recovering when the model expects metrics to be ready

* Changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2533,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-07-06 17:18:46-07:00,3d92ac430f608e9ecc996250decbdb1fb9f21c17,https://github.com/allenai/allennlp/commit/3d92ac430f608e9ecc996250decbdb1fb9f21c17,"Update google-cloud-storage requirement (#5296)

Updates the requirements on [google-cloud-storage](https://github.com/googleapis/python-storage) to permit the latest version.
- [Release notes](https://github.com/googleapis/python-storage/releases)
- [Changelog](https://github.com/googleapis/python-storage/blob/master/CHANGELOG.md)
- [Commits](https://github.com/googleapis/python-storage/compare/v1.38.0...v1.40.0)

---
updated-dependencies:
- dependency-name: google-cloud-storage
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2534,Dirk Groeneveld,dirkg@allenai.org,2021-07-06 18:34:43-07:00,436c52d548ea137918daa003d43455816e0a3edd,https://github.com/allenai/allennlp/commit/436c52d548ea137918daa003d43455816e0a3edd,"Docs update for `PytorchTransformerWrapper` (#5295)

* Updates the docs for PytorchTransformerWrapper

* Changelog

* Forgot one more parameter",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2535,Dirk Groeneveld,dirkg@allenai.org,2021-07-08 13:59:02-07:00,aaa816f707b682806d3ba632f36d76227d9c074c,https://github.com/allenai/allennlp/commit/aaa816f707b682806d3ba632f36d76227d9c074c,"Faster label smoothing (#5294)

* Faster label smoothing

* Changelog

* Update CHANGELOG.md

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2536,Dirk Groeneveld,dirkg@allenai.org,2021-07-08 15:19:49-07:00,7d4a67263d7a210aca22d4f2b03e8568d3c34a48,https://github.com/allenai/allennlp/commit/7d4a67263d7a210aca22d4f2b03e8568d3c34a48,"Transformer Toolkit fixes (#5303)

* Fix the treatment of padding

* Adds a test that exposes the problem

* Makes the epsilon for layer norm configurable and handles positions for RoBERTa correctly

* Fixes the end-to-end toolkit test

* Changelog

* Fix test

Co-authored-by: Dirk Groeneveld <dirkg@dnn1-dgxa13061.ai2.corp>",5,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['(])'],['parametrize(])'],['mark.parametrize(])'],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2537,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-07-16 10:01:35-07:00,3c1ac0329006cafcae36442957b80d3fe0cabca8,https://github.com/allenai/allennlp/commit/3c1ac0329006cafcae36442957b80d3fe0cabca8,"Update wandb requirement from <0.11.0,>=0.10.0 to >=0.10.0,<0.12.0 (#5316)

Updates the requirements on [wandb](https://github.com/wandb/client) to permit the latest version.
- [Release notes](https://github.com/wandb/client/releases)
- [Changelog](https://github.com/wandb/client/blob/master/CHANGELOG.md)
- [Commits](https://github.com/wandb/client/compare/v0.10.0...v0.11.0)

---
updated-dependencies:
- dependency-name: wandb
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2538,Pawe Olszewski,84400296+alle-pawols@users.noreply.github.com,2021-07-19 21:31:49+02:00,56e1f49df918cff52707d64dcf894885250aaf89,https://github.com/allenai/allennlp/commit/56e1f49df918cff52707d64dcf894885250aaf89,"Fix training Conditional Random Fields on GPU (#5313) (#5315)

Co-authored-by: Pete <petew@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2539,John Giorgi,johnmgiorgi@gmail.com,2021-07-19 17:39:58-04:00,f8fad9fc440d4634c412d7bb1a3bea66a7ce58f5,https://github.com/allenai/allennlp/commit/f8fad9fc440d4634c412d7bb1a3bea66a7ce58f5,"Provide vocab as param to constraints (#5321)

* Provide vocab as param to constraints

* Update changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2540,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-07-19 22:14:52+00:00,96293407a7f7ac075a4d973ff1f43adf531392cb,https://github.com/allenai/allennlp/commit/96293407a7f7ac075a4d973ff1f43adf531392cb,"Update google-cloud-storage requirement (#5309)

Updates the requirements on [google-cloud-storage](https://github.com/googleapis/python-storage) to permit the latest version.
- [Release notes](https://github.com/googleapis/python-storage/releases)
- [Changelog](https://github.com/googleapis/python-storage/blob/master/CHANGELOG.md)
- [Commits](https://github.com/googleapis/python-storage/compare/v1.38.0...v1.41.0)

---
updated-dependencies:
- dependency-name: google-cloud-storage
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2541,Pete,petew@allenai.org,2021-07-19 15:37:33-07:00,ef5400d59bf9d8deb31dd346d41c210c79c00b78,https://github.com/allenai/allennlp/commit/ef5400d59bf9d8deb31dd346d41c210c79c00b78,"make W&B callback resumable (#5312)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2542,Dirk Groeneveld,dirkg@allenai.org,2021-07-19 15:46:17-07:00,b2e62a26c355e8584f5527dcc8a2f52abc86f9aa,https://github.com/allenai/allennlp/commit/b2e62a26c355e8584f5527dcc8a2f52abc86f9aa,Prepare for release v2.6.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2543,Pete,petew@allenai.org,2021-07-19 16:39:12-07:00,ca656fc6bac7be66e566e8f1ba3131f3aa3d7729,https://github.com/allenai/allennlp/commit/ca656fc6bac7be66e566e8f1ba3131f3aa3d7729,"FairScale integration (#5242)

* start

* fix up

* start

* fix up

* DdpWrapper

* generalize GradScaler

* OSS

* fp16 params

* idk

* revert API

* refactor

* CHANGELOG

* fixes

* refactor

* wrap modules

* refactor

* fix when no checkpointer

* fix loading

* fix cicular import issue

* upgrade fairscale

* fix race condition when extracting files with cached_path

* better logging

* improve logging

* fix

* fix

* more logging

* keep state_dict tensors on CPU

* remove annoying logging

* set gradients to none

* move params to CPU in mixed precision

* fixes

* find_unused_parameters default to False

* add TODO

* add more tests, make grad scaler configurable

* patch models branch temporarily

* wow, good start

* fix Dockerfile

* beam search as a parameter

* ignore import error of optional dependencies

* fix

* add debugging env variables

* more debugging

* update Dockerfile

* increase shared memory for test container

* fix

* log optional import failures

* allow disabling checkpointer

* fix deadlock when checkpointer disabled

* fix unbound variable

* start using nn.Sequential to prepare for activation checkpointing

* Revert ""start using nn.Sequential to prepare for activation checkpointing""

This reverts commit e3cab770383f9b3b46ca9acabb0c7a60d759a644.

* add chkpt wrapper class with default torch implementation

* get FairScale activation/grad checkpointing working

* pin fairscale to commit

* ignore line-too-long in setup

* add xfail test for TorchCheckpointWrapper

* fix bugs

* update fairscale commit

* use mixin class instead of flags

* clean up APIs for wrapper classes

* clean up test

* add Adafactor optimizer

* implement state checkpointing

* fix

* fix test

* update FairScale commit pin

* add Module class

* doc fixes

* improve repr method of IncompatibleKeys

* clean up FSDP tests

* changelog clean up

* make fairscale a required dependency

* rename 'get_grad_scaler' -> 'init_grad_scaler'

* make hooks private methods

* make _post_load_state_dict pure

* fix comment

* use hardlink

* rename DdpWrapper -> DdpAccelerator

* format fix

* update FairScale to latest release

* fix GradientDescientTrainer.get_best_weights_path

* fix typo

* clarify docstring

* update CHANGELOG

* revert CI patch

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",38,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,0,0,0,1,0,0,2,3,3,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['forward_calls == 1, f', 'forward_calls == 2, f', 'param.grad is not None', 'forward_calls == 1, f', 'forward_calls == 2, f', 'param.grad is not None', 'not isinstance(model.embedding, ShardedModuleMixin)', 'isinstance(model.encoder, ShardedModuleMixin)', 'isinstance(model.decoder.ff, ShardedModuleMixin)', 'not missing_keys', 'not unexpected_keys', 'value.device == torch.device()', 'value.device == torch.device(gpu_id)', 'value.dtype == torch.float, f', 'set(original_state.keys()) - set(consolidated_state.keys()) == {', 'checkpoint is not None', 'model_state[] == i', 'training_state[] == i', 'models == training == target']",[],[],[],[''],[],[],"['', '']","['xfail(', 'parametrize(', 'parametrize(']","['mark.xfail(', 'mark.parametrize(', 'mark.parametrize(']",[],[],"['import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
2544,Makoto Hiramatsu,himkt@klis.tsukuba.ac.jp,2021-07-21 00:45:43+09:00,5b1da908238794efb318da3327271cc945c6ba46,https://github.com/allenai/allennlp/commit/5b1da908238794efb318da3327271cc945c6ba46,"Update links in initializers documentation (#5317)

* Update links to initializers

* Update CHANGELOG

* Add E501 to docstring

* update CHANGELOG

Co-authored-by: epwalsh <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2545,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-07-22 13:35:06-07:00,32750550bda0ca985abb5b697de22c4d15623792,https://github.com/allenai/allennlp/commit/32750550bda0ca985abb5b697de22c4d15623792,"Update mkdocs-material requirement from <7.2.0,>=5.5.0 to >=5.5.0,<7.3.0 (#5327)

Updates the requirements on [mkdocs-material](https://github.com/squidfunk/mkdocs-material) to permit the latest version.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/docs/changelog.md)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/5.5.0...7.2.0)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:development
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2546,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-07-22 21:22:04+00:00,64043ac67a626bc231145135ea196951ffc76758,https://github.com/allenai/allennlp/commit/64043ac67a626bc231145135ea196951ffc76758,"Bump black from 21.6b0 to 21.7b0 (#5320)

Bumps [black](https://github.com/psf/black) from 21.6b0 to 21.7b0.
- [Release notes](https://github.com/psf/black/releases)
- [Changelog](https://github.com/psf/black/blob/main/CHANGES.md)
- [Commits](https://github.com/psf/black/commits)

---
updated-dependencies:
- dependency-name: black
  dependency-type: direct:development
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2547,Pete,petew@allenai.org,2021-07-22 17:07:48-07:00,42d85298467b3f6f0e4b7b70f5fd481ab33df7ce,https://github.com/allenai/allennlp/commit/42d85298467b3f6f0e4b7b70f5fd481ab33df7ce,"allow TransformerTextField to take input directly from HF tokenizer (#5329)

* allow TransformerTextField to take input directly from HF tokenizer

* accept list as well",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tensors[].shape == (3, 11)']",[],[],[],[],[],[],"['(, None])']","['parametrize(, None])']","['mark.parametrize(, None])']",[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2548,Yury Paykov,cry5tal@cry5tal.in,2021-07-23 23:06:19+05:00,67add9d9b297e6dbdca8aa544e94568f34f8d6b5,https://github.com/allenai/allennlp/commit/67add9d9b297e6dbdca8aa544e94568f34f8d6b5,"Fix `ConfigurationError` deserialization (#5319)

* Fix `ConfigurationError` deserialization

Closes #5318

* Ship-shape

* Changelog

Co-authored-by: Pete <petew@allenai.org>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['{} == vars(pickle.loads(pickle.dumps(e)))'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2549,Pete,petew@allenai.org,2021-07-23 13:14:29-07:00,76f2487b8d119c0363178c51700b9db68ff637b1,https://github.com/allenai/allennlp/commit/76f2487b8d119c0363178c51700b9db68ff637b1,"set tqdm lock when new workers are spawned (#5330)

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2550,Dirk Groeneveld,dirkg@allenai.org,2021-07-26 11:05:22-07:00,1f20513d15fc2b5ced2b75f2860917d77813a009,https://github.com/allenai/allennlp/commit/1f20513d15fc2b5ced2b75f2860917d77813a009,"TextFieldTensor in multitask models (#5331)

* update `make_inputs_for_task` to support TextFieldTensors

* Changelog

* Formatting

Co-authored-by: Amit Parekh <7276308+amitkparekh@users.noreply.github.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2551,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-07-26 13:28:03-07:00,1b5ef3a04fdc35fc6e775a08e6cf6b1c3215e4fd,https://github.com/allenai/allennlp/commit/1b5ef3a04fdc35fc6e775a08e6cf6b1c3215e4fd,"Update spacy requirement from <3.1,>=2.1.0 to >=2.1.0,<3.2 (#5305)

Updates the requirements on [spacy](https://github.com/explosion/spaCy) to permit the latest version.
- [Release notes](https://github.com/explosion/spaCy/releases)
- [Commits](https://github.com/explosion/spaCy/compare/v2.1.0...v3.1.0)

---
updated-dependencies:
- dependency-name: spacy
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Pete <petew@allenai.org>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2552,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-07-26 14:16:14-07:00,fd429b2bc0c5282cbd5219fcb978516656512a75,https://github.com/allenai/allennlp/commit/fd429b2bc0c5282cbd5219fcb978516656512a75,"Update transformers requirement from <4.9,>=4.1 to >=4.1,<4.10 (#5326)

Updates the requirements on [transformers](https://github.com/huggingface/transformers) to permit the latest version.
- [Release notes](https://github.com/huggingface/transformers/releases)
- [Commits](https://github.com/huggingface/transformers/compare/v4.1.0...v4.9.0)

---
updated-dependencies:
- dependency-name: transformers
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2553,Dirk Groeneveld,dirkg@allenai.org,2021-07-27 13:45:17-07:00,8714aa0bfdef3f16cf18fb4d28c57fa9c2dfd162,https://github.com/allenai/allennlp/commit/8714aa0bfdef3f16cf18fb4d28c57fa9c2dfd162,"This is a desperate attempt to make TensorCache a little more stable (#5334)

* This is a desperate attempt to make TensorCache a little more stable

* Changelog",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2554,Dirk Groeneveld,dirkg@allenai.org,2021-07-30 14:01:52-07:00,ec3e2943ca0fadb389015fa147c84fe0e841b369,https://github.com/allenai/allennlp/commit/ec3e2943ca0fadb389015fa147c84fe0e841b369,"Create CITATION.cff (#5336)

* Create CITATION.cff

* ... in order of appearance

* Damn you autocorrect

* Include DOI, try to match the paper properly

* Include reference to CITATION.cff in the release process",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2555,Pete,petew@allenai.org,2021-08-03 09:55:41-07:00,b72bbfc9680d4410e0ce7a48a233f834593d9e4a,https://github.com/allenai/allennlp/commit/b72bbfc9680d4410e0ce7a48a233f834593d9e4a,"fix constraint bug in beam search, clean up tests (#5328)

* fix constraint bug in beam search, clean up tests

* fix linting error

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2556,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-08-03 10:02:01-07:00,1df2e517b5c78e12fee3f05a042115c36b0fb23a,https://github.com/allenai/allennlp/commit/1df2e517b5c78e12fee3f05a042115c36b0fb23a,"Bump fairscale from 0.3.8 to 0.3.9 (#5337)

* Bump fairscale from 0.3.8 to 0.3.9

Bumps [fairscale]() from 0.3.8 to 0.3.9.

---
updated-dependencies:
- dependency-name: fairscale
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

* upgrade to 0.4.0

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: epwalsh <epwalsh10@gmail.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2557,Dirk Groeneveld,dirkg@allenai.org,2021-08-05 11:11:34-07:00,311f1104bf4762b7b5c1172eb874276343d562c9,https://github.com/allenai/allennlp/commit/311f1104bf4762b7b5c1172eb874276343d562c9,"Tango (#5162)

* Basic step infrastructure

* Formatting

* Adds a proper StepCache, plus a bunch of other stuff

* Formatting

* Actually run a workflow

This is untested.

* Typo

* More Step infra

* Fix the symlink

* Print some output

* ensure_results()

* Write to a temporary location before writing to the final one

* Steps for reading and tokenizing a dataset

* Formatting

* Remove old TODO

* Show more errors when something can't be instantiated with from_params

* Batches have a length

* Make mypy happy

* Updated dataset definition

* Use cached_transformers wherever possible

* Step for PIQA instances

* Some unimportant mypy stuff

* Compatibility with huggingface

* Create a mask if we have to

* Make LongTensors

* Easy access to the output dimension of an activation layer

* Take an ignore an attention mask in TransformerEmbeddings

* Make it so a pooler can be derived from a huggingface module

* Improved type annotations

* Formatting

* Big refactoring that makes training work

* Making mypy a little less grumpy

* Formatting and unused variables

* Remove symlinks to old results

* Leave TODOs in the code

* StepCache doesn't need to be a MutableMapping

* Fix duplicate line

* Pooler that can load from a transformer module

* GPU training

* Adds an evaluation step and TorchFormat

* Fix duplicate line

* Easy access to the output dimension of an activation layer

* Take an ignore an attention mask in TransformerEmbeddings

* Make it so a pooler can be derived from a huggingface module

* Pooler that can load from a transformer module

* Changelog

* Update transformer_embeddings.py

* Productivity through formatting

* Don't break positional arguments

* Some mode module names

* Remove _get_input_arguments()

* Fix previously broken merge

* Formatting

* Fix the treatment of padding

* Adds a test that exposes the problem

* Makes the epsilon for layer norm configurable and handles positions for RoBERTa correctly

* Fixes the end-to-end toolkit test

* Changelog

* Fix test

* Slightly better error message

* Removing broken config

* Moving the DSPT config where it belongs

* Moving tango things into a tango directory

* Moving the PIQA config to allennlp_models

* cleanup

* Lots of mypy changes

* Fix type of covariance metric

* Silence two warnings

* Moving example steps into their own files

* Removes a useless step

* Rename the huggingface tokenizer step

* Removed obsolete TODO

* Brings back the text_only step

* Fixes the text_only step

* Move and fix the test for steps

* Compatibility with Python 3.7

* Documentation

* More docs

* More docs

* Makes a step's format part of its unique name

* Changelog

* Even more docs

* Turn off zipfile serialization

* More documentation

* Make it clearer which steps are running and which ones are not

* Fix the torch format

* Better error message

* Adds a dataset reader adapter for Tango

* Formatting

* Fix warning

* Fix output of the dataset reader adapter

* Return type annotation for the dataset reader adapter

* Puts the documentation where it belongs

* Fix old name

* Adds an end-to-end tango test

* Formatting 

* More tests

* Test for dry run

* f

* Fix iterable dill results

* Test iterable dill format

* Refactored how dry_run() works

* Test for running Tango programmatically

* Removing one TODO

* Re-initializes random seeds for every step's run

* Rename temp_dir to work_dir.

* Experimental warnings

* Formatting

* Even more formatting

* Remove file that wasn't supposed to be checked in

* Moved changelog entry

* Pin datasets tighter

Co-authored-by: Pete <petew@allenai.org>

* JSON format

* Test for JSON format

* Factor out some stuff

* Refactor some more

* JSON format for the Evaluation step

* Renamed to DatasetDict

* Shorter name

* Use torch inference mode

* mypy

* Set bounds on datasets

* ShuffledSequence

* Convenience methods for DatasetDict

* Use det_hash, giving a way to override how unique hashes are computed

* to_params()

* Some more documentation for to_params()

* Better dethash for types

* Better hash for formats in steps

* to_params and named parameters for data loaders

* 

* Support tuples in input

* Stolen check for how to call __new__

* Fix some type checks

* Makes RefStep as the default step work

* Changes how from_params works with steps

* Fix tests

* Chasing that locktable error

* Hopefully fixes the MDB_BAD_RSLOT error

* Typo

* That wasn't how __new__ works. This is.

* Unique file ids

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Dirk Groeneveld <dirkg@dnn1-dgxa13061.ai2.corp>
Co-authored-by: Pete <petew@allenai.org>",36,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,5,0,0,0,0,0,6,6,6,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['not os.path.exists(output_path)', 'os.path.exists(output_path)', 'os.path.islink(output_path / symlink_name)', 'evaluation_result.metrics[] == 1.0', 'second_run_time * 2 < first_run_time', 'cache1 is cache2', 'not cache1.read_only', 'not cache2.read_only', 'torch.allclose(cache1[], torch.tensor([1, 2, 3]))', 'torch.allclose(cache1[])', 'in result.splits', 'in step.result().splits', 'len(step_graph) == 2', 'isinstance(step_graph[], HuggingfaceDataset)', 'isinstance(step_graph[], TextOnlyDataset)', 'step_graph[]', '[x + 1 for x in range(10)] == list(r2)', '[x + 1 for x in range(10)] == list(r2)', 'not in cache', 'dataset_step not in cache', 'training_step not in cache', 'evaluation_step not in cache', 'len(cache) == 0', 'tango_dry_run(evaluation_step, cache) == [', 'tango_dry_run(evaluation_step, cache) == [', 'not in cache', 'dataset_step in cache', 'training_step in cache', 'evaluation_step not in cache', 'len(cache) == 2', 'step1_result == step2_result', 'step1_result != step2_result']","['(TypeError)', '(TypeError)', '(ConfigurationError)', '(KeyError)', '(KeyError)']",[],[],[],[],[],"['(])', '(, [True, False])', '(, _OPEN_FUNCTIONS.keys())', '(, _OPEN_FUNCTIONS.keys())', '(, [MemoryStepCache, DirectoryStepCache])', '(, [True, False])']","['parametrize(])', 'parametrize(, [True, False])', 'parametrize(, _OPEN_FUNCTIONS.keys())', 'parametrize(, _OPEN_FUNCTIONS.keys())', 'parametrize(, [MemoryStepCache, DirectoryStepCache])', 'parametrize(, [True, False])']","['mark.parametrize(])', 'mark.parametrize(, [True, False])', 'mark.parametrize(, _OPEN_FUNCTIONS.keys())', 'mark.parametrize(, _OPEN_FUNCTIONS.keys())', 'mark.parametrize(, [MemoryStepCache, DirectoryStepCache])', 'mark.parametrize(, [True, False])']",[],[],"['import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
2558,epwalsh,epwalsh10@gmail.com,2021-08-09 11:13:23-07:00,2e11a15e4e26911b814148846412d8081aee76d2,https://github.com/allenai/allennlp/commit/2e11a15e4e26911b814148846412d8081aee76d2,tick version for nightly releases,1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2559,Pete,petew@allenai.org,2021-08-10 16:05:49-07:00,90bf33b899fd3f2a59c87b27f5b5d24062746ef4,https://github.com/allenai/allennlp/commit/90bf33b899fd3f2a59c87b27f5b5d24062746ef4,"small fixes for tango (#5350)

* small fixes for tango

* fix",4,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2560,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-08-16 11:27:55-07:00,524244b6c2f81ed4003b383b702491cc6fcae814,https://github.com/allenai/allennlp/commit/524244b6c2f81ed4003b383b702491cc6fcae814,"Update wandb requirement from <0.12.0,>=0.10.0 to >=0.10.0,<0.13.0 (#5356)

Updates the requirements on [wandb](https://github.com/wandb/client) to permit the latest version.
- [Release notes](https://github.com/wandb/client/releases)
- [Changelog](https://github.com/wandb/client/blob/master/CHANGELOG.md)
- [Commits](https://github.com/wandb/client/compare/v0.10.0...v0.12.0)

---
updated-dependencies:
- dependency-name: wandb
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2561,dependabot[bot],49699333+dependabot[bot]@users.noreply.github.com,2021-08-16 19:00:05+00:00,c1edaef88d7c393eaa57b1c2b6c3e2d5efd78c7a,https://github.com/allenai/allennlp/commit/c1edaef88d7c393eaa57b1c2b6c3e2d5efd78c7a,"Update google-cloud-storage requirement (#5357)

Updates the requirements on [google-cloud-storage](https://github.com/googleapis/python-storage) to permit the latest version.
- [Release notes](https://github.com/googleapis/python-storage/releases)
- [Changelog](https://github.com/googleapis/python-storage/blob/master/CHANGELOG.md)
- [Commits](https://github.com/googleapis/python-storage/compare/v1.38.0...v1.42.0)

---
updated-dependencies:
- dependency-name: google-cloud-storage
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",1,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2562,Dirk Groeneveld,dirkg@allenai.org,2021-08-17 16:51:51-07:00,d45a2dabee49efb750133558776e32b92135487f,https://github.com/allenai/allennlp/commit/d45a2dabee49efb750133558776e32b92135487f,"Make sure that all attention works the same (#5360)

* Adds a test to make sure that all attention works the same

* Autodetect scaling factor

* Refactors attention so that scaled dot product attention lives where it's supposed to

* Formatting

* Formatting

* Changelog",13,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,2,2,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['tuple(output.size()) == (1, 2)', 'tuple(output.size()) == (1, 3, 2)']",[],[],[],[],[],[],"['(, Attention.list_available())', '(, MatrixAttention.list_available())']","['parametrize(, Attention.list_available())', 'parametrize(, MatrixAttention.list_available())']","['mark.parametrize(, Attention.list_available())', 'mark.parametrize(, MatrixAttention.list_available())']",[],[],"['import pytest', 'import pytest']",[],[],[],[],[],[],[],[],[],[],[],[],[]
2563,Gyrgy Orosz,gyorgy@orosz.link,2021-08-18 21:07:10+02:00,bffdbfd1a6da648145ee62556a1c01ba022eb0e4,https://github.com/allenai/allennlp/commit/bffdbfd1a6da648145ee62556a1c01ba022eb0e4,"Bugfix: initializing all tensors and parameters of the `ConditionalRandomField` model on the proper device (#5335)

* Bugfix: initializing all tensors and parameters of the `ConditionalRandomField` in the proper device

* Using `torch.full()` instead of torch.Tensor().fill_()

* Updated CHANGELOG.md

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>
Co-authored-by: Pete <petew@allenai.org>
Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2564,Pete,petew@allenai.org,2021-08-19 10:48:15-07:00,1f5c6e5bb80a27bbf226af8f7945531d6e4e258e,https://github.com/allenai/allennlp/commit/1f5c6e5bb80a27bbf226af8f7945531d6e4e258e,"Use our own base images to build allennlp Docker images (#5366)

* use our own base images

* run docker builds on GitHub hosted runners

Co-authored-by: Dirk Groeneveld <dirkg@allenai.org>",5,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2565,Dirk Groeneveld,dirkg@allenai.org,2021-08-19 11:32:37-07:00,13de38d17dd5a1c67e5327328c01837c6e40f87d,https://github.com/allenai/allennlp/commit/13de38d17dd5a1c67e5327328c01837c6e40f87d,"Log batch metrics (#5362)

* Lists should be lists

* Formatting

* By default, don't log parameter stats

* Log batch metrics

* Changelog

* Don't try to be more general than Patton",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2566,Pete,petew@allenai.org,2021-08-19 19:11:47-07:00,8370cfa37ec256ec369e0806b9a7612cf1e241f8,https://github.com/allenai/allennlp/commit/8370cfa37ec256ec369e0806b9a7612cf1e241f8,"skip loading t5-base in CI (#5371)

* skip loading t5-base in CI

* increase timeout",2,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['()'],[],[],[],[],['skip()'],['mark.skip()'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2567,gabeorlanski,gabeorlanski@gmail.com,2021-08-22 23:10:28-04:00,01e8a35a64441dda6a625851c0de0db2a10cbfd3,https://github.com/allenai/allennlp/commit/01e8a35a64441dda6a625851c0de0db2a10cbfd3,"Improved Documentation For Learning Rate Schedulers (#5365)

* Noam Docs improvements

Added LR formula

Added example config

* Polynomial Decay Docs improvements

* Cosine LR scheduler docs

* Combined LR Docs

* Linear with warmup docs

* Split and Better Docs for Pytorch Wrapped LR Schedulers

* Black Reformatting

* Flake8 fixes

* Added changes to changelog

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",9,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2568,Dirk Groeneveld,dirkg@allenai.org,2021-08-23 12:24:47-07:00,5dc80a650090c700bd4fc158f46257170fe3e8cb,https://github.com/allenai/allennlp/commit/5dc80a650090c700bd4fc158f46257170fe3e8cb,"Adds a dataset that can be read and written lazily (#5344)

* Adds a dataset that can be read and written lazily

This does not work yet. I'm still working on supporting classes.

* This approach might work better.

* Make ShuffledSequence take indices

* Formatting

* Adds failing test

* Fix sparse sequence tests

* Fixes the Sqlite format

* Quality-of-life hack

* Makes an internal string less alarming

* Save the files to the right place

* Formatting

* Fix for SqliteDatasetFormat

* Performance improvement for SqliteSparseSequence

* Changelog

* Global imports",11,False,True,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['len(s) == 0', 'len(s) == 1', 's[1] == ', 's.count() == 2', 'list(ss) == []', 'len(s) == 2', 's[-1] == ', 'len(s) == 0']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2569,Amit Parekh,7276308+amitkparekh@users.noreply.github.com,2021-08-24 21:41:51+01:00,75af38e03638150d92d3cbdffbc1681bf44b2088,https://github.com/allenai/allennlp/commit/75af38e03638150d92d3cbdffbc1681bf44b2088,"Create Vocabulary from both pretrained transformers and instances (#5368)

* Add Vocabulary constructor from both pretrained transformers and instances

* undo autoformatting on changelog (sorry!)

* update changelog without autoformatting everything

* Remove allowing multiple pretrained transformers to a single namespace

See https://github.com/allenai/allennlp/pull/5368#discussion_r694161204 for more information",3,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,4,4,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['vocab.get_vocab_size(namespace) == expected_vocab_size', 'vocab.get_vocab_size(namespace1) == namespace1_vocab_size', 'vocab.get_vocab_size(namespace2) == namespace2_vocab_size', 'vocab.get_vocab_size(namespace1) == namespace1_vocab_size', 'vocab.get_vocab_size(namespace2) == namespace2_vocab_size']",[],[],[],[],[],[],"['(])', '(])', '(])', '(])']","['parametrize(])', 'parametrize(])', 'parametrize(])', 'parametrize(])']","['mark.parametrize(])', 'mark.parametrize(])', 'mark.parametrize(])', 'mark.parametrize(])']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2570,Dirk Groeneveld,dirkg@allenai.org,2021-08-24 19:20:11-07:00,27da04cf4252abb08c78a71eaacd76d0b766f66b,https://github.com/allenai/allennlp/commit/27da04cf4252abb08c78a71eaacd76d0b766f66b,"Dataset remix (#5372)

* Adds a dataset that can be read and written lazily

This does not work yet. I'm still working on supporting classes.

* This approach might work better.

* Make ShuffledSequence take indices

* Formatting

* Adds failing test

* Fix sparse sequence tests

* Fixes the Sqlite format

* Quality-of-life hack

* Makes an internal string less alarming

* Save the files to the right place

* Formatting

* Fix for SqliteDatasetFormat

* Performance improvement for SqliteSparseSequence

* Changelog

* Global imports

* More Sequence classes

* Say DatasetDict when we mean DatasetDict

* Test for the sequences

* Use the step name correctly in the error message

* Use and consume step_name correctly in Step.from_params()

* Uncacheable steps don't get cached even if they have a name

* Adds a step that can remix a dataset

* Improve log message

* Fix relative import

* Changelog

* Adds documentation

* Give the option of changing a det_hash simply()

* Tix fypo

* Adds ability to shuffle datasets

* Test for det_hash",10,False,True,False,False,False,True,True,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['det_hash(c1_1) == det_hash(c2_1)', 'det_hash(c3_1) != det_hash(c2_1)', 'det_hash(c1_2) == det_hash(c2_2)', 'det_hash(c3_2) != det_hash(c2_2)', ""det_hash(c1_2) == det_hash(c1_1)  # because the version isn't taken into account"", ""det_hash(c3_2) == det_hash(c3_1)  # because the version isn't taken into account"", 'det_hash(c1_1) == det_hash(c2_1)', 'det_hash(c3_1) != det_hash(c2_1)', 'det_hash(c1_2) == det_hash(c2_2)', 'det_hash(c3_2) != det_hash(c2_2)', 'det_hash(c1_2) != det_hash(c1_1)  # because the version is taken into account', 'det_hash(c3_2) != det_hash(c3_1)  # because the version is taken into account', 'expected == actual_fn()', 'len(l1) == len(l2)']",['(e.__class__)'],[],[],[],[],[],[],[],[],[],[],['import pytest'],[],[],[],[],[],[],[],[],[],[],[],[],[]
2571,Bruno,brataodream@gmail.com,2021-08-27 15:43:14-03:00,6355f0732057063c1d35708ecd3a0316db796bc3,https://github.com/allenai/allennlp/commit/6355f0732057063c1d35708ecd3a0316db796bc3,"Fix Checkpointer cleaner regex on Windows (#5361)

* Fix to work on Windows

* Update CHANGELOG.md

* Update CHANGELOG.md

Co-authored-by: Pete <petew@allenai.org>
Co-authored-by: Pete <epwalsh10@gmail.com>",2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2572,Akshita Bhagia,akshita23bhagia@gmail.com,2021-08-27 13:01:14-07:00,b41cb3eb6654221562d93970a8d0f1509ab38329,https://github.com/allenai/allennlp/commit/b41cb3eb6654221562d93970a8d0f1509ab38329,"Fix distributed loss (#5381)

* fix distributed loss

* remove extra args",3,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2573,Pete,petew@allenai.org,2021-08-27 20:49:17-07:00,28950215344900e5e04fa5c8a27e5753d4e8837e,https://github.com/allenai/allennlp/commit/28950215344900e5e04fa5c8a27e5753d4e8837e,improve signal handling and worker cleanup (#5378),6,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2574,Dirk Groeneveld,dirkg@allenai.org,2021-08-30 10:39:48-07:00,60213cd7b113dc1fb30bcb0da79cef71caac9ba3,https://github.com/allenai/allennlp/commit/60213cd7b113dc1fb30bcb0da79cef71caac9ba3,"Tiny tango tweaks (#5383)

* Fixes SqliteSparseSequence for empty extends

* Fixes type annotation

* Gives a length to the transformer text field

* Test for empty extends

* Changelog

* Formatting

* Fixes the sqlite format

* Get output dims

* Fixes test",10,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],['len(s) == 0'],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2575,Can Udomcharoenchaikit,udomc.can@gmail.com,2021-09-02 02:34:31+07:00,48af9d3477733ec1b63f3351b8b80eab51e370fe,https://github.com/allenai/allennlp/commit/48af9d3477733ec1b63f3351b8b80eab51e370fe,"Multiple datasets and output files support for the evaluate command (#5340)

* multiple files evaluation

* Add multiple datasets support for the evaluate command

* Add description for --predictions-output-file for the evaluate command

* Add a test case (mutiple inputs/outputs) for the evaluate command

* update change log

* Update allennlp/commands/evaluate.py

assert error message

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>

* Update allennlp/commands/evaluate.py

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>

* Update evaluate.py

* for merging

* Fix  https://github.com/allenai/allennlp/pull/5340#discussion_r683661439

* Fix https://github.com/allenai/allennlp/pull/5340#discussion_r683661439

Co-authored-by: Akshita Bhagia <akshita23bhagia@gmail.com>",3,False,True,False,False,False,True,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],"['computed_metrics == saved_metrics', 'in prediction']",[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
2576,epwalsh,epwalsh10@gmail.com,2021-09-01 14:16:59-07:00,c7bdf6e2368c2450fff38c953eadb4e76e91305a,https://github.com/allenai/allennlp/commit/c7bdf6e2368c2450fff38c953eadb4e76e91305a,Prepare for release v2.7.0,2,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False,[],0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]
